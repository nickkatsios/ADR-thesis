{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Add the parent directory of 'scrapping' to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join(current_dir, '..', 'scrapping')))\n",
    "from text_cleaner import read_and_clean_adrs\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from markdown2 import markdown\n",
    "import openai\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance, OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "import datamapplot\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Path to the ADR directory\n",
    "adr_directory = \"../../data/ADRs-Updated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_date(date_str):\n",
    "    return datetime.strptime(date_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "metadata_path = \"../../data/ADR-Study-Dataset-Metadata/repositories\"\n",
    "total_adr_files = 0\n",
    "earliest_date = None\n",
    "for filename in os.listdir(metadata_path):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(metadata_path, filename)\n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            # Add the value of numAdrFiles to the total\n",
    "            total_adr_files += data.get('numAdrFiles', 0)\n",
    "            for adr_file in data.get('adrFiles', []):\n",
    "                first_commit_date = parse_date(adr_file['firstCommit'])\n",
    "                if earliest_date is None or first_commit_date < earliest_date:\n",
    "                    earliest_date = first_commit_date\n",
    "            \n",
    "# Print the total number of ADR files\n",
    "print(f'Total number of ADR files in metadata: {total_adr_files}')\n",
    "print(f'Earliest commit date: {earliest_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total number of files in the ADR directory\n",
    "total_adr_files = 0\n",
    "for filename in os.listdir(adr_directory):\n",
    "    if filename.endswith('.md'):\n",
    "        total_adr_files += 1\n",
    "print(f'Total number of ADR files in directory: {total_adr_files}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most common terms in adr names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_word_count = {}\n",
    "for file_name in os.listdir(adr_directory):\n",
    "    words = file_name.split('-')\n",
    "    words = [word.replace('.md', '') for word in words]\n",
    "    # convert to lowercase\n",
    "    words = [word.lower() for word in words]\n",
    "    # remove the numbers\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "    # remove the word ADR\n",
    "    words = [word for word in words if word.lower() != 'adr']\n",
    "    # keep words longer than 2 characters\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "    # use limatizer\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    for word in words:\n",
    "        if word in file_name_word_count:\n",
    "            file_name_word_count[word] += 1\n",
    "        else:\n",
    "            file_name_word_count[word] = 1\n",
    "\n",
    "# Top 10 words in ADR file names\n",
    "print(\"Top 10 words in ADR file names:\")\n",
    "for word, count in Counter(file_name_word_count).most_common(50):\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average clean tokens (words) per ADR: 212.4236214605067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce a distibution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words inside adrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for file_name in os.listdir(adr_directory):\n",
    "    file_path = os.path.join(adr_directory, file_name)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        preprocessed_text, words = clean_text(text)\n",
    "        all_words.extend(words)\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "print(word_freq.most_common(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
