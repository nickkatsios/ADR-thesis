kind architecture record adr create datetime relative component hubert sablonnire adr try explain created datetime relative component compare solution ccdeployments component want display list deployment display humanized time ago component console codebase momentjs format kind see httpsmomentjscomdocsdisplayingfromnow problem moment weight mingzip including locale moment support tree shaking load lot code translation never function considered solution libs looked smaller humanized time ago librairies tried httpsdatefnsorgvdocsformatdistancetonow tree shakable around mingzip including locale output long especially french word like almost much handle week httpsgithubcomcatamphetaminerelativetimeformat around mingzip including locale highly configurable low level api accepts unit value javascripttimeago httpsgithubcomcatamphetaminejavascripttimeago around mingzip including locale configurable handle week httpsmomentgithubioluxon feature httpsgithubcomiamkundayjs feature web component github opensourced web component see httpsgithubcomgithubtimeelements around mingzip formatting web component auto update every minute add title human based intlrelativetimeformat fallback safari clear handle fallback output rounding weird almost drawback pushed try something simpler standard mentioned briefly previous section builtin standard browser see httpsdevelopermozillaorgenusdocswebjavascriptreferenceglobalobjectsrelativetimeformat native firefox chrome httpscaniusecomfeatmdnjavascriptbuiltinsintlrelativetimeformat supported safari handle unit value take care selecting right unit rounding given time diff solution create component auto update behaviour like github every second title attribute human like github intldatetimeformat handle past intlrelativetimeformat dumb fallback safari system thank mingzip byte component auto refresh formatting standard dumb fallback locale way small size short output standard based possible weird rounding week difference implementation here example different output different impls computed oct gmt english ccjust momentum second ago datefnsless second ago githubnow second ago second ago second ago second ago second ago second ago second ago momentum second agoa second agoa second agoa second agoa second agoa minute ago datefnsless second agoless second agoless second agohalf minute agohalf minute agoless minute ago githubnownow second ago second ago second ago minute ago minute ago minute ago minute ago minute ago minute ago minute ago minute ago momentum minute ago minute ago minute ago minute ago minute agoan hour ago datefns minute ago minute ago minute ago minute ago minute agoabout hour ago github minute ago minute ago minute ago minute ago minute ago hour ago hour ago hour ago hour ago hour ago hour agoyesterday day ago momentan hour ago hour ago hour ago hour agoa day ago day ago datefnsabout hour agoabout hour agoabout hour agoabout hour ago day ago day ago github hour ago hour ago hour ago hour agoyesterday day ago day ago ccyesterday day agolast week week ago week agolast month momentum day ago day ago day ago day agoa month agoa month ago datefns day ago day ago day ago day agoabout month agoabout month ago githubyesterday day ago day ago day agolast month month ago week ago cclast weeklast month month ago month ago month ago month ago moment day agoa month ago month ago month ago month ago month ago datefns day agoabout month ago month ago month ago month ago month ago github day agolast month month ago month ago month ago month ago month ago cclast month month ago month ago year ago year ago year ago momentum month ago month ago month ago year ago year ago year ago datefnsabout month ago month ago month agoover year agoover year agoalmost year ago githublast month month ago month ago year ago year ago year ago year ago cclast year year ago year ago year ago year ago year ago momentum year ago year ago year ago year ago year ago year ago datefnsabout year agoabout year agoabout year agoabout year agoabout year agoabout year ago githublast year year ago year ago year ago year ago year ago french linstant momentil quelques secondes datefnsil moins secondes githubmaintenant second ago ccil secondeil secondesil secondesil secondesil secondesil secondes momentil quelques secondesil quelques secondesil quelques secondesil quelques secondesil quelques secondesil une minute datefnsil moins secondesil moins secondesil moins secondesil secondesil secondesil moins dune minute githubmaintenantmaintenantil secondesil secondesil secondesil minute minute ago ccil minuteil minutesil minutesil minutesil minutesil minute momentil une minuteil minutesil minutesil minutesil minutesil une heure datefnsil minuteil minutesil minutesil minutesil minutesil environ heure githubil minuteil minutesil minutesil minutesil minutesil heure hour ago ccil heureil heuresil heuresil heureshieravanthier momentil une heureil heuresil heuresil heuresil jouril jours datefnsil environ heureil environ heuresil environ heuresil environ heuresil jouril jours githubil heureil heuresil heuresil heureshieravanthier day ago cchieril joursla semaine dernireil semainesil semainesle mois dernier momentil jouril joursil joursil joursil moisil mois datefnsil jouril joursil joursil joursil environ moisil environ mois githubhieril joursil joursil joursle mois dernieril mois week ago ccla semaine dernirele mois dernieril moisil moisil moisil mois momentil joursil moisil moisil moisil moisil mois datefnsil joursil environ moisil moisil moisil moisil mois githubil joursle mois dernieril moisil moisil moisil mois month ago ccle mois dernieril moisil moisil ansil ansil momentil moisil moisil moisil ansil ansil datefnsil environ moisil moisil moisil plus dun anil plus ansil presque githuble mois dernieril moisil moisil ansil ansil year ago cclanne dernireil ansil ansil ansil ansil momentil anil ansil ansil ansil ansil datefnsil environ anil environ ansil environ ansil environ ansil environ ansil environ githublanne dernireil ansil ansil ansil ansil
title available stock improvement area inventory tag inventory performance stock currently available stock calculation performed every update product true product updated via api also ordered via store api route order placed triggered stockupdaterlineitemwritten performs update available stock subtracting stock quantity open order many open order storage lead bottleneck many order executed time product solved problem updating available stock directly checkoutorderplaced event ordered quantity php public function orderplacedcheckoutorderplacedevent event void foreach eventgetordergetlineitems lineitem lineitemgettype lineitemproductlineitemtype continue arraykeyexistslineitemgetreferencedid idslineitemgetreferencedid idslineitemgetreferencedid lineitemgetquantity order placed event high load event high load simply reduce quantity instead executing high cost update function query new retryablequery thisconnection thisconnectionprepareupdate product set availablestock availablestock quantity foreach quantity queryexecuteid uuidfromhextobytesstring quantity quantity thisupdateavailableflagarraykeysids eventgetcontext prevent executing lineitemwritten logic addition checkoutorderplaced logic set state within cartorderroute query event listener skip process php public function lineitemwrittenentitywrittenevent event void dont want trigger update method inside order process eventgetcontexthasstatecheckoutorderroute return addition optimization perform stock update one three relevant field stock minpurchase iscloseout changed checked productindexer within update method php stock eventgetprimarykeyswithpropertychangeproductdefinitionentityname stock iscloseout minpurchase thisstockupdaterupdatestocks eventgetcontext
unity dependency injection extends dependency injection amended autofac dependency injection issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
postcodesio postcode lookup application finding service closest search point service coordinate latlon format currently application request either outcode postcode search point submitted postcode resolved latlon query postcodesio provides outcode postcode lookup result return latitude longitude service free supported monitored contains full set active postcode supplied ons consequence currently active postcode return response mean deactivateddeleted postcode return coordinate retrieved application able return result additional search term town name added application additional lookup service might required service might replace alongside postcodesio hosted service ever became unreliable unavailableshutdown code data instruction run freely available
lihaoyis autowire weve got single page app talk server scala scalajs mean lihaoyis autowire macro although essentially richardson maturity model huge benefit term speed change also moment one client spa afford tight coupling doesnt preclude moving toward something restful add route recognise autowire consequence compile time safety front back macro magic cause headache beware immutableseq
amplitude analytics build product understand user amplitude free plan everything beginning consequence
subject transform metadata value author jnmoyne derekcollison tbeets implemented tag server problem statement part multiple technical implementation nats server create mapping formula transform applied input subject yielding desired output subject transforms part core nats subject mapping account level jetstream stream definition jetstream sourcing jetstream republish crossaccount service stream mapping shadow subscription across leaf subject transform shall defined source filter defines input subject eligible via match transformed destination subject mapping format defines notional subject filter transformed output subject match input subject token match source wildcards survive transformation input mapping function whose output build output subject design destination taken together source form valid subject token transform resulting transform applied input subject match source subject filter determine output subject weighted clusterscoped mapping case core nats subject mapping account level actually one mapping destination per source mapping weight percentage total weight percentage indicate likeliness mapping furthermore weighted mapping clusterscoped meaning also create mapping destination total per cluster name apply take precedence server part cluster specified allows administrator define mapping change depending upon cluster message initially published example consider following mapping foo destinationfoowest weight cluster west destinationfoocentral weight cluster central destinationfooeast weight cluster east destinationfooelsewhere weight mean application publishing message subject foo result message published core nats subject foowest application connected server west cluster foocentral application connected server central cluster fooeast application connected server east cluster also define worth destination catchall server apply cluster supercluster server running clustered mode example message published cluster south would mapped fooelsewhere transform rule given input subject must match source filter usual subscriptioninterest way transform valid valid input subject sourcematching literaltoken position ignored usable mapping function sourcematching wildcardtoken position mapping function transform destination format sourcematching wildcard single token token passed destination mapping function wildcard cardinal position number wildcardx notation number first instance wildcardtoken source filter instance wildcardtoken source filter sourcematching wildcard multi token token mapped respective position destination format literal token destination format mapped output subject unchanged position value wildcardtokens transforms source transforms defined interaccount import stream service destination must make wildcardtokens present transforms source however starting version transforms place core nats account mapping subject transforms stream stream import stream republishing allowed drop number wildcardtokens mapping function mapping function placed transform destination format subject token format mappingfunction legacy notation equivalent wildcardx still supported backwards compatibility note mapping function name valid upper camelcase lower case wildcard wildcard valid transforms defined interaccounts import stream service allowed mapping function wildcardx legacy list mapping function currently following mapping function available wildcardx output value token wildcardtoken index equivalent legacy notation partitionxabc ouputs partition number assigned deterministic hashing value wildcardtokens splitxy split value wildcardtoken multiple token presence character splitfromleftxy split two value wildcardtoken character starting left splitfromrightxy split two value wildcardtoken character starting right slicefromleftxy slice multiple token value wildcardtoken every character starting left slicefromrightxy slice multiple token value wildcardtoken every character starting right example transforms input subject source filter destination format output subject onetwothree uno unoonetwothree fourfivesix eins einsfourfivesix onetwothree onetwothree fourfivesix einszweidreivier einszweidreivierfourfivesix onetwothree one uno unotwothree onetwothree onetwo unodosunodosthree oneoneunouno onetwothreefourfiveonethreefiveunounofourtwo onetwothreefourfiveonethreefiveunowildcardwildcardunofourtwo onetwothreefourfivetwothreeunounoonefourfive abcdefghijsplitabcdefghi splitfromleft splitfromright slicefromleft slicefromright note nats cli provides utility server mapping experimenting different transforms input subject
adr model overview table content reading understanding software emergency attribute complicated application grow exponentially become extremely hard understand also massive gap engineering understanding product business team reduce gap weve decided domaindriven design technique see adr weve divided domain architecture two scope model overview see overview architecture considering relevant entity local domain overview every file domain folder theyre considering domain detailed view exploring inner object considering external entity affect always changing consequence primary consequence outdated domain architecture keep simple update nothing last forever domain architecture change every day
usedotenvformanagingenvironmentvariables accessing env directly without wrapper limited introduce problem want tooling help guard missing environment variable nil accidentally provided start process preferable fail fast explicit message without nil passed stack cause strange behaviour code designed dependency instead adding nil guard throughout codebase required environment variable envfetchfoo default managed centrally previously figaro purpose deprecated httpsgithubcomlaserlemonfigaro supported gem ensure get support form fix security patch also want able stub environment variable test suite easy example environment variable feature flag mechanism want stub value test scenario without influenced real value loaded mutating actual env value allowenvto receivewithboxidandreturn possible may unexpected consequence part process test variable figaro handy abstraction layer could stub allowfigaroto receiveenvwithfooandreturnbar consider stub environment variable dotenv load environment variable consequence docker docker compose added project environment variable loaded dockercompose envfileenvdevelopment rather dockercomposeenv pattern file managing environment variable env dockercomposeenv undesirable due overhead keeping sync dotenv load environment variable doesnt offer interface figaro dotenv youd access writing envfoo rather dotenvfoo make supporting climate control support testing
layer author opqdonut macroz adr try document current state rem application architecture backend layer http apilicenses apiworkflows apiusersettings api layer license workflow usersettings service layer license workflow usersettings ega dbext layer license workflow usersettings ega remsdbcore postgres api layer api layer take http request transforms ideally one call service layer api layer also responsible coarsegrained access control api role api schema swagger documentation api layer life remsapi namespaces service layer service represents public api specific part rem easy call must handle dependency etc creating resource workflow etc fetching complete representation resource workflow etc business action like enabling resource workflow etc joining related item like organization resource process manager async action command service typically call multiple different layer namespaces implement functionality service layer life remsservice namespaces historical note service layer created expanded subsequent like avoid circular dependency namespaces contained discussion purpose service namespaces clear conclusion reached layer purpose layer handle serializing deserializing data database involve schema coersions see remsdbevents renaming key see remsdbform single namespace layer handle one concept layer also contain simple domain logic example remsdbattachments checking allowed attachment type namespaces layer depend actual sql query defined resourcessqlqueriessql one automatically get corresponding function remsdbcore namespace remsdb namespaces depend remsdbcore perform query problem circular dependency circular dependency service example remsapiblacklist call remsservicecommand remsserviceblacklist servicescommand already call servicesblacklist cant servicesblacklist call servicescommand data dependency remsservicedependencies namespaces dont obey rule remsdbapplications depends many namespaces service probably split remsapplicationrejecterbot remsapplicationapproverbot probably service since invoke function todo others code notable piece code dont fit apiservicesdb layering dont application model remsapplication pure code implement domain model safely called anywhere remscommon namespaces code shared backend see example remscommonform contains form template validation various utility configuration namespaces like remsapiutil remsconfig remscontext database migration remsmigrations supporting api implementation like remsauth remsmiddleware etc amendment schema author opqdonut macroz layering also apply schema want make possible separate schema api schema make apparent shared particular remsapischema remsapi namespaces common schema fragment many apis share also big important schema live remsapischema discoverability remsapi namespaces define apis also contain schema apis schema dont shared remsschemabase contains common schema everywhere remsschemabase remsapischema shouldnt depend api service component schema json remsschemabase remsdb namespace feature amendment external layer integration author macroz sometimes external service database namespaces like remsext like remsextega also referred service namespace like remsdb namespaces
adding line item approved many payment method require product cart detail provided lineitems within makepaymentrequest integration generate lineitems commercetools cart klarna affirm payment automatically besides klarna affirm many payment method either require benefit lineitems provided integration add lineitems affirm klarna user write additional logic include lineitems payment method pose inconvenience example issue lineitems field defined within makepaymentrequest extension skip lineitems generation leave provided lineitems extension application configuration flag named addcommercetoolslineitems set true integration add lineitems payment method require lineitems user set addcommercetoolslineitems true makepaymentrequest integration generate lineitems regardless setting application config backwards compatibility integration still add line item affirm klarna matter addcommercetoolslineitems configuration set extension add lineitems payment method lineitems beneficial thus save api call fetch cart payment method type requires lineitems klarna affirm afterpay afterpaytouch klarna ratepay facilypay clearpay grabpay paybright pix zip consequence spare user integration additional effort adding lineitems required payment method
replacing ramda lodash arrow function much natural way reduce visual noise javascript consequence consequence
custom uri lifecycle interface winery generate lifecycle interface interface take uri name considered httpopentoscaorginterfaceslifecycle httpwwwexamplecominterfaceslifecycle httpdocsoasisopenorgtoscatoscaprimervtoscaprimervhtml toscainterfacesnodelifecyclestandard httpdocsoasisopenorgtoscatoscasimpleprofileyamlvtoscasimpleprofileyamlvhtml outcome chosen httpwwwexamplecominterfaceslifecycle although standardized one consistent primer tosca license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
least delivery ready pay order proposed ready pay order handled special care wed like guarantee least delivery order order payment processing businesscritical scenario selling meal whole point case guarantee order store payment processor pick order execution time important avoid double payment concurrency issue order ready pay state arrives theory processed one time lead doubled tripled charge user account delivery ready pay order performed messagequeue software message acknowledgment additionally expect order come unique client device time processing order processing existence order checked version number staleness validation case event version discarded processing service consequence slightly decrease performance get data integrity usage eventstore projection order state help handle correct state change order
switch zsh place bash starting macos catalina zsh default shell zsh place bash consequence difference shell require change way configured may small learning curve whilst getting difference shell zsh widely thought better shell bash productivity gain
architecture record datomicbased configuration adr indicates store entire application config single rich data structure schema config database implies possible easily search query update configuration value also implies configuration value general enough store arbitrary data dont know kind thing user module author include system allows define query update arbitrary data schema looking database required data store characteristic must available permissive open source license anything else impose unwanted restriction arachne operate embedded jvm process want force user install anything else run multiple process get arachne work database must serializable must possible write entire configuration disk reconstitute exact state separate process module build schema progressively schema must inherently extensible possible module progressively add new entity type new attribute existing entity type usable clojure without painful impedance mismatch configuration ontology extension rationale discussed adr useful enumerate possible case configuration configuration schema together configuration read application bootstrap control behavior application configuration schema defines type value application read modify structure behavior boot time run time configuration application author communicates intent application fit together run higher conceptual level code configuration schema module author communicate application author setting entity structure available application configuration schema module author communicate potential module author extension point module extenders safely read write entitiesattributes declared module upon depend configuration schema validate particular configuration explain deviate actually supported configuration exposed via user interface various type end user analytics debugging explaining structure application thing way serialization configuration together particular codebase identified git sha form precise complete reproducible definition behavior application extent configuration schema express communicates category possibility space application formal ontology desirable characteristic degree practical useful learn reuse existing work around formal ontological system implementation instance four broad category data store match first three data store characteristic defined relational derby hsqldb etc keyvalue berkelydb hashtables etc rdfrdfsowl store jena datomicstyle datascript eliminate relational solution fairly quickly sql schema generally extensible flexible failing condition addition fare well sql query update particularly fluent clojure similarly eliminate keyvalue style data store general schema least type rich schema provides meaningful data contract ontology point arachne leaf solution based rdf stack datomicstyle data store viable would provide unique benefit arachne different drawback explaining core technical characteristic rdfowl datomic beyond scope document please see jena datomic documentation detail information rdf owl semantic web general wikipedia article rdf wikipedia article owl owl semantics standard document rdf clear choice jvmbased permissively licensed standardscompliant rdf api apache jena benefit arachne owl good fit insofar arachnes goal define ontology application point configuration schema first foremost serve unambiguous communication regarding type entity exist application possible relationship definition defining ontology exact case owl designed address information model good fit clojure tuples declarative logic open extensible design well researched smart people likely avoid common mistake would result building ontologylike system existing technology well known beyond clojure ecosystem existing tool could work arachne project configuration box openworld assumption good fit arachnes permodule schema modeling since module cannot know module might present application likely want introduce rdfsowl application anyway point abstract entity metaschema note firmly decided yet tradeoff arachne mitigation owl complex learning effectively skill right might asking lot require module author owl representation common concept verbose andor convoluted way would make schema difficult readwrite restriction class owl schema although open world assumption valid good writing ontology mean owl inferencing incapable performing many kind validation would want apply complete configuration want check correctness example openworld reasoning never validate owlmincardinality rule mitigation although owl inferencing cannot provide closedworld validation given rdf dataset tool exist mechanism validating particular closed set rdf triple include writing sparql query catch various type validation error deriving validation error jena rule engine existing rdf validator eyeball although unfortunately eyeball seem well maintained clojure would possible validate given owl class generating specification clojurespec could applied concrete instance class map form jena api aggressively object oriented odds clojure idiom mitigation write dataoriented wrapper note working proof concept already sparql stringbased query language opposed composable data api mitigation possible hook jena arq query engine object layer expose dataoriented api sparql semantics api similar datomic datalog owl inferencing known performance issue complex inference arachne configuration tiny knowledge base unlikely esoteric derivation unknown whether cause problem kind ontology mitigation could restrict owl even owl lite sublanguages tractable inferencing rule jena apis impossible write immutable version rdf model least without breaking jena api trivial write dataoriented wrapper intractable write persistent immutable one datomic note datomic satisfy first requirement closedsource proprietary software open source project datascript emulates datomics apis without storage element either one would work arachne since arachne subset feature support fact arachne datomicinspired route would probably want support datomic existing investment datascript desire open source way benefit arachne well known clojurists highly idiomatic clojure question would performant technically suitable arachnesized data datomics schema real validating schema data transacted datomic must always valid datomic schema open extensible tradeoff arachne mitigation expressivity datomics schema anemic compared rdfsowl example builtin notion type focused towards data storage integrity rather defining public ontology would useful arachne mitigation want something ontologically focused possible build ontology system top datomic metaattributes datalog rule example system already exist build ontology system top datomic existing one would still responsible getting right ensuring meet potential case arachne maintaining internal logical consistency mitigation could still work done owl world reimplement subset axiom derivation top datomic ontological system built top datomic would novel module author therefore would require careful extensive documentation regarding capability usage satisfy user datomic well requirement open source necessary abstract across datomic datascript mitigation work already done provided user stay within subset feature supported product steering group decided rdfowl approach highrisk wrap clojure implement time reward mostly intangible openness interoperability rather something help move arachne forward short term therefore datomic style schema arachnes configuration user may either datomic pro datomic free datascript runtime application provide multiplexer configuration implementation utilizes asserts result equal module author ensure stay within subset feature supported platform arachne leaf alpha declared ready experimental production release thirdparty module revisit question whether owl would appropriate whether encountered issue owl would made easier time allows reserve either refactor configuration layer jena primary store porting existing module provide owl viewrendering ontology stored datomic proposed consequence possible write schema precisely define configuration data module consume configuration system open extensible additional module adding additional attribute metaattributes system provide ontologically oriented view system data without additional work additional work required validate configuration respect requirement datomic support natively required attribute every arachne application must include either datomic free datomic pro datascript dependency keep eye open look situation formal ontology system might better choice
httpvyoukucomvshowidxmjkodqnzamghtml dnspod word excel ssh winmaclinux lastpass usd user passpackchosen usd user password usd user consequence passpack ref manage password team httpsmediumcomaltcademyhowtomanagepasswordsinateamedbcccf
adr amplitude model deciders redeboer spflueger problem statement perspective pwa fitter package responsibility modexpertsystem construct amplitudemodel serf blueprint function evaluated function following requirement able compute list realvalued intensity mathbbrm dataset fourmomenta mathbbrmtimes ntimes number event number final state particle contain parameter tweaked optimized regard certain estimator technical story coupling parameter amplitudemodel difficult done place dynamic intensity section counterintuitive cannot done parameter section overwriting existing dynamic old parameter cleaned parameter section parameter contain name changed result mismatch key parameter section name parameter entry point compwa math language blueprint function also discussed early mid dropped favor custom python code amplitf reasoning effort writing new math language plus generator converting mathematical expression function various backends requires much manpower driver solution requirement amplitudemodel convertible function evaluated various computation backends numpy tensorflow theano jax ideally model complete sense contains information construct complete model mean common function like breitwigner blattweisskopf form factor also contained inside amplitudemodel guarantee reproducibility adding new operatorsmodels trigger many code modification openclosed principle instance adding new dynamic formalism extendible add replace current part existing model example replace dynamic part decay change function plus dataset estimator function subtle important point function hide detail backend mathematical expression yet extendable estimator definition easy extraction component component certain subpart complete mathematical expression least needed calculation fit fraction plotting individual part intensity considered solution customized python class currently amplitudemodel contains five section instance specific class kinematics defines initial final state particle particle definition spin etc dynamic mapping defines dynamic type apply particle intensity actual amplitude model converted fitter package function described parameter inventory parameter intensity dynamic structure represented yaml see example fitter package convert intensity together dynamic function reference parameter intensity dynamic contain converted parameter function parameter initialized value listed parameter section amplitudemodel solution toctree maxdepth sympy operator evaluation pro con customized python class current state positive faster implementation prototyping possible compared python operator additional dependency negative openclosed new model conversion various backends dry function replacement extension feature becomes difficult handle model complete since complete mathematical description example breitwigner function referred directly implementation defined amplitude model docsympy sympy positive easy render amplitude model latex model description complete absolutely information model included reproducibility follows openclosed principle new model formalism added without change interfacing component tensorwaves lambdify convert expression backend exprsubs substitute couple parameter replace component model instance set custom dynamic negative lambdify becomes core dependency behavior cannot modified defined sympy keep track component expression tree symbol mapping docpythons operator library operator positive control different component expression tree control convert functionality function additional dependency negative essentially reinventing sympy outcome docsympy initially leave existing amplitude builder module helicitydecay canonicaldecay alongside sympy implementation possible compare result turn setup result result comparable performance replace old amplitude builder new sympy implementation
deal translation article translated english french spanish italian german original article necessarily english initial text given translation already translated article translation must keep link original article review process remains draft translated article must redactor translator new mongodb document created translation document inherit article model consequence link must present translation source article translator must set given translation easy perform query retrieve translation given language
adr choosing mvvm pattern july structure file way make codebase easy navigate intuitive searching certain component organization adhere practice net community mvvm modelviewview model approach widely wpf window presentation foundation community difficult search web insight building wpf application without running information mvvm architecture mvvm appears standard application component divided model view view model folder folder containing necessary item displaying interpreting data app consequence easier find solution coding problem online accepting widelyused design pattern however doesnt necessarily solve problem item organized lib image font etc retrospect mvvm pattern overall beneficial often confused strictly adhere mvvm pattern mvvm say view accompanying view model model however app containing many design element often felt unnecessary data model tied view would model modal would different view model
record root path handling part work release next major version three route special handling adr proposes behaviour one root html requested return exact html per otherwise redirect register resource versionregister requested version json regardless format specified version root html requested redirect see otherwise redirect register resource versionregister requested version json regardless format specified version root redirect register resource versionregister requested version json regardless format specified
utilize codox read clojurescript source supercedes dont build top codox initially thought reading metadata source file built grimoire implemented separately project like leingrim implementation leingrim work cljs cljc file copying previous adr decided build top codox generate documentation still believe codox want generate final artifact html apps relatively solid feature come reading source file extracting metadata codox writer allows easily retrieve raw data plain format easy understand codox retrieve metadata source file storage metadata stored grimoire consequence codox provide mean read source var implemented separately perhaps clojurereplsourcefn however issue
implement unix shell script superceded remove unix script issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
data location time aware data related geographic structure added odh standardized way geojson format encoding variety geographic data structure httpstoolsietforghtmlrfc geojsonevents extends rfc geojson instant interval time httpsgithubcomsgilliesgeojsonevents consequence advantage representation geolocation clear specific disadvantage geolocation data represented many different way transformation geojson publishing odh back format outgoing data introduces additional cost
site wide configuration proposed certain element talk frank site loaded regardless user entry point current user story involves adding warning message bar appears page updated support addition site wide setting new site setting content model created sitewide item created contain sitewide setting would allow following future setup content item type site setting sitewide homepage setting override sitewide value homepage drug setting override sitewide value drug page reference httpswwwcontentfulcomrknowledgebasedynamicmicrocopy httpswwwcontentfulcommunitycomtisitcommontohaveasettingscontentmodel consequence additional api call would made frontend framework fetch sitewide setting check override current page future page specific setting could handled adding new page url field content model
idempotence service approved computing idempotent operation one additional effect called input parameter vast majority critical flow web service running required provide guarantee client thus make sense extract functionality library support common usecases two common approach industry come implementing support idempotency distributed inmemory data store redis database master node avoid issue caused possible replication lag client typically additional requirement client enable idempotency add unique identifier request expected side effect sometimes apis make mandatory property request security consideration lower chance collision recommended uuidv unique request identifier service critical requirement processing service persisted result successful failed nonretriable error request nonblocking concurrent request identifier rejected transient error result persistence aim avoid heavy computation retry duplicate request original request completed success nonretriable error client freedom choice exactly persisted format quick failure case aggressive retry policy client side ensures server resource blocked wasted concurrent request identifier request processing procedure persistence result transactional require request execution logic idempotence update happen transaction requirement come cost client flexibility allowing client control transactional introduces edgecases failure persist idempotency whereas action completed side effect taken place provide code idempotence service based database approach specific database integration pluggable inmemory database approach pro con going depth comparision mostly due lack adoption redis current infrastructure said definitely consider providing support future require request execution logic idempotence update happen transaction requirement come cost client flexibility allowing client full control transaction introduces edgecases failure update imdepotency action side effect already took place would require client verify side effect taken place execution consider suboptimal common case approach prof limiting certain flow extend core service interface allow client choose different execution strategy better control transactional consequence guarantee strong data consistency fast lookup near nonblocking execution
generate help file supercedes write help file issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
initial uploadsimports support scene creation process consists multiple step raster foundry work already completed import scene landsat sentinel data lesson learned process applied raster foundry approach supporting user uploads adr summarizes highlevel desire regarding initial user scene creation give outline accomplishing high level scene creation process data three thing put imagery data location accessible raster foundry create new scene required metadata determine level ingest metadata rdd nearnative resolution pyramided rdd data come number source raster foundry remain agnostic much feasible api model image already accomplishes ultimate goal would replicate something similar carto allows user import imagery easily main issue importing data imagery differs something like import carto allows often raster data requires gathering initial metadata additionally size import vary significantly term number file size well one usecase raster foundry encounter handle uploads local filesystem application developed azavea allowed user upload data supplied signed url allowing user make put request url seem feasible case imagery often user may raster foundry definitely know amount data uploaded file extension necessary information generate signed url raster foundry initially limited capability determine metadata scene metadata required metadata omitted negatively impact searchability scene scene creation handle arbitrary amount metadata possibility metadata included external file raster foundry support twostep process user creating scene user required upload data folder bucket submit scene metadata via api includes level ingest import later edits workflow allow user forego adding imagery bucket designate provide uri raster foundry access uploading data prior importing data raster foundry user orthorectified data form upload point future provide orthorectification think wait uplaods initiated via initial post apiuploads return upload object local fileystem upload upload get apitokensidcredentials return json response includes follwing aws api credential write access bucket upload prefix uploads randomly generated upload uploaded file associated back user benefit approach following user whatever tool desire upload something including amazon provided sdks native support multipart streaming uploads raster foundry determine amount storage user uploaded raster foundry provide mean removing uploads though implemented immediately project endpoint return signed url seem feasible following reason user indeterminate amount file upload single ingest filename type known advance signed put url requires filename limit type upload tool client creating scene point background task airflow poll new uploads processed create scene initiate work required instance newly uploaded file thumbnail footprint generated ingested rdds yet task generating thumbnail footprint begin given scene consequence main consequence adr set work started support initial uploads user data rather uploads initiated raster foundry however issue revealed start thinking longterm design work done import process emphasizes following import start uploading image uploading image grouped together metadata manually uploaded user able upload arbitrary file contain metadata separately associated aws specific emphasized image metadata upload process actually agnostic stand instance raster foundry already index publicly available imagery landsat sentinel imagery available open imagery network without import image raster foundry bucket image hosted anywhere raster foundry access case could easily http url accessible location permission scoped raster foundry raster foundry user support cloud provider planned shortterm nothing stated far inhibits adding additional support time user dictate client able list uploads delete desire unclear affect scene metadata however one problem want avoid file imagery get deleted without removing imagery something think since shortterm goal dogfood apis committing hold bit additionally conduct research orthorectification solution support orthorectification prior additional step importing unclear orthorectification technique available automatically instance dem file user input always required case upload may directly precede scene creation since separate orthorectification required command line utility written upload list file directory create scene build python work already done importing imagery airflow task case become evident work accommodate shortterm job already written ingestion updated allow uploads
tracking external file revisited adr supersedes adr strategy adr difficult recall therefore difficult confide proposed approach document logical change main kind external file want track configuration file zshrc vimrc would better document logical change step tooling least advantage logical change easier comprehend raw configuration step pickable layering configuration step robust especially across different system dropping track snapshot however documenting logical change come overhead prepare finalize configuration commiting turn carry risk piling uncommitted configuration balance thing committing snapshot raw configuration toolingsnapshots external file currently kind external file want track disregarding adopting tradeoff none known retrospective tbd
cobra command line interface edward provides rich commandline interface intended command structure familiar developer cobra cli framework consequence cobra provides opinionated structure commandline application allowing functionality separated user interface make adding new command unit testing functional code easier future
running experiment first run early startup rejected deciders teshaq travis khudson jhugman jaredlockhart technical story httpsmozillahubatlassiannetbrowsesdk problem statement experimenter would like run experiment early user first run application however experiment data available second run would like experiment data available user first run information httpsdocsgooglecomdocumentdqwgxyhvjzdmhxhnqyzycsyajglmoydmedit driver availability experiment early first run impact experimentation data analysis flexibility creating experiment ability quickly disable experiment simplicity release mobile expectation nimbus sdk idempotent considered nothing keep everything way preventing experimenting user early first run bundle experiment data app release release initialexperimentsjson defines experiment applied early first run later first run client would retrieve actual experiment data remotesettings overwrite bundled data retrieve experiment data first run deal delay retrieve experiment data first run experiment data however available short delay network disk outcome none feasible sticking nothing experiment planned expected run early startup first run revaluate bundle experiment data app release rejected mainly due difficulty disabling experiment pausing enrollment create negative user experience prevents disabling problematic experiment additionally tie experiment creation application release cycle retrieve experiment data first run deal delay rejected due fact change nimbus sdk longer idempotentand possibility introducing undesirable pro con nothing good keep flexibility experiment creation good disabling experiment still done remotely experiment good keep nimbus sdk idempotent bad doesnt address main problem exposing experiment user first run bundle experiment data app release good allows run experiment early user first run good prevents wait experiment especially user slow network connection bad tie experiment creation release cycle bad prevents disabling problematic firstrun experiment without dot release bad prevents pausing enrollment firstrun experiment without dot release bad requires investment console team modify existing flow retrieve experiment data first run deal delay good enables retrieve experiment user first run good keep flexibility experiment creation good disabling experiment still done remotely experiment bad experiment may ready early user experience bad force customer application deal either delay changing configuration shortly startup loading spinner preonboarding screen experimental control delaying initialization onboarding screen experiment loaded bad change programming model nimbus idempotent configuration store configuration changing nondeterministically bad experimentation platform could force app add unchangeable user interface entire population may effect key metric link rfc bundling fenix document presented product manager retrieve experiment data first run deal delay httpsdocsgooglecomdocumentdxhctzcrpopioiurueloaiezjqslanzohjyedit demo presenting retrieve experiment data first run deal delay httpsdrivegooglecomfiledhwnlwrabmsnsbtjwlkzdpwabiuviewuspsharing
aspnet web application framework issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
replace flask django supercedes flask flask turned poorly designed piece software relay much magic like manipulation global object like seems like also decide relational database switch django well written server also battery included like good orm layer feature like middlewares simplify thing consequence extra work rewriting functioning code better development practice testing
james cli based webadmin api lazy consensus partially implemented james server offer commandline interface order interact server however relies jmx protocol known insecure jmx server embedded apache james also command line client exposed java deserialization issue according nvdcve detail thus execute arbitrary command besides current cli interface also optimal user place action front entity contiguous syntax making harder user remember command example entity get action command interact design place entity first outgoing action interact entity afterward user easily imagine heshe entity creates intuitive interface easier remember webadmin apis http protocol secure jmx protocol interact james server webadmin commandline interface upcoming replacement outdated securityvulnerable jmx commandline interface decided write new cli client running top jvm communicating james via webadmin protocol http library http client feign library http client part james continue cli picocli library picocli onefile command line parsing framework written java allows create command line application almost code allows mixing positional parameter follow order parameter automatic type conversion command line argument type annotated field provide automatic help better subcommand support easily handle exception limit breaking change new cli cause work wrapper adapt old cli api locate cli code serverprotocolswebadmincli write man page picocli generates beautiful documentation cli html pdf unix man page decided adopt modern modular cli syntax jamescli entity action argument optional parameter running command line entity represents entity perform action action name action perform argument argument needed action example add domain domain list jamescli url http domain create domainnametobecreated commandline url http entity domain action create argument domainnametobecreated consequence aim providing modern secure cli also bringing compatibility ability old cli reference nvdcve detail picocli picocli homepage native image maven plugin jira discussing adr
translation translatable string create message msgctxt contains question text mean string translated question asked two issue approach element incorrect example answer guidance title answer questiontext translatable string question level dont cause problem english text doesnt vary question variant translated text httpstrellocomcjedbgtltetranslationsaddcontexttoallchildelementsofaquestionm remove current message answer questiontext new question questiontext message translatable property within question title allows text within question vary based question add new type propertytype comment every string extracted based value table type question definition list item help translator understand asked translate json path type note title questionnaire title legalbasis questionnaire legal basis message global answer error message message rather message message individual translation sectionstitle section title section summary final summary hub sectionsrepeattitle section title repeating section sectionssummaryitemstitle custom section summary item title sectionssummaryitemsaddlinktext custom section summary list add link sectionssummaryitemsemptylisttext custom section summary empty list text groupstitle group title heading summary blockstitle block title deprecated blockssummarytitle list collector summary heading deprecated section summary block removed section definition blockssummaryitemtitle list collector summary item defines form string summarise item list strictly speaking doesnt translated current usage addblockcanceltext list collector add block cancel link contenttitle content page heading main heading content page contentcontentstitle content page content title contentcontentsdescription content page content description contentcontentslist content page content list questiontitle question text questiondescription question description questioninstruction question instruction instruction field interviewer questiondefinitionstitle question definition link questiondefinitionscontentstitle question definition title questiondefinitionscontentsdescription question definition description questiondefinitionscontentslist question definition list questionguidancecontentstitle question guidance title questionguidancecontentsdescription question guidance description questionguidancecontentslist question guidance list answersvalidationmessages answer error message answerslabel answer label answersdescription answer description answersplayback relationship playback template playback relationship chosen person person answersoptionslabel answer answersoptionsdescription answer description answersoptionsdetailanswerlabel detail answer label answersoptionsdetailanswerdescription detail answer description answersoptionstitle relationship answer question text question text set answer selected thinking person person husband wife answersoptionsplayback relationship answer playback text playback relationship chosen person person husband wife answersguidanceshowguidance answer guidance show link answersguidancehideguidance answer guidance hide link answersguidancecontentstitle answer guidance title answersguidancecontentsdescription answer guidance description answersguidancecontentslist answer guidance list helpful reference another property value additonal comment added initially json path comment answersdescription answer label answer label answersoptionsdescription answer answer label answersoptionsdetailanswerlabel answer answer label answersoptionsdetailanswerdescription answer answer label answersoptionstitle answer answer label answersoptionsplayback answer answer label example detail answer enter main language type detail answer label answer including british sign language msgctxt question personnamepossessive main language msgid enter main language msgstr
jetstream based object store metadatavalue author scottf partially implemented tag jetstream client objectstore spec revisiondateauthorinfo scottfinitial design jaremaadd metadata jaremaadd compression document describes design jetstream backed object store adr still considered betaexperimental may subject change overview intend hit basic initial feature set future facing goal indicated current feature list represent object store store large quantity related byte chunk single object retrieve byte single object store metadata regarding object store multiple object single store ability specify chunk size ability delete object ability understand state object store data compression object store nats server possible future feature event notification adddeletelock locking archiving tiered storage searchingindexing tagging versioning revision overriding digest algorithm capturing contenttype mime type per chunk contentencoding gzip read individual chunk basic design object store bucket backed stream multiple object placed bucket object info stored json payload message object info message subject object info subject always rolled per subject object chunk stored payload message chunk message subject naming specification protocol naming convention fully defined adr object store object store name bucket name bucket formulate stream name specified restrictedterm dash underscore object object objectnuid nuid object name individual object name restricted base encoded form nameencoded digest currently sha supported digest please uppercase form rfc specifying digest shaidgpuymgtrgecoqfolrdaxukhfsvzqqpsg modified time modified time never stored putting object link store client populate modtime current utc time returning user getting object getting object link info client populate modtime message time server default setting default setting overridden per object basis setting value note chunk size client may tune appropriate objectstore stream config object store config basis stream configuration map field stream config like type objectstoreconfig struct bucket string stream name template description string stream description metadata mapstringstring stream metadata ttl timeduration stream maxage maxbytes int stream maxbytes storage storagetype stream storatetype replica int stream replica placement placement stream placement compression bool stream compression compression requested configuration set value stream config object store expose internals stream config therefore bool value stream configuration subject template component template stream name objbucket chunk stream subject obucketc meta stream subject obucketm chunk message subject obucketcobjectnuid meta message subject obucketmnameencoded example stream config json name objmystore description description metadata owner infra subject omystorec omystorem maxage maxbytes storage file numreplicas rolluphdrs true allowdirect true discard new placement cluster clstr tag tag tag compression structure objectlink embed link bucket object type objectlink struct bucket name object store bucket stringjsonbucket name link single object empty mean link whole store like directory name string jsonnameomitempty objectmetaoptions type objectmetaoptions struct link objectlink jsonlinkomitempty chunksize uint jsonmaxchunksizeomitempty objectmeta object meta high level information object type objectmeta struct name stringjsonname description stringjsondescriptionomitempty header headerjsonheadersomitempty metadata mapstringstringjsonmetadataomitempty optional opts objectmetaoptions jsonoptionsomitempty objectinfo object info meta plus instance information field objectmeta serialized line direct field objectinfo type objectinfo struct objectmeta bucket string jsonbucket nuid string jsonnuid total object size byte size uint jsonsize modtime timetime jsonmtime total number chunk chunk uint jsonchunks http digestalgorithmdigestvalue digest string jsondigestomitempty deleted bool jsondeletedomitempty objectinfo storage objectinfo stored json payload message meta message subject modtime mtime never written part stored objectinfo message retrieved server message metadata timestamp modtime example objectinfo json json name objectname description objectdesc metadata owner infra header key foo key bar baz link bucket linktobucket name linktoname maxchunksize bucket objectbucket nuid ckuylexzhbyjjawcfih size chunk digest shaabcdefghijklmnopqrstuvwxyz deleted true objectstorestatus object type objectstorestatus interface bucket name bucket bucket string description description supplied creating bucket description string bucketlevel metadata metadata mapstringstring ttl indicates long object kept bucket ttl timeduration storage indicates underlying jetstream storage technology store data storage storagetype replica indicates many storage replica kept data bucket replica int sealed indicates stream sealed cannot modified way sealed bool size combined size data bucket including metadata byte size uint backingstore provides detail underlying storage currently supported value jetstream backingstore string iscompressed indicates data compressed disk iscompressed bool choice iscompressed method name idiomatic language maintainer make similar idiomatic choice functional interface objectstoremanager object store manager creates load deletes object store api objectstore lookup bind existing object store instance objectstorebucket string objectstore createobjectstore create object store createobjectstorecfg objectstoreconfig objectstore deleteobjectstore delete underlying stream named object deleteobjectstorebucket string objectstore storing large object efficiently api required unless noted optionalconvenience put put place content reader new object error put objectmeta contains link addlink addbucketlink putobjectmeta inputstreamreader objectinfo optionalconvenience example putname string inputstreamreader objectinfo putbytesname string data byte objectinfo putstringname string data string objectinfo putfilename string file stringfile reference objectinfo putfilefile stringfile reference objectinfo note convenience method accepting file information consider reference could operating specific path information transferable one solution would actual file name object name discard path information get get retrieve named object object store deleted object treated object dont exist least one language specific variant getname string language specific handling outputstreamwriter getname string outputstreamwriter objectinfo getname string objectresult error optionalconvenience example getbytesname string byte getstringname string string getfilename string file string getinfo getinfo retrieve current information object return info deleted object except optional convenience method getinfoname string objectinfo optionalconvenience example getinfoname string includingdeleted bool objectinfo getinfoname string opts watchopt objectinfo updatemeta updatemeta update metadata object name description header updated object link bucket link allowed updated error update metadata deleted object error rename object name existing object updatemetaname string meta objectmeta delete delete delete named object acceptable noop object already deleted error delete object exist least one variant deletename string void deletename string objectinfo seal seal seal object store modification allowed least one variant seal void seal objectstorestatus watch watch change underlying store receive meta information update watchopts watchopt objectwatcher list list list object store listing object filter object deleted necessary requested provide convenience method optional argument include api user desire list list array objectinfo retrieves runtime backing store bucket objectstorestatus objectstore link link currently discussion whether necessary required api proposed please note version api possible obj objectinfo bucket objectstore could stale meaning state changed since read object deleted info read addlink addlink add link another object object store error link deleted object error link link okay name link name exist okay name link existing deleted object okay name link another link bucket link overwrite error name link existing deleted regular object addlinkname string obj objectinfo objectinfo addbucketlink addbucketlink add link another object store okay name link name exist okay name link existing deleted object okay name link another link bucket link overwrite error name link existing deleted regular object addbucketlinkname string bucket objectstore objectinfo
bulk import output cell one feature app cell produce output cell run typically contain view data transformed via app including new calculation made new data created however bulk import cell could result dozen new cell created could overwhelm user lead confusion easy upload process adr detail provide output cell apps run bulk import cell author briehl ialarmedalien considered include output cell apps finish dont include output cell apps finish group output cell single tabbed output outcome consequence bulk import cell produce new output cell app completion instead ensure report view available imported object carry consequence user may expect output cell one two uploaded object type based single uploader extra documentation help bulk import cell importer apps employ output cell importer output cell import genbank genome staging genome viewer import gfffasta genome staging genome viewer importer apps output cell importer output cell load paired end read file read viewer load single end read file read viewer workaround user click object name object section result panel click object data panel left side narrative either action create appropriate viewer narrative pro con include output cell apps finish keep behavior current app cell show expected output newly created upload object likely create ton output cell could clog narrative lot extra cell order output would semirandom whenever job finish retrying job would confuse output order dont include output cell apps finish prevents spamming narrative output cell consolidates output result tab result retried job handled efficiently user could miss expected output might guidance see data expected group output cell single tabbed output maintains expected flow output produced bulk import apps new unscoped undesigned work creates output view user may may want may difficult navigate given could hundred thousand item view
selenium scrape koshvani data problem statement required framework scrape store data koshvani platform machine readable format driver structure koshvani platform platfrom link reflect selection criterion automation job requirement data scraping periodical job access new data outcome selenium create robust browserbased automation
config set port config value application know deployment environment yet environment variable configure app rather file considered yaml file would allow structured config
preexisting requirement following nonexhaustive list requirement serve basis architectural requirement imposed problem domain provisioning tosca csar marked pragmatic requirement availability rest api deploy web archive java application server pragmatic requirement tomcat application server pragmatic requirement persistent storage capability csars well metadata surrounding deployment already existing support persistent storage csars implemented opentosca winery support existing planbuilder service capability support existing application bus code infrastructure support existing management bus code infrastructure support pluginbased extension capability implemented container application specifically refers supporting existing plugin system planbuilder plan engine well management application bus
openzeppelin origin sdk contract designed upgradable abstracting proxy logic storage separate contract approach lead maintaining separate solidity file per contract openzeppelin implementation based generalized proxy logic storage remove keeping separate custom implemented contract consequence improves security delegating part functionality community standard library allows openzeppelin cli tool deployment migration
remove unix script supercedes implement unix shell script issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
caching layer based memoized function backed sqlite proposed cljdoc store adhoc data doesnt directly fit data model example project download stats clojars project contributor star github etc data show alongside project documentation source truth kind data service across network clojars github maven central etc making multiple network call render documentation project deteriorates performance decide cache data avoid multiple network call clojurecorememoize provide layer cache enables memoize function make network call clojurecorememoize requires implementation clojurecorecachecacheprotocol memoize return value function provide implementation protocol cache two important property first persistent backed cljdoc datastore dont want loose cached data server restart second ttl functionality data github star clojars download count etc refreshed timely ttl set expiry time cached item consequence performance avoiding multiple network call render documentation reduce page load latency debugging memoized function may return data original data source cache cache hit debugging purpose sometimes could challenging trace data coming security cache implementation backed sqlite provide persistence run raw sql query prone sql injection attack safety measure value received client parameter initialize cache
adr flipflop feature toggle part migration mainstream publisher away bootstrap towards govuk design system wish able workinprogress change viewable deployed environment integrationstagingproduction without impacting majority user part spike investigated flipflop gem feature toggle rail application recently introduced whitehall flipflop provides dashboard viewing toggle path flipflop default page disabled production would mean deployed environment since planning putting anything sensitive behind toggle chosen remove restriction make dashboard always available flipflop provides several different strategy managing toggle summarise form database cooky term database active record sequel redis supported since mainstream publisher mongodb supported able store feature toggle database mainstream publisher also connect redis instance investigated leaf cooky mean toggle feature flipflop featuretoggling within mainstream publisher dashboard toggling feature available environment user able toggle feature consequence restricting access toggle dashboard user would able enabledisable toggle issue since would mean user could potentially view workinprogress change transitioning page design system without storing toggle database changing toggle either peruser dynamic user would able dynamically dashboard globally static changing default value configfeaturesrb file would require run deployment pipeline whenever changed
kotlin development language deciders menno morsink problem statement starting new app choose build either java kotlin course dont choose want make consistent driver new empty project kotlin fully supported android google considered java kotlin outcome chosen kotlin way modern java fully supported android google eliminates risk dropped time soon positive consequence code fun learn new language great interoperability java needed negative consequence learn new language
jetstream consumer multiple filter metadata value author jarema approved tag jetstream client server problem statement initially jetstream consumer could one filter subject number feature request specify multiple subject increased feature added could also reduce number consumer general server httpsgithubcomnatsionatsserverpull design client side consideration implement feature without breaking change new field added consumer config server client new field filtersubjects string jsonfiltersubjects subject cant overlap fit interest stream case overlapping subject error returned one filtersubject filtersubjects passed passing result error future improvement old api consumer creation one without filtersubject consumer create request new api yield error client support feature add new field marshal json array string ensure compatibility old server aware filtersubjects field client check returned info update create filter set properly example json durablename consumer filtersubjects event data client check single multiple filter passed server validate client add new error return client language idiomatic fashion server side make change possible reasonable peformant server buffer first message subject filtered deliver order delivering message subject buffer subject filled resulting close overhead initial buffer fill optimized affect api
process onboarding new tenant enrolling marain service proposed defined adr way intend implement tenancy marain instance maraintenancy service noted adr managing desired model hand would excessively error prone design tooling allow create manage new tenant allow marain service licenced build tooling design underlying process tenant onboarding enrollment offboarding work allow new client tenant onboarded marain service without tightly coupling service central thing know everything envisaging central controlplane api referred remainder document management api marain primarily build top tenancy service provide standard operation creating new tenant enrolling marain service also allow manage concern licensing billing metering scope adr covered additional adrs work item documentation required onboarding onboarding relatively simple part process create new tenant client determine intend licensing work part management api play enrollment service enrollment interesting aspect process order avoid tightly coupling marain service management api two thing mean discovering available service mean determining configuration thats needed enroll service receiving attaching configuration tenant enrolled defined way creating required subtenants service making call dependent service behalf client described adr envisaging service tenant created single parent service tenant tenant underpin discovery mechanism allows management api enumerate service tenant enrolled provided discovery mechanism define way gather necessary information needed enroll tenant service intending make work defining common schema service communicate configuration requires well service upon depends service attach manifest file containing information service tenant via well known property key allowing management api obtain manifest part discovery process since process enrollment unenrollment standard across tenant actual implementation form part management api driven data manifest ever encounter situation service perform nonstandard action part tenant enrollment extend process support way service notified new enrollment could simple callback url potentially broadcasttype system something like azure event grid since dont yet service would attempt define mechanism time enrolling tenant service two thing firstly attach relevant configuration service tenant thats enrolled secondly service thats enrolled dependency service create new subtenant service tenant service enrolled service accessing dependency behalf client new subtenant enrolled dependedupon service level dependency dealt way example consider scenario two client three service root tenant client tenant contoso litware service tenant workflow operation foobar dependency tree service look like workflow contoso operation litware foobar seen diagram contoso licenced workflow foobar litware licenced workflow operation workflow dependency operation foobar operation dependency foobar let assume three service require storage configuration look happens litware enrolled workflow firstly manifest attached workflow service tenant obtain list required configuration enroll tenant workflow workflow manifest state workflow requires cosmosdb storage configuration also dependent operation foobar manifest operation foobar service tenant determine configuration required operation dependent foobar process repeated process determine list required configuration workflow sum four thing workflow storage config operation storage config foobar storage config invoked workflow foobar storage config invoked operation assemble information likely via marain management begin process enrollment first enroll litware tenant workflow attaching workflow storage configuration litware tenant workflow dependency create subtenant workflow service tenant call dependency behalf litware attach new tenant litware tenant well known property name specific workflow root tenant client tenant contoso litware workflow storage configuration workflowlitware subtenant workflow service service tenant workflow workflowlitware operation foobar next enroll new workflowlitware tenant operation foobar service start operation repeat process carried litware workflow resulting similar outcome workflowlitware tenant configuration attached operation service dependency operation foobar result sub tenant created operation calling foobar behalf workflowlitware new tenant attached workflowlitware operationsspecific wellknown key root tenant client tenant contoso litware workflow storage configuration workflowlitware subtenant workflow service service tenant workflow workflowlitware operation storage configuration operationsworkflowlitware subtenant operation service operation operationsworkflowlitware foobar next new operationsworkflowlitware tenant enrolled foobar service foobar service dependency create tenant simply attach storage configuration foobar tenant enrolled return also completes workflowlitware tenant enrollment operation root tenant client tenant contoso litware workflow storage configuration workflowlitware subtenant workflow service service tenant workflow workflowlitware operation storage configuration operationsworkflowlitware subtenant operation service operation operationsworkflowlitware foobar storage configuration foobar next continue workflow enrollment litware tenant enrolling new workflowlitware tenant workflow dependency foobar operation service enrolling operationsworkflowlitware foobar result tenant created foobar config attached workflowlitware root tenant client tenant contoso litware workflow storage configuration workflowlitware subtenant workflow service service tenant workflow workflowlitware operation storage configuration operationsworkflowlitware subtenant operation service foobar storage configuration operation operationsworkflowlitware foobar storage configuration foobar completes litwares enrollment workflow service seen resulted multiple servicespecific litware tenant created litware never explicitly made aware existence tenant able directly parent service make call dependency behalf litware tenant however step litware also enrolled operation service present workflow able operation litwares behalf workflowlitware tenant however implementation detail workflow something able change without impacting litware long result change public workflow api order allow litware operation service directly process went workflow repeated storage configuration operation attached litware tenant subtenant operation created accessing foobar behalf litware root tenant client tenant contoso litware workflow storage configuration workflowlitware subtenant workflow service operation storage configuration operationslitware subtenant operation service service tenant workflow workflowlitware operation storage configuration operationsworkflowlitware subtenant operation service foobar storage configuration operation operationsworkflowlitware foobar storage configuration operationslitware foobar new operationslitware tenant enrolled foobar service result foobar storage configuration attached operationslitware service root tenant client tenant contoso litware workflow storage configuration workflowlitware subtenant workflow service operation storage configuration operationslitware subtenant operation service service tenant workflow workflowlitware operation storage configuration operationsworkflowlitware subtenant operation service foobar storage configuration operation operationsworkflowlitware foobar storage configuration operationslitware foobar storage configuration foobar completes enrollment litware workflow operation service seen three different path litware make indirect foobar service possible client separate storage fact default even client marain storage data three different usage scenario foobar stored different container noted client get configure new subtenants directly fact unaware essentially implementation detail approach multitenancy marain able retrieve subtenants tenancy service update directly said likely management api allow configuration changed without exposing fact subtenants exist default configuration whilst want allow user bring storage marain service may likely scenario effectively four main way marain fully hosted default storage service storage deployed alongside service fully hosted managed nonstandard storage deploy separate storage account per client hosted clientprovided storage bring storage model selfhosted deployed client azure subscription case would expect storage deployed service essentially fully hosted order make first last simpler make configuration default storage available enrollment process simply copied tenant enrolled rather requiring explicitly stated every enrollment manifest file schema allow marking configuration optional indicating default configuration provided sensible location store default configuration service tenant offboarding offboarding considered many question happens client data stop marain likely depend licensing agreement put place result considered later consequence whilst adr address tenant created configured part enrollment yet cover updated new version service deployed requires different configuration scenario tenant service would potentially updated new configuration may dealt versioning requiring tenant enrolled specific version service separate service tenant existing version service would require take sidebyside approach versioning marain would likely make much straightforward deploy update move tenant onto new version deferring work better answer question versioning
wait pool payment pool payment fail due stellar transaction submission timeout since endpont httpsexplorerurlapivreservationspoolspaymentpoolid deployed wait method added wait payment info done successfully consequence pool payment chance success increased unless retries fail
adr single activity viewbased screen navigation system superceded fragment introduced android api way model behavior portion user interface fragment shared multiple activity replaced fragment without affecting parent activity however fragment lifecycle although part activity lifecycle slightly different two sychronous created class bug many common android apps fragment usually created activityoncreate called state restoration fragment get created activityoncreate activity property may initialised exchanging data activity activityonactivityresult get called activity resumed creating fragment result received crash app fragment resumed activityonresume called documentation recommends activtyonresumefragments instead fragment lifecycle event synchronised activity lifecycle trying introduces extra layer complexity race condition difficult avoid asynchronous lifecycle causing pain suffering misery single activity hold screen entirely avoid fragment class switch screen flow library enables navigating different state flow make easy construct screen view class view inflated synchronously drastically reduces complexity eliminates race condition inflate layout xml layoutinflaterinflate guaranteed view ready making modification single activity also allows easy animation interactivity transition harder get right since view class screen also lose ability back stack flow also help providing view based backstack consequence single activity hold view flow navigation quite unusual flow external library written maintained thirdparty open source library get neglected take task maintaining fragment activity class common community help easy find obtain run roadblock flow find degree support android also provides way share data activity activitystartactivityforresult cannot architecture one activity box flow provide way share data screen built mechanism achieve maintained
modularization riptide started monolithic project worked good enough long feature minimal dependency growing feature set several issue came single artifact became bloated hard tell core functionality apart additional optional feature picking feature carte unnecesarily hard since usually involved carefully includeexclude optional dependency order counter aspect riptide fundamentally build idea module manifest two aspect module subdirectory hosting maven submodule containing separate package dedicated readme core several api extension point spis encourage modularization plugin interface extend processing pipeline request response route interface build compose reuse response handling function navigator interface build custom routing algorithm attribute interface provide public interaction point plugins usually criterion extract something separate module include limited isolate rarely dependency ideally single module group functionality logically single responsibility principle different maturity level therefore higher probabilty change openclosed principle consequence multiple module unique distinct purpose allows user pick module provide something really also keep list dependency small manageable another sideeffect module exposing spis even initually module open possibility user provide extension one aspect keep mind though interaction module slightly harder implement since always consider fact module
application layer naming clearing naming layer lpa service layer front service layer actor access service front service layer viewer access service backend service shared two front service provide data access domain logic service called actor front viewer front api consequence common naming convention layer
text file simple configuration certain piece configuration change often easy change colleague developer example include document type api recognises metadata like ther title description council service api recognises metadata like name google group choice came either storing configuration database storing text file text file configuration consequence benefit text file edited easily anyone even place github reading text file performant reading many time database data hardly change drawback changing configuration requires deploymentthis deemed acceptable due pipeline making deployment quick automatic
picture dcr document outline picture dcr work way lot methodology come frontend however dcr didnt immediately parity frontend imagepicture rendering built time improve overall goal picture rendering ensure serve correct resolution image user case involve looking thing like page image layout well client property like dpr background info background info section aim give enough information anyone hasnt worked lot picture source element source set feel free skip like dcr html picture tag render image offer advantage regular img tag source element help browser understand size quality image download saving user bandwidth money fastly image optimiser key enabler fastly image optimiser allows specify image width requesting image url example given image say httpsiguimcoukimgmediaxxxxxyyyjpg able specify important image transformation property width quality dpr others width allows specify width image pixel quality allows specify much compress image compressed preserving best quality possible dpr device pixel ratio allows scale size image number example widthdpr would return wide image medium query mediaquery within given picture tag multiple source child element medium html attribute syntax medium query tell browser source element look image source example source mediaminwidth would tell browser pick source viewport wider browser choose stick first matching source element find important ensure theyre dom right order another important medium query orientation portrait check portrait device smartphone size size size html attribute act translation layer size viewport size image source youd like pick good way think beyond certain width main medium inline image never beyond wide html attribute give way communicate browser example source sizesminwidth tell browser hey viewport wider always look image source wide default image width viewport width provide many size query want query query syntax last argument without query default none others match source set srcset source set work final piece puzzle browser already picked source element size figure size width image looking source set allows provide list url width image one browser look best fitting image source set formatted like source srcsethttpsurltoimage httpsurltolargerimage comma separated list source specifies first url given image source real pixel width image unit distinguish pixel inside image screenthere many pixel per high dpi screen case fastly image optimiser thing changing image url query parameter dpr width width dpr dpr originates concept pixel width medium query often different actual resolution device display example imagine phone super high resolution wide high screen following breakpoint size wed try render desktop type experience user however reality screen maybe inch across site would totally unusable pixel dpr rescue browser different width calculating breakpoints medium query etc real resolution screen pixel let say sake argument browser pixel width wohoo displaying mobile experience well dpr ratio pixel actual resolution give dpr important discussed later dpr problem problem come browser try compensate high dpr display choosing image source previous iteration frontend dcr provided source regular set set source high dpr display targeted medium query ensure picked unfortunately browser would try compensate high dpr well efficient way browser figured size source want size attribute source element multiplied dpr display get desired width look srcset desiredwidth width image browser look srcset size chosen size based query size attribute dpr ration pixel device resolution desiredwidth size dpr posed problem tell browser hey choose image browser dpr say actually look image source far higher resolution needed user good experience dpr solution problem first solved frontend replicated dcr rather source element instead source element per breakpoint one high dpr one regular display provide one size source set source element let look simplified example source per breakpoint html picture source mediaminwidth srcsethttpsxxxpngwidthpx source mediaminwidth srcsethttpsxxxpngwidthpx source mediaminwidth srcsethttpsxxxpngwidthpx source mediaminwidth srcsethttpsxxxpngwidthpx picture example logic usually would size attribute sizesminwidth extrapolated individual source element breakpoint larger offer choice source lower breakpoints looked source closest size replacement solves dpr problem medium attribute pixel offer image source element browser picked source element basically strong arm source dcr partially deprecated see dcr maintains parity frontends implementation image key difference dcr relies frontend generate image source frontend offer higher resolution source portait immersives dcr remove redundant source make dom effecient implementation dcr picked involves creating element breakpoint one regular one high dpr display example html picture source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmaxdpr mediaminwidth webkitmindevicepixelratio minwidth minresolution dpi source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmax mediaminwidth source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmaxdpr mediaminwidth webkitmindevicepixelratio minwidth minresolution dpi source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmax mediaminwidth source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmaxdpr mediaminwidth webkitmindevicepixelratio minwidth minresolution dpi source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmax mediaminwidth source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmaxdpr mediaminwidth webkitmindevicepixelratio minwidth minresolution dpi source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmax mediaminwidth source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmaxdpr mediaminwidth webkitmindevicepixelratio minwidth minresolution dpi source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmax mediaminwidth source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmaxdpr mediaminwidth webkitmindevicepixelratio minwidth minresolution dpi source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmax mediaminwidth source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmaxdpr mediaminwidth webkitmindevicepixelratio minwidth minresolution dpi source srcsethttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmax mediaminwidth img altthe palace theatre london showing harry potter cursed child srchttpsiguimcoukimgmediapicturejpgwidthqualityautoformatfitmaxdprsabecdbbefbd height width classdcrbpnrccss picture immersive main medium immersive main medium get special treatment image due unique quality desktop full width image always fill desktop breakpoints portrait full height portrait device filling must handled differently specific case handled optimally original solution however immersive main medium image often content value theyre sometimes thing screen article load getting right important desktop deprecated see regular image well loop breakpoint pick appropriate source based desired width breakpoint work well nonresponsive fixed width image know exactly size image want breakpoint sideeffect always image source exist within confines breakpoints cause problem higher screen resolution largest breakpoint fullwidth image know wed want image scren larger say even source available couldnt largest breakpoint solution rather looping breakpoint picking appropriate image source instead loop image source provided frontend width breakpoints see landscapeimmersivemainmediasource picturetsx taking advantage full range image source offered frontend improving image quality available larger display mobile portrait coming soon
graphql api layer phase work administrative office court exploring api centralized source truth court data mean access data well manipulate one primary challenge faced diverse way different court access data daytoday work different court different convention rule processing case difficult design single software solution managing case path analysis recommended api central tool offer flexible access data still allowing court autonomy data convention rest apis battletested wellunderstood rest apis define resource http endpoint associate http verb get post put define action however rest apis present difficulty difficult change client start leading simultaneously maintaining various version api usually feasible dynamically define data returned api leaving client either data thats endpoint return requiring make multiple request related data graphql different api paradigm designed specifically address issue efficiency flexibility phase work primary api interface graphql although domain logic application independent enough allow change future consequence graphql move many difficulty processing data frontend backend traditional rest api frontend code often accepts whatever form data api sends left manipulate merge filter data suit user graphql frontend define precision exactly data shape data take also schema central graphql frontend developer discover specifically type data available making data validation easier frontend developer accustomed rest graphql api require additional learning work serving graphql api however difficult backend rather defining specific endpoint send specific data graphql server parse json query take variety form mix match data potentially many source present efficiency problem single request user lead many request database issue manageable tool dataloader layer smart caching result within single query however explored yet since api currently simple enough
samediff file format proposal proposed alex black discussed raver samediff model serializable something save disk send network additionally able save load model file readable language mainly java currently flatbuffersbased format samediff graph serialization number problem discussed issue httpsgithubcomeclipsedeeplearningjissues transition pure flatbuffers zip flatbuffers model format flatbuffers graph structure parameter stored separately graph structure also within zip introduce ability support multiple version graph model file enable model file support storing multiple data type example version quantized int version multiple different checkpoint parameter iteration multiple version given model english chinese caseduncased etc default loading graph unless otherwise specified load recent model tag tag must valid filefolder identifier case sensitive structure zip file follows tagstxt list graph tag one per line utf format duplicate oldest first newest last tagnamegraphfb graph structure flatbuffers format tagnameparamstxt mapping variable name parameter file name tagnameparamsfb set ndarrays parameter flatbuffers format tagnametrainingconfigfb training configuration updater learning rate etc tagnameupdatertxt mapping variable name updater state file name tagnameupdaterfb set ndarrays updater state note paramstxt allow parameter sharing via reference parameter mynormalparam sharedparam othertagname mean parameter value parameter mynormalparam present tagnameparamsfb within zip file parameter value sharedparam available othertagnameparamsfb note also motivation paramstxt file instead raw parameter name file name parameter invalid ambiguous file name myparamname myparam etc term updater state stored similar format example adam updater state array shape parameter myparam otherparam mean myparamm tagnameupdaterfb myparamv tagnameupdaterfb format also allows updater state sharing graph structure graph structure encoded flatbuffers format schema part list variable name datatype placeholder constant parameter shape list operation name nametype input variable name output variable name argument note legacy custom ops encoded way legacy ops simply operation type operation number operation argument encoding done named argument essentially mapstringt structure one long double boolean datatype allows improved backward compatibility ambiguity ops modified graph file written improved interpretability compared simple array iargs bargs targs dargs one consequencedownside define mapping named argument iargsbargstargsdargs java essentially done manually though clearly dont want replicate work future language avoid significant amount work moving namearg mapping code generation following proposed mapstringt split flatbuffers schema pair field string iargnames long iargs string targnames double dargs string bargnames boolean bargs string dargnames datatype dargs clearly name value array pair would length namevalue correspondence array index essentially equivalent mapstringt representation benefit needing define mapping named args arraystyle args time soon also allowing add future mainly write graph betterproper backward compatibility change extensibility type suppose future want store data variable array example include list map example nlp application implement right number adding without breaking backward compatibility first enhance paramstxt file format perhaps something like following mapparam map second add similar text file type example paramsmapstxt format paramstxt content tagnameparamsmapsfb
perturb lambda simulating family simulation generated based lambda value provided user seemed simulation generated realistic enough thought slightly modifying lambda value every often would create realistic simulation code implemented simply base simulated family given lambda perturb lambda consequence simulated family slightly smaller variance size one want recreate simulated condition think perturb one want simulate realistic condition recover number rate category perturb work better although made sttdev normal distribution around multiplier much smaller got rid negative lambda still worked well dividing like instead
application technology stack superseded adr deciders daniel stefaniuk jonathan pearce steven faro identified development api enable uec service provider lead change rag also known capacity service api authenticate user via modern authentication approach establish whether user authorised able update state service api full api documentation fully automated testing deployment cloud platform adr concerned technology stack api written following three python web application framework considered evaluated flask django tornado due size api limited implementation time python flask deemed appropriate technology decided django framework far heavy weight may offer flexibility tornado seemed inappropriate dealing long running query process neither dealing hundred thousand request technology stack therefore python flask framework extension flaskrestplus flasksqlalchemy psycopgbinary pytest consequence light touch framework available extension bring exactly solution requires flask extension complete solution well known documented identified extension far flaskrestplus provides rest functionality api documentation swagger plug flasksqlalchemy psycopgbinary required enable connectivity postgres rds database also provides orm modelling pytest python automated unit test framework writing running unit test easy work documentation come flask good flask debug mode concise understandable
merging maraintenancy maraintenantmanagement approved original build maraintenancy provided two main thing provided api existing corvustenancy project allowing build multiple service around tenancy system without service needing aware underlying persistence mechanism tenant provided drop replacement direct corvustenancyabstractionsitenantprovider form clienttenantprovider maraintenancyclienttenantprovider however service impose particular tenancy model consumer simply exposed capability corvustenancy library subsequently functionality remaining marain service extended properly support multitenancy became necessary define tenancy model would shared across marain service documented maraininstance adrs multitenancy approach marain process onboarding new tenant enrolling marain service additional code required support available maraintenantmanagment repository built wrapper around existing maraintenancy api currently exposed via command line interface worked reasonably well cli code provided maraintenantmanagement multiple location work tenant several different way based underlying model defined adrs linked however become apparent marain two essentially inseperable marain service bar maraintenancy validate request ensure tenant making request enrolled service called requires code referenced maraintenantmanagement maraintenancy addition new requirement service able obtain list enrolled client difficult implement efficiently without blurring line two library brought focus fact maraintenancy something outlier marain world despite service manage marain tenant service marain ecosystem fully buy marain tenancy model mean expand model cover new scenario including creation additional tenant management tooling simplify onboarding offboarding potentially begin integrate billing metering likely end either continuing add extension maraintenantmanagement library adding separate api act wrapper around maraintenancy simplify approach modify maraintenancy api expose reflects tenancy model marain ecosystem mean existing functionality provided maraintenantmanagement extension become api endpoint enrollment clientservice tenant creation etc existing cli provided maraintenantmanagement maraintenancy merged separated project form basis cli tooling required standard task marain service well making tooling simpler functionality available one tool rather spread across multiple ensure maintain good practice ensuring task carried via relevant apis consequence update required marain service since service maraintenancy retrieve tenant invoking endpoint validate enrolment likely service require level change ease transition leave existing endpoint place marked deprecated required remove future release allow migrate marain service new endpoint controlled manner update required maraininstance change different cli tool require update maraininstance new tool service registration
title processing nested line item area checkout tag checkout cart lineitems want handle nested order line item currently line item available nested cart processor consider first level line item one hand could implement cart processor process level line item hand nested line item added via plugins would implement processing logic core cart processor continue work getflat enrich way required data item cart fenced item could also processed processor process method hand still work getflat take care line item first level way collision processing line item plugin reuses core line item easily call processor handle nested line item example namespace shopwarecorecheckoutcart shopwarecorecheckoutcarterrorincompletelineitemerror shopwarecorecheckoutcartlineitemcartdatacollection shopwarecorecheckoutcartlineitemlineitem shopwarecorecontentproductcartproductcartprocessor shopwarecoresystemsaleschannelsaleschannelcontext class plugincartprocessor implement cartprocessorinterface var creditcartprocessor private creditcartprocessor var productcartprocessor private productcartprocessor public function constructcreditcartprocessor creditcartprocessor productcartprocessor productcartprocessor thiscreditcartprocessor creditcartprocessor thisproductcartprocessor productcartprocessor public function process cartdatacollection data cart original cart tocalculate saleschannelcontext cartbehavior behavior void lineitems originalgetlineitemsfiltertypepluginlineitemtype structure plugin line item plugin line item product line item credit line item foreach lineitems lineitem thiscalculatelineitem original behavior data tocalculateaddlineitem private function calculatelineitem lineitem cart original saleschannelcontext cartbehavior behavior cartdatacollection data void lineitemhaschildren originalremovelineitemgetid originaladderrorsnew incompletelineitemerrorlineitemgetid child return temporiginalcart new carttemporiginal originalgettoken tempcalculatecart new carttempcalculate originalgettoken provide nested product credit item temporiginalcartsetlineitems lineitemgetchildren first start product calculation required data product processor already loaded stored cartdatacollection thisproductcartprocessorprocessdata temporiginalcart tempcalculatecart behavior calculate credit credit scoped already calculated product required data credit processor already loaded stored cartdatacollection thiscreditcartprocessorprocessdata temporiginalcart tempcalculatecart behavior line item calculated new child lineitemsetchildren tempcalculatecartgetlineitems consequence plugins implement processing logic alternatively extend shopwares cart processor specific implementation nested line item
external facing api design implementation office head start expanding data sharing across internal system support tta hub would like make documented apis available external system reliable consistent secure way considered achieve two path considered expose existing internal apis tta hub robust set apis already implemented support react frontend pro already implemented well documented con api highly coupled tta hub become difficult change rapidly authentication based session stored browser cooky authorization fully limited existing tta hub role create new api layer external partner creating new api layer would decouple data tta hub pro existing api continue optimized consideration new api rigidly backwardscompatible authentication scheme easily customized authorization scopebased integrated full oauth implementation con two api endpoint maintained data model change new api layer chosen better set trade offs distinguish api flavor external api namespaced apiv route path authentication initial api client also utilizes singlesignon solution api authentication done passing token via authentication http header tta hub validate token verify user json format promote consistency external facing api conform jsonapi schema much possible first endpoint include object attribute may eventually migrate relationship tradeoff made due exponential growth required api endpoint object represented relationship section consequence result stable external api simple authentication logic maintaining agility uidriven internal api risk come undertaking maintaining second representation tta hub data
add paypal supported payment deciders ben bangert barry chen tyler duzan bianca danforth yeon kim wennie leung problem statement subscription platform implemented stripe payment processor driver subscription logic stripe source truth whether account subscription associated would like add paypal payment subscription integrate appropriately existing system leasteffort manner ideally flexible enough support future expansion payment processor iap driver engineering resource future effort needed integrate iap code complexity relates existing subscription platform infrastructure considered stripedriven outofband invoice processing paypal subscription linked fxa recurly outcome stripedriven outofband invoice processing originally considered slower approach paypal subscription ended approximately engineering effort given additional user experience benefit stripedriven approach recommend implementation path pro con stripedriven outofband invoice processing stripe default subscription billing automatically payment source file stripe stripe also provides subscription collectionmethod sendinvoice model stripe track subscription generate invoice paid outofband allows stripe accurate record charge invoice subscription invoice considered paid fxa paypal feature called reference transaction allow fxa get customer authorization charge paypal account authorization allows later payment charged paypal account track reference stripe metadata customer mark subscription sendinvoice fxa implement additional logic listen invoice creation webhooks switch autoadvance subscription metadata indicating paid via paypal reference check invoice amount charge run paypal charge via paypal api invoice updated reflect whether paid successfully pro stripe continues serve accurate source truth regarding customer subscription logic determines active subscription entitlement stripe asis multiple product support work asis support representative see accurate payment history stripe customer paying via paypal support credit paypal customer credit card customer extend similar manner track correlating iap user handle switching payment method credit card paypal reference vice versa paypal authorization retained additional product purchasedcredited without requiring user return paypal flow cancelresubscribe subscription expires work asis con additional metadata stripe start pushing closer metadata limit object recreate stripe automatic advancement collection logic run paypal transaction ensure work correctly check prevent doublecharging retries transaction success verification still could end storing paypal reference separate table ensure track prior paypal billing could easily support multiple payment method back end would add complexity subscription management flow front end paypal subscription linkedtracked fxa approach would create productsplans paypal link back stripe equivalent updating stripe metadata productsplans fxa would also gain additional database table map paypal subscription account logic fxa look user subscription would updated check paypal linking table determine active subscription paypal would handle running charge recurring basis per paypal plan setup fxa would periodically check subscription via paypal api ensure theyre still actively paid paypal fairly lenient handling whether payment occurred schedule want pro paypal responsible charging customer managing subscription lifecycle extend similar manner track correlating iap user con logic determines active subscription entitlement additional logicabstractions query database table map active paypal subscription stripe subscription ability easily cancelresubscribe management page lost canceled paypal billing agreement cannot restored reduce complexity anyone paying via paypal would locked paypal later subscription user paying via stripe would presented paypal payment could frustrate user want switch theyd cancel wait till subscription expires subscribe paypal stripe subscription feature cant crediting user month coupon consolidating multiple plan single subscription aligned billing every additional subscription requires full paypal authorization flow paypal occasionally miss delivery webhooks requires build script periodically verify paypal subscription still active latest transaction processed successfully paypal subscription suspended resumed doesnt map equivalent stripe subscription would require custom handling code logic entitlement recurly recurly hosted solution similar stripe mange subscription unlike stripe process transaction leaving payment processor recurly multiple payment processor stripe paypal would handle running transaction similar manner stripedriven approach except theyve already built pro implement paypal logic recurly handle ongoing future maintenance lower stripepaypaletc change time maintained recurly con recurly list actual cost integration estimated around additional total revenue addition payment processing cost substantial work involved migrate user switch stripe integration logic work recurly apis would completely custom solution still iap
title adr web app language framework selection adr web app language framework selection superceded superceded adr since february retained historical purpose starting develop number userfacing application web interface styled look like govuk etc order keep thing consistent want pick single programming language framework write weve previously sinatra ran issue default configuration isnt secure leading vulnerability therefore want choose something come secure default make easier avoid sort issue requirement must well supported govuktemplate govukfrontendtoolkit well future govukfrontend project must understood broadly member team must understood broadly member frontend developer community within dicsussion head frontend community member team choice seems rail following reason wwwgovuk written rail verify frontend therefore well known within frontend developer community well supported frontend toolkits project available gem provide rail engine given wide rail future govukfrontend project likely support framework thats familiar team opinionated come secure default making much easier create secure web app ruby rail create new userfacing application web frontends superceded adr consequence consider porting existing application ruby rail
evaluation resilience framework general framework typically implement timeout circuit breaker fallback pattern bulkhead implemented due node single thread nature although longrunning procedure implemented pool file database general resilience framework play important role java world client likely due exhausted thread bounded resource rather limited hardware resource cpu memory mechanism scaling additional node based monitoring low level resource must place nevertheless even killer argument cascading failure disappears argument resilience framework still applicable fallback provides consistent way exposing fallback help mental model thinking happens downstream system available timeouts applying timeouts still good idea reduce memory cpu outbound port pressure result maintaining potentially infinite parallel request slow admittedly timeouts decrease likelihood cascading failure apply circuit breaker well deal shana downstream system system better sfsf graceful towards system remains good idea pet cattle contribution cloud ecosystem statistic good resilience framework collect plenty stats distribution response time median percentile percentile framework classical hystrix dashboard work allows visualizing connectivity health system httpsgithubcomnetflixhystrixwikioperations command pattern command pattern although prominent allows nice useful abstraction see discussion httpsgithubcomnetflixhystrixwikifaqgeneral also wrap aspect multitenancy via command key userbased isolation via command key caching provided top comparison framework categoryframework hystrixjs brake rsxjs opossum version star downloads per week named command yes yes yes timeout yes yes yes yes explicit error determination yes yes fallback yes yes error propagation yes error propagation yes hystrixsse stream yes rxjs otherwise runtime error due changed observable api yes yes circuit breaker yes yes implementation odd circuit breaker timeout everything set zero half open state breaker yes two configure available yes last update year ago still depends rxjs nov jan jan hystrixsse stream yes rxjs otherwise runtime error due changed observable api yes box yes offset circuit eval yes circuitbreakerrequestvolumethreshold yes waitthreshold yes yes maxfailures allowwarmup volumethreshold ppms risk low low medium never requested mit license medium never requested asl license typescript support yes tried yet yes ship dts file yes tried yet noteworthy complete documentation bitbucket seems support metric dashboard missing circuit breaker threshold success rate instead failure rate strong detailed stats event callback tbc love universe evaluate framework line code required solve problem question even good haskell monad sacred anymore httpsgithubcomrobeyprofuse httpsgithubcomjikeengineeringcircuitbreakerts httpswwwnpmjscompackagecircuitbreakermonad httpsgithubcomjulekgwasimplifiedhystrixjs based opossum summary time writing opossum seems framework satisfies evaluated dimension except providing dedicated error handler thus application code must aware implication onto surrounding resilience framework rethrowing error faulty http code hystrixjs seems soundly implemented however seems maintained since year bitbucket documentation throw type available additional community content brake provides nice hystrixcompliant statistic however poor circuit breaker implementation halfopen circuit recovery allow graceful circuit breaker opening result opossum recommended framework information event emitted opossum breaker consult opossum documentation page documentation opossum failure vdm team decided integrate framework internally dependency jscloudsdk circuit breaker integrated exported vdm method provided user service vdm module framework opossum offer circuitbreaker object encapsulates possible event may occur request communicating component build circuitbreaker object builder function provided framework circuitbreaker expects parameter asynchronous function performs http request optionally configuration object includes desired constraint request following architecture vdm module odata request performed execute method provided request builder class createrequestbuilder vdm servicesin instance passing service call method execute parameter circuitbreaker object builder method parsed function thus vanishing internal data class constraint stipulation keyword allows access class attribute set undefined therefore lose away internal information essential build odata request configuration cause raise several error runtime cannot read property method undefined method attribute accessed internal class attribute entire vdms module built around class represent odata vdm wrapping execution call externally method described opossum documentation feasible consider two different approach deal instance integrate opossum internally jscloudsdk dependency instance employ framework effectively wrapping axios http call directly circuit breaker rate resilience provided optional feature user wrap odata call execution method function asynchronous pattern function return promise entity fulfilledfail breaker fired example see implementation next section counterside case potential http call csrftoken destination retrieval monitored circuit breaker satisfy provided constraint framework recommendation integrating opossum establish resilience opossum framework first add circuitbreaker file header entity request executed javascript import circuitbreaker opossum circuitbreaker provides interface carry circuit breaker design pattern mechanism internally expects one parameter type function wrap asynchronous request optional object map circuit breaker configuration jssdk perform entity request targeted service businesspartner service respective request builder javascript const allbupa businesspartnerrequestbuildergetallexecutedestination order wrap http request circuit breaker wrap executedestination method return eventual completion entity object promisebusinesspartner instance function javascript function getallbupadestination return businesspartnerrequestbuildergetallexecutedestination const breaker circuitbreakergetallbupa circuitbreaker emits different event occur http call firing breaker fire event emitted breaker object javascript breakerfiredestinationthenresponse something returned entity discus team still decide whether resilience facility provided cloudsdk outofthebox following possible resilience functionality highly interwoven java world due thread missing decide keep separate advise customer implementation resilience via blog documentation positive side enables others provide framework choice wrap resilience functionality offer firstclass citizen framework result cloudsdk opinionated way commits aboverecommended framework positive approach wrapper could implement additional resilience functionality caching provide multitenantuserbased resilience outofthebox based information furthermore cdt negative side team buy providing multitenancy box requires provisioning additional access strategy see jwtaccessorstrategies java sdk others like chosen library dependency introduces maintenance opensource dependency might necessary contributing red hat nodeshift project misc run hystrix dashboard locally check behavior download httpsgithubcommlabouardyhystrixdashboarddockerblobmasterhystrixdashboardjar run java jar hystrixdashboardjar run httplocalhosthystrix
route capability route define direction data flow interpretation usecase flow different various reason general support readmultipletimes writemultipletimes scenario generous work often limited integration limitation like transferring data transferring data finding equivalent target missing requested way configure route behaviour core without adding work integrator limitation transferring implemented skipping existing step change behaviour represented simple boolean flag every step limitation result flow component get boolean flag consequence pro common known implemented behaviour handled globally applied route allows wide range operation portal developer provide combined later configuration
one time event livedata event pushed certain lifecycle event rotating device returning fragment another navigation path error special event like automatic navigation executed new event introduced viewmodels clear purpose occur consequence existing viewmodel class one time event edited second livedata variable exposed view also state none skipped view
adr dont decrypt payload google pay two possible tokenization method making payment request google pay paymentgateway direct feature paymentgateway tokenization merchant identifying govuk pay google pay set simply pas encrypted response google pay payment gateway operational overhead key management already handled google pay payment gateway feature direct tokenization merchant govuk pay google pay pci compliant already decrypt response get information send payment gateway operational overhead key management roll key year register google pay either tokenization method get number data one relevant last card digit billing address includes name email address card network direct tokenization decrypt get pan expiration month year thing choosing whether decrypt payload google pay informed following two deal breaker able retrieve cardholder name email last digit card dont want service manage sort keyscertificates unlike current implementation apple pay chosen decrypting payload following reason get information require last card digit billing address name email address card network unencrypted form service wont manage keyscertificates payment request made google pay specify payment gateway worldpay google pay return response encrypted payment gateway public key response decryptable payment gateway private encryption key already key management process google pay payment gateway initial assumption google pay encrypts merchant public key incorrect operational process needed part manage keyscerts
architecture record rail initially kosa chickenegg problem choosing database graph relational choosing web framework explored number looking something would stable longlasting capable supporting pariyatti library start rail started python first django flask however developer available initial work comfortable rail also felt rail ecosystem sufficiently stable point chosen rail consequence future developer comfortable ruby unfortunately library required update due neoj dependency carrierwaveneoj clearance problem neoj ruby intersection neoj problem nonetheless
create caracter creation completed way player character generated intentionally certain statistic decided player instead random outcome give player opportunity control character strength weakness add playability game create player module user interaction affect starting statistic character
implement special page implement two special page privacy policy page page cant map dont want user would forced read scanning spiral solution external page mean could create page like privacypolicyhtml user access outside map adhoc page dont map background pro simple rest api call con really good looking url html extension others dont map disappears would better see map item like item even carpet centre map item position map mitigate con html extension may add rule nginx file solution make item like one map pro given point able show item map like item belong blog solution start building system even complete dont implement blog yet two special page con complicated implement may additional field item change item view figure show item thats outside map item title item content rest api return item map doesnt return item outside definition simplify implementation may renounce title sure later want implementation display item title ill implement solution solution complicated want prioritise release first working website consequence later implement second solution anyway
adr entusiasme application development prologuesummary software development professional market woman developer facing difficult choose programming language study decided choose kotlin raise project company tecnologies product discussioncontext discussion technical development community group appears difficult woman choose technology start learn software development google tecnology great company supporting improving good documentation small learning curve java developer easy switch oop language interoperability easy learn sugar syntax waystateversionmodel consequence update information
build bash script generator transformation step create script build deploy generated artifact considered build general bash script generator let plugins build bash script outcome chosen build general bash script generator come best see pro con build general bash script generator provides component everyone plugins implement thing multiple time script component managed tested one place script working every platform target artifact plugin specific component let plugins build bash script plugin specific script component private duplicated code every plugin script style
memory store deciders nathan fiedler application handle several important piece information first mapping request login particular login action second login result initial request allows client application signal login begin get login url query result login action sake reliability information could written database storage device however add complexity deployment application data ephemeral best lasting second minute alternatively application could simply inmemory data store avoids leaking data event system breach expense losing data application restarted application inmemory store rather file database particular nodejs module selected named memorystore support timetolive expiration cached data limit time exposure sensitive user data consequence application inmemory store since beginning issue link memorystore github
serverside pagination user story easi case volume data shown page large serverside pagination ssp range useful reducing initial page load time mandatory prevention page crash running memory long pagination virtual scrolling clientside unlikely ever run later issue based current understanding easis usecases considered implement ssp implement ssp offsetbased strategy graphql implement ssp cursorbased strategy graphql outcome ssp consider cursorbased strategy future data volume grow large enough cause long initial load time currently largest volume data easi load one view cedar system list data inmemory caching data initial load time range millisecond load data remains available clientside pagination without subsequent load server result user experience seamless thing like sorting filtering browsing paginated data open question limit would consider acceptable initial load time view might data load easi grow time pro con ssp significant code change made reduces complexity codebase especially implementing feature like sorting filtering smooth user experience data initially loaded subsequent data load paging sorting filtering longer initial load time view load large number record implement ssp offsetbased strategy graphql limit initial load time prevents page crash due running memory likely issue easi simplest ssp strategy implement increase complexity codebase especially implementing feature like sorting filtering cause smooth user experience navigating data filtering sorting data must loaded server time implement ssp cursorbased strategy graphql limit initial load time prevents page crash due running memory likely issue easi flexible ssp strategy allows cursorbased ssp strategy also allows offsetbased idbased ssp strategy setting cursor equal offset record increase complexity codebase especially implementing feature like sorting filtering cause smooth user experience navigating data filtering sorting data must loaded server time
model hub zoo download implementation proposed adam gibson jan order properly consume model omnihub proper interface needed allow people download model due sheer volume model market scalable way interfacing various pretrained model java needed proposal interface allowing people create pretrained model instance new interface note supplant old dlj model zoo user able download model via following interface java access samediff interface create resnet model pretrainedsamediffresnetcreate user interface pretrained namespace class samediff dlj similar codegen work poet generate interface dynamically generated dsl dsl kotlin poet download model configuration setup code downloads model instantiates user code model loaded locally omnihub directory downloaded pre specified github repo directory url model zoo configurable environment variable environment variable default value bash export omnihubhomeuseromnihub export omnihuburlhttpsmediagithubusercontentcommediakonduitaiomnihubzoomain default directory homeomnihubsamediff homeomnihubdlj downloaded model note directory python omnihub downloads specified zoo download samediff dlj subdirectory converted model downloaded underneath cover pretrained namespace point different url sub folder resolve model dlj point dlj folder samediff point samediff folder consequence advantage java consume model allow creation model zoo repository git base increase number model access without needing convert manually disadvantage workflow converting model completely automated requires manual curation tool isnt complete solution adding new model come model found guaranteed converted may manual interference
remove custom json serialization supercedes provide simplified testing issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
django rest framework build geem api proposed updated proposed tbd consequence
existing apis instead creating project specific api registraties project contain page show data per address verblijfsobject existing apis like basisregistraties adressen gebouwen bag basisregistratie kadaster brk handelsregister required data readily available project mvp contain simple search field autosuggest functionality get data existing api endpoint therefore doesnt backend setup api future might initial phase frontend code capable retrieving formatting showing data apidataamsterdamnl application container component saga injected saga responsible retrieving data single endpoint situation call saga retrieve data one endpoint consequence project specific api mean instead one xhr request per page multiple request needed retrieve data lead time needed completely render page apart data cannot shown since request depend output api response page show data gradually filled section section interface element like table content summary jump behaviour later point time made consolidate data retrieval application rebuilt single saga retrieves data instead saga per container component
create useable item class item already way combat way add item change flow battle eventually money shop system add combat variation create way item integrate combat flow progress added healing item
newrelic sql consequence ref new relic httpsnewreliccomapplicationmonitoringfeatures httpwwwinfoqcomcnnewsmonitoringapplicationscategory
jetstream extended purge metadatavalue author aricart implemented tag server client jetstream jetstream provides ability purge stream sending request message jsapistreampurgestreamname request return new message following json typescript type ionatsjetstreamapivstreampurgeresponse error apierror success boolean purged number error field apierror success field set true request succeeded purged field set number message purged stream finegrained control purge request achieved specifying additional json payload typescript seq number keep number filter string seq optional upperbound sequence message deleted noninclusive keep maximum number message retained might depending whether specified count available seq keep mutually exclusive filter optional subject may include wildcards filter message matching filter purged filter seq purge message matching filter sequence number lower value specified filter keep purge message matching filter keeping specified number message seq keep specified filter stream removekeep specified number message keep number message multiple subject invoke purge different filter provided message purged consequence tooling service endpoint remove message creative way example stream may contain number sample periodic interval service sum replace single aggregate
stop recording architecture supercedes record architecture issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
dataloader dealing query issue graphql resolvers user story none there potential problem graphql resolvers written could impact scalability database get larger fetch data complex structure cedar nested object graphql resolvers make query database underlying data source cedar respond request example graphql query graphql query accessibilityrequestsfirst edge node name statusrecord euauserid end making sql request accessibility request make separate sql request accessibility request record utc log statement select accessibilityrequests deletedat null utc log execute select accessibilityrequeststatusrecords requestid order createdat desc limit utc detail parameter edfadbbbeab utc log execute select accessibilityrequeststatusrecords requestid order createdat desc limit utc detail parameter ddfdbafdbb utc log execute select accessibilityrequeststatusrecords requestid order createdat desc limit utc detail parameter beacacfaeacaa could cause scalability issue number record database also potential issue querying cedar see comment example problem prevents optimizing graphql schema considered nothing dataloaderbased approach batching multiple query see httpsgithubcomgraphqldataloader httpsgqlgencomreferencedataloaders information general approach implement dataloaden library dataloadenproofofconcept branch proof concept batch sql query implement graphgophersdataloader library outcome chosen nothing though keep eye issue going forward isnt currently causing problem start impact future well revisit pro con batch query general approach definitely solves issue database data source may necessarily work querying cedar cedar endpoint would support searching multiple searching deployment multiple separate system implement batching dataloaden proofofconcept work recommended dataloader library gqlgen general graphql framework dataloaden library hasnt updated since mean bug arent likely fixed implement batching graphgophersdataloader library seems actively maintained proofofconcept make sure work gqlgenbased code though see discussion github nothing minimum effort required problem doesnt appear severe right especially easis database data source due small amount data dealing doesnt address problem larger data set database data requested cedar could run issue backend taking long time resolve graphql query
maven build tool problem statement build tool considered maven gradle ant outcome chosen maven none gradles customizability overhead setup come required structure come maven make build file easier understand compared ant pro con maven good eclipse project maven building good plugin almost everything good good integration third party tool good robust performance good high popularity good one favor declarative imperative bad getting dependency list straight forward bad based fixed linear model phase bad hard customize bad plugins everything bad verbose leading huge build file gradle good build script short good follows convention configuration approach good offer graphbased task dependency good easy customize good offer custom dependency scope good good community support good performance time maven performance bad many plugins availablemaintained yet bad lack wide variety application server integration bad medium popularity bad allows custom build script debugged ant good offer lot control build process good agile dependency manager good low learning curve bad build script quickly become huge bad everything written scratch bad convention enforced make hard understand someone build script bad nearly community support bad low popularity bad offer much freedom link gadr httpsgithubcomadrgadrjavablobmastergadrjavabuildtoolmd license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
gradle rule deprecated app navigation module facing concern creating circular dependency causing longer build time decided creating navigation module neglected reflection create fragment instance achieve app navigation accepting argument class dto reflection break type safety
adr lowering barrier entry experimental component stage approved adopted recap draft work new component rewrite old component often start prototype include semantically versioned semvered main bundle approach served well since dec draft along causing lot confusion adr explains draft relevant part sure api component put different bundle primerreactdrafts draft experimental api follows development convention primerreact component draft accompanied design spec process accessibility review component check multiple box component lifecycle contract consumer opting component dont confidence yet problem draft incompatible semver expectation draft confident api structure component slip breaking change draft component minor release primerreact consumer side make every upgrade even patch potentially breaking upgrade effectively opting semver upstreaming component built product requires reevaluating bakedin assumption likely change api make useful confusion maturity generic name draft cause lot confusion especially experimental prototype experiment way component lifecycle defines experimental maturity experimental candidate team build react component look upstream reusable component natural look draft place put however barrier entry draft isnt low still follow design review dev convention api review etc feature team primer may intimately familiar primer component lifecycle criterion time andor knowledge meet often feature team create component outside primer find difficult contribute lead lower primer adoption conflicting version similar functionality throughout github product want enable feature team contribute primer also want make clear contribution havent evaluated high standard primer component npm package experimental component defined component lifecycle part semantically versioned npm package primerreact npm package experimental component independently published versioned semver breaking change tagged major version example githubexperimentalreactcommentbox code experimental component live new repository example githubreactexperimental published individual package suggested point help sharing experimental component monolith project outside monolith ownership responsibility maintenance shared multiple team including primer risk require improvement development publishing workflow experimental component without making investment could create friction make contribution difficult considered code experimental component live new repository code githubcomprimerreactcandidates support different convention process experimental component convey shared ownership primer product team keeping experimental component primer org suggests primer team would take maintenance component still candidate bug remedial etc new parallel workstream team current team size might able give required attention code experimental component live inside monolith githubgithubmodulesreactshared instead new repository lowest barrier entry developer working monolith however would significantly difficult nonmonolith project example memex difference component consumed monolith relative import nonmonolith project published package would create additional challenge havent explored yet code experimental component live githubcomprimerreact published multiple npm package would result maintenance overhead keeping component one repository however might make harder enforce different dev conventionsprocesses code ownership experimental nonexperimental component
adr drawing shape mark annotation model created december panoptesfrontends drawing tool largely developed previous custom project andor added one time support specific project several inconsistency discovered downsteam analysis aggregation explain inconsistency definition needed rhc right handed coordinate system defined system positive angle rotate object axis axis angle along axis lhc left handed coordinate system defined system positive angle rotate object axis axis angle along axis domain range value number take inclusive exclusive upper origin point upper left plot lower origin point lower left plot inconsistency comprise browser svg coordinate system rhc upper origin resulting positive angle rotating clockwise plotting software python matlab rhc lower origin resulting positive angle rotating counterclockwise position origin inconsistent tool effect final annotation center point dont drawing tool lhc tool annotation angle rotation unclear annotation refers center point shape unclear annotation point rotation mark annotation model issue well shape default value create bias example ellipse default axis ratio many volunteer left default creating bias comment freehand drawing tool peformance impact browser drawing created job create classification export well current annotation consists every single point created shape mark annotation model change consistency improved postclassification analysis following way annotation mathematical standard rhc domain consistent angle calculation annotation model angle naming rotation angle replaces usage rotation annotation model replace xcenter ycenter shape applicable exception nonshapes like point line transcription line tool nonsymmetric shape like fan shape clustering aggregation always done center rotation defined xcenter ycenter point rotation cannot defined around center point point clearly recorded annotation xrotation yrotation conditional logic component code avoided mobxstatetrees computed view function get either xcenter xrotation mapped markx code example const circlemodel type modelcirclemodel xcenter typesoptionaltypesnumber ycenter typesoptionaltypesnumber radius typesmaybetypesnumber angle typesmaybetypesnumber viewsself get coords naming reusing whats already done point line consistency return selfxcenter selfycenter nonsymmetrical shape like fan xrotation yrotation const fanmodel type modelfanmodel xrotation typesoptionaltypesnumber yrotation typesoptionaltypesnumber radius typesmaybetypesnumber angle typesmaybetypesnumber spread typesmaybetypesnumber viewsself get coords naming reusing whats already done point line consistency return selfxrotation selfyrotation default value removed wherever possible replace project builder configurable value set project builder lab tool setup parameter default value suggested parameter set lab attempting drawing tool classifier classifier display error message tool fully setup yet lab also prompt inputing value lab include instruction warning biasing effect tool default ellipse rotate rectangle fan freehand drawing tool mark annotation string svgs path responsibility postclassification analysis convert usable point include sample script datadigging repo project owner reference aggregation caesar updated conversion first tool change toolindex clarify referring index input task area toolindex useful distinguish multiple instance tool tip drawing task drawing annotation drawing tool mark tasktype tooltype attribute added map enumeration type task tool like drawing point ellipse etc respectively enables aggregation caesar code autoconfigure extractor without checking data type comment certain annotation model may internal property denoted preceding underscore property removed classification complete action remove help prevent confusion project owner downstream analysis proposed consequence github issue tracking port drawing tool updated specific change relevant tool mark annotation model adr define drawing subtask annotation model addressed follow adr breaking change pfe new classifier project migrating pfe new classifier may write new analysis code deal change new annotation model could submitted json schema proposed adr assist aggregation code caesar updated check classification metadata classifierversion know updated clustering code update mark annotation model could checked proposed json schema included annotation schema versioned starting pfe version freehand drawing tool mark annotation exception rest mark annotation model due performance reason communicated configuable value instead constant default value certain drawing tool entirely eliminate bias effect eliminate default value entirely moment know best way changing require research experimentation recommendation ellipse tool suggest multiple click comment another might text input drawing
implement shell script adrs plain text file stored subdirectory project tool create new file apply small edits section existing file tool implemented shell script standard unix tool grep sed awk etc consequence tool wont support window plain text file adrs created hand edited text editor tool make process convenient development cope difference unix variant particularly linux macos
fhir interface proposed deciders daniel stefaniuk todo issue seeing motivating change todo change actually proposing consequence todo becomes easier difficult change
azure map instead google map deciders kakarotto technical story change map provider azure map problem statement map added product missile shown real time driver easy knowledge already exists native product technology considered google map azure map outcome decided azure map since native azure net product well integrated azure signalr going realtime notification got experience azure map already positive consequence implementation faster easier particular case negative consequence planned get google map api knowledge well link
record dont log event result error made architectural event sourcing capture request publishing api mutate data please refer adr information incoming request api example request create content item might fail validation missing mandatory field proposal capture event request rejected publishing api event captured event log event log inconsistent view data resides system problem state system would harder understand event log contains information bearing behaviour system attempt replay event history containing rejected event would encounter error capture event result error response publishing api also follows case error response returned publishing api internal state system mutated consequence event log updated transaction change internal state publishing api downstream asynchronous request allowed fail validation must performed publishing api part synchronous requestresponse cycle asynchronous downstream request fail regarded system error investigated developer
adr adding undoredo workflow step november engaging crowd wanted support workflow branching step single answer question lead different task depending selected answer recursive step given task returned annotated multiple time single subject volunteer able move backward forward workflow without losing work theyd already done solved problem adding undoredo history stack classifier task area added global history stack storeannotatedsteps refines moving global history manager individual history management subject subjectstephistory history managed mst middleware undomanager record snapshot single subtree store history item single step key one annotation representing current state task area back load previous step key annotation history next load next step key annotation creates new history item one doesnt exist already going back changing branch branching workflow clear existing redo history start fresh history current point consequence workflowconfigurationpersistannotations default true workflow annotation value remembered unless explicitly turn feature annotation value remembered recursive looping workflow feature wasnt supported pfe annotation cant undone redone without generating new empty annotation work around annotation change wrapped undomanagerwithoutundo code future iteration could rewrite classification model allow undoing redoing annotation without destroying value storeclassifications storeworkflowsteps independent subtrees cant tracked directly undo manager future iteration classifier model could store step annotation subtree would simplify history management proposed
catalog promotion validation problem statement catalog promotion new feature sylius developed apifirst manner course provides functionality well challenge faced implementation validation either unified api separated driver catalog promotion validation easy customize extend work api validate business scenario syntactical correctness considered unified validation custom validators first approach validation concept custom validator action scope correct validation chosen based key provided syliuscatalogpromotionactionvalidator tag custom validators contain business syntactical validation latter configured anywhere else good custom validators unified api result lack duplication bad business syntactical validation mixed even though different type validation bad resulted problem validation message display catalog promotion form quite complicated unified business validation separated syntactical validation variation previous still custom validators business functional validation syntactical validation delivered separately api good syntactical business validation separated good validation form problematic still extendable customizable semibad result apparent duplication logic bad easy way syntactically validate request apiplatform done validators anyway outcome chosen unified business validation separated syntactical validation syntactical functional validation two different type validation separated especially approached differently technical point view regarding interface api moreover separation give better control requestsforms validated value passed form validated sylius theyre already protected symfony type output result following structure validators srcsyliusbundlepromotionbundlevalidatorcatalogpromotionaction base business validation catalog promotion action related concept bundle currently empty interface srcsyliusbundlecorebundlevalidatorcatalogpromotionaction business validation catalog promotion action related concept bundle product variant srcsyliusbundlecorebundlevalidatorcatalogpromotionscope business validation catalog promotion scope related concept bundle taxon srcsyliusbundleapibundlevalidatorcatalogpromotion syntactical validation api request validators usually decorate validators corebundle syntactical validation form data shall done specific form srcsyliusbundlecorebundleformtypecatalogpromotionscope reference approach chosen approach
api project design proposed deciders donald gray problem statement best structure api project make easy developer navigate comprehend considered organise feature mediatr traditional aspnetmvc layout outcome organise feature mediatr mediatr encapsulate various usecases api together feature folder allow developer easily identify capability api target section pro con organise feature mediatr mediatr doesnt huge amount allows controller easily fire command request request clarity without knowing handled inputoutput request clearly identified request contract allows pipeline built processing request inside mediatr help cross cutting concern like timing logging help keep handler logic clean name request case name containing file help document capability api ingestimage reingestimage createspace deletecustomer lead feature folder help contain everything related together rather everything spread glance see project handle imagesspaces etc rather glance seeing handle controllersmodelsviews traditional setup bash feature image imagecontrollercs command reingestimagecs ingestimagecs deleteimagecs request getimagescs command could allow querying stringx space customer etc rather lot granular command handler sort logic space spacecontrollercs programcs startupcs controller thin approach know request construct dependency imediatr send command public class imagecontroller controller public imagecontrollerimediatr mediatr thismediatr mediatr public taskactionresult reingestimagestring imageid var ingestimagecommand new ingestimageimageid var result await mediatrsendingestimagecommand handle resultset code etc positive consequence better organisation application related component together easier new developer comprehend whats happening usecases system documented class prevent dependency explosion controller controller construct sends request ability pipeline behaviour generic constraint target specific request would involve different ioc container negative consequence debugging example stepping await mediatrsendingestimagecommand would take mediatr framework code rather handler ingesting image mitigated request handler classfile make debugging intuitive overuse pipeline behaviour lead obfuscated difficult understand code pipeline behavious well documented readme etc overuse mediatrsendingestimagecommand controller sends handler sends handler sends handler etc awful best try stick one single send controller traditional aspnetmvc layout default project layout configured default starting new project class stored type controller model rather functional area positive consequence familiar expected layout net developer aware approach negative consequence looking solution show mvc application link mediatr project mediatr pipeline behaviour msdn article feature slice
analytics foundation deciders daniel lucca victor perin marcelo travi technical story company starting growth fast growth common see complex data analysis weve solved installing metabase readreplica okr transactional database even structure lack complex analytics concurrently previous statement company plan create analytics product customer enabling realtime complex analysis user cant ignore proper analytics foundation inside bud also cant afford investing large amount time building infrastructure since everything could change fast find way create flexible analytics infrastructure could provide meaningful data regarding customer flexible enought integrate multiple source allow usage external application nutshel infrastructure primary source truth company could allow customer fetch data even application could scope driver flexibility easy integrate external source implementation difficulty considered snowplow time quintoandar ive heard lot tool called snowplow simple way enriching behaviour data creating data pipeline could nourish data warehouse enriched data snowplow could easily fetch data amplitude hubspot smartlook others enrich adding data transactional database finally could store data proper database building etl common way solving issue creating custom etl available tool could easily met requirement want creating complex infrastructure matter airbyte searching viable found tool called airbyte theyre pretty new still alpha already integrate source almost every tool idea pretty simple airbyte export data source import destination apply transformation call process elt pro con snowplow pro extremelly flexible realtime integrate almost every tool con cant integrate database designed enrich tracker data complex implement evaluate license see create product future building etl pro anything want would easier create product future would know exactly work decide work con would take long time implement problably would worse especialized product airbyte pro flexible integrate database easy implement installed infrastructure con would check license see create product still alpha realtime run integration every minute outcome evaluating weve decided proceed airbyte meet almost every specification extremelly easy implement follows best standard isnt inhouse solution current scenario would big deal also could learn maybe create new tool future designed met positivo consequence infrastructure going achieve robust elt infrastructure little effort easily create analytics application going serve business requirement minimal effort also airbyte dbt hood said even change elt structure would still able migrate dbt project negative consequence two main negative consequence able query real time data pointed marcelo travi airbyte would able query realtime data usecases would issue considering first requirement serving evolution graph given keyresult percentual proggress issue fix suggest data analytics transactional data enrich large query could affect application pointed victor perin since common implementation aware complex analytics query could impact application since integrating directly plenty way fix easiest one would creating readreplica data warehouse query analytics would separate analytics minizing issue
adr api tech stack november retrospective zooniverse maintains numerous rail apis mostly built three five year ago vary wildly amount attention theyve received gem deprecated unmaintained otherwise generally good idea tyool research necessary modern standardized api functionality solution would meet following requirement crud serialization pagination filtration authentication authorization considered refers different thing ootb rail course sufficient building fullfeatured api however weve come expect certain feature lighten cognitive load app dev dev broke question possibility api format plain straight json representation resource pro straightforward build extra part required con another nonstandard api stable jsonapi spec pro follows proven standard lot dropin stuff thatd manual otherwise con bit learning curve front back end devs rail nonjsonapi mostly ootb rail gear api would simpler initially featureful said dropin gem provide required feature could mean rolling something entirely freeform building internal schema validation system example stack could either auth pundit given across pagination kaminari serialization tojson blueprinter internallydefined json schema filtration ransack custom pro straightforward build focus getting something working overall complexity jsonapi spec con still lot make gem pagination filtration etc another nonstandard api stable apps dip jsonapi spec managing link relationship manually implementing piece spec others new totally bespoke interface seems like movement wrong direction jsonapi spec jsonapi spec jsonapiorg schema standard intends normalize way apis interacted web perfect might even strictly necessary allows code written client gem every piece mentioned top make assumption rail solution exist everywhere spectrum full replacement literally controller code helper deserialize ill get internal difference here upshot pro follows proven standard lot dropin stuff thatd manual otherwise client server side abundant existing documentation knowing something acting client surface bug server code knowing expecting getting learningprofessional development opportunity catch rail world con learning curve potentially overkill project size fastest route functional api said suboptions suboption jsonapiresources httpsjsonapiresourcescom big one space full dropin replacement foralmost everything designed controller literally entirely empty inheriting including gem class boom api give crud everything whether want handle interaction request model pretty much suboption diy jsonapi build stack without magic similar stack gem pundit kaminari ransack include basic jsonapiformatted serialization fastjsonapi seems like there lot churn space lately though record here may seem fine first blush ended vetoing activemodelserializers fully maintenance mode update since mid big one long time several apps readme say look elsewhere jsonapirb confusingly similarly named next one point first however hasnt seen lot activity recently either open since whole section documentation labeled todo suboption jsonapirb httpsgithubcomstasjsonapirb found gem research precisely would suboption loc gem bundle together gem planning primarily ransack fastjsonapi tie together boilerplate code boilerplate validation error handlingformatting getting data tofrom ransack filteringsorting pagination link outcome end day difficult choose jsonapi spec greenfield project balance standardization gadgetiness basic nondry controller one end graphql spec front end devs sortof familiar account existing service sortof implementation gave opportunity rabbit hole bit learn whats discovery surprising activemodelserializers fully deprecated whod guessed mind test drove suboptions jsonapiresources framework sure relatively simple case could handled found getting hung straightforward question wasnt sure magic correctly definitely seemed like overkill wanted accomplish furthermore magic extra required documentation reading would make much difficult onboard someone new work app end decided jsonapirb lean existing popular tech hard stuff fastjsonapi ransack serialization filtersort respectively pretty much everything else stuff implement manually way though see exactly done override necessary there sorcery empty controller simple classesmethods clear extendable even fixed example readme merged couple hour later certainly active said would relatively straightforward process disentangle gem entirely rest app grabbing necessary class lib throwing apps
api superceded graphql api discussed architecutretooling api including jsonrest api graphql api decided implement json api documented openapi formerly swagger openapi specification think since graphql would additional learning curve better stick rest enhance graphql future desired consequence openapi help design build document api
store payment data firestore deciders ben bangert barry chen bianca danforth danny coates orchard problem statement payment data stripe paypal apple google iap handled individual document typically access different portion different time addition schema occasionally change api update stripe paypal api limit mean typically duplicatecache data retrieve moment cache data redis mostly work restricts ability run query across payment data set without pulling bigquery making substantial amount stripepaypal request handle iap store apple receipt google subscription object organized fxa user belong theyre arbitrary json document also copied bigquery etl job futureproof payment data storage flexibility needed store stripepaypal payment data data store etl capability driver engineering resource arbitrary json document querying ability ease loading data etl job capable storing arbitrary json data integration stripe payment system considered google firestore mysql redis outcome google firestore weve firestore eventbroker rich api extension overlap requirement reduces engineering operation resource pro con google firestore firestore json document oriented datastore store document collection table also ability nest collection document single user document could collection payment document defined schema arbitrary json document stored firestore eventbroker along streaming watch capability immediate update cached data dispatch event stripe built multiple extension firestore keep invoice customer data sync google also built variety extension firestore including bigquery sync extension would handle etl pro already firestore integrated fxaeventbroker operationally simple google host manages firestore extension supported stripe bigquery extension handle requirement comprehensive querying capability portion json document document nesting organization payment data con may still cache commonly accessed data redis reduce firestore spend increase database authserver talk mysql firefox account mysql data shortlived recreatable data stored redis oauth token related could store payment data mysql rest user data mysql support json document limited query capability mysql additional json functionality partial document update would required pro already mysql integrated fxaauthserver additional setup con cant query arbitrary path json document arent mysql complicates json document manipulation redis firefox account redis heavily caching short term data storage fast caching variety json document already pro already integrated authserver fast little additional costresource overhead con arent redis cluster mode ensures data durability query ability portion document stored string
support stable tenant tenant always automatically generated corvustenancy part marain come across scenario useful control tenant primarily applies tenant toplevel container client service tenant well service tenant absence ability know tenant advance fallen back well known name tenant effectively introducing wellknown well introducing potential point failure due keep name unique far efficient locate tenant name avoid effectively introduce way identifying tenant allow tenant controlled created done adding new method itenantprovider interface createwellknownchildtenantasync allows caller specify guid generate new tenant rather generating random guid internally existing createchildtenantasync method resulting new tenant still generated concatenating parent tenant hash provided guid mean order tenant well known ancestor must also wellknown order prevent two tenant created necessary check already prior creating new tenant consequence allowing client control tenant mean longer guarantee globally unique unique across different tenant provider ever migrate tenant store change make process complex
adr separate frame viewer may support nontranscription project multiimage subject built separate frame viewer feature additional feature pfe frontend app subject viewer display workflowconfigurationmultiimagemode separate subjectviewerseparateframesview toggled true flipbook viewer subject one location location image plan add finegrained choice subject viewer project builder future relevant change separate frame viewer discussed another adr feature configurable project builder handled separate frame viewer layout default column col col grid grid row choose whether clone drawn mark frame default false workflowconfigurationmultiimageclonemarkers choosing appropriate separate frame viewer layout project team instance subject portraitoriented image easily displayed column grid contrast subject landscapeoriented image would work best column layout regardless selected layout component code switch column layout individual frame width browser minframewidth defined separateframesviewerjs prevent subject image shrinking unclassifiable size note enableswitchingflipbookandseparate workflowconfiguration store enables switch separate frame view button flipbook control separateframe component separate frame viewer repeatable component designed include image toolbar controlling one frame separateframe component contrast generalized imagetoolbar classifier layout relies subject viewer store handle pan zoom rotate invert state separateframe local state feature instead drawing task clone marker frame checkedenabled project builder drawn mark circle appear every frame flipbook viewer frame volunteer added mark still recorded annotation volunteer drag mark new position new position display frame clone marker frame uncheckeddisabled project builder drawn mark appear frame initially drawn frame volunteer added mark recorded annotation volunteer drag mark new position new position apply dragged mark consequence implement drawing tool separate frame viewer refactoring interactionlayers handling current frame needed interactionlayer displayed top subject image aware showdrawedit mark current frame however pull current frame value subject viewer store mark drawn subject viewer fem current frame recorded annotation concept current frame yet separateframe component implement drawing tool config explained drawn mark separateframe component somehow record frame index separateframe component also able showdrawedit mark frame index adr regarding flipbook viewer similar consequence implementation drawing tool viewer include explanatory adr
expose geoprocessing api mmwbigcz platform performs number geospatial processing task initiated submitting task http endpoint web application provides tool workflow assembling submitting input monitoring execution progress collecting visualizing result job platform provides value assembling required national scale data infrastructure necessary perform processing effort extend capability alternate workflow dont involve web platform client want formalize externally consumable http api mmwbigcz already includes make limited django rest framework drf support convenience method around creating http apis api objective support execution current future analyze sub task land soil etc support execution rapid watershed delineation model execution functionality exposed available registered user usage recorded long term goal would charge access consideration geoprocessing routine asynchronous requiring submission polling determine result available geoprocessing resource intensive operation geoprocessing endpoint must remain open anonymous user web platform azavea maintains client current api therefore freedom make change api released well treat release platform carefully possibly retain backwards compatibility based api solution adhere following implementation detail mechanism authenticating user two seem potentially appropriate api key associated user account expiring token generated based client supplied credential api key easier inherently secure since reused multiple party included request revoked allowing failsafe long term unauthorized expiring token require user securely manage credential difficult especially desire api frontend browser code least rudimentary rate limiting capability unrestricted job submission even modestly could considerable negative impact web platform performance user anticipate api batch processing restricted often submit result duplicated code web platform access unauthenticated endpoint could theoretically accomplished domain white listing within drf endpoint existing endpoint regardless implementation generalized one specific place api platform utilize enforce size shape validation front end code submits analysis job responsible majority shape validation included api well additional potential conflict like coordinate system contained within conus may require restriction upload payload size currently handled nginx reuse existing endpoint existing endpoint startanalyze startrwd exact functionality needed limited specific implementation detail require authentication validation largely handled front end submission routine path naming selected public api cors enabled create new drf based api endpoint drf already application support authentication system token auth well helper view manging creation token also support pluggable auth system includes broader party set auth provider including potentially sophisticated technique jwt default usage logging would handled manually support mechanism throttling customized azaveas climate change api library aws api gateway proxy api request agw could pas request existing new endpoint come robust system feature set including usage plan rate limiting logging versioning tooling execution around service relatively unknown team also would authorize request based authentication application requiring custom code existing django rest framework implement new api endpoint secured default token authentication provided framework throttle request configurable amount per minute add account page list user api key allows invalidedregenerated validation encoded endpoint applicationenvironment user associated user api key endpoint basic logging request done within django modeldatabase attribute confirmed client consequence nonexpiring key trade security consumer convenience none content currently protected better low barrier entry determine actual user demand feature future paid tier added enough workflow update required provide opportunity revisit mechanism since well logging database well provide interface data suggest keep simple create management task export range usage data csv evaluated excel feature end gaining traction well want invest robust solution drf plugin may assist task evaluated since public facing api make swagger generate documentation may required upgrade drf make latest version feature upgrade django already planned
choosing service name service problem statement scale service clear way choosing service name service name reflects common name provider exposed gui name currently exposed name property service declaration sort represented filesystem currently exposed filename service declaration without json extension case service name presented end user reflect closely possible official service name identified easily internally exposed analysis easy handle script tool constraint long stored filesystem unix window apfs casesensitive duplicate support caseinsensitive filesystems character support transfer fat utf space capital supported even caseinsensitive filesystems however utf filename fixable problem git utf filename default quoted git leading example ttxt displayed ttxt online service align brand name domain name even though utf officially supported domain name support limited service even nonwestern official ascii transliteration least domain name tencent rzdru yahoo yahoo currently github gui service presented user instead service name name email notification outcome service name one service matter alphabet example dont support nonascii character service least long database git filesystem order minimise risk service derived service name normalization ascii example tuturu example historielrerdk historielaererdk example rte support punctuation except character meaning filesystem level replaced dash example yahoo yahoo example lastfm lastfm example restart restart example support capital casing expected reflect official service name casing example example deviantart deviantart example line line support space space expected reflect official service name spacing example app store app store example deviantart deviantart prefix service name provider name selfreferences ambiguous separated space example facebook refers selfserve service simply cannot shared database thus call service facebook example facebook facebook example analytics google google analytics example firebase google firebase example app store apple app store
select web framework criterion mature featureful easy implement rest support relational database candidate flask django commentary prefer allinone tightly integrated approach django approved django django rest framework author ntoll
nimbus desktop glean instrumentation author travis long deciders nimbus team anna scholtz data engineering daniel berry data science problem statement current nimbus desktop implementation relies legacy telemetry event borrowed normandy component migrate glean metric recorded glean become necessary nimbus event experiment also recorded glean purpose analysis adding complication instrumenting event glean nimbus rust sdk mobile minor difference telemetry implementation current legacy event include enroll unenroll expose compare enrollement unenrollment exposure glean event nimbus sdk mobile nimbus rust sdk also includes disqualification event current desktop equivalent desktop includes failure event enrollment unenrollment considered quo nimbus desktop continue legacy telemetry new glean event exact duplicate existing legacy telemetry event glean event match mobile sdk collection mapped legacy event close possible merge existing mobile sdk event desktop event preferring sdk name ensure desktop migrates rust sdk continuity data collection due needing support component running experiment might either legacy legacy glean simultaneously glean continue record data legacy telemetry deprecated removed componentsmeasurements migrated glean outcome firefox desktop component already migrated glean well component instrumenting critical new metric glean cannot simply rely current legacy telemetry event instrumented nimbus desktop component migrate glean benefit experiment metric recorded glean alongside guardrail interesting metric may wish monitor running nimbus experiment longterm goal eventually migrate firefox desktop nimbus sdk currently mobile device instrumenting metric match existing legacy metric could potentially create collision conflict issue migration occurs legacy telemetry also includes metric currently instrumented rust sdk mobile specifically enrollfailed unenrollfailed event reason ensure continuity existing experiment preferred approach nimbus rust sdk enrollment unenrollment exposure event direct parallel firefox desktop telemetry recorded information manner existing legacy telemetry instrumentation ensure continuity aid verification migration analysis tooling relies upon event nimbus sdk disqualification event current analog nimbus desktop overlap unenroll telemetry recorded nimbus desktop currently removed disqualification event nimbus sdk already treated unenrollment monitoring finally enrollfailed unenrollfailed event instrumented glean event firefox desktop also added nimbus rust sdk consistency table show merged set event instrumented firefox desktop including failure event implemented nimbus sdk reason experimenttype extra also implemented nimbus sdk nimbus desktop nimbus sdk merged enroll enrollment enrollment unenroll unenrollment unenrollment expose exposure exposure disqualification removing enrollfailed enrollfailed unenrollfailed unenrollfailed existing desktop event appear following structure category normandy method enrollunenrollexposeenrollfailedunenrollfailed object nimbusexperiment value experimentslug extra branch branchslug included event enrollmentid enrollmentid included event reason reason included failure unenroll event experimenttype type included enroll event featureid featureid included exposure event glean event slightly different structure contain information name nimbuseventsenrollmentunenrollmentexposureetc extrakeys experiment experimentslug included event branch branchslug included event enrollmentid enrollmentid included event reason reason included failure unenrollment event experimenttype type included enrollment event featureid featureid included exposure event
java implement complete solution issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
category adr tag visualization javascript title adr pick visualization language noted adr codecharta web browser visualization stack havent decided language program though language familiar developer language allow quickly start developing especially relevant team member change frequently superseded adr javascript default choice web browser familiar developer consequence javascript look like analysis language knowledge easily transferred unlike analysis language javascript static typing make knowledge transfer harder also static type good choice larger program visualization could eventually become
title payment flow area checkout tag checkout payment flow provide standardized way shopware extension implement custom payment implement two possible handler synchronous payment asynchronous payment handler optionally implement acceptingprecreatedpayments payment transaction fails user choose payment method trigger flow handler synchronous payment synchronous payment intended execute payment immediately order created without user interaction client pas additional data handler process payment order handler throw syncpaymentprocessexception error occurs following diagram show happy case sequence synchronous payment handling error handling described asynchronous payment asynchronous payment handler implemented client user redirected payment gateway website client redirected actual payment site payment site later redirect client back success error page shop handler executed link prepared validates referred finalize redirect back payment service following diagram show happy case sequence asynchronous payment handling error handling described app payment app payment flow similar synchronous asynchronous flow app implement one flow define external http api endpoint callback endpoint called instead executing regular php code custom handler response define payment flow like example accepting precreated payment improve payment workflow headless system reduce order without payment payment handler implement additional interface support precreated payment client single page application prepare payment directly payment service shopware pas transaction reference token shopware complete payment payment handler verify given payload payment service shopware cannot ensure transaction created frontend valid current cart successful verification order created payment handler called charge payment charge successful payment set paid user forwarded finish page failure order payment process active highly recommended implementing optional feature creation capturing payment separated order payment error case possible produce failed payment failure case order payment process begin client choose new payment method retry payment entire payment loop synchronous asynchronous payment start
configuration environment variable approved application configured differently depending running example backend running locally different configuration backend running production environment variable configure application consequence environment variable allows easily configure application consistently good support cloudgov configuration via environment variable also frontend easy configure frontend library allow setting environment variable env file
database backup strategy currently backup firestore database would ideally like back data production every day restore database case issue assumption assuming entering long comment quote etcthat single record form exceed size approx according client form year mean total size needed store form data exceed year plus admin overhead security etc since data exported compressed backup daily storage requirement exceed day month day backup file deleted automatically per gcps policy costfree video recording audio recording kept sitelinks cloud storage concerned storing video audio image stored dropbox contain reference url decided export function firestore github action automate backup firebase database different considered database backup strategy import export firestore data manually cloud firestore managed export import service recover accidental deletion data offline processing however would require manual intervention every time data exported pro readily available con would manual step step export data every day timeconsuming automate import export firestore data github workflow github action automate export function firestore google apis exported data stored gcp bucket pro provides automated export great configuration flexibility configuration cron job automate backup recovery secminhoursdayweek support export via gcloud cli facilitates various level granularity fast easy follow implement automated firebase backup approach automated backup blaze plan restoring backup import scheduling approach refers firebase realtime database automatic backup project firestore database final decided ahead github workflow cron job run every day automate export firestore data data stored gcp storage bucket case disaster recovery import done manually backup recovery due various consideration regarding cost time consumption effort decided backup recovery needed performed manually following step detailed document httpsdocsgooglecomdocumentdclczqgpchhhiqsgxubauxyclzgmbjdseditheadinghpewbrrkwh
gradle build system choose build app gradle flexible plugins docker integration mkuzmin know technology well
kata dependency knowledge solve certain kata depends knowledge one gathered katas within one katabundle eslanguage well defined done already done across katas repo kata might require knowledge something learned kata able inform user learning path katas able reflect dependency throughout entire repo see kata done katas export available katas like const buildreferenceforid bundle eslanguage export const arraysortbasics buildreferenceforid arraysortwithfunction buildreferenceforid globalparseint buildreferenceforid inside katas kata refered importing refering exact kata inside eslanguagerawmetadatajs import eslanguagerawmetadatajs const requiresknowledgefrom esglobalparseint consequence
mysql qps sql qps tps mysql cpu cpu sql mysql sql cpucpu cpu sql cpu cpu mysql myisam innodb mysql aliyun ssd ssd mysql select mysql maxconnections ddl mysql select consequence aliyun mysqlcpu ref mysql httpblogcsdnnetuarticledetails httpblogcsdnnetuarticledetails aliyun rds httpshelpaliyuncomdocumentdetailhtml rds httpshelpaliyuncomknowledgedetailhtml rds httpwwwcnblogscomolinuxphtml
designing integration new newslabs pstt service superseded adr deprecated deciders eimi ashley ben technical story march contractor working reusable component front platform stt problem statement want connect newslabs shared stt service named newslabs pstt outcome ashley building service api gateway bucket uploading bucket trigger stt event uploading bucket previous architecture limitation define communicate newslabs pstt service one shared bucket per environment service service name bucket newslabssttmediatotranscribe newslabssttmediatotranscribetest limitation newslabs pstt handle audio file wav flac client dpe ensure upload audio video etag reference object key instead servicenameobjectkeyext assume client sending unique object key example upload uploading file object key object key prepended service name dpemp endpoint requesting transcription lambda return transcription example response readme make request api gateway endpoint please ask something like request body json objectkey dpeuuidext
field format naming convention proposed desire consistency across api provide set sensible naming convention adhere require client likewise naming convention field naming standard closely follows json api definition spec consulted full list allowed disallowed reserved character brief field name case sensitive must contain least one character begin character nonreserved urlsafe character following additional standard also force applicationvndopgdatav field name lower case must begin alpha chatacter underscore separate compound field name space permissible field name field data format integer integer boolean represented true false null value represented null empty array always shown represented represent time government mandate iso standard represent time payload response help people read time correctly consistent format look like time form unicode encoding unicode transformation format utf standard mandatory government encoding text textual representation data json data xyzalwaysastring integer string like boolean true boolean false datetime explicitemptyarraysareshown explicitnullforeverythingelse null useunderscoresinnaming true fieldsalllowercase true fieldsarecasesensitive true consequence consistency greatly improved
azure example cloud platform issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
sort hand single hexadecimal string hand rank function rank hand type value card relevant hand type value kicker card could implement sort putting value array comparing item item string comparison would awkward value two digit could zero pad easier approach would base encode hand type rank card value value one hexit producing alphabetically sortable string hand simple lessthan operator trick sort hand alphabetic comparison hexadecimal string encoding value relevant relative hand rank consequence solution little magic confusing simpler imperative number array comparison approach make easier implement
dependency injection supercedes hardcode dependency extended unity dependency injection issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
tenant inherit parent property corvustenancy support hierarchy tenant two thing firstly control pertenant basis child tenant data tenant stored example two sibling tenant tenant child parent tenant data child tenant stored completely different location default separate container storage account could completely separate storage account secondly enable better organisation tenant parent tenant group related tenant together one function tenant hold clientspecific configuration application client example would client workflow service tenant contain two piece storage information one workflow one workflow instance configuration stored collection keyvalue pair attached tenant possible tenant child tenant hierarchy tenant workflow service child may also workflow service case choice decide allow workflow storage configuration tenant inherited child require tenant contain configuration determined make property tenant available child default application consume library implement functionality required example manually copying property parent child new tenant created whilst property inheritance seems desirable development perspective example creating temporary tenant testing purpose setting tenant developer likely useful envisaged production scenario case hierarchy organisational purpose inheritance relevant parent tenant solely group child configuration parent tenant irrelevant exist tenant right case hierarchy represents genuine parentchild relationship many potential reason goal project dictate specific case however making implement property inheritance necessary find case desirable case paas product providing multiple service endjins marain platform platform contains several base service tenancy workflow operation claim licensed client client may choose service build platform marains tenancy service provide platform service customer case client customer represented child tenant tenant situation two negative outcome allowing configuration inherit parent child tenant client may make marain service workflow provide service customer configuration service stored configuration client tenant automatic property inheritance would mean default child tenant client would also ability access service case configuration attached client tenant contains various piece sensitive information example may contain storage account detail storage directly owned client reason marain allow client view configuration data parent however client able view modify configuration child tenant automatically allowed property inherited child tenant would possible client create child tenant examine inherited property access effectively client configuration data consequence whilst providing inheritance standard reduces risk leaking configuration parent child tenant possible envisage scenario inheritance would desirable scenario instead necessary manually copy configuration parent child potentially maintain multiple copy situation client application simulate inheritance automating duplication property maintaining additional property indicate value effectively inherited explicitly set child tenant
indepth katas separated normal katas wolfram writing katas slowly see pattern arising write also depth want lately thing made think indepth version katas one writing objectfromentries kata writing kata took week every evening figuring certain detail spec transport kata made realize kata become complex get feeling objectfromentries work also made realize want depth dont want write kata state wrong thing kata simply become big detailed discussing jscc also jslang meetup realized people would appreciate simple introductory kata allows one learn feature superficically indepth expert kata cover specific might described spec katas might come two flavour simple kata indepth kata case described objectfromentries kata two katas stored eslanguageobjectapifromentriesjs eslanguageobjectapifromentriesindepthjs two separate katas separate metadata etc simple kata serf purpose understanding able functionalityapi indepth kata cover thing like functionality behave edge case type coercion function directly prototype alike thing consequence katas simple katas easier solve stay reduced complexity allow one learn feature
drop pattern extensibility facilitate organizing shell customizations smaller readable understandable maintainable block provide clear common patter extensibility create zdotdeedir directory extension file stored add rooutine zprofile zshrc source file found directory lexagraphical order file name consequence ensure zprofilezshrc file remains small unlike zsh plugins keep custom code local readily available inspection modification
matching adyen notification commercetools payment adyen notification matched commercetools payment equivalent payment key merchantreference fetching commercetools payment object query keymerchantreference since introduced custom reference refund payment key could custom field payment transaction defined user therefore payment longer always able obtained merchant reference key pspreference payment key field originalreference pspreference originalreference exist merchantreference payment key matching payment notification web component version pspreference obtained makepaymentresponse extension module update payment key therefore match payment pspreference given notification web component version pspreference first provided notification authorization event different web component version pspreference already provided adyen api response extension module update payment key therefore still merchantreference payment lookup scenario payment found update payment key pspreference obtained notification event authorization refund capture cancel originalreference notification original pspreference obtained authorization notification notification ctp payment key fetch payment first check originalreference exists yes find payment key key merchantreference originalreference otherwise find payment key key merchantreference pspreference find corresponding transaction payment interactionid interactionidpspreference detail please refer code snippet consequence possible lookup payment different transaction throughout whole payment process payment key pspreference originalreference also unique payment
adr kotlin language prologuesummary software development woman developer facing difficult find content good software development find opportunity learn improve technical knowledge decided create open source project teach software development real purpose accepting longterm improvement solution discussioncontext discussion technical development community group appears difficult woman professional level place improvement knowledge create real software development project learn agile project practice project structuring architecture concern make backend development environment local development environment setup objectoriented programming paradigm clean code tdd testdriven development ddd domaindriven development design pattern solid testing automated testing continuous integration continuous delivery continuous deployment share knowledge learned coaching waystateversionmodel version java consequence dependency jvm java update information
artistimagesfromspotify korin would look much better artist image unfortunately lastfm removed artist image api replaced placeholder get artist image music story documentation easy understand sdk designed web browser also custom associate artist imdb one unique feature lyric music brainz creative common everything except artist image spotify artist information including image custom imdb spotify viable consequence spotify api
web map service choice database depend information database store mapbox consequence pro easy setup admin well organized documentation easy integrate mobile con free service
matching adyen notification commercetools payment deprecated adyen notification matched commercetools payment equivalent custom field merchantreference fetching commercetools payment object query customfieldsmerchantreferencemerchantreference native payment key field native payment key matching payment notification extension module validate reference field makepaymentrequestreference handling payment avoid unnecessary call adyen payment key set make payment handler also makepaymentrequestreference validated avoid mismatch notification native payment key fetch payment first find payment key keymerchantreference find payment corresponding transaction interactionid interactionidpspreference consequence easier fetch key rather custom field also key indexed field key performant payment key unique payment possible set key mypayments endpoint prevents default changingremoving key accidentally secure custom field custom field might changed mypayment endpoint check detail httpsdocscommercetoolscomapiprojectsmepayments please refer matchingadyennotification latest change regarding matching notification payment
runner runner application live form metadata generated building form create interactive online form current runner codebase nodejs form published self contained form running ingres url service namespace formbuilderservicesliveproduction current runner work reason current architecture designed collaboration security team keep form distinct entity form scaled independently error one form impact form rebuild runner team embarked changing offering moving towards self service model current editor could fulfil replacing storage mechanism gtithub storage first part adr current runner editor live form preview exactly representation live form code review code base felt rewriting service would beneficial following reason editor developed different technology making complicated runner preview form within editor current codebase work well exactly expected difficult follow make change noticeable lag page form runner architecture runner kept single tenant allowing published form run independently design runner also change well technology nodejs codebase ruby rail create new runner editor tech team experience ruby enabling quicker development feature roll metadatapresenter ruby gem take valid form metadata json format convert valid html govuk design system component gem consumed runner preview feature new editor runner provides form metadata startup presenter defines route flow connection backend service comms hold asset
kotlin android development concept start implement new application mobile chose new modern technology longterm development application various functionality cool feature besides plan develop many mobile application base first success application advantage compatibility compatible jdk older device arent left behind performance par java interoperability inoperable java including annotation footprint runtime library kotlin tiny compilation time there little overhead clean build way faster incremental build learning curve easy learn especially people modern language java kotlin converter intellij android studio make even easier also mix kotlin java project take time learning kotlin add feel comfortable kotlin supported advertised google android editor chose kotlin develop first android application way keep tech longer target development consequence advantage kotlin language easier maintain save time development android application keep technology key point develop feature application
ruby rail application adr outlined overall technical approach data submission service highlighted component expect developed adr focus technology choice building portion application particular submission app public facing frontend supplier submit return administration app frontend staff support operation service onboarding app frontend staff manage onboarding new supplier commercial agreement data storage api api three application store retrieve data language framework choice many possible language framework choice development application service existing miso service built aspnet service mixture php javaspring digital marketplace python govuk mixture ruby rail sinatra python make language framework consider skill current team available build service current team comfortable skill future team large enough pool supplier contractor could support main service future external toolkits module useful toolkits module could reduce development effort govuk frontend toolkit cost cost developing way licence cost hosting would picking language restrict hosting consider service manual guide choosing technology ruby rail application data submission service development team working choice large community developer inside outside government ruby rail government digital service consequence choice affect future support application require knowledge ruby rail
adr apis live together top level folder protobufs describe apis config service talk client generated protobuf file deploymentservice protobufs config allow user configure work flaw first clean separation service implementation api mean certain service update service api dependent service must rebuilt similar thing true config deploymentservice end depending service chaining cause deploymentservice rebuilt define apis config toplevel api directory toplevel api directory subdirectory external public facing api currently exposed automategateway internal api definition service config config definition service global config definition service want communicate client internal api subdirectory taking dependency service must update expeditorconfigyml file information component service dependency component service expeditorconfigyml file
faa problem statement execute variety different function based different messaging pattern want function service faa approach driver must support kubernetes must support kafka trigger event well known proven solution support common programming language least java python javascript support serverless framework considered openfaas openwhisk kubeless knative serving outcome want openfaas pro con openfaas good support kubernetes via faasnetes installation via helm kubectl via openfaas operator good support serverless framework good easy serverless framework good simple architecture well understood good support kafka via kafkaconnector openwhisk good support kubernetes installation via helm good support serverless framework good mature serverless framework supported apache foundation backed ibm bad complex openfaas leverage many component couchdb kafka nginx redis zookeeper kubeless good integrates natively kubernetes crd good support serverless framework good doesnt require extra tooling kubectl enough good kafka messaging system event trigger bad isnt mature openfaas openwhisk documentation isnt good others knative serving good baked google good support kubernetes good knative eventing support kafka event bad requires istio bad complex openfaas
thredds serve netcdf data noc case requires access large netcdf dataset currently stored archer system current usage requires data extracted shell script process take long time identify better way access dataset allow datalabs environment make best decided thredds server present unified view dataset provide significant performance improvement manual scripting order achieve data moved jasmin group workspace gws allow provision thredds server jasmin managed cloud consequence better access noc wave dataset able datalabs environment identify performance gain current access method duplicated wave dataset jasmin environment may cause long term management issue particularly ensuring monthly update applied
framework tool within tool section raster foundry provide interface allows linking user resource raster foundry various processing tool easily create imagery processing pipeline browser dragginganddropping component diagramming interface user able specify source fed processing tool whether output tool routed another processing tool new source imagery already existing robust wellmaintained opensource framework allow focus effort building interface built around diagramming framework rather reinvent wheel previous research phase modellab extensive research done topic see original modellab issue following framework evaluated jointjs cytoscapejs drawd visjs jsplumb blockly research jointjs emerged recommended choice build research reevaluate recommended library ensure remains best choice given current architecture raster foundry finalize jointjs several key feature jointjs make viable completely interactive element link custom shape element link smart routing link avoid collision builtin json deserialization graph event driven touch enabled fully evented nature jointjs make ideal integration example jointjs emits unique event following interaction element element connected link position change including zaxis angle change size change attribute change embedding another element embedding another element transition startend case initial recommendation made jointjs provide automatic layout element must explicitly positioned development jointjs continued regular pace jointjs also commerical extension rappid ensures level commitment library commercial offering add feature arent necessary raster foundry prebuilt widget interaction component integration integration jointjs raster foundry would done manner similar leaflet component could created handle encapsulation library management necessary binding initial diagram data json could passed component via oneway binding change diagram would trigger updateworkflow function could parse data persist resulting workflow rfworkflowdiagram initialdiagramctrlcurrentworkflowjson ondiagramchangectrlupdateworkflowdiagramjson rfworkflowdiagram complex interaction workflowservice singleton could utilized manage processing workflow state handle communication various workflow construction component list tool user access current diagram jointjs emits event essentially interaction therefore wrapping servicecentric angular component straightforward rfworkflowdiagram initialdiagramctrlcurrentworkflowjson workflowservicectrlworkflowservice rfworkflowdiagram initialization component would create necessary event listener would send relevant event data workflowservice jsplumb jsplumb like jointjs wellmaintained commercial wrapper also lightweight dependency html rather svg element however unlike jointjs api straightforward additionally opensource version lack much useful functionality jointjs provides pan zoom json deserialization make feature available commercial version integration integration jsplumb would follow method described jointjs jointjs remains best choice diagramming framework raster foundry tool straightforward api useful opensource version make optimal usecase documentation example also help propel integration library implementation tool jointjs also provides mechanism ingesting json intialize graph greatly ease many aspect integration consequence greatest challenge result building layout logic diagram design building interface allow user add source tool processing flow also familiarize jointjs api highquality documentation ease burden
resolving api key convenient system managing api key python client system give user multiple providing api key making request api include storing api key user system reading api key environment passing api key directly api request method user may multiple valid api key associated account given time system storing api key user system must accommodate provide clear deterministic way resolving api key given project anticipate store data related radiant mlhub unrelated authentication instance may track progress downloads resumed interrupted may want specify base url config file developer test staging environment method choose storing api key user system must preclude storing additional information python client resolve api key request following order passing apikey argument directly method setting mlhubapikey environment variable passing profile argument directly method read api key given profile see detail setting mlhubprofile environment variable read api key given profile see detail api default profile profile stored mlhubprofiles file user home directory file ini file containing least default section apikey value file may contain section corresponding named profile profile argument passed method must correspond one section name raise exception consequence user single api key able save default profile mlhubprofiles file user directory project access api key user projectspecific api key specify named profile someproject mlhubprofiles file user finergrained control api key specify environment variable argument request method user knowledge guidance syntax mlhubprofiles file order configure correctly also guidance generate andor find api key outside python client ini file mean configparser module python standard library removing additional dependency like toml additional configuration base url added config file additional file written mlhub directory without affecting authentication flow
nats connection metadatavalue author jarema implemented tag client server spec revisiondateauthorinfo jarema initial draft summary document describes client connect nats server nats cluster includes topic like connection process reconnect discoverability node cluster motivation ensuring consistent way client establish maintain connection nats server provide consistent predictable behaviour across ecosystem guidelevel explanation establishing connection todo add websocket flow minimal example client initiate network connection server server responds info json client sends connect json client server start exchange pingpong message detect connection alive note client set protocol field connect equal greater server send subsequent info ongoing connection client handle appropriately update server list server info auth flow todo two flow available server enable standard nats explicit method available nats server version client initiate network connection server server responds info json server info contains tlsrequired set true client requirement set true client performs upgrade client sends connect json client server start exchange pingpong message detect connection alive first implicit method available since nats server two prerequisite method server config enabled handshakefirst field block client set tlsfirst set true handshakefirst possible value false handshake first disabled default value true handshake first enabled enforced client flow fail connect duration hybrid mode wait given time allowing client follow tlsfirst flow duration expired info sent enabling standard client flow auto default value default wait upgrade sending info flow flipped established server sends info client initiate network connection server client upgrade connection server sends info json client sends connect json client server start exchange pingpong message detect connection alive server discovery note server send back info server sends back info may contain additional url client make connection attempt client store url reconnection strategy client turn advertised url default url todo add indepth explanation topology discovery work reconnection strategy progress ondemand reconnect client way allows user force reconnection process useful refreshing auth rebalancing client triggered client drop connection current server perform standard reconnection process mean subscription consumer resubscribed work resumed successful reconnect reconnect respected client mean reconnect method clientconnection handle detecting disconnection two method client detect disconnection missing two consecutive pong server number missing pong configured handling error network connection reconnect process client detects disconnection start reconnect attempt following rule immediate reconnect attempt client attempt reconnect immediately finding disconnected exponential backoff jitter first reconnect fails backoff process kick default jitter also included avoid thundering herd problem server returned additional url client try reconnecting random order server list unless randomization disabled client successful reconnect reset timer upon reconnection client resubscribe created subscription change connection state connecteddisconnected client way notifying user callback function idiomatic mechanism given language reporting asynchronous event disconnect buffer client buffer aggregate message client side case disconnection fill buffer send pending message soon connection restored buffer filled connection restored publish attempt return error noting fact referencelevel explanation client although client provide sensible default handling connection many case requires tweaking list defines changed mean default ping interval default minute client server might know connection severed nats pingpong protocol client set interval send ping server expecting pong two consecutive pong missed connection marked lost triggering reconnect attempt worth noting shorter ping interval improve responsiveness client network issue also increase load whole nats system network added client max ping default set number allowed outstanding pong response client ping marking client disconnected triggering reconnect retry failed initial connect default false default client make connection attempt fails connect return error many scenario user might want allow first attempt fail long client continue effort notify progress enabled client start initial connection process return standard nats connectionclient handle background connection attempt continued client wait first connection succeed fail network scenario take much time first attempt fails standard reconnect process performed max reconnects default none specifies number consecutive reconnect attempt client make giving useful preventing zombie service endlessly reaching server also footgun surprise user expect client give entirely connection timeout default specifies long client wait network connection established language hang eternally timeout mechanic might necessary others network connection method might way configure timeout custom reconnect delay default none finegrained control reconnect attempt interval needed allows user specify one implementation make sense given language example callback reconnectattempt int duration disconnect buffer given client support storing message disconnect period allows tweak number stored message also allow disable buffering entirely required default false set client enforces whether server also requires scheme connection string also enforces ignore advertised server default false connecting server may send back list server cluster aware helpful discoverability remove client pas server connect also may unwanted example server url unreachable given client retain server order default false default many server address passed connect string array client try connect random order help healthy connection distribution specific case list treated preference list randomization may turned function expressed enable retaining order disable randomization depending idiomatic given language protocol command grammar info linklink send server establishing depending flow contains information server nonce server url client connect connect connect send client response info contains information client including optional signature client version connection ping pong mechanism detect broken connection may reported network connection given language server sends ping client answer pong client sends ping server answer pong two configurable consecutive pong missed client treat connection broken start reconnect attempt default interval ping minute error handling todo server respond authorization error security consideration discus additional security consideration pertaining implementation connection handling future possibility smart reconnection could potential big improvement
systemvehicule test supercedes record architecture issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
convert static website document outline convert careersmozillaorg django website static website current architecture career django based website hosted two cluster fetch job posting greenhouse polling api every minute two mariadb instance master replica autoreplicating setup store fetched job posting convert static reduce hosting complexity two hosted apps backend couple bucket cdn similar reduce hosting cost cluster elbs database reduce code maintenance cost urgent python upgrade security vulnerability overall engineering time enables consider historically career admin interface submit university day replaced static file named universityeventsyml also career setup multilocale support enus ever implemented plan support locale future there currently site functionality requires dynamic backend site get rebuilt pushed static html whenever universityeventsyml change job posting greenhouse get created updated deleted build hosting discussed number generating static site including cron job apache airflow google cloud composer github action travisci aws lambda circleci gitlabci jenkins would work want move away current jenkins instance static site would hosted cloudfront cdn front another suggested netlify take care generation hosting website since netlify brought time possible solution meao project make good candidate try lower profile site compared property like careersmo netlify offer compelling set feature including webhooks directly triggering build greenhouse custom http header certain path like feed issue motivating influence constrains key point taken consideration green house integration includes parse logic normalize format posted job well rewrite integrate static site generation tool django site work fine well maintained upgraded minimal effort django soon see lts release supported least april limited engineering time devote effort agreed continue maintain django project upgrade django lts release create script generate static copy django site along required build acceptance test verify build correct netlify host generated static copy django project setup webhook greenhouse netlify update site whenever job post get updated setup webhook trigger daily site rebuild addition greenhouse webook monitor dead man snitch consequence risk site update greenhouse update site update triggered webhook executed greenhouse every job post updated event cause failure greenhouse retry webhook exponential backoff theory enough ensure site remains updated test real deployment
hostname resolution metadatavalue author kozlovic approved tag client problem statement client library take random address performing host name resolution prior creating tcp connection prior work client host name resolution shown shuffle list unless norandomize enabled shown design library create tcp connection given host name name resolution must performed list returned randomized unless existing norandomize enabled could introduce new specific list opposed server url provided user connection happen order shuffled list stop soon one successful driven fact client behaves described user shown interest client behaving way user dns order almost never change client library performing randomization would cause client connect server consequence considered change client library since changing default behavior strongly felt new default behavior optout existing norandomize new introduced disable new default behavior
separate api userfacing application amended allocation api responsibility amended unify api presentation layer moving beta allocation first area work manage offender custody team also discovery handover area know little stage intend look future anticipate build one product part work meet different different user mean likely build one application part larger service area future decide whether start building one application allocation follow common pattern separating api layer presentation microservices many advantage microservices architecture also cost start one application make early responsibility may take work change later learn hand start one application decide later want split several work likely substantial given timescales involved omic may hard prioritise paying technical debt becomes burden anticipate service allocation data likely make accessible via apis stage anyway service may access allocation data different way frontend work may needed support even api start operating microservices microservices introduce operational complexity moving function call network call introducing moving part deployed however expect number microservices remain relatively small anticipate complexity significant choice kubernetesbased cloud platform hosting see adr make easier scale small service efficiently independently also give easy access tooling designed support many small service expect far follow microservices approach minimal impact hosting cost start two application allocation allocation api call apis read data nomis future delius oasys allocation frontend call allocation api serve progressively enhanced html user see adr consequence clear separation data presentation concern start define approach api early team data well make easier team contribute allocation api starting one service ensure choose tooling workflow support multiple service start make easier spin new service area work manage offender custody
adr drawing subtask created january updated april drawing mark subtask designed support volunteer answering additional question drawing mark annotation allows single choice multiple choice question task text task dropdown task slider task annotation json structure current subtask annotation json structure json point subtask consisting question task dropdown task annotation task value frame tool detail value value value value value null frame tool detail value value value value value frame tool detail value value value value value annotation structure subtask detail issue solely relies array index relate back original subtask make difficult make downstream analysis aggregation script aggregation code parse detail array make mock annotation correct structure passed along next reducer subtask subtask positioned fixed relative position mark notably transcription project commented interferes able transcribe successfully since dialog may cover part subject cannot moved without moving drawing mark initial support support single multiple choice question task text task subtask slider task may deprecated dropdown task may changing way plan yet supported later make sense add annotation json structure annotation detail array updated object contains reference subtasks unique identifier task annotation stored classification annotation array flattened main benefit reorganization downstream analysis aggregation aggregating drawn shape first step clustering cluster found subtasks aggregated within cluster easier structure subtask annotation task asked code take subtask annotation within cluster pas reducer list main task annotation without reshape addition markindex added subtask annotation purpose identifier relating back parent drawing task annotation value array represents mark example new subtask annotation json structure classification submission json annotation task tasktype drawing value frame toolindex tooltype point detail task task frame toolindex tooltype point detail task task frame toolindex tooltype point detail task task task tasktype single markindex value task tasktype dropdown markindex value value value value null task tasktype single markindex value task tasktype dropdown markindex value value value value task markindex tasktype single value task markindex tasktype dropdown value value value value metadata classifierversion subtask identifier follow convention taskkeytoolindexdetailsindex note structure classification submission classifier internal store model may difference purpose keeping track inprogress annotation mark made drawing subtask change adopt design antislavery manuscript asm generalized design pseudomodal notable difference true modal initial position near associated mark made interaction allowed image toolbar allow zoom rotate well opening tutorial field guide task help submission classification allowed subtasks required modal closeable required annotation made mark deleted cancelled dialog moved resized support movability resizing leverage reactrnd library asm grommet layer cannot since intended actual modal side panel cannot arbitrarily positioned moved consequence flattening annotation array drawing task subtasks conceptually consistent move workflow step flatten combo task however breaking change change communicated project builder classification new classifier checked presence classifierversion classification metadata future would also like include link json schema annotation type recommended adr flattening also added benefit panoptes generating classification export parse flattened array convert machine readable string human readable string task without check value nested detail array traverse raw classification export also benefit researcher want analyze outputted csv directly prefer flatter json structure flat structure facilitate research team able load data without jsonbased manipulation many team would benefit ability readin csv excel start analyzing result opposed needing first parse json still json structure csv export contribute toward minimizing transcription task automatically configured drawing task subtask new variant text task includes autosuggestion caesar reduction subtask suggested change adr well aggregation aggregation caesar code needed updated accommodate new annotation structure subtasks implement change sample extractor reducer new code setting extractor set extractor url encode keywords json task shape point detail ttoolindexsubtask questionextractor ttoolindexsubtask dropdownextractor ttoolindexsubtask questionextractor ttoolindexsubtask dropdownextractor look like httpsaggregationcaesarzooniverseorgextractorsshapeextractortasktshapepointdetailsbttoolindexsubtaskaquestionextractorcttoolindexsubtaskadropdownextractorcttoolindexsubtaskaquestionextractorcttoolindexsubtaskadropdownextractord although expect decoded url would also work tested httpsaggregationcaesarzooniverseorgextractorsshapeextractortasktshapepointdetailsttoolindexsubtaskquestionextractorttoolindexsubtaskdropdownextractorttoolindexsubtaskquestionextractorttoolindexsubtaskdropdownextractor keywords define task shape drawing tool extractor subtasks example two point tool task question subtask followed dropdown subtask subtasks explicitly defined detail keyword ignored extracted setting reducer reducer url pram also detail section format extractor example dbscan reducer keywords would look like default cluster params json shape point detail ttoolindexsubtask questionreducer ttoolindexsubtask dropdownreducer ttoolindexsubtask questionreducer ttoolindexsubtask dropdownreducer encoded url would httpsaggregationcaesarzooniverseorgreducersshapereducerdbscanshapepointdetailsbttoolindexsubtaskaquestionreducercttoolindexsubtaskadropdownreducercttoolindexsubtaskaquestionreducercttoolindexsubtaskadropdownreducerd decoded url httpsaggregationcaesarzooniverseorgreducersshapereducerdbscanshapepointdetailsttoolindexsubtaskquestionreducerttoolindexsubtaskdropdownreducerttoolindexsubtaskquestionreducerttoolindexsubtaskdropdownreducer
contentful page content several contentonly page served page table page within app mirror page within contenful allows content designer via contentful ability edit add delete page without help developer remove highvoltage rely final generic route directs pagescontroller slug retrieve page tpages consequence possible content designer name page slug clash route within app rail prioritise routing generic routing issue apparent early testingqa easily fixed renaming
api structure tdr store information consignment file relational database updated user make change tdr frontend backend processing result antivirus scan rather connect application database several disadvantage requiring multiple application secure connection coupling structure building api called application tdr alpha prototyping phase looked building api rest graphql style see alpha note graphql rest graphql prototype full api alpha prototype built graphql scala sangria library prototype rest api developer team familiar rest previous project graphql tdr beta phase found sangria straightforward work alpha prototype simple define field generate graphql schema add deferred resolvers avoid overfetching lack mature graphql client library scala came working approach prototype defining individual query validating schema sbtgraphql tdr api internal api likely stay way tdr temporary record store transferred tna moved preservation system eventually access system let people see data access system may well public api data come directly tdr dont expect choice tdr api constrain future apis make tdr api good candidate testing slightly experimental approach graphql rather wellestablished pattern rest without impacting system turn harder work aware government department considering graphql also good opportunity share learn developer across government team still concern around graphql particularly around error handling rest wellestablished convention around error code usually understood layer caching graphql allows finegrained error handling decide custom error handle client application keep eye beta see work practice
adr implementing workflow new classifier created july updated september current classifier based assumption accurate time became outdated additional functionality added workflow step consisted single annotation action however project builder wanted annotate via drawing selecting list single step gave rise combo task would always want show summary hide classification summary tool became public project actually wanted expected wouldnt show information volunteer end changed firstly intervention experiment later feedback shown workflow task completed combo task drawing subtasks specifically create issue since task array becomes list task reference task code sus task combo take normal workflow sequence requires disproportionate amount code amount edge case term project building example combo task one drawing task defined subtasks javascript displayname combo task test task help task type drawing tool type point color label tool name detail instruction task type combo task help task type drawing tool type point color label tool name detail help type single answer label foo label bar question required true instruction task firsttask prioritized false grouped false pairwise false configuration implement classification process like classification subject consist series step single step consists task hook notification hook task hook consists array one workflow task notification could intervention feedback sugar notification information conveyed volunteer practice probably mean current workflow store store resource panoptes api project workflow loaded derive store workflow step drive user interface workflow resource updating support new step structure discussed zooniversefrontendmonorepo workflowsteps map stored mobx observable map almost feature map supported major browser support value keyvalue pair object taskkeys set array task key optionally next property step key optionally defined next step support recursive workflow order otherwise assumed order step map key map ordered key added object thus iterating map object return key order insertion since order reliably derived step map drop workflowfirsttask workflowtasks remain backwards compatibility single question task branching still next property answer object set step key instead task key step taskkeys property set summary load optional summary step end classification shift summary optin rather optout present summary display example could look like javascript task answer label yes next branching single question task label next type single step taskkeys taskkeys taskkeys next recursion back step taskkeys summary consequence fundamental change way structure classifier devs educated change request update add step property workflow resource json directly support map storing database involve one two first try javascript helper library full support map serialize object map subclass object json parse back map would probably preferred since would make sure serialization parsing consistent key string would straight forward conversion standard object manage type conversion wed choose storing array object stringifying example httpalitycomesmapjsonhtml httpexploringjscomeschmapssetshtmlarbitrarymapsasjsonviaarraysofpairs since task object changed backwards compatibility classifier export aggregation confirmation implementation able describe step task notification serializable format plain unique name string requirement mobxstatetree step task notification converted map needed programmatically provide serializable key mobxstatetree project builder update able group task step design time early idea kanban style representation step new workflow editor
corvustenancy provides wrapper facilitate transition described adr corvustenancy create storage container automatically corvustenancy introduces change application responsible creating necessary container onboarding client creates challenge application already deployed following thing may true tenant may exist subset storage container exist nodowntime migration compute farm may mixture component enable application currently corvustenancy migrate without disruption clearly defined path system upgraded upgrade multiphase approach single compute node application step nothing library mostly see mode library onboarding new client style config available falling back config autocreation container config available library nontransitional mode phase would run tool transition configuration tool completed work free move phase there particular hurry move final phase tenant configuration migrated there behavioural difference phase main motivation moving phase enables application remove transitional code transition complete phase might occur year phase example library marain enable developer host instance service might choose retain transitional code long time give customer library time complete migration support zerodowntime upgrade necessary support state compute node particular store mixture two adjacent phase move period time node still phase phase however avoid ever three phase simultaneously example wait compute node completed move state moving state following section describe behaviour required state support transition there nothing document phase thats system already today behave phase library operating mode node phase upgraded library transition support essentially operating mode never create new configuration new tenant continue onboarded way librariesthe application precreate container expects tenancy library create demand required give application lowimpact way upgrade library without changing behaviour also open path migration towards new style operation one difference behaviour reason describe mostly mode configuration present particular configuration key following effect application configuration even look see configuration present application presume relevant container configuration already created attempt create anything demand necessary support case node completed transition phase none phase moved phase node still phase point able cope possibility client onboarded phase node configuration available expect configuration present particular container point migration tenant onboarded way configuration start node reached phase configure node run mode storage suitable transitional interface iblobcontainersourcewithtenantlegacytransition application must provide two configuration key one configuration one configuration transitional adapter never create configuration look look configuration configuration present phase library operating mode falling back necessary node phase library onboarding new tenant precreates necessary container store config still transition support case existing tenant configuration available fall back old behaviour difference phase phase application onboards new tenant phase transitional adapter exactly way configuration migration node phase tool run upgrade configuration aspect tooling necessarily applicationspecific application know discover tenant application know configuration storing key
idempotency key approved payment modification action post request post idempotent definition therefore default possible retry payment modification request fail want avoid unwanted duplication example partial capture get timeout error adyen could cause doubleprocessing request retry adyen consider retry request new partial capture request enable retry failure payment modification idempotency key sent every request idempotency key sent header idempotencykeykey unique per request retry request idempotency key payment modification action currently supported adyenintegration could affected idempotency problem partial capture partial refund payment modification triggered adding payment transaction new string custom field called idempotencykey added payment transaction custom type keyctpadyenintegrationtransactionpaymenttype field idempotencykey present payment transaction adyenintegration take value send value idempotencykey header source httpsdocsadyencomdevelopmentresourcesapiidempotency
parcel boundary map source may improve usability map required include parcel boundary default layer data currently provides mapping layer includes parcel boundary openmapsgovbcca add data openmaps parcel boundary layer default map consequence adding additional layer map increase amount data requested displayed make user experience slower improve view property information boundary
kotlin project language free pick jvm language static typing developer expected background jvm language except java kotlin look like better java painless onboarding scala radical move towards functional paradigm adopt kotlin project language consequence project migrated kotlin
multiplelabelitems title multiple label item proposed mlaoi item able bring multiple label would useful feature training multiclass classifier one imagine label stac item building separate stac item field stac item link object array many label item could linked single mlaoi stac item limiting single label link limiting single label link however appealing label item metadata could copied mlaoi item would remove follow link label item processing practice would make mlaoi item also label item allowing reuse tooling understands label multiclass label dataset would required would mechanical preprocessing step combining existing label single stac label item could mean either union geojson featurecollections per item configuration complex stac label item link multiple label asset allowing multiple label main appeal consuming multilabel mlaoi item would allow referencing multiple label source could external without preprocessing thus minimizing data duplication multiple label allowed mlaoi preprocessing step would pushed mlaoi consumer consumer would appropriate metadata order decipher label structure would require either crawling full catalog kind metalabel structure combine metadata included label single structure could interpreted consumer mlaoi item limited linking single label item requiring consumer interpret multiple label item pushed unreasonable complexity user additionally combining label likely requires series processing validation step one would likely require judgment call exception instance combining building field label datasets user check building field polygon overlap realistic expect possible requirement process expressed simple metadata structure therefore better explicitly require label combination separate process done user resulting label catalog capture design iteration required process anyway consequence mlaoi item copy label extension property label item effect mlaoi item extends label item adding link feature imagery formulation line original problem statement mlaoi extension
language window manager deciders andreas tennert problem statement language shall development window manager driver want learn kotlin want learn python dont want take care update api layer window manager code library display management tooling area usually written considered kotlinjvm kotlinnative python outcome chosen kotlinnative compiles fast native code capis directly positive consequence capis directly converted automatically tooling compiles fast native application extra api layer negative consequence separate compiling every machine type pro con kotlinjvm good good knowledge java java library good byte code working every machine jvm good automatic garbage handling good meet kotlin learning goal bad extra api lib potentially loosing support update bad jvm kotlinnative good framework needed run interpreter virtual machine fast good direct capis good meet kotlin learning goal bad resource aqcuired via library cleaned manually bad compiled machine type separately python good run machine python interpreter good automatic garbage handling good meet python learning goal bad might little slow interpreted language bad extra api lib potentially loosing support update
adopt kotlin kotlin become language choice back end development within hmpps digital adopt kotlin preferred language new code within courtcaseservice practical migrate class change consequence developer focus key kotlin skill beneficial long term ability kotlin feature including inherent null safety immutability codebase become hybrid kotlin java code there risk detrimental maintainability jpa present challenge kotlin poorly implemented could negatively impact application stability last point main risk also one developer going become comfortable time anyway work new project mind particular care taking adopting kotlin jpa entity data class purpose doubt team discretion may appropriate continue java preference kotlin particularly kotlin considered risky prohibitively difficult compared expected benefit
confirm performance issue optimizing multiple equallyeffective way implement many feature case straightforward implementation might involve making api call strictly necessary tcdatasetcreate make additional call retrieve created dataset server construct returned dataset simplest understandablywritten implementation feature prioritized performance reducing number api call real performance issue identified optimization done asneeded basis consequence function unnecessarily optimized cost readability
jetstream direct get metadata value author ivan derekcollison alberto tbeets ripienaar implemented tag jetstream client server revision author info tbeets initial design ripienaar add multi batch behavior server motivation initial design jetstream reading message stream directly via consumer delivery thought administrative function api read routed current stream leader underlying stream store read call tracked administrative incur tracking overhead case notably key get stream materialized view desirable spread message read load multiple server accessing message store local bypass administrative api overhead feature direct get jetstream direct get feature enables stream peer stream leader respond stream read call service responder queue group responder source local message store direct get number server eligible respond read request replica count stream extended feature mirror direct get responder stream direct get enabled also upstream source mirror stream mirror peer server also participate responder queue group direct get call upstream manner message read spread many additional server mirror cluster upstream server respond direct get request upstream strategically placed client latencyreduction different geographic location serving distributed client also read availability enhanced mirror may available client upstream offline note readafterwrite coherency existing get api jsapistreammsggetstream provides readafterwrite coherency routing request stream current peer leader single server client publishes message stream ack assured subsequent call get api return message read server defines current contrast direct get assure readafterwrite coherency responder may nonleader stream server may yet applied latest consensus writes mirror downstream server yet consumed latest consensus writes upstream implementation stream property allow direct stream configuration add new allow direct boolean property allowdirect allow direct always set true server maximum message per subject maxmsgspersubject configured max limit specified user pass allow direct explicitly stream create edit request value overriden based maxmsgspersubject allow direct set automatically based inferred case stream maximum message per subject telltale stream bucket direct get api allow direct true stream server configures responder subscribes jsapidirectgetstream fixed queue group sys note allow direct false responder direct get api stream client make request receive reply message time request client may make request payload get message api populating following server struct text seq uint jsonseqomitempty lastfor string jsonlastbysubjomitempty nextfor string jsonnextbysubjomitempty batch int jsonbatchomitempty maxbytes int jsonmaxbytesomitempty starttime timetime jsonstarttimeomitempty example request payload seq number get message sequence lastbysubj string get last message subject nextbysubj string get first message lowest seq specified subject starttime string get first message newer time specified rfc format since server seq number nextbysubj string get first message seq input seq specified subject seq number batch number nextbysubj string get batch number message seq specified subject seq number batch number nextbysubj string maxbytes number limited maximum size message received byte subjectappended direct get api purpose form environment may choose apply subjectbased interest restriction user permission within account andor crossaccount exportimport grant specific subject stream may read subject stream allow direct true stream server also subscribe jsapidirectgetstream fixed queue group sys request api endpoint interpreted shortcut lastbysubj request lastbysubj derived token series token following stream name rather request payload error client call subjectappended direct get includes request payload batched request batch maxbytes key one request multiple message single api call server send multiple message without flow control reply subject send maxbytes message maxbytes unset server maxpending configuration setting server default currently batch sent zero length payload message sent natsnumpending natslastsequence header set client determine batch call needed would also header set description header eob request made server support batch first response received nothing follow old server detected absence natsnumpending header first reply multisubject request multiple subject requested manner batch requested mode support consistent point time read allowing group subject read point time assuming stream hold enough historical data help inform proper feature consumer multisubject request may allow matching subject result reply request like multilastkvusers latest value subject wildcard returned specific data user could requested multilastkvusersname kvusersaddress rather getting user data value two specific key returned facilitate consistent multi key read uptoseq uptotime key added restrict result certain point time imagine new bucket nats put user name bob message seq nats put user surname smith message seq nats put user address main street message seq nats put user address oak lane message seq update message normal multi read multilastkvusers would get address oak lane returned however get record certain point past could supply sequence time adding uptoseq request return address main street along data likewise assuming noticeable gap time changing address uptotime could form temporal querying batch parameter added restrict result set certain size otherwise server decide end batch eob marker message seen batched mode addition natsuptosequence header server cannot send data respond like batch zerolength payload message including natsnumpending natslastsequence header enabling client determine batch call needed addition would also header set description header eob natsuptosequence header set indicating last message stream matched criterion number would subsequent request uptoseq value ensure batch multigets done around consistent point time response format response may include code indicates end batch message description header would value eob request valid matching message found stream request empty invalid multi subject get match many subject error code returned header nats bad request success returned nats code direct get reply contain message along following message header natsstream stream name natssequence message sequence number natstimestamp message publish timestamp natssubject message subject natsnumpending batched number message left stream matching batch parameter natslastsequence batched stream sequence previous message natsuptosequence multi subject get sequence following request ensure consistent read regular jsonencoded nats message returned stream store example call direct get lastbysubj request text pub jsapidirectgetkvmykv inboxztubeqxiczlnaiueipqmmlzadfe lastbysubjkvmykvmykey reply text hmsg inboxztubeqxiczlnaiueipqmmlzadfe nats natsstream kvmykv natssubject kvmykvmykey natssequence natstimestamp utc hello direct get nextbysub starting seq request text pub jsapidirectgetkvmykv inboxpodfghxuaxqsjwrawoyxjczucy seq nextbysubjkvmykvmykey reply text hmsg inboxpodfghxuaxqsjwrawoyxjczucy nats natsstream kvmykv natssubject kvmykvmykey natssequence natstimestamp utc goodbye subjectappended direct get request text pub jsapidirectgetkvmykvkvmykvmykey inboxqoxafqhfzqnnqrgnplgdypxjry reply text hmsg inboxqoxafqhfzqnnqrgnplgdypxjry nats natsstream kvmykv natssubject kvmykvmykey natssequence natstimestamp utc hello illegal subjectappended direct get request text pub jsapidirectgetkvmykvkvmykvmykey inboxnogkopzkewtqhfhfiujvyoteep seq nextbysubjkvmykvmykey reply text hmsg inboxnogkopzkewtqhfhfiujvyoteep nats bad request
aleph circrequests denied entry handling june superseded alephcircrequestsdeniedentriesresubmissionmd circrequests assumed aleph always provides complete list hold hold considered valid long list provided aleph described alephinteractionassumptionsforcircrequestsmd originally thought necessary application track hold sent caiasoft well hold caiasoft denied resubmit caiasoft denies entry information denied entry presented caiasoft interface based discussion hilary thompson han breitenlohner repeatedly submitting denied entry caiasoft necessary merely add extra work clear caiasoft interface remove functionality track resubmits denied entry consequence application perspective information returned caiasoft regarding denied entry trigger special action denied entry displayed caiasoft interface assumed issue caused denial handled staff access interface
title iso millis datetime transfer weight problem statement question whether rest api return iso formatted string utc timezone unix time number millisecond since quite controversy httpsstackoverflowcomquestionsepochorisodateformat httpsnbsoftsolutionscomblogdesigningarestapiunixtimevsiso opinion iso format always utc better reason better readability elm folk side httpspackageelmlangorgpackageselmtimeiso httpspackageelmlangorgpackagesrtfeldmanelmisodatestringslatest one convert iso datetime string utc time epoch millis vice versa information iso string epoch millis avoid confusion datetime value encoding outcome epoch time every timestampdatetime value transfered unix timestamp reason elm application frequently calculate value render current waiting time etc better number without requiring parse first since written elm probably good adopt style
adr improvement time api internal representation serialization changelog created adr time type defined tendermint provide data type time calculation better safety ergonomics prostdictated timestamp struct defined tendermintproto based google common protobuf message description concern raised type api however currently lack wellsupported library rust ecosystem would provide desirable formatting serde enforce range usable value domain type seems necessary current api time following problem newtype struct publicly exposing datetimeutc inner value provided chrono crate chrono known issue soundness security eta yet getting fixed dependency chrono trigger cargo audit failure every project tendermint library range usable value supported time explicitly defined enforced currently time allows value cant valid rfc representation whose equivalent unix timestamp value allowed google protobuf specification timestamp serde implementation time proto timestamp struct always serialize expect value string even serialization format humanreadable allow efficient binary representation arithmetic operator provided time via addsub trait implementation however result output type surprising make poor usability overloaded operator arithmetic comparison operation much slower parsed datetime structure integer timestamp representation time meant performancesensitive workload operation datetime value offsetting duration time difference time comparison internal representation optimized integer arithmetic timeasrfc conversion method named improperly regard rust naming guideline make change possibly step make inner member time struct private specify datetimes year range inclusive represented time value match restriction specified google protobuf message definition timestamp remove conversion fromto chronodatetime introducing impls instead impl tryfromtimeoffsetdatetime time fallible due additional range restriction impl fromtime timeoffsetdatetime change serde implementation tendermintprototimestamp derivingviaconversions tenderminttime memberwise struct serialization nonhumanreadable serializers remove add sub impls time replacing operator overloading checkedadd checkedsub method fashion systemtime timeoffsetdatetime provides speed bump api user must take care potential range overflow way force parenthesis appended error handling cruft nested expression tree change internal representation time unix timestamp nanosecond rename timeasrfc back timetorfc also tendermintproto public helper function named serializerstimestampasrfcnanos similarly renamed proposed consequence positive time get clear purpose documented validity range implementation detail time made private changed future little breakage api consumer interfacing ecosystem library time computation made optional enabled via featuregated conversion particular chrono completely cut localtimer issue fixed giving tendermint library consumer cargo audit peace checkedadd checkedsub method replacing arithmetic operator time conventional chainable duration arithmetic integer timestamp value fast changing internal representation unix timestamp put treatment leap second outside tendermintrs making aligned representation time tendermint protocol none rust library explicitly support google hour linear smear standard utc chrono idea representing leap second rather complex hard correctly negative breaking change api application developer prefer chrono despite fault lose convenient way convert time chronodatetime timestampbased internal representation time memoryefficient parsed time struct inconclusive performance code retrieve human time representation time timestamp affected case supported internally redesigned time api parsing formatting including serde implementation humanreadable format case added conversion overhead negligible proportion parsingformatting logic application convert time value timeoffsetdatetime potentially chronodatetime foreign crate type may become popular future value computation reference issue httpsgithubcominformalsystemstendermintrsissues httpsgithubcominformalsystemstendermintrsissues httpsgithubcominformalsystemstendermintrsissues implementation httpsgithubcominformalsystemstendermintrspull
naming convention defines uri tag implement uri identifies data implement component named according naming convention uniform resource identifier uri string character unambiguously identifies particular resource guarantee uniformity uris follow predefined set syntax rule also maintain extensibility separately defined hierarchical naming scheme tag uri scheme consequence see also tag uri
merging diaperbase partnerbase singular application added late oct application originally two application diaperbase partnerbase lived different repos original separate application based security perk isolating data sensitive data would leak one application noticed cost maintaining two application outweighed benefit two application therefore decided merge two application merge two application unified application named human essential changed due inclusive serve period bank change came effective httpsgithubcomrubyforgoodhumanessentialspull merged consequence merging two application benefit reducing complexity ease maintaince however great deal refactor work needed remove old concept based two application aka redundant model interim data modeling confusing refactor
checker handling capitalisation regex matcher sentence start moment apply suggestion regular expression there sometimes unexpected side effect overwrite casing matched text example regex ibmediaeval note flag mean case insensitive always suggest word medieval cause problem word begin sentence end sentence medieval produce match suggesting medieval position refactor corpus capture group initial char appropriate example imedieaval replacement edieval possible arrive correctness way itll take long time corpus large havent annotated rule casesensitive replacement detect sentence start capitalise accordingly change corpus possibly edge case havent yet considered think detecting sentence start better fit large corpus take great deal work refactor possible automate part work must distinguish replacement care capitalisation whatsapp alsatian dog always lower case replacement dont medieval detecting sentence start allows make correct suggestion user missed capital sentence start offering replacement bonus shouldnt spend long corpus rule benefit case likely replaced dictionary approach sooner rather later consequence dont change corpus may encounter edge case result approach cummings start sentence result may way enforcing case sentence start
utility lazily initialized proposed mention synchronous utils intended command work adrs given project adr marker file since mandatory adr directory existing adrs initialized beginning object constructor several command script already include script initialize object script loading part require statement resulted loading whenever command loaded might performance implication immediate functional lacuna assumes loaded every time course assumption break running init command definition load init command creates resulted trying run init command existing directory error adr project loaded lazily needed assumes init command doesnt require hence invoke command require existing file command loaded still create object create instance actual loaded easily assumption seems safe enough since init command indeed creates adr file probably hold similar command command require adr continue today loaded lazily course make sure isnt createdcalculated every time called searching adr dir every time one utility function called word memoize contextcreating function consequence adr created necessary cached throughout command execution
title initial state loader area customerorder tag performance statemachine cache performance optimization noticed determination initial state state machine currently associated quite high database load although one must determined consequence checkout unnecessarily much load database caused order determine initial state must determined orderstate orderdeliverystate well ordertransactionstate machine responsible load shopwarecoresystemstatemachinestatemachineregistrygetinitialstate method usually follows php thisstatemachineregistrygetinitialstateorderstatesstatemachine contextgetcontextgetid thisstatemachineregistrygetinitialstateorderdeliverystatesstatemachine contextgetcontextgetid thisstatemachineregistrygetinitialstateordertransactionstatesstatemachine contextgetcontextgetid inside getinitialstate complete statemachine object loaded including transition state criterion new criterion criterion addfilternew equalsfilterstatemachinetechnicalname name setlimit criteriagetassociationtransitions addsortingnew fieldsortingstatemachinetransitionactionname addassociationfromstatemachinestate addassociationtostatemachinestate criteriagetassociationstates addsortingnew fieldsortingstatemachinestatetechnicalname since mean unnecessary load database deprecated method provided new smaller faster service furthermore usage core removed replaced new service php namespace shopwarecoresystemstatemachineloader class initialstateidloader implement resetinterface public const cachekey statemachineinitialstateids public function getstring name string issetthisidsname return thisidsname thisids thisload return thisidsname private function load array return thiscachegetselfcachekey function return thisconnectionfetchallkeyvalue select technicalname lowerhexinitialstateid initialstateid statemachine help service able reduce determination initial state load multiple cache shown invalidated dal written event statemachine entity
asset minimization may look like good idea make monolith compress retrieved asset saving page purpose reducing resulting document file size given main purpose program save page convenient store share manner mostly archiving tool aside able tell monolith exclude certain type asests image javascript would outside scope program implement code compressing asset minimizing file embedding reduce amount data transferred either separate tool later compress minimize page saved monolith needed consequence monolith support modification original document asset purpose reducing size sticking performing minimal amount modification original web page whatever needed provide security exclude unwanted asset type
data geocoder june presently submitting new property editing existing property within inventory way set latitude longitude value manually ideally inventory would location value pulled data better source truth providing way property address pull valid coordinate data geocoder would improve data user experience additionally geocoder verify address manually entered geocoder data api swagger developer api key api host httpsgeocoderapigovbcca integrate data geocoder api user type address list viable match displayed user selects one match set address coordinate consequence submitting new property editing existing property easier error prone coordinate tightly integrated single source truth therefore consistent authentic address value verified
adr handling plural label sometimes label handle pluralization could easy adding end word english french spanish language variation plural form require better handling exploration could pluralization library come cost added weight bundle well guaranteeing success complex string could also simply handle string translation file chose follow second approach add overhead bundle come cost contributor add plural version string want translated explicit approach also reduces risk error inconsistency consequence contributor make sure add keyplural version mapping singular version key translation file gettext method set third argument useplural true pas fourth argument count property decide string
adr mtl style effect superseded adr haskell way manage sideeffects particularly game bunch including mtl style everything freer monad havent mtl style anger yet yet keen give also steaing lot idea dinorush seems mtl style mtl style consequence going write lot class instance
command line processing package adt tool becomes complex processing argument associated subcommands also becomes complex requires programming effort proportion actual implementation functionality external package command line processing traditional apache cli library limited processing required subcommands decison picocli package fit well current architecture adr tool subcommands implemented seperate class consequence requires major refactoring code tool evolves complex handling argument added without extra code complexity
adr window presentation foundation wpf july touch table app support multi touch also robust enough handle various demand although initially considered model universe center table approach dropped didnt help accomplish learning goal given window device touch table must choose technology run machine although considering unity early planning phase dropped consideration due learning curve unity also dropped support javascript language team familiar transition javascript seemed jarring resource shared knowledge initial work table also done help florian block designed deeptree another app built wpf consequence fortunately documentation quite strong language allows enough flexibility fit table net community also active easy find answer obstacle would encounter development however wpf seems losing popularity many article concerning wpf written decade ago although stack overflow post year two old retrospect although concerned longevity wpf subsystem fit project also helpful panoptes net client available future project however discerning see many framework package wpf becoming deprecated silverlight microsoft surface sdk future think would worthwhile explore new technology however wpf suitable choice
quart http framework august pending order wrap flowkit toolkit single http api http framework required variety purpose flask django flask django offer significant plugin ecosystem battletested however heavy side bound legacy design two flask much boilerplate overhead quart considerably newer quart compatible flask ecosystem plugin built follow newer asgi standard lightweight offer impressive performance take full advantage recent addition asyncio python quart also support websockets immediate priority likely useful future dynamic iteration api quart become defunct close mapping flask api provides lowimpact exit flowkit api make quart framework consequence api implementation somewhat tied asyncio
plantuml diagramming amended plantuml diagramming stdlib issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
support external data store deciders nathan fiedler application handle several important piece information including requestuser mapping session state browser connection default information stored memory within application process however application fails another instance begin process request via load balancer login request still progress lost user get error try enable smooth failover ensure high availability external data store provided requestuser mapping session state stored store would configured like aspect application via environment variable configured existing inmemory data store default behavior simply storing data reliable fashion easily done disk file however application deployed several machine one machine disk file unavailable instance assuming local disk storage alternatively data stored separate system database keyvalue store database often complex set really necessary purpose application keyvalue store adequate question becomes keyvalue store ideally would popular mature well maintained would also actively maintained client library available node package best solution would one easy setup cloud computing service azure application offer support redis keyvalue store several reason choice redis popular well supported maintained year redis configured memoryonly filebased storage nearly cloud computing provider offer readilyavailable redis instance consequence development dockerbased redis container worked well enabling failover application link redis website noderedis github
viewmodel exposing whole state instead single data stream reverts adr saw result adr update stream mess read blog post regarding redux like android apps move back exposing whole state object viewmodel viewmodels exposing single state object sealed class handled fragment consequence viewmodel class refactored state class implemented therefore also unit test altered fit new logic
library handle many device one made purpose library collect together data one sensor device save data database periodically create send batch data processing library setup handle multiple device checking logging data device turn left application library pro multi device easier application developer provide access detail device away pro single device device may well different timing manage data different way two extreme data stored device collected daily device requires sampling second interval level complexity better handled application delay collecting data one device could knock effect collection interval another one keep simple library written one device future may add setting accomodate threading prof useful consequence
kotlin programming language choose main language app kotlin main language jetbrains summer practice ended simplify maintenance contribution jetbrains employee consequence favorite open source devops community may complicate contribution people outside jetbrains
postcodesio reverse geocoding coordinate provided browser reverse geocoded order identify country origin lookup service already employed lookup postcode place service postcodesio consequence place postcode location lookup performed service existing api client data nonuk location
static asset participant brice schaffner christoph bcklin servicestac serve static asset admin page image icon django appropriate serve static file production environment currently django served directly gunicorn good practice avoid issue slow client avoid denial service attack gunicorn served behind reversed proxy apache nginx clear yet reverse proxy really necessary architecture cloudfront kubernetes ingres decided whitenoise static asset middleware seems performs well cdn like cloudfront therefore serve static file simple take care compressing setting corrects header caching consequence might reconsider future reverse proxy gunicorn proxy nginx serve static file instead whitenoise reference static file made easy django compressor whitenoise aws cloudfront heroku isnt serving static file python horribly inefficient
model hub zoo download discussion proposed adam gibson jan model zoo hub web service different vendor provide venue researcher engineering team want open source work publish model case typically finetune model finetuning model mean adapting model trained one task generalize another replacing objective coupling binary file format distributing model file typically happens large binary file optional metadata case tensorflow onnx protobuf pytorch python pickle archive model hub provide sdks downloading model within python proposal goal interop model hub integrated python library add appropriate tooling converting model something consumable model import framework user able download model standard python interface modelhub modelhub implementation might look like python class modelhubobject def initself selfhuburl selfframeworkname def downloadmodelselfpath string def stagemodelselfmodel storage type specific model hub concrete function enums like specify underlying web service kind model want order load model model hub tends provide different way downloading model via compressed archive uncompressed order able specify access type enum python enum storagetype compresseduncompressed loading model done either samediff deeplearningj leverage extend existing work model import work built previously storage directory every model downloaded interface stored uncompressed format onnxpb file original name standard unified directory separated framework ensures ease debugging case user want directly import model view model viewer like netron directory default modelhub directory user user also override directory modelhubpath environment variable note model stored duplicate copied modelhubpath reason preserve original framework underlying model case user work around bug work underlying library separate environment also added benefit allowing previous model cache underlying library avoid download case model stored modelhubpath form work model import framework staging model every model downloaded original sdk preprocessed call staging staging secondary step take model adjusts end form worked example tensorflow may freeze model first storing import consequence advantage allow interop different ecosystem provide foundation finetuning model finetuning model scope adr provide way download manage model testing model import functionality provide way enhance built dlj model zoo importing model ecosystem standardized way unified way downloading accessing model multiple framework standardized directory allowing model easily worked keep underlying framework model around debugging also prevents underlying library redownloading library benefiting already downloaded model user underlying model library elsewhere disadvantage complexity maintaining ongoing sdk downloading maintaining model different ecosystem potential storage complexity involved running maintainingtesting model way know model hub change loading importing model different ecosystem messy additional work may done per model order make usable additional work scope adr storage user system due secondary cache
template generator proposed house rent agency platform make contract docdocx dynamic html template currently ueditor variable excel hour contract even experienced people idea docdocx html html edit online store template support spring django ever local script httpsgithubcombradmontgomerywordhtml support docx result well support doc httpsgithubcommwilliamsonpythonmammoth wordhtml based pandoc web service httpswwwzamzarcom good free month httpswwwonlineconvertcom good better local httpsconvertiocozhdocumentconverter good per month pas consequence ref httpsalternativetonetsoftwareckeditor
wagtail bedrock bedrock evolves expanding number contentmanaged page give greater agility needed evaluate pick bestfit solution previously contentful headless decided httpsdocsgooglecomdocumentdicqcotcimhducdrlkkyrbfgsbwsyrftuhwvjvldbkoedit move wagtail wagtailorg well integrate bedrock codebase httpsdocsgooglecomdocumentdaqcfrhixqwoaxmvbpszyuacvqhzyfrgttlkedit consequence integration djangobased bedrock codebase allow significantly faster clearer developer experience creating contentmanaged page plus time member org create new page based template development needed unless page new design significant amount engineering work needed including well integrate wagtail bedrock first necessitates refactoring away bespoke mechanism djangos logic well develop workflow around adding wagtailmanaged page whole team understands well integrate wagtail chosen localization vendor requires custom integration stopped contentful source data last exported state data migrate page previously contentful new
adr composite run step customer want able compose action action httpsgithubcomactionsrunnerissues important step towards meeting goal build functionality action user simply execute number step guiding principle dont want workflow author know internal working action work user shouldnt know internal working composite action example defaultshell defaultworkingdir inherited workflow file action file deciding design certain part composite run step want treat one logical step consumer composite action treated one individual job step known encapsulation adr support running multiple run step action build support mapping flowing input output env variable nested step access parent input variable nested step overwrite input variable composite run step feature feature support top action level name description input run output feature support run step level name run env shell workingdirectory feature support run step level timeoutminutes secret conditionals etc continueonerror step example workflowyml yaml job build runson selfhosted step step actionssetuppythonv step actionssetupnodev actionscheckoutv usercompositev name workflow step run echo hello world name workflow step run echo hello world example usercompositeactionyml yaml run composite step run pip install requirementstxt shell bash run npm install shell bash example output yaml npm installation output pip requirement output echo hello world echo hello world add token called composite allows runner code process composite action invoking composite runner code process step attribute convert template code list step finally run run step sequentially step fails condition defined whole composite action job fails default support default composite action shell workingdirectory run step composite action action author set shell workingdirectory attribute step shell attribute required run step action author know workflow author operating system explicitly prevent unknown behavior making sure run step explicit shell set action author hand workingdirectory optional moreover composite action author map value input shell workingdirectory attribute step level action example actionyml yaml input shell description name default pwsh step run echo shell inputsshell note workflow file action file treated separate entity workflow default never change shell workingdirectory value run step composite action note default workflow apply run step step step action running local script example workflowyml yaml job build runson selfhosted step usercompositev example usercompositeactionyml yaml run composite step run chmod githubactionpath testscriptsh shell bash run chmod githubactionpathscriptsh shell bash run githubactionpath testscriptsh shell bash run githubactionpathscriptsh shell bash usercomposite file structure actionyml scriptsh test scriptsh user able run script located action folder first prepending relative path script name githubactionpath githubactionpath contains path composite action downloaded file live note youll chmod running script git check script file github repo executable bit turned input example workflowyml yaml step foo usercompositev yourname octocat example usercompositeactionyml yaml input yourname description name default ethan run composite step run echo hello inputsyourname shell bash example output hello octocat input variable composite action viewable scope output example workflowyml yaml step foo usercompositev run echo randomnumber stepsfoooutputsrandomnumber shell bash example usercompositeactionyml yaml output randomnumber description random number value stepsrandomnumbergeneratoroutputsrandomid run composite step randomnumbergenerator run echo setoutput namerandomidecho random shell bash example output setoutput namemyoutput randomnumber output variable composite action viewable workflow file composite action word every child action output viewable parent dot notation stepsfoooutputsrandomnumber moreover output accessible within scope defined note example workflowyml file access output randomid reason dont want require workflow author know internal working composite action similar workflow file composite action access object github env strategy environment composite action youll able setenv set environment variable like could action secret support secret composite action functionality focused future adr well pas secret composite action parent workflow file composite action secret created composite action secret action yaml well automatically mask secret ifcondition condition supported composite run step feature supported later new feature old reasoning example workflowyml yaml step run exit usercompositev run marked always running always example usercompositeactionyml yaml run composite step run echo succeeding shell bash run echo run current scope succeeding shell bash success run exit shell bash run echo run current scope failing shell bash support ifcondition composite action functionality focused future adr see paragraph rudimentary approach thank cybojenix idea example explanation approach statement parent example workflowyml show whether run composite action composite action run since condition running composite action always note ifcondition parent propagate rest child though child action example actionyml start clean slate word imposing ifconditions similar logic paragraph echo run current scope succeeding run since condition check previous step within composite action failed run echo run current scope failing run since previous step resulted error default expression set success ifcondition set step step cancelled opposite approach cancelled composite run step cancel step condition workflow cancelled timeoutminutes example workflowyml yaml step bar usertestv timeoutminutes example usercompositeactionyml yaml run composite step foo run echo test timeoutminutes shell bash foo run echo test shell bash foo run echo test timeoutminutes shell bash support timeoutminutes composite action functionality focused future adr composite action entirety job set timeoutminutes whole composite action step long sum timeoutminutes composite action step attribute timeoutminutes equal timeoutminutes composite action default timeoutminutes composite action step time taken step combination individually exceeds whole composite action timeoutminutes attribute whole job fail individual step exceeds timeoutminutes attribute total time including step overall composite action timeoutminutes individual step fail rest step run based timeoutminutes attribute still abide condition though reference example composite step foo take minute run step fail rest step foo foo proceed long total runtime previous failed foo action composite action timeoutminutes minute composite step foo take minute run cause whole composite action job fail rationale behind user configure step condition conditionally set step rely due additional capability offered combining timeoutminutes andor wanted timeoutminutes condition dumb possible affect step usage limit still apply continueonerror example workflowyml yaml step run exit bar usertestv continueonerror false foo run echo hello world step run example usercompositeactionyml yaml run composite step run exit continueonerror true shell bash run echo hello world step run shell bash support continueonerror composite action functionality focused future adr step fail composite action continueonerror set false whole composite action step workflow file step run flip side continueonerror set true whole composite action step workflow file next job step run composite action step follows logic example hello world outputted previous step continueonerror set true although previous step errored visualizing composite action github action want composite action step condensed original composite action node visual representation first example yaml compositeactionnode echo hello world echo hello world echo hello world echo hello world consequence adr lay framework eventually supporting nested composite action within composite action adr allows user run multiple run step within github composite action support input output environment step well timeoutminutes continueonerror attribute composite action step
strict time control test suite proposed number test section code make one following assumption time move perceptibly statement time move perceptibly statement record sorted creationorder createdat timestamp test written today pas given day year timecop specific test setup enough control time throughout stack assumption opposition one another none universally true lead flakey andor timebomb test proposition restore order must strictly control application clock test suite mean cannot allow clock run freely must robustly reset time known value test also freeze time default move time consciously needed wei created timecop wrapper called testsuitetimemachine provides slightly higherlevel api controlling time test api guidance pretenditisdatetime start test suite soon possible test setup set baseline whole test suite run travelpermanentlytodatetime set time start test needed affect test per test traveltemporarilytodatetime temporarily travel time within test affect test many time needed within test commonly temporarily move back time specific test setup advancetimetoadvancetimebyduration move time forward within test affect test many time needed within test mostly jump forward specific point time test behaviour system point advance move time forward one second many time needed within test commonly ensure createdat timestamps increment expected series record creation reset reset time baseline end test handled circumstance unfreeze allows clock move forward naturally current time sparingly test specifically testing behaviour system time pass reverttorealworldtime unstubs time entirely allows system clock move naturally infrequently ever pro confident test pas given day year provided natural way moving time forward key point test progress reveal code unwittingly dependent precision timestamps andor risk race condition externally control presumed time test suite allow run test suite multiple important deadline well sweep ahead timesensitive test running suite rolling period future remove coupling timecop con update lot test new api replace timecop coupling new coupled coupling testsuitetimemachine wrapper may extracted gem future think carefully effect time test write write code make assumption passage time relation creation record
dutch resource name exposing api endpoint exposing exposing resource field name decide language cater majority world english dutch creating resource flemish government dutch term external requirement dictated organisation consequence possibly provide translation layer ever want cater international audience
implementation complex eaipatterns faa problem statement enterprise integration pattern complex structure part behaviour implemented generically part modifiable end user case system admin mico already decided faa platform provide modifiability form code configuration work well pattern complex pattern easy allow modifiability via faa especially case user want write little code possible meaning generic part component implemented mico team driver modifiability pattern must provided via faa function function contain little code possible generic code pattern provided mico platform either library import faa function component call said function challenge implement generic logic implement logic faa function implement custom logic generic logic faa function implement custom logic faa function state configuration channel faa function get current state configuration dynamic router let faa function subscribe kafka separate send current configuration together message sending multiple destination unknown destination router specific endpoint send message may even send message many endpoint implement generic routing recipientlist routingslip let faa function write route message header let function send message directly kafka stateful component pattern inherently stateful store state store state generic component send faa function message performing intermediate request step content enricher perform request get content inject message offload implementation completely user split two part one determining request needed one injecting requested content message affected pattern evalrst pattern dynamic config destination stateful router yes maybe dynamic router yes yes maybe content based router maybe yes maybe aggregator yes resequencer yes process manager maybe yes maybe message normalizer maybe outcome implement logic decided state configuration channel decided stateful function decided routing support custom routing faa function always interpreting routing slip present routing slip support multiple destination one routing step also allow make pattern possible everything stateful single generic kafka faa connector intermediate request decided evaluation implement generic logic implement generic logic faasfunction good kafka trigger function good allows easy extension modification generic logic needed bad implement generic logic supported language libraryframework bad would mean complex faa networksdependencies generic logic capsuled faa function implementing generic logic kafka faa adapter good one implementation one language bad generic logic support pattern possibly complex implementation stateful pattern store state compacted kafka topic good extra component bad useful storing configuration channel statestate change often bad many assumption bad whole channel read load state store state good really good storing querying state bad management isolation different faa function difficult send state message faa function good faa function trivially stateless bad state could large bad generic component know state send priori assumption sending multiple unknown destination allow faa function send message directly kafka good allows complex routing pattern bad faa function understand react various header field cloud event routingslip route history implement generic routing via header field routingsliprecipientlist good ensure semantics header field implementation bad header field sufficiently complex support complex routing intermediate request offload complete implementation user good request controlled user code bad user may reimplement generic code bad faa function know kafka topic split request part merge part good split implementation easyer understand good split implementation allows generic request handling implemented mico bad split pattern implementation complex
rely payment service provider proposed ordering system accept wide variety payment method satisfy user expectation increase user base number payment system significant nuance api way communication party payment provider delegate dealing different payment system consequence save time required implementing large payment system track trend pay fee processing money transaction internal payment system still leave room implementing additional adapter emerging payment system risk careful processing personaldemographic detail user wrt compliance auditing
provide restful api deciders nathan fiedler authentication service serf multiple product none quite like interface service easy possible anywhere short mean accessing network client application likely live different system whats protocol one common every system support may guessed would http easy understand debug supported basically everything trivial implement via readily available library could include graphql fancy add complexity unnecessary simple application handwritten protocol creates work client benefit http quite obvious consequence service http primary client interface since beginning worked well tested easily debugged commonly available tool curl familiar many system administrator link representational state transfer wikipedia
cache query deciders frederic lepied problem statement handle load multiple connected user api service always elasticsearch request index minmize number request driver simple solution start integrating well existing choice capacity evolve distributed solution needed future considered caching front api service reverse proxy caching inside api service outcome chosen optional authentication scheme would beed difficult manage picked flask caching simple caching memory memoize method cache query time capacity distrubted setup later needed positive consequence siege able simulate user without problem single laptop
thinking rule engine proposed rule engine part data process thinking add mini version rule engine simple example see httpsgithubcomnikunjyrulesblobmasterjsonqueryg business rule management systemhttpswwwdroolsorg equal equal greater equal greater equal contains start end list present logical expression consequence consequence
invoke adrconfig executable get configuration packagers homebrew developer want configure adrtools match convention installation currently done sourcing file configsh sit beside adr executable name common configsh file executable doesnt belong bin directory replace configsh executable named adrconfig output configuration script adr tool eval output adrconfig configure consequence configuration within adr tool little complicated packagers write implementation adrconfig output configuration match platform installation convention deploy next adr script make development easier implementation adrconfig project src directory output configuration let tool run src directory without installation step packagers include script deployable package
jvm backend since backend monolithic choose language least platform develop jvm platform specifically kotlin production code groovy test consequence initial development pace might slower since fluent kotlin groovy java example language fully interoperable java mean ton communitydriven java project reused needed without compatibility issue
remove alignment implemented deciders thomas nilefalk problem statement alignment adjustment code memory handling cause complexity make memory management harder refactor outcome decided remove alignment adjustment code consequence risk architecture unknown alignment might issue unknown actually exists architecture handle unaligned data pointer value stored across long word boundary case possible performace impact disregarded
single confidentiality level per data component related uniform bucketlevel access storage granularity access determines boundary control regarding protection confidential information example bucket uniform bucket level access therefore information bucket confidentiality level make sure right access permission applied store data single confidentiality level data component consequence advantage management access confidential data bound explicit platform component prevents unintented disclosure confidential information disadvantage handling information different access level additional storage component must created coming additional overhead
port protocol type java implementation kafka protocol defines primitive type send request parse response httpskafkaapacheorgprotocolprotocoltypes providing easy way define schema request response quite critical make library extensible enough weve decided basically port java implementation php world well written simplifies thing lot minor thing obviously adapted well leave type upcoming release arent implement message planning provide moment consequence implementation schema request response much easier reliable fact type skipped dont really interfere overall functionality library
create software defined everything implemented python version implemented api first implemented openapi implemented code config separation implemented javascript framework implemented shell scripting implemented testing framework implemented gitops deployment implemented expand pip requirement implemented declarative preferred action implemented odrl policy implemented project company data implemented coding guideline implemented feature toggle feature branching implemented data catalog specifies data component implemented data retention defined data component implemented deployment pull request softwaredefined everything sdx definition technical computing infrastructure entirely control software operator human intervention operates independent hardwarespecific dependency programmatically extensible sdx approach application infrastructure requirement defined declaratively functional nonfunctional requirement sufficient appropriate hardware automatically derived provisioned deliver requirement benefit sdx lowerseliminates effort towards infrastructure maintenance allows company move focus part software ensures consistence also allowing extensibility remote deployment configuration without downtime allows leverage power versioning git possible software infrastructure whatever deployed source code human management software infrastructure performed consequence advantage advanced capability enable transition one configuration another without downtime mentioned automatically calculating set state change one configuration another automated transition step step thus achieving complete change via software disadvantage developing sdxready organization requires people right mindset right skill set
require php amends require php bit issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
defining customizations proposed extends customize different feature tool raise question specify customization one hand there offer flexibility expressive power assuming average user competent developer obvious way achieve enable kind programming interfacedefinition given tool written reasonable assume definition done well might much power resulting potential performancebugssecurity issue hand there motivation keep tool simple enough configuration minimal still expressive always start limited definition eye extension case wed like customizations happen consistent uniform manner sense extendsgeneralizes allow permissive file name simply allowing kind customized file name working file name customization order enable future extension well choose customization method based jsbased extension well define file called adrcustomjs contain customization done tool file reside adr directory directory adr file customization code simple code predefined object depending api defined tool documented separately example defining file name pattern well probably require object predefined name file customization file adrcustomjs module form moduleexport etc easily consumed tool code assume user customizing tool competent enough handle simple scripting limitation customizations resulting easier customization left specific feature consequence feature tool require customization read file document necessary expected object
jetstream subscribe workflow metadatavalue author kozlovic partially implemented tag jetstream client document attempt describe workflow jetstream subscription library creation behavior runtime deletion subscription design creation library apis allows creation jetstream subscription depending language may various type subscription like channel based various queue subscription etc different apis one set configuration creating subscription user provide several thing subject case required see stream name section optional stream name optional consumer name optional consumer configuration see queue name subscription meant queue subscription indication push pull subscription handler receiving message asynchronously whatever mean library language misconfiguration checked subscribe api return error outright instance queue name provided configuring heartbeat flow control mistake since server would send message random member subject provided along stream name library wont able locatecreate consumer pull subscription ack policy none error time writing consumer configuration object look like ordered alphabetically seen jsgo type consumerconfig struct ackpolicy ackpolicy jsonackpolicy ackwait timeduration jsonackwaitomitempty delivergroup string jsondelivergroupomitempty deliverpolicy deliverpolicy jsondeliverpolicy deliversubject string jsondeliversubjectomitempty description string jsondescriptionomitempty durable string jsondurablenameomitempty filtersubject string jsonfiltersubjectomitempty flowcontrol bool jsonflowcontrolomitempty heartbeat timeduration jsonidleheartbeatomitempty maxackpending int jsonmaxackpendingomitempty maxdeliver int jsonmaxdeliveromitempty maxwaiting int jsonmaxwaitingomitempty server return error provided deliversubject provided optstartseq uint jsonoptstartseqomitempty server return error provided deliver policy bystartsequence optstarttime timetime jsonoptstarttimeomitempty server return error provided deliver policy bystarttime ratelimit uint jsonratelimitbpsomitempty bit per sec replaypolicy replaypolicy jsonreplaypolicy samplefrequency string jsonsamplefreqomitempty stream name stream specified subject subscribe api call required error returned case library subject provided way find stream subscription request sent server prefixstreamnames subject json content subjectsubject response list stream name positive contains single entry library stream name otherwise error indicating matching stream name returned however even provided stream name subject may needed instance consumer created library filtersubject set consumer lookup performed incoming filtersubject empty ensure match subject consumer name consumer name specified indicates library intent existing consumer library lookup consumer server get consumerinfo lookup fails considered error unless subscription pull subscriber case library still proceeds subscription queue name user attempt create queue subscription consumer name durable specified common pattern error noticed user member jsqueuesubscribefoo bar member jsqueuesubscribefoo bar report member receiving message subscription call would create ephemeral jetstream consumer could break api force user specify consumer name instead client taken approach describe consumer name provided natsbindstream consumer durable natsdurabledurablename library would queue name durable name push consumer active information queue group binding lookup succeeds newer server consumerinfo field called pushbound boolean pushbound bool jsonpushboundomitempty boolean indicates server already registered interest push consumer deliver subject consumerinfoconfig consumerconfig object inspected detect delivergroup set hand library return proper error user attempt create invalid subscription pushbound true delivergroup user try create non queue subscription return error duplicate subscription regardless pushbound value user try create non queue subscription delivergroup non empty return error trying create non queue subscription consumer created queue group user try create queue subscription delivergroup non empty match user queue name return error trying create queue subscription consumer created different queue group user try create queue subscription delivergroup empty return error trying create queue subscription consumer create without deliver group check filtersubject empty must match subject passed subscribe api return error indicating subject mismatch user trying create pull subscription deliversubject empty return error indicating user cant create pull subscription push based consumer opposite user creating pull subscription deliversubject empty return error indicating pull susbcription required generally user provided configuration match configuration get consumerinfoconfig error returned indicate change applied deliver subject changed existing consumer flow control set consumer queue deliver group requested return error indicating flow control supported queue heartbeat configured consumer queue deliver group requested return error indicating heartbeat supported queue nats subscription point nats subscription created deliver subject found consumer info inbox note subscription created prior attempt create consumer applicable durable subscription way server detect durable already subscription interest server simply update delivery subject durable consumer creating consumer library determined attempt create consumer consumer name provided durable name exists library fill consumer config provided user push consumer deliversubject specified library pick inbox name pull consumer deliversubject left blank library set filtersubject user provided subject ensure ackpolicy set possibly field maxackpending set delivergroup queue name subscribe call queue subscription request sent prefixconsumerdurablecreatestream namedurable name durable subscription prefixconsumercreatestream name ephemeral operation successful library get api response consumerinfo since library successfully created jetstream consumer keep track fact delete consumer unsubscribe drain ephemeral consumer name saved consumerinfos response since available beforehand result indicates consumer already exists mean race process got lookup found error attempting create jetstream consumer got already exists error case library perform consumer lookup perform check described push consumer active information queue group binding section note pull subscription basic check consumer type validity done check specific push consumer unless queue subscription api call return error consumer already exists push consumer nats queue subscription created prior addconsumer call destroyed replaced new nats queue subscription consumer info deliversubject jsack server sends message subscriber message replyto value called ack reply subject aka jsack message must contain replyto jsack format considered jetstream message jsack always start jsack jsack without modification publish subject message acks jetstream message jsack encodes delivery information stream consumer name stream sequence contains information allowing proper routing multiple account preventing ack account ack message stream consumer name another account multiple format jsack period delimited string version contains field must supported ensure client backward compatible previous version server version domain account hash inserted position directly jsack bringing number token may additional token added future must ensure client support token version version token new token may added end token format replyto start jsack token token token correct data type client raise error token version version token format jsackstream nameconsumer namenum deliveredstream sequenceconsumer sequencetimestampnum pending token version version token format jsackdomainaccount hashstream nameconsumer namenum deliveredstream sequenceconsumer sequencetimestampnum pending domain server still set token special value underscore server make sure user cant pick domain name user client expose domain value either emptynull string documenting meaning domain note domain always present simplifies library code bother variable number token somewhere close beginning subject possibly shifting find location field care append new token end simplify exportimport subject jsackdomainaccount otherwise would possibly something like jsackdomainaccount account hash client time routing last token ack handling ack accomplished publishing message jsack subject payload consisting byte ack type client must support terminal ack type ack nak term progress ack type wpi terminal ack type published message client ignore user request send type ack suggested implementation mark message sent terminal ack type way successful publish ack rely state subsequent acks consumer configured ack policy none client ignore request send type ack client return throw escalate error unless publishing ack error server instance due connectivity automatic management client provide automatic management asm default client behavior asm mean handling message heartbeat flow control pull gap awareness etc client optionally provide mode allow user handle required offered support backward compatibility preexisting user heartbeat jetstream consumer configured idle heartbeat interval server send heartbeat server pending message library set timer monitor either message received ensuring server connected message received within certain time period alarm surfaced user way make sense client language example notifying user asynchronous error callback time allowed alarm raised time idle heartbeat interval client may optionally provide way user configure time message gap checking message gap applies consumer participating queue library interrogate jetstream message heartbeat message contains last consumer sequence last stream sequence jetstream message information found ack replyto subject see ack heartbeat message information found header natslastconsumer natslaststream library detects gap consumer sequence surface notification user way make sense client language example notifying user asynchronous error callback note gap checking disabled queue deliver group subscription ordered consumer ordered consumer see adr ready rely message gap handling implementation ordered consumer possibly want handle detection gap client may want provide optional detection message gap flow control jetstream consumer flow control enabled applicable pull consumer library may receive flow control message instead regular jetstream message time message would normally passed user processing either synchronously via next message via asynchronous callback client respond provided replyto publishing value subject message empty payload flow control message reached server likely sent message user requesting message synchronously via next message client try respond next buffered message responds flow control within wait time supplied user part next message call note format flow control subject inspected since may change server discretion always publishable subject possible either flow control response missed consumer considered stalled server perspective server requires flow control turned idle heartbeat set flow control message missed heartbeat message contain header called natsconsumerstalled value identical flow control subject client detects heartbeat stalled header publishes server would respond flow control possible idle heartbeat duration flow control multiple heartbeat message contain flow control subject required respond specific subject suggested client track last flow control subject responded avoid replying multiple time flow control server ignore duplicate unnecessary traffic pull mode pull mode surfaced user considered fetch iterate count miscellaneous error know error condition passed user raised error conflicting thing like trying pull push consumer exceeding max ack pending etc responder like try reply subscription went away unknown error recognized client passed user raised error unsubscribe drain subscription unsubscribed drained library created consumer called addconsumer got jetstream consumer deleted end call note think problematic queue subscription since first member start create consumer case consumer already exists marked needing delete consumer unsubscribedrain member may attached consumer instance consumer exists create queue group durable named shared since consumer exist call create one member jsqueuesubscribefoo bar natsdurableshared another application add member since consumer existed prior call following call create consumer subscription marked delete consumer member jsqueuesubscribefoo bar natsdurableshared however point member away memberdrain completes library delete consumer shared library created cause member stop receiving message unsubscribe normal unsubscribe processing done subscription marked needing delete consumer library send deleteconsumer request return error drain deletion consumer delayed past point subscription fully drained removed connection since asynchronous process deletion consumer fails error pushed asynchronous error callback consequence possible existing library change would break simver left library maintainer evaluate
add graphbased pipeline proposed alex black discussed feedback received past konduit serving pipeline essentially stack pipeline step connected next however case require complex structure allowing parallel andor conditional execution pipeline step example case select one model part pipeline split testing test different model different inputsusers one model per selected dynamically per region language time day etc select model might occasionally useful case like sensor fusion image text sound optionalunreliable input parallel branch ensemble model parallelization execute slow step parallel reduce overall pipeline execution time database access network communication etc fallback model rnn provide response otherwise return model fails return adr proposed graphpipeline enable case existing sequencepipeline functionality stack step approach would changed proposal graphpipeline two consideration functionality provide api providing functionality functionality graphpipeline like sequencepipeline single data input single data output allows number thing including embedding graphpipeline within another pipeline sequencepipeline graphpipeline api serving method serving code sequencepipeline graphpipeline user dont internally graphpipeline amount branching parallelism etc single input single output restriction cause usability problem due fact data instance contain number value number keyvalue pair hence anything multidata input design achieved combining splitting data instance proposed provide support directed acyclic graph loop allowed within graph pipeline provide type graph step standard single input single output normal pipelinestep graph switch operation ofn data instance routed one output based criterion value data instance otherwise example case testing switch selects model step merge nto simply copy content input data instance one output data instance nto simply forward first possibly available data instance typically conjunction switch step one branch executed combine function nto arbitrary nto function without input available first addition allowing custom javapython udfs provide small number builtin function ensemble allows weighted averaging etc integer aggregation selection inidx argmaxiniscore timeout condition return get value within otherwise return internally json merge probably implemented special case combinefn really type implementation perspective ofn example case conditional execution branch switchab mergeanyxy output either execute left branch inaxmergeanyout right branch inbymergeanyout combinefn select return prediction model highest probability could also introduce split operation ton splitting single data instance practice simply number simple subset pipeline step parallel example subsetpipelinestep subsetpipelinestep subsetpipelinestep simply copy subset input data keyvalue pair output data instance note routing input output easily supported proposal change inference step needed added later approximated series switch noop pipeline step return empty data merge operation api java goal api make easy passible create graph pipeline exactly unambiguously user expect least two exist functionalstyle api builder style api like dlj computationgraphconfiguration propesd semifunctional api follows java graphbuilder new graphbuilder graphstep input binput standard pipelinestep graphstep mystep inputthenmystep new somepipelinestep always require name merge graphstep merged mystepmergewithmymerged input name optional graphstep banystep step name optional combine combinefn graphstep combined bcombinefn step step name optional switch note exact api tbd essentially functioninteger numoutputs method switchfn graphstep switched bswitchfn mystep construct final graphpipeline pipeline bbuildcombined build method take final output step assuming functionalstyle design there many design mainly related naming method name adding step call followedby inputto probably lot possible method name merging merge mergewith etc method name merge first etc method name combine combine combinefn combinefunction aggregate etc there also concern merge combine close namemeaning confuse people suggestion welcome api python python almost idestical true functional interface pipeline step python graphbuilder input binput stardard pipelinestep mystep inputmystep somepipelinestep merge merged mystepmergewithmymerged input banystep step combinefn combined bcombinefn step step switch switched bswitchsf mystep construct final graphpipeline bcombined bbuildcombined json consider json part public api also want people able write graph step jsonyaml hand sequencepipeline defining step simple user provide arraylist step like json step type step type config value config value type step type config value config value graph pipeline encode extra information graph structure name input graph component pipelinesteps proposal stay close sequnencepipeline representation possible changing following step becomes object map list object key step name add input alias input field within pipeline step pipeline step take single value size list mergeanycombinefn take listarray calling field input input avoid avoid ambiguity clashing name come json serialization time arbitrary configuration class called input user field called input configuration class problem example json graph pipeline pipeline step connected pipeline input one merge step connected input step mystep json step mystep input input type step type config value config value mymerged input input mystep type merge consequence advantage allow build complex type pipeline java python json yaml simple enough user understand type graph step standardpipelinestep switch merge combine pipeline construction there difference term api sequencepipeline graphpipeline exact client api method performing inference type pipeline later easily add embedded pipeline graphpipeline sequencepipeline example disadvantage input input type type issue mentioned earlier multiple nto type could nonobvious first glance user read doc merge combine
add netlifycms team would like control editing logingov content instead engineer edit large yml file goal know code order make edits logingov add netlify content management system architecture logingov consequence content editing fall designated content editor whether may content writer product manager designer member team katherine netlify added architecture content editor able add edit delete content without relying engineer adding netlify require content editor github account account federalist permission required order access published content change result github pull request pull request identitysite repository requires least one approval order content added website mean engineer may still involved content editing process although required
adr image text subject viewer april support subject image location text location image text view toggled pill button image text view image view utilize existing singeimageviewer text view utilize existing singletextviewer fem image text viewer support project researching ocr verification digileap project subject consist image ocr output text file create image text viewer imageandtextviewer utilizes existing single image viewer single text viewer proposed consequence create image text viewer imageandtextviewer utilizes existing single image viewer single text viewer
adr wrapper action pending addition action regular execution action author may want action chance participate job initialization action collect machine resource usage cpuramdisk workflow job execution start perf recorder beginning job job cleanup action dirty local workspace machine environment execution cleanup change end job actionscheckoutv write githubtoken local gitconfig execution post job cleanup defined undo change add pre post execution action node action example yaml name action pre description action pre run node pre setupjs preif success optional main indexjs post cleanupjs postif success optional container action example yaml name action pre description action pre run docker image mycontainerlatest preentrypoint setupsh preif success optional entrypoint entrypointsh postentrypoint cleanupsh postif success optional pre post default preifpostif set always setting pre always make sure matter condition evaluate result main get runtime pre always run already pre executes order step defined pre always added job step list job setup action referenced local repository myaction wont get pre setup correctly since repository havent checkedout job initialization cant github api download repository since minute delay git push new commit available download github api post pushed poststeps stack lazily action pre main execution passed condition check run cant action contains post pop run post pre main finished currently post work repository action orgrepov local action myaction valid action main pre main main post pre main post invalid action pre post pre post potential downside introducing pre extra magic wrt step order user control step order especially introduce template eliminates possibility lazily download action tarball since pre always run default download tarball check whether action defined pre pre doesnt work local action suggested customer local action testing action change action avoid delay git push github repo tarball download api condition pre cant controlled dynamic step output pre executes early
adr prefer multiple config file people involved iamturns issue configuration stored within packagejson multiple file best choice prefer multiple config file storing configuration file extension allows additional feature comment merging computing based environment reduce git conflict within packagejson easier sync project simply copying configuration file storing extension yml json provides syntax highlighting easier find configuration easier ide tool discover improved separation concern
splitting object graph code gen serialization discussed paul dub alex black november serialization code generation different come object graph laid generating code lot easier able directly access referenced object traverse graph however object graph serialization object appear multiple place becomes apparent defining constraint single constraint might referring input multiple time also multiple constraint refer multiple input main reason want keep serialization mind want keep code generator language viable serializing graph meant runtime code generation however would easily become problem object identity required equality comparison implementer different language would therefore work graph find identical object would know identity coincidence meant way creating object graph make explicit make work easier two distinct object graph one code generation serialization consequence advantage easier work object graph aligned usecase error prone access direct disadvantage explicitly transform one object graph another want support reading json back also define backwards transformation
environment variable override config file supercedes config config file environment port variable available startup overriden see httpsgithubcomserviantechchallengeappissues add environment variable override back consequence two way configure application cause complexity
microsoft graph api email integration procurement operation team shared mailbox hosted dfes exchange online communicate school buying professional key requirement case worker record email interaction regarding case case management system full view case associated interaction microsoft graph integrate microsoft exchange online microsoft identity oauth client credential grant flow set application permission graph api restricted permission access shared mailbox microsoft graph recommended microsoft outlook api deprecated consequence would increased initial security setup governance set permission rail application
title clarify spatial extent encoding geoshape box format unclear discussion httpsgithubcomesipfedscienceonschemaorgissues httpsgithubcomesipfedscienceonschemaorgpull proposed per fulljsonld example fix duplicate person problem json update spatialcoverage content guidesdatasetmd edits spatial section introduction point location discussion edits geoshape location section add additional discussion problem approach bounding box coordinate specification coordinate order deal extent include pole question coordinate ordering syntax describing bounding box describe spatiale extent try clarify behavior google dataset search spatial extent consequence metadata harvester able systematically index geolocation specified schemaspatialcoverage
file system folder structure typenamespaceid structure winery data stored file system adr content repository human readable machine processable considered folder structure typenamespaceid everything one folder hashbased storing similar git outcome chosen folder subdivided typenamespaceid final file system layout documented repositorylayout human readable everything one directory cause many file listed thus human difficulty find right file folder top level tosca component node type relationship type service template second structuring element namespaces namespaces established method avoid naming conflict structuring element tosca open system everyone create node type one global control name given node type thus might two different node type name namespaces provide natural structuring winery reuses idea third structuring element respective definition child type template element contained respective namespace directly folder name within folder componentspecific information stored machine processable window cannot create directory named httpwwwexamplecom therefore name encoded appropriate folder generated license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
record alias pixel art entry currently image filename url slug link individual pixel art entry occasionally may want change filename may typo name may decide want change naming convention url may bookmarked shared elsewhere still want old url remain valid pixel art entry may define multiple alias thought previous filename sans file extension generate page pixel art entry also generate page alias listed include link preview redirect canonical url instead consequence previous url pixel art entry remain valid still invalidate old url defining entry list alias redirects generated alias mechanism outlined clientside routing history api redirects redirects longer load time
tracking external file adr superseded adr track file like bashrc program configs git repo theyre often read modified external program therefore cant change location approach track sole purpose backup lowcost approach sync via dropbox drive although add another ecosystem track case like share file publicly place project doesnt work softlink repo system file bashrc reposomepathbashrc wont commit file content literal byte softlink hardlink repo system file bashrc reposomepathbashrc work mostly opening editing file either location affect target want therefore change program show unstaged change git there problem remote change made like githubs web interface another computer git pull overwrite symlink new copy file result external change bashrc stop showing unstaged change leaving without hint anythings changed file may diverge meaning cant blindly recreate hardlink fwed always diff manually merge first softlink system repo file reposomepathbashrc bashrc averts git pull issue since softlink point repos file path much like git pull issue translated side bashrc overwritten well destroying symlink example programsmaybe even editorscommonly atomic write writing content temporary file copying file file may diverge fact weak issue wellin word hardlinks break overwritten either side easier explain hardlink system repo file reposomepathbashrc bashrc know hardlinks brittle worst clearly softlinking system repo filehas least issue well supplemented git hook detects broken link broken link diff warn confirm continue operation broken link diff warn confirm force softlink way nagged two file match given force symlink generalize many file well work array hook oddly array contain file containing since hook pushed tradeoff none known retrospective see adr
kotlin gradle build definition language gradle build written kotlin esoteric comparing groovy one intellij idea great support kotlin based build adopt kotlin gradle build definition language consequence gradle build migrated kotlin
lambda instance scheduling part platform sustainability goal want shut non production instance outside working hour save money energy want scheduling work across multiple account flexible enough allow user opt schedule time tagging completed spike came several achieve third party lambda looked party lambda written python terraform httpsgithubcomdiodonfrostterraformawslambdaschedulerstopstart pro con roughly want modification still needed multi account adjust schedule work older instance limited python skill one core language security risk third party lambda aws instance scheduler aws instance scheduler solution pro con want cloudformation wouldnt work older instance without ssm agent installed order would either start supporting cloudformation stack rewrite cloudformation stack terraform started rewrite stack soon realised would hard hard maintain going forward aws system manager platform user already started aws system manager local scheduling pro con want wouldnt work older instance without ssm agent installed doesnt scale well multiple account create custom lambda pro con want new challenge working deploying lambda work older instance additional code maintain core language flexibility change needed create new custom lambda consequence upskill team member already underway figure strategy running lambda locally figure strategy testing lambda figure strategy deploying lambda
push refactor issue motivating influence constrains acceleration team developing version push team saw opportunity structure code make easier understand maintain general push command logic complex codebase command still considered experimental seemed like right time place invest energy refactoring cli code push split roughly two method conceptualize actualize conceptualize responsible taking user input flag manifest property etc generating push plan app pushed struct containing various piece information needed createpushupdate app actualize responsible taking push plan based plan taking necessary action complete push process refactor preserve spirit division prevents two method growing large unmaintainable goal refactor make easier add feature push new flag new flag new manifest property make easier unit test component push workflow mean meant splitting command several smaller function tested individually composed sequence based given user input change proposing agreed implement conceptualize actualize part push process split refactored manner inspired hexagonal architecture hexagonal architecture purpose hexagonal architecture mean following one place code responsible calling given sequence function order output one function passed input next function function signature central place function called agnostic function new featuresbrancheslogic added one function new function added encapsulate generally shouldnt touch place function called splitting conceptualize previously called conceptualize look roughly like note still iterating code may evolve time longer look exactly like still code illustrates idea going var pushplans pushplan manifestapplication range geteligibleapplicationsparser appnamearg plan pushplan orgguid orgguid spaceguid spaceguid updateplan range actorpreparepushplansequence var err error plan err updateplanplan override manifestapplication err nil return nil err pushplans appendpushplans plan return pushplans nil central place prepare push plan function called loop actorpreparepushplansequence array function call one push plan opportunity return modified push plan get passed next function case function also called override manifestapplication represent user input form flag manifest property respectively let function inspect user input modify push plan accordingly loop completes original push plan flowed function sequence modified include information based given flagsmanifest let look actorpreparepushplansequence defined actorpreparepushplansequence updatepushplanfunc setupapplicationforpushplan setupdockerimagecredentialsforpushplan setupbitspathforpushplan setupdropletpathforpushplan actorsetupallresourcesforpushplan setupdeploymentstrategyforpushplan setupnostartforpushplan setupnowaitforpushplan setupskiproutecreationforpushplan setupscalewebprocessforpushplan setupupdatewebprocessforpushplan simple array bunch function conform correct interface type updatepushplanfunc example one func setupscalewebprocessforpushplanpushplan pushplan override flagoverrides manifestapp manifestparserapplication pushplan error overridesmemoryisset overridesdiskisset overridesinstancesisset pushplanscalewebprocessneedsupdate true pushplanscalewebprocess vactionprocess type constantprocesstypeweb diskinmb overridesdisk instance overridesinstances memoryinmb overridesmemory return pushplan nil simple function populates field push plan based flag override return enhanced push plan making easy test function run updated push plan actualize step doesnt know flag manifest property anymore receive push plan user input resolved combined push plan object splitting actualize still time writing function called actualize look like changeappfunc range actorchangeapplicationsequenceplan plan warning err changeappfuncplan eventstream progressbar warningsstream warning err nil errorstream err return planstream plan quite similar loop actorpreparepushplansequence loop actorchangeapplicationsequenceplan return array function call one push plan one return push plan get passed next function note rest code stream report progress error warning focus adr may end changing well biggest difference conceptualize instead static list function like actorpreparepushplansequence actorchangeapplicationsequence function take push plan return array changeapplicationfuncs allows dynamically build sequence action run based push plan rather run sequence every time let look work actorchangeapplicationsequence funcplan pushplan changeapplicationfunc var sequence changeapplicationfunc sequence appendsequence actorgetupdatesequenceplan sequence appendsequence actorgetprepareapplicationsourcesequenceplan sequence appendsequence actorgetruntimesequenceplan return sequence function responsible building sequence based given plan delegate three helper build subsequence action here one func shouldcreatebitspackageplan pushplan bool return plandropletpath plandockerimagecredentialsneedsupdate func actor actor getprepareapplicationsourcesequenceplan pushplan changeapplicationfunc var preparesourcesequence changeapplicationfunc switch case shouldcreatebitspackageplan preparesourcesequence appendpreparesourcesequence actorcreatebitspackageforapplication case shouldcreatedockerpackageplan preparesourcesequence appendpreparesourcesequence actorcreatedockerpackageforapplication case shouldcreatedropletplan preparesourcesequence appendpreparesourcesequence actorcreatedropletforapplication return preparesourcesequence case want include one three function final sequence determined based property push plan since function small straightforward easy unit test composed together different sequence build different push workflow based different flagsmanifests refactor really start pay consequence becomes easier difficult risk introduced change mitigated becomes easier figuring write code add new flag becomes easier consider recent commit added nowait flag push command bulk change needed add new branch workflow new threeline method implementing updatepushplanfunc interface plus unit test oneline change actor add new method changeapplicationsequence simple change pas new push plan property method change commit highlight part relevant adr becomes harder slightly harder grasp piece fit together first glance array function detailed immediately clear called since abstracted away different part codebase believe spending time understanding new structure thing developer appreciate straightforward make change
executor engine separation deciders roleyfoley problem statement hamlet currently built two application stack set bash script run deployment invoke generation output freemarker wrapper supporting template handle creation output tight coupling component difficult determine authoritative source share stack driver improve user experience introduced cli tool based click library built python integrating cli environment highlighted cli tool also exposed tight coupling two application stack considered replicate cli feel provided click existing bash environment maintain existing coupling migrate bash process java based application call freemarker java based process create clearly defined abstraction layer existing bash script freemarker wrapper outcome chosen create clearly defined abstraction layer existing bash script freemarker wrapper make architecture cleaner provides clear way hamlet scale future positive consequence explicit definition hamlet made work make choice appropriate tool specific service within hamlet negative consequence defining building layer separation add complexity hamlet pro con replicate cli feel provided click existing bash environment maintain existing coupling rather looking introducing new tool hamlet instead update existing bash based script offer centralised cli experience model central bash script called hamlet would invoke bash script currently know exist call good remove extra dependency tool set education required introducing tool good requires effort introduce migrate bad bash testing tooling service arent mature language bash mostly intended script rather application migrate bash process java based application call freemarker java based process would move bash script currently freemarker wrapper java application would require rewriting bash script java equivilents providing java based cli good would reduce number application stack involved hamlet system good would cross platform java intended cross platform bad would require significant training retooling currently create clearly defined abstraction layer existing bash script freemarker wrapper would maintain existing tooling introduce abstraction layer two service model would define freemarker component engine responsible creating output content cmdb outline list instruction contract supporting document require bash component would become executor responsible actioning output provided engine providing output execution back cmdb model engine would invoked default set parameter requesting generation contract engine would create output outline additional output document required given action executor invokes engine parameter provided contract create output required could include contract executor run perform additional task order complete given action requires executor essentially implement contract would made defined step include parameter required complete step executor responsible providing implementation step defined engine good creates clear line bash tooling performs freemarker tooling performs good defines functionality within hamlet rather basing tooling good allows functionality implementation change required reduced impact redevelopment bad introduces new layer way hamlet work requires design implementation existing stack rather rewriting existing process redevelop existing implementation incorporate design
invalid graphql api facade created ukasz grnicki derberg invalidated remove component proxying request kubernetes api server console allows access different functionality different apis consequence displaying single view might require performing several api call different endpoint client side simplify solution desirable keep call server side approach improves resiliency performance browser make single call api prone error api facade receives internal call call apis internally much higher speed thanks istio integration simple configuration mashup implementation much easier implementation involves client side another argument approach architecture many component kyma early version alpha beta apis change frequently decoupled approach introduced facade make resistant breaking change rare case query modified developer must adjust code query readjust code new api common problem traditional rest architecture graphql optimal solution kyma extensive querying delivers data required particular view come builtin resiliency mechanism query multiple apis one fails return information data received apis successfully returned whereas missing data marked null graphql api facade console invalidated consequence every functionality exposed must routed facade
thing architected high level overview structure thing decide high level structure app take goal learn fun time aspirational selling point ever get published seriously potential thing ill publish make element life easier enabler life automation choice pro con federated syncing multiple device standalone instance app sync whenever conflict resolution could avoid internet security optionally allowing direct connection pro excuse git hood conflict resolution possibly way introducing branch public least conflict resolution resiliant way creating internet kind exciting con device type would native coding probably desktop mobile native could spin positive load learning complexity would decent challenge federated locking syncing without syncing edit data one device order change master instance connected nope restrictive aspirational phone primary think whatsapp app phone would primary run app place active connection phone pro excuse play real time connection single source truth conflict deal phone pretty much always connected internet con restricts app phone although phone usually hub thing language probably python desktop primary hosted server true online service pro already know con server maintenance privacy issue centralized nightmare building federated syncing aspirational one hell challenge awesome main con complexity learning project bring next sketch layout piece
standalone prometheus issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
mysql proposed iop aliyun mysql rds pas mysql pas ssd master aliyun rds mysql aliyun rds self built mysql rds dts rds mysql min logslaveupdates binlogformatrow consequence github ref mysql upgrade mysql mysql httpwwwineedwebhostingcoukblogmysqlupgradefrommysqltomysql mysqltimestampdatetimeinthttpssegmentfaultcomq change affecting upgrade mysql httpsdevmysqlcomdocrefmanenupgradingfrompreviousserieshtml aliyun rds httpshelpaliyuncomdocumentdetailhtml mysql logslaveupdates httpwwwcnblogscomzejinphtml mysql httpblogsaesinacomcnarchives httpmpweixinqqcomsbizmjmodyxmdaoqmididxsnacbfcaefa
selection graph database software skos taxonomy management deciders garyttierney danielgrant robmarch technical story dtm problem statement persistence retrieval skos taxonomy require storage layer support storing rich freeform linked data data model could represented traditional rdbms however would require specialized serialization deserialization implementation whereas graph database typically store rdf natively driver high availabilityfault tolerance learning curve maintenance overhead vendor lockin considered apache tinkerpop apache jena fuseki postgresql outcome chosen apache jena underlying postgresql persistence store custom persistence layer provides highly available database persistence widely available managed service opted apache jena sdb achieve state maintenance since june positive consequence postgresql clustered making highly available postgresql broadly available managed service utilise postgresql database storing additional data user role etc negative consequence design schema code interacting postgresql database pro con apache tinkerpop tinkerpop graph database implementation abstraction layer various graph database backends present frontend consisting query language named gremlin method chaining style syntax build graph query backends tinkerpop support listed azure cosmosdb amazon neptune neoj query example tinkerpop gremlin gremlin gvhasid httpexamplecomskosconceptoutskosbroaderconceptvaluesskospreferredlabel persistence example tinkerpop gremlin gremlin gaddvskosconceptpropertyid httpexamplecomskosconceptpropertyskospreferredlabel value query language reference documentation good support various graph database backends good relies standardized query language making persistence implementation almost graph database agnostic bad query language designed simple crud operation instead determining relationship across graph edge bad extremely heavyweight generalized solution data fitting specific model bad extremely high learning curve associated gremlin query language compared something like sparql sql bad built groovy first jvm second apache jena fuseki fuseki hosted backend apache jena sparql engine allows storage rdf data first serializing turtle querying back jena api executing sparql query query example jena sparql sparql prefix skos httpwwwworgskoscore select broader httpexamplecomskosconcept skosbroaderconcept broader persistence example jena api java rdfconnectionfactory connection connectionloadhttpexamplecomskosconcept httpwwwworgskoscorebroaderconcept httpexamplecomskosbroaderconcept good store skos native representation rdf good extensive java api available good query persistence intuitive easy bad maintained open source sparql server available bad selfhosted would require maintenance well deployment new unfamiliar technology
adr nodevibrant library july pick library finding prominent color image scope project subject change future unsure yet project fit cond nast platform architecture deterministic quality purpose nodevibrant popular therefore well maintained tested
postgres database postcode checker database store valid service area allowed post code currently requirement involve looking postcode postcodesio future may want build feature involve sophisticated geolocation capability database support geolocation natively postgres geolocation capable sql database future enable postgis extension postgres database consequence postgres mature widely adopted open source database serf immediate postgres allows enable complex geolocation feature future postgis extension
adr graphql data layer installation ariadne apollo complete creation graphql schema progress boxwise middle planned migration old phpbased dropapp new app based new stack pythonreact old app backend data model closely intertwined sql string written directly within php made challenging evolve data model app turn imposed many product functionality constraint slowed development time especially since dropapp data model prototype rather designed scalability productmarket fit team migrates new app explores possibility entering new market time reexamine team might benefit separation concern data layer driver scalability well support expected future change restructuring database migration etc timescale technology expected defunct developer experience given rotating environment loosely affiliated developer different background support rapid onboarding developer data structure onboarded chosen technology pleasant useful career progression standpoint maintainability expect rapid change structure expand functionality easy solution maintain evolve documentation support productionreadiness library mature enough production environment active community support channel run problem considered api style full rest interface backend would involve creation multiple endpoint resource devs request wellunderstood professional devs new devs coming data analysis background example would learn correct rest standard overunderfetching problem cause network traffic heavy difficult evolve api dont know query requesting field specific resource often lead creating one endpoint per client data layer separation concern would require devs fluent current table structure change data model paired cascading sql query change equivalent orm blended environment graphql endpoint inventory rest endpoint login logic might easier create rest endpoint login user proof concept already started rest overfetching underfetching issue user katie said preferred build everything one style point implementing login graphql single endpoint everything benefit avoids underfetchingoverfetching problem readable frontend query language super easy compared learning sql scratch enables parameterized query inherently support incremental evolution field explicitly specified query supported facebook adopted major tech company paypal github ebay etc con new kid block devs much familiar graphql concept requires devs understand concept query mutation resolvers problem easy cache rest server graphene take code first approach development reportedly lagging behind maintainer looking people take oldest python solution around likely quite stable many frustrated user reddit ariadne take schemafirst approach excellent documentation functionality designed mimic industry leader apollo server nodejs compatible python backend fewer star compared graphene however compensates somewhat spectrum support channel wellloved reddit release supported small dev shop mirumee software client apollo client wellsupported industry leader extensive documentation sophisticated caching solution large footprint previously considered hard set configure due sophistication apollo boost package make thing super simple speedy urql lightweight tiny client solution intended make graphql simple however lack one major benefit apollo client cacheing supported mediumsize dev shop younger apollo client well server graphql single endpoint everything selected paired ariadne serverside apollo client side reasoning graphql may steeper learning curve professional developer familiar standard long run scalable iteration easier maintain multiple rest endpoint future end ingesting external data apis unhcr data easier pull graphql endpoint well also favorable developer experience standpoint onboarding maintaining codebase due graphqls introspective capability humanreadable json query structure degree clientside specificity requesting fieldlevel data apollo selected clientside due maturity product robust feature including sophisticated caching excellent documentation huge community ariadne selected graphene server side due designed deliberately intended mimic apollo server ariadne active development mirumee software excellent documentation developer crossreference apollo server documentation believe outweighs con come mature library graphene finally believe performance concern could result query abstracted sql resolvers compensated load network due overfetching long query created consequence easier requesting data backend initial set complete integrating external data source readability query making change database without breaking every single existing query data structure understanding keeping track data structure relationship one another versioning difficult initial set mean cannot take advantage flask utility create rest endpoint thing like login routing initial set data schema optimizing query performance error handling graphql inherently http response code like rest potentially optimizing scalability performance within large scale distributed system reading httpsgoodapicoblogrestvsgraphql
nginx caching case list response performance case list page currently reasonably slow account complex database query entail also central user journey thus high traffic whilst receiving update day make good candidate caching hopefully significantly improve whilst reducing load courtcaseservice nginx reverseproxy introduced front courtcaseservice act cache make cheap fast query determine last modified case list returning lastmodified header client case nginx proxy provide timestamp back ifmodifiedsince header courtcaseservice return modified case change made case list nginx serve cached response validated still fresh consequence speed response repeat call case list improve drastically court case requested lastmodified set default past service went live allow empty case list cached
architecture record project template starting new project isnt practical start completely scratch every time would like varity starting point project different purpose lein template clojure space leiningen template fill purpose set special stringinterpolated file rendered working project special tooling however two major drawback work leiningen build tool template file actually valid source file make difficult maintain change manually copied template rail template rail also provides complete project templating solution rail project template templaterb file contains dsl form specify operation perform fresh project operation include creating file modifying project dependency adding rake task running specific generator generator particularly interesting idea generate modify stub file pertaining specific part application new model new controller invoked point initial project creation start arachne template standard git repository containing arachne project special syntax valid runnable project box order allow user create project template project include rename script rename script recursively rename entire project directory something user chooses delete git rerun git init therefore process start new arachne project choose appropriate project template clone git repository github run rename script rename project whatever wish start repl begin editing maven distribution certain development environment full access open internet particularly certain governmental application therefore accessing github prove difficult however order support developer organization often run maven mirror convenience user situation necessary build wrapper compress install project directory maven artifact standard maven command line tooling possible download decompress artifact local filesystem directory proceed normal proposed consequence take moment user create new arachne project straightforward build curate test maintain multiple different type template project code write support template rename script rename script capable renaming code file template awareness naming requirement convention clojure namespaces code template project built continuously contrast rail one way approach inferior rail template approach atomic templating happens happens whole project rail template composed many different generator generator invoked point project lifecycle quickly stub new functionality also implication maintenance rail generator updated along rail release template stable wheras arachne template would updated every single time arachne change imposes maintenance burden template maintained core team risk poor user experience user find try outofdate thirdparty template however mitigating difference arachne rail relates directly philosophy approach two project rail project source file project directory layout ask controller answer pointing relevant file appcontrollers directory rail task create new controller equivalent creating number new file appropriate place containing appropriate code hence importance generator arachne contrast project ultimately defined source file directory structure defined config course source file directory structure convention organize definition project instead project configuration canonical definition project ask controller arachne meaningful answer point data configuration task create controller mean inserting appropriate data config usually via config dsl consequence arachne focus code generation generating config data instead providing code generator writes source file project structure arachne provide config generator user invoke comparable effort config script arachne template typically small arachne code generation antipattern instead making easy generate code arachne focus building abstraction let user specify intent directly terse manner
author validation currently user provided little useful feedback error questionnaire building change aim provide way user see feedback change making exposing validation error multiple type validation intraentity validation field within entity question page must populated title interentity validation validation across entity answer validation reference answer reference previous answer intend validate questionnaire api provide graphql type expose validation result json schema ajv json schema chose json schema format defining requirement field store questionnaire json requires transformation well understood department also documentation data type exist within author questionnaire ajv given json schema needed find appropriate library interpreting running schema investigation spike found ajv good choice request extremely fast could validate empty survey larger survey ashe qpses ajv capable validating request time schema defined ajv straight forward api clearly documented spike also possible extend ajv add custom validation provide interentity validation custom keyword possible require additional pass questionnaire required schema validator additionally ajv active project keeping json schema version change functionality added expect ajv track change implement released validate questionnaire every request investigation found completely improbable extreme case could cause validation run slowly make retrieving data resolvers easier implemented validation express middleware would every graphql request appreciate necessarily optimal simple work initial version validation start becoming slower investigate including persistingcaching validation every write running validate resolvers guaranteed revalidate questionnaire every mutation validation error change afer mutation update error held happened result read response mutation contain correct validation error provide validation error entiy level entity validation error array field graphql type contain list error error contain location fieldproperty name error errorcode code representing type error consequence change able provide data able show error exist within questionnaire uis responsibilty error significant complexity around error shownhidden dealt prototype hamishtaplin
specificity feature request summary route dynamic route discovery proposed new route automatically discovered synchronized order reduce risk new route missed programmatically making change production routing table serious business potential cause network outage specified route synchronized prevent unintentional change consequence end user must update request configuration add new route want sync remove route longer synced
layout layoutspagenjk title adr bloomreach channel manager pagetitle adr bloomreach channel manager pagedescription path blueprint permalink blueprintadrsadrusebloomreachchannelmanagerhtml eleventynavigation parent architecture key adr bloomreach channel manager order pending sought determine whether deliver document management capability content management platform natively integration external document management platform sought determine whether bloomreachs channel concept would suitable managing various site required brought onto platform mvp future deenary speciality sight part consideration made around ease creating new site ability share component ability segregate content specific channel site ability share content stack needed appropriate permission model required support model bloomreachs concept channel well suited meet running site required nwp platform umbrella channel offer ability build new site share component module enables greater consistency utilising role permission within content segregated available relevant whilst allowing content made available organisational stack national content aggregated regional level blueprinting functionality allows site created series parameter standardising creation site needed easy fashion consequence channel blueprinting functionality core offering product well documented
name endpoint service ingres get inherited controlling externalservice easify finding according endpoint service ingres ressources named exactly externalservice ressource nethertheless course owner set correctly well every ressource get label app externalservicename change proposing agreed implement consequence order break scheme adjust place resource fetched applied
title checkout gateway area checkout tag checkout app payment shipping cart adr enhanced checkout gateway feature response evolving landscape checkout decisionmaking propose introduction centralized opinionated solution solution aim facilitate informed checkout process based cart content current sale channel appsystem particular stand benefit significantly enabling seamless communication app server presently achieving functionality constrained app script limiting capacity making nuanced checkout based app server logic moreover payment shipping provider necessitate specific criterion determining availability respective method criterion include consideration risk assessment related current customer cart unavailability criterion merchant connection validation checking correct credential service availability testing detecting provider outage additionally provider require ability block cart checkout based risk assessment adr focus aforementioned feature implementation designed allow seamless future extension checkoutgatewayinterface address outlined challenge propose introduction checkoutgatewayinterface interface invoked checkout process determine response tailored current cart sale channel php namespace shopwarecorecheckoutgateway shopwarecorecheckoutgatewaycommandstructcheckoutgatewaypayloadstruct shopwarecoreframeworklogpackage packagecheckout interface checkoutgatewayinterface input struct consists cart sale channel currently available payment shipping method public function processcheckoutgatewaypayloadstruct checkoutgatewayresponse plugin developer encouraged create custom implementation checkoutgatewayinterface specific checkout logic based external system erp pim checkoutgatewayresponse include entitycollection payment shipping method suitable current along collection carterrors input struct response designed future extension allowing intricate decisionmaking checkout storeapi new store api route checkoutgatewayroute storeapicheckoutgateway introduced route call checkoutgatewayinterface implementation respond accordingly integral cartorderroute request ensuring cart validity checkout order process storefront default invocation checkoutgatewayroute occur checkoutconfirm page editorder page socalled order change language currency trigger reload payment method selection calling app server checkout gateway command streamlined response manipulation plugins app server alike propose executable chain checkoutgatewaycommands implementation appsystem heavily rely command structure however encouraged mandatory custom implementation pluginsystem implementation checkoutgatewayinterface follow command structure command chosen predefined set responded plugins app server initial release include following command addpaymentmethod removepaymentmethod addshippingmethod removeshippingmethod addcarterror depending command payload may differ necessitating update documentation propose handler pattern facilitate execution command command executed order provided response appsystem initial release shopware support single implementation checkoutgatewayinterface provided appsystem appcheckoutgateway sequentially call active apps app defined checkoutgatewayurl manifestxml file app manifest address challenge apps new app endpoint defined manifestxml new key gateway added manifest file subkey checkout define endpoint gateway key signalizes possible future similar endpoint different purpose checkout gateway endpoint configured new element called checkout xml gateway checkouthttpsexamplecomcheckoutgatewaycheckout gateway checkout gateway app payload app server receive current saleschannelcontext cart available payment shipping method part payload appcheckoutgateway call app server payload json saleschannelcontext saleschannelcontextobject cart cartobject paymentmethods paymentmethodtechnicalname paymentmethodtechnicalname paymentmethodtechnicalname shippingmethods shippingmethodtechnicalname shippingmethodtechnicalname shippingmethodtechnicalname note paymentmethods shippingmethods array contain technical name method full entity checkout gateway app response json command removepaymentmethod payload paymentmethodtechnicalname paymentmyapppaymentmethod command addcarterror payload reason payment method available cart level blockorder true event new event checkoutgatewaycommandscollectedevent introduced event dispatched appcheckoutgateway collected command app server allows plugins manipulate command executed based payload app server retrieve consequence app php sdk appphpsdk enhanced support new endpoint data type ensuring seamless integration command structure following adaptation made checkout gateway request payload deserialized checkoutgatewayrequest object checkout gateway response deserialized checkoutgatewayresponse object every possible checkout gateway command class representing facilitating easy manipulation payload
title medium path rewrite area core tag medium url strategy current medium system possible configure different shopwarecorecontentmediapathnamepathnamestrategypathnamestrategyinterface strategy store file uploaded medium entity certain path configured strategy also generate url frontendstore api embed file generation url currently triggered event subscriber registered medialoaded event generating url implementation urlgeneratorinterface php interface urlgeneratorinterface public function getabsolutemediaurlmediaentity medium string public function getrelativemediaurlmediaentity medium string public function getabsolutethumbnailurlmediaentity medium mediathumbnailentity thumbnail string public function getrelativethumbnailurlmediaentity medium mediathumbnailentity thumbnail string interface pathnamestrategyinterface public function getname string generate hash missing url omitted public function generatepathhashmediaentity medium mediathumbnailentity thumbnail null string generate cache buster part path missing url omitted public function generatepathcachebustermediaentity medium mediathumbnailentity thumbnail null string generate filename public function generatephysicalfilenamemediaentity medium mediathumbnailentity thumbnail null string issue pathnamestrategyinterface well urlgeneratorinterface dependency dal always fully loaded entity generate url big overhead consider data currently needed url generation end medium upload must always done via shopware application folder structure stored file system generated url match conditionally possible upload medium directly cdn without uploading file via shopware stack theory strategy must never reconfigured file uploaded file uploaded footestjpg strategy changed one would place file bartestjpg new strategy take effect url generated file never moved filesystem current strategy called cache busting system uploadedat value included file path however work url statically included replacing medium file always lead new file path image longer reached old file path address issue listed make following change system file path saved directly medium entity thumbnail file uploaded way dont access strategy generating url might changed meantime allow change file path via api write directly creating entity way file synchronized directly external storage path changed entity given import generate strategy new location structs easily created via service remove dependency dal generate file path generating url implement new service operated without entity url generation resource efficient done without fully loaded entity new url generator new cache busting system writes updated timestamp medium entity query parameter url way file path remain even file updated change entity meta data also result new url promise backwards compatibility take following measure old url generator still generates url old strategy new url generator generates url based mediaentitypath project specific strategy must migrated new pattern provide bcstrategy convert new format old format easy transition major make possible always mediaentitypath relative path realize via entity loaded subscriber generates value runtime via url generator writes path property consequence resource generate absolute medium url generate url even without fully loaded entity strategy changed time without moving file file system load file directly external storage adjust path entity remove dependency dal strategy url generator example php namespace example shopwarecorecontentmediacoreapplicationabstractmediaurlgeneratoruse shopwarecorecontentmediacoreparamsurlparamsuse shopwarecorecontentmediamediacollectionuse shopwarecorecontentmediamediaentityuse shopwarecorecontentmediapathnameurlgeneratorinterface class beforechange private urlgeneratorinterface urlgenerator public function foomediaentity medium relative thisurlgeneratorgetrelativemediaurlmedia absolute thisurlgeneratorgetabsolutemediaurlmedia public function barmediathumbnailentity thumbnail relative thisurlgeneratorgetrelativethumbnailurlthumbnail absolute thisurlgeneratorgetabsolutethumbnailurlthumbnail class afterchange private abstractmediaurlgenerator generator public function foomediaentity medium relative mediagetpath url thisgeneratorgenerateurlparamsfrommediamedia absolute url public function barmediathumbnailentity thumbnail relative directly stored entity relative thumbnailgetpath path generation entity related could also partial entity loading also call batch see url thisgeneratorgenerateurlparamsfrommediamedia absolute url public function batchmediacollection collection params foreach collection medium paramsmediagetid urlparamsfrommediamedia foreach mediagetthumbnails thumbnail paramsthumbnailgetid urlparamsfromthumbnailthumbnail url thisgeneratorgeneratepaths url flat list url medium also thumbnail class forwardcompatible forward compatible featureisactivev function public function foomediaentity entity provide entity loaded subscriber assigns url urlgeneratorinterfacegetrelativemediaurl path property till always relative url mediaentitypath proprerty path entitygetpath featureisactivev new generator call absolute url else old generator call absolute url
language generic composition pattern implementation problem statement decide language implementing mico composition service framework apache kafka see adr driver known everyone developement team must support apache kafka considered java pro easy setup spring boot java language every team member proficient python python prototyping stage explored outcome want java since existing knowledge experience given everyone
cache instead wbterms efficient fetching data needed display entity short form adr item property displayed short form either link simple text reference data needed render short form currently loaded sql table wbterms wbterms causing several significant issue possible maintained long run wbterms initially introduced sql search index tracked change discussed code review also httpsphabricatorwikimediaorgt seems dramatic performance improvement expected neither noticed switching wbterms instead loading data entire item property wikibase already mediawikis caching mechanism production wikidata environment based memcached reduce loading full entity data case lexeme form entity type provided wikibaselexeme extension different internal structure item property wbterms source data short form display full lexeme data loaded instead early test didnt show significant performance issue see httpsphabricatorwikimediaorgt also due different internal structure lexeme form way short form displayed built possible wbterms even seem feasible without changing semantics table long sql table storage data displaying entity short form bring significant performance gain decide stop wbterms data source case instead data whole entity going retrieved storage layer database cached storage already place efficient enough case hugesize wikibase instance like wikidata data needed display also stored cache label item particular language reduce amount computation needed especially language fallback applied etc consequence reliable benchmark place possible new way displaying entity performs worse worst case switching back wbtermssolution would quick fix could easily applied case serious problem increased memcached wikidata production environment might impact performance caching system case huge amount entry added cache new approach cache going storing data changing edited possible cache invalidation mechanism considered left specific adr document appendix wbterms table removed look like field type null key default extra termrowid bigint unsigned pri null autoincrement termentityid int unsigned mul null termfullentityid varbinary yes mul null termentitytype varbinary null termlanguage varbinary mul null termtype varbinary null termtext varbinary mul null termsearchkey varbinary mul null termweight float unsigned
adr choosing new name ashlar jean cochrane open source fellow summer name ashlar already taken pypi since pypi requires unique name package mean want distribute package pypi well either convince owner ashlar give name pypi package something similar ashlar slightly different like ashlarcore come new name project seems unlikely given maturity ashlar package pypi recent last release april four month ago number perfectly functional frustrating branding distribution perspective since potential introduce confusion andor competition existing ashlar package instead believe best course action choose rename project require come new name ashlar notoriously difficult considered based idea flexible construction material joist lintel silicone grout propose rename project grout among grout name sound best one believe offer closest allegory project grout construction material widely known physical flexibility practical versatility fluid concrete create waterproof seal masonry structure advantage name grout include grout respect origin project referencing masonry material unlike ashlar name grout emphasizes core feature project flexibility versatility base material scaffold tie together much complex project grout one syllable one fewer ashlar easiest word pronounce among considered perhaps importantly grout available pypi consequence changing name well take number step update project create new repo project fork ashlar move code grout update code refer grout instead ashlar internally import namespaces rename repos reference name ashlar including ashlarfellowship ashlarblueprint since ashlar esoteric name grout package may lose seo well able distribute project pypi short memorable name
preferred navigation bar type deciders team aim cover doubled none navigation bar issue deeplink routings baseviewcontroller tyrootviewcontroller manage override preferred navigationbartype example usage native case directly selected baseviewcontroller inheriting basevc native bar dont anything tyrootviewcontroller none case selected directly override inheriting tyrootviewcontroller going tynavigationbar dont anything although get inherit want usage inheritance override native show native navigation bar none hide native navigation bar notdetermined doesnt mess meat milk doesnt anything select child controller usage like override var preferrednavigationbartype navigationbartype native consequence duplicated dissappearing navigation bar fixed deeplink navigation
category adr tag analysis title adr decide analysis architecture analysis interact many different metric tool transform metric ccjson format visualization understands sense analysis act like funnel visualization probable besides basic parsing code many code part reused analysis architecture handle different input parameter analysis pipe filter architecture filter small processing step miniprogram pipe connects output one filter input another architecture seen window linux commandline fex bash script invokes two different program combination tell often codecharta mentioned project grep codecharta codecharta consequence architecture neither popular known one make analysis learning curve steeper
new shape normalization issue motivating influence constrains confusing case analysing union optimization copying property shape find recursion consequence becomes easier difficult risk introduced change mitigated
backup airtable organization see airtablebackup postgres path determine organization requiring firsttime scraping directly pulling organization airtable organization persisted determine organization requiring firsttime scraping single database query see addfirsttimescrapingjobsjs determineorgstoscrapefirsttime function rather series query one organization backup also safety net catastrophic data loss removal airtable future two benefit backup possible pulling data airtable determining firsttime scraping job periodic rescraping job decoupled separate process cronscheduled oneoff dynos run adhoc periodic analysis data airtables interface andor api doesnt permit see message
manage data armadillo suite project manage data armadillo suite molgenisarmadillo client manage data armadillo suite mean managing folder file data backend based rdata consequence managing data client entitles following consequenses perform crud operation file folder subfolders armadillo data backend login logout armadillo service allowed copy data one folder allowed upload rdata folder armadillo data backend allowed upload file client check rdata file uploaded armadillo data backend
payment standalone configuration solution contentful deciders reino muhl ben bangert julian poyourow bianca danforth lisa chan problem statement recent subscription platform rearchitecture provide limited configuration relying party stripe metadata adopted temporary solution subscription platform configuration however solution quickly become inflexible providing limited number configuration introducing unintended behaviour could easily resolved hindering new feature request relying party problem exacerbated relying party onboarded driver flexibility expand configuration localization support user friendly frontend provide immediate field validation ease configuration empower relying party configuration considered stripe metadata current solution firestore hcms strapi hcms contentful outcome chosen hcms contentful partially completely meet driver especially user friendly frontend ease driver statement applies hcmss considered adr even though strapi scored higher team hcms comparison since contentful already mozilla already setup save subscription platform team time money compared strapi pro con stripe metadata maintain current solution continuing stripe metadata good already implemented provides minimum required configuration bad inflexible allowing string keyvalue pair bad validation making change metadata validation error reported sentry engineer inform relying party issue bad support multiple locale bad requires stripe production access maintain bad provide user friendly frontend firestore migrate configuration firestore collection good give engineering complete control flexibility good reuse existing configuration without requring additional effort relying party neutral totally bespoke solution bad user friendly frontend bad validation field change bad requires custom tooling engineering support maintain hcms strapi selfhosted implementation headless strapi good flexible providing relational content model good enables complex configuration feature time simplifying configuration good provides localization support good provides user friendly frontend good provides immediate validation entering data good extensible similar tech stack subscription platform team good allows relying party configuration good simple get running good run cloud sso support neutral relying party would training new configuration bad requires sre effort setup bad currently within mozilla bad provide workflow support hcms contentful provider cloud hosted implemenatino headless contentful good flexible providing relational content model good enables complex configuration feature time simplifying configuration good provides user friendly frontend good provides immediate validation entering data good extensible frontend via react extension good allows relying party configuration good simple get running good already mozilla meaning nominimal setup required good enterprise cheaper competitor due existing contract good provides workflow support good run cloud sso support neutral relying party would training new configuration neutral provides localization currently support language supported subscription platform bad lowest score hcms comparison bad poor community support
handle put libra hearing depicted chart match way common platform case stored load file resourcesputlibracasehandlingdrawiodrawiosvg appdiagramsnet make amendment flowchart
adr python orm discussion participant roanna david katie implementation complete database change managed phinx php sql query written string php since migrating old php code base dropapp new codebase python react needed decide handle reading writing going forward graphql solve still hook graphql interface somehow driver learning curve community support power reliability considering production environment considered pure sql string python orm would require backend fullstack devs pick sql david strongly recommended run contrary best practice interpolating sql string python code mean cant read parsed debugger formatters utility sqlalchemy clear industry leader within python community web application development across many framework including flask django however although david also professionally recommends project given structure looselyaffiliated developer different experience level sqlalchemy properly requires significant upfront investment understanding complexity including mastering concept session management relationship loading peewee orm driven primarily single maintainer stable release designed simpler smaller hackable sqlalchemy still remaining expressive composable generated controversy open source community account main contributor behavior open contribution still significant community github fast release ponyorm mature peewee release come useful utility data diagram modeler like peewee mostly driven single contributor peewee despite sqlalchemy gold standard orms longterm volunteer mastered library aside david difficulty ramping everyone sqlalchemy maintaining outweighs difficulty potential volunteer familiar sqlalchemy pick one easier orms comparing release note peewee ponyorm david commented peewee recent release relate support edge case new technology stack whereas ponyorm release still appear involve developing functionality fixing bug around core case therefore concluded peewee productionready solution consequence easier philipp peewee professionally place work reactive robotics indicates concern sqlalchemy industry gold standard move towards big issue peewee come flask integration difficult harder people already fluent sql python orms audit query
workspace implemented proposed adam gibson mar discussed paul dub neural network require significant amount memory execution often range billion parameter improve performance manage memory usage take advantage fact neural network allocation cyclic nature since workload repeatedly allocate ndarrays create memory abstraction known workspace avoid redundant memory allocation approach help optimize memory usage enhance overall performance proposal architecture record discus implementation workspace concept ringbuffers within namespacelike abstraction java trywith resource memory allocation garbage collection workspace require configuration several parameter controlling memory allocation see description section detail memorymanager allocate indarray operation elementwise multiplication performed workspace indarray automatically closed released try block exited workspace track different type memory including allocated memory external memory unreferenced memory workspace memory gradient memory reduce memory usage reusing ring buffer described key trick reducing allocation reuse memory operation learned learning policy done ring buffer store memory operation user reuse existing memory traininginference increasing performance reducing memory usage description create named scope reuses memory instead allocating ringbuffers within namespacelike abstraction combine java trywith resource indicate scope memory well automatically garbage collect relevant memory order workspace configuration determine workspace created allocates memory following parameter possible initialsize initial size workspace byte workspace exceeds size automatically expanded maxsize maximum size workspace byte workspace try expand beyond size exception thrown overallocationlimit amount extra memory allocate beyond initial size workspace created useful workload high variability memory usage policyallocation allocation policy workspace strict strict allocation overallocate overallocation always always allocate new memory policylearning learning policy workspace none learning optimized optimized learning training full training mode policymirroring mirroring policy workspace enabled enable mirroring disabled disable mirroring hostonly mirror host memory policyspill spill policy workspace fail fail workspace run memory reallocate reallocate memory fly external spill external memory overallocationlimit amount extra memory allocate beyond initial size workspace created useful workload high variability memory usage tempblocksize size temporary memory block workspace byte usecycledetector whether enable cycle detector workspace detects prevents memory leak workspacemode workspace mode enabled enable workspace mode single single global workspace none disable workspace mode helperallowfallback whether allow fallback cpu gpu memory helperminsize minimum size byte workspace helper operation example usage example trywith block automatically close workspace release indarray workspace memory try block exited create workspace specified configuration within try block get memorymanager workspace allocate indarray workspace memory within another try block perform operation case elementwise multiplication java create workspace configuration initial size host memory workspaceconfiguration config workspaceconfigurationbuilder initialsize initial size policymirroringmirroringpolicyhostonly host memory build create workspace specified configuration try workspace workspace ndjgetworkspacemanagercreatenewworkspaceconfig get memory manager workspace memorymanager memmgr workspacegetmemorymanager allocate indarray workspace memory try indarray input memmgrallocatenew long databuffertypefloat indarray operation elementwise multiplication inputmuli indarray automatically released workspace memory try block exited workspace automatically closed try block exited since trywith block create workspace allocate indarray automatically closed released workspace memory try block exited regardless whether exception thrown order create workspace track following kind memory allocated memory memory explicitly allocated workspace particular operation computation external memory memory allocated outside workspace operation within workspace external memory useful working large datasets model fit entirely within workspace unreferenced memory memory allocated workspace longer operation computation unreferenced memory automatically deallocated workspace free memory resource workspace memory memory explicitly allocated workspace managing memory workspace state workspace memory include thing like memory managing scope tracking allocation deallocations managing internal structure gradient memory memory storing gradient backpropagation training dljs workspace track different type gradient memory including standard gradient external gradient deferred gradient note misuse cause memory leak following way closing workspace properly workspace properly closed cause memory leak happen user forgets close workspace exception occurs workspace closed catch block workspace long workspace long cause memory leak happen workspace reused many time cleared holding onto reference reference object created within workspace held onto long cause memory leak happen object released workspace longer needed many workspace many workspace created cause memory leak happen workspace created unnecessarily properly managed incorrect workspace configuration workspace configured incorrectly cause memory leak happen workspace allocated enough memory allocation policy set correctly consequence advantage memory allocation workspace allow preallocation memory avoid overhead associated dynamic memory allocation training memory reuse reusing allocated memory rather allocating new memory operation workspace help reduce memory fragmentation improve performance scope management workspace created within particular scope closed longer needed allows efficient memory management prevents memory leak automatic deallocation workspace closed memory allocated within workspace automatically deallocated freeing memory resource operation multiple workspace dlj allows creation multiple workspace useful running multiple model training process simultaneously disadvantage increased code complexity implementing workspace code add additional layer complexity require careful management workspace creation usage memory overhead workspace require overhead workspace creation management tracking increase memory usage workspace size limitation since workspace preallocated fixed size may case allocated size sufficient larger model datasets limit performance accuracy training process training slowdown depending specific case workspace implemented may case workspace could actually slow training process rather speed learning curve workspace effectively requires good understanding work manage properly may require additional learning training time
url schema developed fundraising application pay close attention url schema ended three different style slashy pseudoreststyle url like donationadd actionsentences like applyformembership combination like contactgetintouch dont search engine optimization seo form meaningful localized stable url main traffic donation page come banner dont much relevant content search engine index actionsentence style url future follow pattern verbnoun verbprepositionnoun reasoning behind convey information route verb english language instead restricting get post reststyle url deceiving application real api explicitly written restful architecture still dedicated rest api future api route sentence style fit better case architecture also read like sentence whenever change url decide create redirect old one new nginx configuration get support good indicator redirect route like functional endpoint like donationupdate dont redirect add information url point subdirectory prefix deapplyformembership enapplyformembership con listed httpssupportgooglecomwebmastersanswerhlen outweigh benefit consequence whenever touch route follow actionsentence style change decide adding redirect old one
title extract text file weight problem statement support file type must way extract text better extract text source file contrast extracting text converted pdf file multiple multiple file type priority javascala library reduce external dependency considered office document one library know apache poi support docx xlsx however doesnt support opendocument format odt opendocument format two library apache tika parser odftoolkit tika tikaparsers package contains opendocument parser extracting text huge dependency tree since superpackage containing parser almost every common file type odf toolkit depends apache jena also pull quite dependency much tikaparser bad since library manipulating opendocument file extract text created test extracted text odtods file worked first sight running test loop resulted strange nullpointer exception worked first run richtext richtext supported jdk richtexteditorkit swing pdf image pdf file tesseract text pdf file library apache pdfbox also itext agpl license image image image pdf file already tesseract place html html must converted pdf file text extracted textmarkdown file asis obviously outcome office file poi library open document file tika integrating source file make open document parser due huge dependency tree library added pdf apache pdfbox know library better itext
starting flask app feel set standard starting flask app one entrypoint start flask app openapigenerator entrypoint default mainpy look similar usrbinenv python import connexion openapiserver import encoder def main app connexionappname specificationdiropenapi appappjsonencoder encoderjsonencoder appaddapiopenapiyaml argumentstitle petstore api pythonicparamstrue apprunport name main main flask app started locally executing running python mainpy running flask app google app engine gae appyaml gunicorn start flask runtime python entrypoint gunicorn pythonpath mainpy port mainapp worker instanceclass note gunicorn automatically available gae python runtime environment
configuration start rfc httpsgithubcomopenmrsopenmrsrfcfrontendpull definition config file allow implementers customize behavior microfrontends providing static file common format include json yaml hcl config schema set expectation microfrontend implementationprovided config file say config file must structured key must constrains type value allowed config library code module allows developer define config schema load config file accordance schema may also provide tooling related configuration microfrontend developer official openmrs config library config library javascript module provides api module define config schema provides api module access config value provides api implementation provide config file validates config file nonproduction environment generates documentation config schema provides api implementation esmrootconfig specify config file hierarchy config file provides viewing resultant configuration configuration value come file providing temporary override similar singlespa allows import map override config library require configuration element default value specific apis look like topic separate rfc reason config library configuration firstclass citizen everything encourage developer make module configurable rather producing implementationspecific module providing standard mechanism help good error message bad configs config library allows defining constraint acceptable config value allows application fail fast good error message good error message essential expect nondev implementers configuration expect configurers able debug code generate config documentation hard keep doc complete would much easier nicelyformatted documentation could generated schema enforce convention config library enforce certain convention example config namespacing acceptable way reference concept validation configwriting speed production config library execute complex potentially expensive validation implementer working configuration production validation turned reduce load time possible future support config file type systemjs provides native support json import would great allow implementers write config file verbose easier work support comment good candidate include hcl yaml default value eliminate boilerplate supporting hierarchical configuration many organization multiple implementation many similarity difference forced manage config file implementation separately config library handle hierarchy provide config tool configuration hierarchy quickly get messy developer handle configuration like probably almost everyone make microfrontend configurable native json import mechanism user probably face incomprehensible runtime error bad configuration value provided provide tooling runtime module working configuration could thing config library would wouldnt actually bundled application microfrontend developer would interact config file native json import mechanism developer would probably actually tooling since wouldnt meaningfully integrated application would reduce config validation documentation best practice would likely often ignored common practice enforced wherever possible developer encouraged make thing configurable rather writing implementationspecific code emphasis configurability allow collaboration yield higherquality product
adr implementing start command clientside abstract cli start command must function similarly start command stage start app push nostart see story capi endpoint see design board whether implement feature capi cli posed challenge ultimately implement cli implement staging unstaged package start command cli side following step check app already started exit detect package ready staged assume user package meant staged recently uploaded package hasnt successfully turned droplet already curl get vappscf app appname guidpackagesorderbycreatedatperpage convert json response package take guid curl get vpackagespackageguiddropletsstatesstagedperpage final curl get droplet staged state run latest package came empty list resource build latest package curl post vbuild package guid packageguid poll staging log wait complete assign resulting droplet app curl patch vappsrelationshipscurrentdroplet data guid dropletguid start app curl post vappcf app appname guidactionsstart poll get process endpoint web process started state share step receive feedback client close contact provide open source resource client dependent start behavior implementation overly complex prefers breaking existing user workflow leaf potential room error around case user get unpredictable state depends imperative declarative workflow consequence stemming implement cli positive consequence cli user experience breaking change maintains rest api purity granular endpoint give advanced api consumer lot freedom implement creative solution allows future cloud foundry api client historic knowledge workflow depend way allows current client evolve around way negative consequence multiple client reimplement logic coherent definition start across client cause complex clientside logic difficult predict specific implementation interact new workflow rollback chose implement capi implementing capi would break fundamental principle designed avoid unpredictable orchestrator type api endpoint vappsguidactionsstart endpoint still relies modelhook vbuild endpoint currently follows api style guide preference endpoint asynchronously communicate component return pollable job combining two single endpoint would definitely lead unwanted complexity distribution business logic across multiple component resource general unpredictability one reason two action originally separated migration furthermore serverside implementation would imperfect interpretation restful design capi meant follow one principle restful architecture separation client serverside concern allows user interface evolve independently around consistent api allows scalability serverside simplifying component source given concern brought specific client capi meant service single client implementing serverside would cause unnecessary complexity finally clientside implementation relies api imperative way declarative workflow might preferred implementing start thorough series imperative endpoint would mean client would responsible predicting state user would want get externally leaf room error user get unpredictable state particularly around rollback case feedback capi consumer although concern start stage start unstarted application brought cli user worth noting client depend workflow well concept start changed greatly api side stretch imagine many client dependent old behavior would reimplement potential clientside interpretation opened dialogue held meeting apps manager team clientside implementation hear concern told open either solution would want notified api change might break current start implementation depended endpoint history collecting user feedback acceleration team brought attention order maintain essential workflow given vat access cli capi code base fell engineer decide whether changed behavior would implemented cli capi engineer chose implement behavior cli
geoprocessing caching geoprocessing call large shape take long time complete user draw custom shape also pick list predefined shape system geoprocessing shape multiple user select wasteful unnecessary caching geoprocessing result predefined shape well known area interest wkaois improve user experience application performance outside geoprocessing also database call much faster comparison likely see significant improvement caching especially since cache could table database adr consider following question cached cached cached cached cache invalidated also sketch implementation plan consider consequence sideeffects cached output geoprocessing service wkaois cached almost always json blob keyvalue pair key combination overlaid cell value set raster value count cell input geojson shape set related argument specify raster operation type etc could cache entire output mapshed run update constituent raster vector data would force recalculation whole caching timeconsuming geoprocessing result ensure update constituent raster would invalidate specific cached result leaving others still current since vector data result would never cached always current upon update well case mapshed modification change geoprocessing query thus request cached easily modification change geoprocessing query case cache current condition modificationless run scenario since storing arbitrary shape balloon size cache quickly may revisited future case foresee updating raster often may beneficial consider caching entire json response api cached current stack already django caching setup allows cache single line code python djangocorecache import cache cachesetkey value none key unique identified consisting wkaoi geoprocessing operation value result geoprocessing operation none timeout value ensures value dont ever expire retrieval simple python value cachegetkey value calculate cache value return value key prefixed geop namespace cache entry app composed wkaoi consists table name integer geoprocessing operation name example geopboundaryhucnlcdsoils practice key may actually something like geopboundaryhucnlcdsoils configurable appwide prefix default version number prefixed key however long always access cache via djangocorecachecache shouldnt worry cached django caching framework configured number cache backends including redis database currently setup redis elasticache production advantage redis already configured allows take advantage django caching framework configured redis redis really fast good candidate storing keyvalue pair like intend designed cache thus come mechanism timeout lru cache miss box disadvantage redis case system failure cached value lost cached purge least recently value might good candidate storing hardtoprocess large wkaois rarely cached user selects wkaoi request made analyze modeling wkaoi result havent already cached run cache time build cache new user request wkaois get cached result cached celery task calculation would otherwise happen select wkaois large process production infrastructure hucs timeout mapshed gathering phase run geoprocessing step powerful infrastructure longer timeouts batch process cache result decommission make available regular user production app without needing extra power render purpose well pair new django management command first run geoprocessing step given wkaois save result file run super environment second take file preprocessed result given shape operation add cache run production environment cache invalidated since every cache entry tagged type certain raster updated remove related cache entry example update uspercentslopemepsg raster nlcdslope slope request could simply run python cachedeletepatterngeopnlcdslope cachedeletepatterngeopslope refresh specific shape could python cachedeletepatterngeopboundaryhuc could management command well implementation plan see geoprocessing currently done via summaryjob done via mapshedjob consistency rewrite geoprocessing bit mapshedjob instead split nlcdsoilcensus three request nlcd soil nlcdsoil first two analyze much faster second modelingtr update geoprocessing submodule take geojson shape wkaoi geoprocessing type return output update celery task django view geoprocessing submodule new interface add caching support geoprocessing submodule geoprocessing done two part start finish case cache hit signal passed start finish instructs fetch value cache instead sjsretrieve update send wkaoi instead geojson predefined shape rwd user defined shape still sent geojson consequence make worst case scenario cache miss slightly longer currently well checking cache actual geoprocessing case elasticache failure cache would rebuilt large wkaois processed outofband may get pushed cache cache exceeds maximum size user defined shape still cached runtime improved since longest time taking activity geoprocessing fetching tile adding network cache may help improve runtimes
add cache control header superseded cache control header prevent client browser rerequesting page changed may leveraged proxy return cached page multiple client cachecontrol header added valid request error cached consequence client locally cached version page possible reducing server load
splitserviceintotwo tap service comprises distinct responsibility provide public facing grant application form styled govuk style guide provide private portal manage grant application formal recorded manner private grant management area secured behind dit vpn public facing grant application process area require authentication system necessarily required authentication system two area share user account user type person could feasibly access area different purpose done two unconnected user account grant application data shared two area decided separate two system service service split codebase separate project however leave within git repository reason service share single git repo remove versioning two service thus saving valuable development effort development environment much easier spin locally service managed within single dockercomposeyml file foresee codebase service become large name service frontend backoffice due developer constraint within team small team backend developer django framework create service service communicate via json rest request database read write access others database consequence require work infrastructure side project however dit ecosystem already made many small service running paas ground work around tooling already available utilise mitigating additional work create development testing require effort building feature require change service separation data user help manage data access requirement user access nothing
deploy via heroku pipeline initially project appropriate deploy heroku needed mit touchstone authentication however based adr authentication via touchstone saml able remove modshib requirement initially prevented heroku heroku pipeline staging production build consequence application environment proven production previous application
gnu make centralise task problem statement want able centralise single tool task called development cycle build cycle cicd pipeline driver must significant user base community must require significant installation must sufficiently simple learn considered gnu make invoke rake scons outcome chosen gnu make compared evaluated tool see pro con fit bill invoke well maintained well documented facto standard sufficient community rake required install learn ruby scons build tool seems difficult apprehendget grip pro con gnu make gnu make manual good well known widely standard huge existing community preinstalled default system easily installed existing system require install specific language python ruby etc enough purpose writing task plenty documentation plenty existing information source bad concept difficult grasp default behavior unclear cause script work difficult debug complex feature invoke good python based promise like ruby rake clean high level api like gnu make emphasis minimal boilerplate common pattern ability run multiple task single invocation bad facto standard python large number unresolved untriaged issue time writing large number opened pull request dating back suggests slack maintenance seem large enough community previous point seem disqualify solution rake good proven tool facto standard ruby world extensive community extensive documentation bad requires knowlearn another language python ruby requires install ruby stack scons good written python seems fairly active bad build tool task tool getting grip tool documentation cumbersome large number unresolved untriaged issue time writing suggests slack maintenance limited number star github
removal concierge service architecture simplification ditto related github issue idea ditto committers came order simplify architecture amongst many benefit get rid ditto concierge service ditto architecture move authorization task currently responsible existing ditto service background change came discussion concierge service authorization policy enforcement external api interaction processing command message within ditto acting middle man ditto edge service gateway connectivity entity persistence service policy thing persistence entity manage already facade library character thingid sharding key shard region order provide horizontal scalability cache policy enforcer concierge node cluster due effect policyid thingid lot caching thingid policyid relation policy enforcer authorization reduced library purpose may also done either ditto edge service gateway connectivity entity service policy thing would lot benefit comparing current ditto architecture separate concierge service potential benefit simplified architecture overall resource consumption cpu memory container operate hop ditto service cluster saving least one hop per processed api call one additional one response wanted beneficial resource consumption json deserialization required ditto service lower overall latency higher overall throughput possible improved stability rolling update rolling restarts ditto concierge always additional error source shard region restarted ditto edge service could short period forward command authorize additional benefit depending authorization policy enforcement done future aspect approach authorization edge gatewayconnectivity approach authorization entity service policiesthings policy enforcer caching distributed caching potentially instance edge eventually cache policy enforced specific policy unpredictable cache size due missing sharding localized caching policy one thing cached within thingpersistenceactor policy partial event handling edge directly policy enforcer create multiple partial event based one source event information regarding edge split one source event several partial event must piggybacked event header live command message processing edge directly route authorized live command message interested edge gateway connectivity live command message one additional hop compared left column hop currently concierge service also necessaryvia thing service done thing service would also authorize live commandsmessages smart channel selection rather complex state machine logic concierge must moved edge supporting live channel condition case live channel condition logic done completely thingpersistenceactor simplifying implementation lot conditional message rather complex implementation required similar smart channel selection simple implementation done completely thingpersistenceactor overall weight concierge service removed ditto instead authorization policy enforcement concierge logic moved entity service policiesthings consequence api perspective nonbreaking change therefore would strictly require ditto release however architecture configuration change configuration change done concierge service moved suggest kind architecture change major ditto release ditto require resource provide lower latency higher throughput processing api interaction
every meal delivery pick pin code network connection might lost meal delivered fridge user come grab fridge cant check data user online card swapping inapp distance opening fridge pin pad keyboard still quite sophisticated software internal memory process order update expect every meal unique provided kitchen meal might customized general catalog let say lactosefree lasagna addressed specific user purchase production process update user device meal unique generate access code based meal meal dispatched ghost kitchen special digit code consequence user grab meal even smartfridge disconnected network moment picking meal pin code meal formed upfront delivered early device smartfridge userdevice possibly might mechanism update code prepared meal delivery pin code quite long lower chance bruteforce attack bonus feature easier delegate meal grabbing people risk someone lucky guess pin code first attempt argument long digit code long type
graphql api supercedes api graphql different way think apis overcome shortcoming rest overfetchingunderfetching inflexibility also provides greater depth analysis agreed change api rest documented openapi graphql consequence allow flexibility rapid iteration front end easier maintenance evolution api also think graphlike nature graphql well suited domain model may address common challenge graphql caching rigidness query monitoring
environment variable instead config singleton configts exported single config object single debug boolean property debugutilstsx control whether render extra debug information one problem order activate change value file version control remember revert never commit debug true removed configts file environment variable instead environment variable set set running new script defined packagejson consequence start watcher yarn startdebuginfo enable without modify file
title base factory area core tag core saleschannel performance cache within store api request storefront sale channel must built building sale channel resource consuming task database since many dal object included sale channel therefore cache corresponding service shopwarecoresystemsaleschannelcontextsaleschannelcontextfactory already implemented past shopwarecoresystemsaleschannelcontextcachedsaleschannelcontextfactory however since also contains customer selected shipping address well billing address cannot cached customer logged php namespace shopwarecoresystemsaleschannelcontext class cachedsaleschannelcontextfactory extends abstractsaleschannelcontextfactory public function createstring token string saleschannelid array saleschannelcontext thisiscacheableoptions return thisgetdecoratedcreatetoken saleschannelid private function iscacheablearray bool return issetoptionssaleschannelcontextservicecustomerid issetoptionssaleschannelcontextservicebillingaddressid issetoptionssaleschannelcontextserviceshippingaddressid however since also data independent customer data possible cache resourcecosting data across customer even customer logged selected different payment method shipping method address implemented shopwarecoresystemsaleschannelcontextbasecontextfactory responsible creating shopwarecoresystemsaleschannelbasecontext data belongs sale channel independent customer account loaded basecontext php namespace shopwarecoresystemsaleschannel class basecontext protected customergroupentity currentcustomergroup protected customergroupentity fallbackcustomergroup protected currencyentity currency protected saleschannelentity saleschannel protected taxcollection taxrules protected paymentmethodentity paymentmethod protected shippingmethodentity shippingmethod protected shippinglocation shippinglocation protected private cashroundingconfig itemrounding private cashroundingconfig totalrounding basecontextfactory well basecontext marked internal intended extension intervention loading basecontext quickly lead cache miss therefore supported addition corresponding saleschannelid current session parameter passed service contains list changed parameter basecontextfactory take account following parameter also effect corresponding cache permutation service shippingmethodid contains selected shipping method paymentmethodid contains selected payment method countryid contains selected shipping country countrystateid contains selected shipping state currencyid contains selected currency languageid contains selected language addition shopwarecoresystemsaleschannelcontextbasecontextfactory shopwarecoresystemsaleschannelcontextcachedsaleschannelcontextfactory implemented responsible caching base assembles cache key based parameter listed load base cache already loaded php namespace shopwarecoresystemsaleschannelcontext class cachedbasecontextfactory extends abstractbasecontextfactory public function createstring saleschannelid array basecontext ksortoptions key arrayintersectkeyoptions saleschannelcontextservicecurrencyid true saleschannelcontextservicelanguageid true saleschannelcontextservicedomainid true saleschannelcontextservicepaymentmethodid true saleschannelcontextserviceshippingmethodid true saleschannelcontextserviceversionid true saleschannelcontextservicecountryid true saleschannelcontextservicecountrystateid true key implode name mdjsonencodekeys jsonthrowonerror caching sale channel handled two level cachedsaleschannelcontextfactory responsible global caching provides fast hit rate load time customer logged cachedbasecontextfactory responsible caching generic object relate customer account customer created another payment shipping method shared loggedin user
optimised origin proposed deciders donald gray tom crane issue problem statement dlcs currently notion customeroriginstrategy dictate asset fetched http via scli http etc credential required also optimised flag conflates thing asset tileready jps dont transcoded asset treated storage copy source image dlcs split different thing driver flexibility able asset tileready andor storage treated simplicity easy work asset handled dlcs outcome splitting customeroriginstrategy addressed optimised storage optimised column customeroriginstrategy indicates asset treated dlcs storage fast stable enough stream file resource orchestrate image optimised restricted sambient origin optimised applied anything sambient origin strategy add additional complexity specialserver specialserver ignorant customeroriginstrategy doesnt know access something via http credential sambient negates iam policy applied orchestrator specialserver tileready indicate asset imageserver ready could small jpeg tileoptimsed jpeg pyramidal tiff introduce new imageoptimisationpolicy key useoriginal useoriginal valid image asset may want restrict useoriginal customer show combination optimised imageoptimisationpolicy affect various part system fasthigher iop represents anything useoriginal optimised iop engine iiifimg file false fasthigher download origin convert jpthumbs save dlcsstorage orchestrate dlcs storage stream dlcs storage true fasthigher download origin convert jpthumbs save dlcsstorage orchestrate dlcs storage stream origin false useoriginal download origin create thumb copy origin dlcs storage orchestrate dlcs storage stream dlcs storage true useoriginal download origin create thumb orchestrate origin stream origin additional change ordering addition introduce priority field customeroriginstrategy table allow control order strategy checked simplify complex rule configured wellcome positive consequence easier understand control asset tileready allows customer profile etc negative consequence leak internal implementation detail dlcs api consumer incorrectly useoriginal huge image could put unnecessary load cantaloupe changing meaning field run update deployment depending usage may check customeroriginstrategy regex origin determine imageoptimisationpolicy may fit single migration
create item view state adapter problem statement creation list item viewstate viewmodelusecase cause lot model wrappingoperation data flow viewmodelusecase layer item view state creation facing concern tight coupling decided create item view state adapter neglected creating item view state viewmodelsusecases achieve consistency seperation concern
title inventory manager take care fridge inventory manager fridge manager inventory manager would hold food item fridge would manage physical fridge inventory manager manage following manage fridge manage food item including pricing manage number item fridge consequence would easier inventory manager take care item rather separate manager
entering locationsdestinations trip destination entered trip somehow two obvious choice seem typing kind autocompletion feature clicking directly map set marker paradigm dominant one existing apis sitemap website aim support autocomplete clicking map would convenient user site consequence two method adding destination mean two additional function code complexity added maintenance testing method work mobileresponsive well vastly better additional work additional testing additional code additional code complexity
adr build thing accessibility monitoring team require mean picking website test random list weighted variety criterion complaint passed previouslytested site test change site specifically chosen guiding body collecting maintaining list public sector website pick triaging site check live check accessibility statement measure size page etc prioritising site testing tracking progress testing website creating report completed test sending report site owner managing recording interaction site owner whilst number accessibility testing solution available geared towards testing one site require least assume access source code deployment system testing multiple site party outside site domain common requirement vendor similarly whilst report generated testing tool good standard content ironically accessibility furthermore control content generated report therefore combination database administration semiautomatic accessibility testing customer relationship support ticket management system able move data usable fashion rdparty tool provide part functionality required made communicate easily write whatever code necessary form glue bind together automate whatever worth automating consequence partiallybespoke system even though intended internal built adherence way change apis integrating may render system inoperable future channel change alerted mechanism modify system match change
heroku scheduler recurring task user receive daily email around certain time heroku scheduler free service created heroku let schedule task run specific time hackney already heroku scheduler hackney repair project since established pattern heroku scheduler project continue pattern adopting project consequence creating editing recurring task require access project heroku heroku doesnt give guarantee thing run precisely time high level precision required meet user
derived attribute derived attribute readonly following attribute derived file system name file name without extension contenttype file extension without dot lowercased consequence consequence
allow overriding configuration local configuration proposed mention adr flow tool command line tool managing adr file aimed command line mswindows primarily also platform guiding principle order preserve simplicity dont want introduce separate data store data stored managed file includes configuration explicit easily identifiable editable given adr decided adr directory identified file called adr file also contain configuration tool reduce number moving part marker file adr also configuration file part value statement file available source control easily shared collaborated team mean marker file versioncontrolled well time configuration may change perdeveloper basis example location editor edit adrs introduce separate configuration file mean definition always separate configuraton file top empty marker file make sharing configuration slightly harder make hard share configuration customize others environment variable approach configure system environment variable osdependenet make configuration somewhat explicit also harder share across team necessary keep adr file current dual role marker file shared configuration file addition well add supply localadr file format adr file allow developer specify property override property specified adr value taken consequence developer specify separate localadr file local configuration overriding adr order avoid overriding others configuration localadr ignored version control system added gitignore git
create whale comparator variety whale many attribute thus may necessary sort whale various different grouping order sort object function object must implemented one three possible design nested class anonymous class lambda expression implement comparablewhale create compareto default method field specie specie nested comparator class field whaleid long whale consequence nested comparator class best choice program due wide availability reusability future iteration program versus oneuse nature anonymous class lambda expression additional compareto default method implemented proper function comparablewhale whale class
navigation activity fragment problem statement navigation multi module application requires indirect solution putting navigation abstraction single file invalidates cache every time changed singleresponsibility interface segregation principle navigation facing concern cache issue decided creating featurenamefragmentprovider featurenameactivityintentprovider navigation interface featurenameapi neglected navigation module achieve may split feature featurenameapi featurenameimpl module accepting creating module way flexible break module changed feature
architecture record graph data neoj spent inordinate amount time debating ruby python java postgres neoj pariyatti data model ultimately require complex relationship wellsuited relational database anticipation point time spent early portion project exploring graph database anticipated stopping project collection artefact book audio video etc tagging metadata graph database may necessary possible manipulate metadata want apply artefact relational model awkward however expect begin collecting literature pariyatti cross line language script culture country century stuck neoj sufficient rubyrails support neoj strong activerecord postgres problem primarily datamodeling information architecture problem technical problem conversation expert suggested graph database sensible one continue neoj commitment strictly graph data modeling neoj future capacity switch wikibase graph database like dgraph becomes popular harm switching consequence future developer familiarize neoj activegraph previously neojrb developer understand appreciate neoj static schema take great care manipulating model schema rail application must aware ultimately wikibase probably best backend tool job heavy complicated serve data store kosa continue run complication rubygems feel developer time wasted unreasonable switch postgres long serious discussion shortcoming switching database huge task committed graphshaped data team designer encouraged exploit capability design
title adr plan migrate cflinuxfs cflinuxfs adr plan migrate cflinuxfs cflinuxfs cflinuxfs configured packaged deployment ubuntu bionic base layer stack container build tenant source code maintained cloudfoundry foundation ensure new release contain fix mitigation relevant april ubuntu bionic reach end standard support period longer receive security update cloudfoundry foundation also cease support cflinuxfs time effect relying support present greater risk subsequently discovered exploitable vulnerability mitigated patched ubuntu jammy successor ubuntu bionic cflinuxfs succeeds cflinuxfs april cloudfoundry foundation introduce cflinuxfs cfdeployment make default stack april remove cflinuxfs cfdeployment default provide ops file reintroduce optionally complicating factor reaching end support period piece software common upgrading next version isnt typically big deal however case cflinuxfs cflinuxfs complicating factor tenant application implicitly depend operating system exact collection library version supplied library major version often change release example bionic openssl jammy openssl cannot assume changing base layer container image wont break application tenant must test application cflinuxfs resolve problem cannot provide much support given number application platform variety technology tenant often slow respond communication call action problem faced lifetime platform usually build plan providing long window example month postgres deprecation act issuing regular reminder unfortunately case given long lead time feb cloudfoundry foundation still buildpacks missing support cflinuxfs regardless must provide adequate timeframe tenant act govuk paas middle decommissioned every tenant asked migrate away platform many consuming significant proportion development capacity case work prioritize migration activity work swap cflinuxfs must set expectation quickly tenant act accordingly may choose transition cflinuxfs favour trying migrate away platform cflinuxfs deadline given complicating factor risk associated running unsupported base operating system version following offer cflinuxfs govuk paas soon available keep cflinuxfs default communicate upcoming change tenant provide monthly reminder alongside decommissioning news provide month window make change make cflinuxfs default end month period offer cflinuxfs platform fully decommissioned support tenant cannot choose make switch tenant risk must clear information assurance team risk management process etc risk mitigationscontrols basing tenant application unsupported version present medium level risk due opportunity vulnerability varying severity unpatched exploitation unnoticed account monitor ubuntu security notice bionic continued visibility vulnerability cloud foundry foundation vulnerability management working group also continue publish ubuntu security notice bionic long supported way cfdeployment notification cve team responsible understanding scope severity inform tenant necessary point mitigation put place mitigate risk somewhat reducing number instance container running cflinuxfs base encouraging tenant move cflinuxfs making clear end month period still cflinuxfs responsible risk application consequence consequence continue base tenant application ubuntu bionic cflinuxfs default month april july month may july ubuntu bionic unsupported operating system version elevated risk accept tenant mitigate moving cflinuxfs also choosing offer unsupported operating system rest lifetime platform default month period allow support tenant either cannot switch cflinuxfs allows risk assumed tenant selectively think existing application isolation security control sufficient protect platform tenant event serious exploitable vulnerability discovered ubuntu bionic leaf standard support period
kata naming draft katas come life overlap etc version exist structure needed allow grouping katas form one example katas group array api object api string api etc also katas group name logically correct order make easy allow grouping example arrayapikatas one group present website somewhere else group must consistently many katas put following group done across board language katas also library etc order coherent structure make easier user understand look katas xxx api katas promise katas good example perfect point time good standard like group name xxx api example promise api string api directory name xxxapi example eslanguagearrayapi group contains api katas xxxmethod xxxproperty katas two additional katas provided basic kata kata describes basic knowledge needed understanding topic example promise explaination see promise basic kata well api kata give quick overview api understand done pick common case every methodproperty show briefly explicit kata like promiseall cover feature detailed needed might even indepth kata katas good example syntax katas katas help learn syntax javascript group example block scope template string rest operator destructuring others tbd adhere naming scheme tbd katas kata type must described even standardized consequence kata group become easier identify understand might also lead better way visualize katastopics exist different language version therefore allow become useful
adr track content item language adr agreed focusing english page noticed last month restriction causing issue benefit content item contentid different locale needed handle edge case retrieving information publishing api order work around retrieving english language content impact quality metric content wont accurate page track content metric content item regardless locale
lab analysis workflow lab interface several iteration initial implementation initially started tool added toolruns realized needed way create copy tool adjust source basic workflow browse existing tool manually created api request create tool run tool edits tool run generate new tool run tool run effectively like export current implementation backend frontend first class support maml method translating mathematical expression asts tool workflow browse tool called template create tool run template called analysis modify tool run instead generating new tool run every time analysis result referenced url act basemap calculated fly required feature easy way share analysis result template others ability interactively create analysis ability preview share map generated node proposed solution discussion nathan eugene ive concluded workflow centered workspace rather singular analysis make sense design tradeoff supporting multiple asts level support export sharing arent worth workflow user creates new workspace user either build new analysis scratch workspace import template create one user preview node verify thing user share preview link update analysis modified may always completely valid user publishes analysis workspace new template template version immutable relied upon change production usage basemaps imagery published template require explicit export order update user make change analysis publishes new version template user view tagged version template user clone workspace copy analysis new workspace link otherwise template published various visibility permission future version maml allow referencing directly node open possibility black box algorithm user interations workspace user point entry creating analysis workflow user search workspace analysis contain multiple analysis allow specifying default analysis rendering sharing import export template create new analysis node add node existing analysis compare output analysis migration create new workspace every existing analysis analysis individual asts modified place change effective immediately required named anymore linked template easier export future able reference template analysis toolreferencenode probably renamed add readonly attrubute prevent exported analysis edited template list immutable ast export metadata versioning searching model template uuid string name string detail string description string thumbnailurl uuiduser owner uuiduser createdby uuiduser modifiedby createdat modifiedat uuidorganization organization visiblity visiblity string requirement uuidlicense license templatecategory template category templatetag uuidtemplate template uuidtag tag templateversion int auto increment easy sort string version uuidtemplate template uuidanalysis analysis createdat modifiedat uuiduser createdby uuiduser modifiedby workspace uuid string name string description uuidanalysis activeanalysis workspacecategory uuidworkspace workspace uuidcategory category workspacetag uuidworkspace workspace uuidtag tag workspaceanalysis uuidworkspace workspace uuidanalysis analysis createdat modifiedat uuiduser createdby uuiduser modifiedby
category adr tag analysis title adr filter share nothing adr argued would rather embarrassing code quality tool become tangled bugridden tangle created dependency unit code avoid decided separate analysis visualization two tech stack share nothing keep analysis turning tangled mess except one module called model filter allowed share code filter depend another filter model contains code generate ccjson metric parsing code consequence filter parse different metric code replication happen negligible shared model mean code shared explicitly naming module model instead shared hope make clear contain model contain code replicated
move demo gcp previously demo bedrock run heroku worked fine herokus recent security incident meant integration disabled prompting discussion selfmanaged demo instance addition possible demo bedrock pocket mode heroku amending setting via heroku web domain set wwwdemoxallizomorg originally set mozorg may confusing colleague reviewing pocket change flipping unflipping setting heroku enable mozorg mode pocket mode also extra legwork ideally would without implemented new selfmanaged approach running demo handful google cloud platform service cloud build cloud run significant one cloud build trigger monitor push specific branch build bedrock container branch appropriate env var pocket mozorg including sitemode env var specifies mode bedrock run cloud run deploys built container serverless webapp default supervisord run container update file automatically process triggered simple push specific target branch pushing code mozorgdemo result relevant code deployed mozorg mode wwwdemoallizomorg pushing pocketdemo deploy wwwdemotekcoptegcom pocket mode environment variable also configured developer via two dedicated env file bedrock codebase demo service clash unlikely still managed common sense consequence upside easier stand pocket demo addition existing mozorg demo plus full control infrastructure demo run longer heroku demo future may also able support adhoc review apps also heroku past downside new secret value required demo instance value cannot demo env var file codebase public srelike devops needed add secret value gcps secret manager service quick requires understanding side fit together plus access may backender add moment meao backend team gcp access handy monitor whether demo successfull pushed amend secret etc issue addressed without lot work
konduit serving packaging system proposed alex black discussed sam paul konduit serving complex modular tool intended deployed number different configuration multiple packaging format given modelpipeline deploymentpackaging scenario vary widely example user might want deploy tensorflow model via konduit serving one configuration many docker image packaging tensorflow cuda linux arm system serving via httprest selfcontained exe embedded jvm samediff tensorflow import run model cpu window avx system intel mkl mkldnn onednn included serving performed via grpc currently packaging konduit serving done via maven profile maven module user selects combination dopendencies functionality enabling number profile system property example building window cpu uber jar look something like mvn clean package dskiptests puberjar pcpu ppython pnative ppmml ptensorflow dchipcpu djavacppplatformwindowsx packaging executed adding different profile approach got quite far term packaging enabling flexible packaging including uberjars docker war debrpms tar file exe file running limit approach specifically approach following problem combination available user going continue grow many profile combination devsusers know understand combination difficult impossible profile property example building binary window linux mac ppc etc easy leave performance table ndjsamedifftensorflow etc binary built without avx support many incompatibility become apparent runtime example build cuda version find tensorflow release cuda hence runtime problem dataapi rewrite configuration execution separate one configuration run many different way example tensorflow model could run tensorflow samediff tvm possibly automated conversion onnx etc challenging support via profile property build approach usability issue example user know lot different profile configuration etc get optimal even functional deployment even know possible example user might build uberjar without pmml profile enabled discover jar cant run pipeline pmml model packaging custom code dependency asset inc model vocabulary file etc difficult impossible present building konduit serving artifact uberjars docker image etc requires cloning main source code repo though hide automatically case python clibased source build proposal scope proposal limited creationpackaging konduit serving uberjar may deployed many form docker rpm war etc note nonjava packagingdeployments pipeline scope deploy pure binary osgi support relevant scope extent osgibased system could work build top functionality described proposal proposal goal goal packaging proposal follows retain enhance existing deployment uberjar docker war exe etc remove reliance build source constructing konduit serving artifact enable greater flexibility builddeployment configuration enable custom java python code dependency easily included deployment improve usability reliability packaging following way remove reliance maven profile property least executing build automate selection recommendation module include given pipeline look pipeline config find whats necessaryuseful include add validation checking common pitfall dependency issue incompatible cpu architecture wrong cuda version etc make clear user requirement term hardware software satisfied deployment system requires cuda java etc proposal overview proposal number part build tool top gradle via buildgradlekts generation utilizes configuration format actually perform required build konduit serving build configuration format command line tool creating build configuration user pipeline necessary triggering build based generated build configuration file system packaging custom java code dependency note usability possible well make user doesnt aware build configuration file example simple cli might configure execute build cli would generate configuration pas build tool without user aware configuration file however advanced user case system administrator devops etc allow configuration file written modified directly outside cliui workflow user part build tool given configuration file specifies included build detail later build tool execute build necessary create requested artifact jar docker image etc note term build tool may ideal name proposed tool simply thin layer top maven comparable true build tool like maven gradle ant etc note also principle though proposed right multiple build tool creating final artifact configuration definition build tool build execution separate look pure deployment main possible second build tool would osgibased deployment however would still maven based proposed build tool generate execute via gradle buildgradlekts file based configuration file similar current module profile approach continue maven plugins actual packaging creation uberjars etc generated buildgradlekts file include repository section repository mavencentral plugin section plugins java dependency section listing direct dependency required konduit serving module konduitservingtensorflow konduitservingndj etc native library backend dependency ndj nativecuda backends example logging etc dependency property sourcecompatibility targetcompatibility section necessary creating build artifact docker image war file etc utility task enforcing dependency convergence etc one consequence packaging module would removed favor single konduitservingbuild module konduitservingdocker konduitservingrpm konduitservinguberjar etc longer exist future likely allow build tool create multiple different artifact based one configuration file one uberjar user target platform output example separate jar file one linux linux armhf window usability perspective note user usually wont interact build tool directly instead touching aware uicli layer top gradle maven near term either tool gradle maven adequate implementing proposal build tool maven advantage something team currently experience however gradle seems edge two respect build speedperformance httpsgradleorgmavenvsgradle extensibilityflexibility including coding directly buildgradle file plan proceed gradle result major blockes either switch add parallel implementation based maven gradle kotlin instead groovy generated build file practice wont make much difference build configuration generated written hand kotlin provide benefit groovy better ide support due static typing hence get benefit autocompletion easy navigation source easier refactoring etc work generated buildgradlekts file directly part configuration file configuration file provide information necessary determine build via generated buildgradlekts file set direct dependency plugins property profile end following information included part configuration konduit serving module include konduit serving version optional default latest specified deployment packaging type uberjar docker etc associated configuration deployment target architecture cpu gpu etc selected preferred pipeline step runner one exists one included pipeline step information necessary package required externalcustom code dependency file resource etc additional dependency configuration override dependency management exclusion etc metadata timestamps comment author etc jsonyaml proposed format build configuration file part cli cli build tool one way user configure build required deployment artifact uberjar docker image etc internally usually without user aware cli tool create build configuration pas build tool execution two mode operation proposed cli command line style wizard style command line style provide information necessary produce configuration file short form exact configuration designed detail later likely look something like following bash konduitbuild mypipelinejson module tensorflowndjimage deploy docker dockerconfig namexversiony incudejava comcompanymylibrary wizard style cli guide user selecting pipeline term implementation priority implementation command line style specific design worked suggested usage look something like following konduitbuild konduit serving build tool enter path pipeline json yml file ctrlc exit myfileyml select deployment environment comma space delimited case insensitive linux window mac osx lahf linux arm armhf linux arm arm lla wizard style would output command line style command entered optionally configuration file would execute build based configuration part build build would simple singlepage nothing fancy feature rich near term focused three thing guiding user configuration process pipeline main goal show user required module serving pipeline customing deployment target platform selected model runner configure step etc creating configuration file though would implemented backend based user selects via triggering build based generated configuration file user able load previouslycreated build configuration file partially completely specified starting point pipeline build later may add way visualize create pipeline configuration also look would separate adr proposed starting stopping build straightforward assuming user konduit python package similar installed konduitbuildui konduit serving build launched httpslocalhost ctrlc exit workflow would user would something like launch konduitbuildui select konduit serving pipeline deploy later allow generic model similar selection instead providing pipeline configuration select deployment environment cpu architecture cpu gpu avx support etc later device profile select pipeline step runner multiple available example running tensorflow model whether samediff tvm etc run model optionally add custom java code python code dependency java codedependencies simple specifying gav coordinate user project python packaging dependency tbd may something like directory requirementstxt optionally embed filesresources deployment artifact including model file required select packaging uberjar docker exe etc selected show configuration relevant packaging click verify check produce final report would check dependency estimate final file size verify binary compatibility etc necessary prompt user thing explicitly approve example necessary accepting license party software bundled click build execute build would pas configuration build tool create final artifact uberjars docker image etc point user would able save current configuration yamljson file load back later stage would allow user select consistent previous choice still visible grayed step regarding device profile idea would allow user select thing like raspberry jetson nano generic linux possibly even common cloud vms reduce amount knowledgeconfiguration required create pipeline part pipeline analysis module selection important component cli would determining konduit serving module included execute pipeline available runner could execute step contained within nearterm could add something semiautomatically trackaggregate execution supportcapabilities across module wed build mapping module name rather pipelinesteprunners pipelinestep configuration run basic version especially difficult idea would encode information like samediffpipelinesteprunner module konduitservingsamediff execute step type tensorflowpipelinestep advanced version actually check configuration would added later samediffpipelinesteprunner run tensorflow model well check configuration time one thing keep mind extensibility example one day might custom pipeline step available via konduit serving hub codedependencies custom pipeline step could pulled automatically however substantially alter basic approach analysismodule selection principle simply adding external web lookup step determine run given step part customexternal java code dependency pipeline user want write custom java code example custom pipeline step custom metric etc custom java code dependency direct transitive also included built jar easy system including code dependency konduit serving pipeline java proposal handling trivially simple user package code standard maven project user mvn install project including custom code local maven repository note uberjar standard modulejar direct transitive dependency fine user specify gav coordinate group artifact version custom functionality configuration file likely via cliui additional possible mechanism could added later would provide way building github repository clone install add konduit serving deployment would doable couple line configuration could useful cicd based pipeline install provide gav approach also work fine osgibased buildsdeployments future future adrs number aspect packaging system would worked future adrs adrs may may produced following component configuration format design custom python code dependency embedding architecture compatibility checking dependency native code include dependency actually work arm ppcle etc fileresource embedding usability isuses user pipeline access embedded file consequence advantage get flexible powerful build system enable mostall javabased packaging including improved configuration optionscontrol current profilesproperties approach improved build reliability via compatibility check built system move problem run time buildconfiguration time improved usability via guiding user available compatible via cli easier debugging build see exact generated standalone pombuildgradlekts work backwards something wrong try figure exactly included disadvantage check difficult implement may possible always perform reliably example arbitrary python library work arm add yet another configuration fileformat user know learn proposed custom java packaging via maven projectinstall might work well gradle sbt user however analogous workflow gradlesbt could added added discussion consider basing tool gradle may better match maven easier extend necessary gradle maven originally adr proposed maven also gradle may beneficial ifwhen deploy android though many issue android deployment consider beyond mavengradle note however pomxmlbuildgradle wont generated reused longlived project anything instead generated build config usability user experience ide support shouldnt matter maven gradle one benefit alex either building overseeing team generally maven experience also necessarily eitheror could maven gradle build tool implementation switch later without user really aware switch gradle pomxml file generator also might provide another make build tool live inside parent build tool motivation enable user access konduit serving build functionality without external installation though pip install konduitserving way get build tool probably serve average python developerdata scientist wont ideal jvmbased developer perhaps maven plugin gradle task would provide good usability mvn aikonduitservingforpipeline foobaryaml gradle dowhateverineed ability konduit serving build jvm maven gradle installed nothing else either potentially oneliners getting set konduit serving build tool include sudo aptget install konduitserving linux user konduitbuildw script wrapper script like maven gradle wrapper mvnw gradlew actually going build konduit serving source people build tool would require even encourage building source given generating pomxmlbuildgradle work release version without local copy source target audience build tool user usually wont interact build tool directly instead touching aware uicli layer top target whole package functionality cliuibuild tool etc pretty much user standard offtheshelf model serving anyone custom codedependencies customize build specific hardware specific execution framework etc line see expanding allow packaging deployment target like helping people deploy android expect every single user konduit serving building special build deployment thats kind tangential proposal there nothing stopping offtheshelf buildsartifacts common scenario linuxwinmac cpu example without tool either distributed directly via docker hub whatever simply simpledefault build one day well provide osgibased deployment allow automaticruntime download installation module dependency also
record xjsonserver primary data store experimenting xjsonserver binary available google certificatetransparency repository server name suggests experimental like certificate transparency log server except accepts json document rather certificate current model register includes total ordering entry want cryptographic certification entry therefore natural way approach submit entry xjsonserver accept ordering entry simply order appear log however caused problem particular doesnt feel right ordering key concept within register domain entirely within control xjsonserver asynchronous nature addjson endpoint document added within given update interval merged log arbitrary order extensibility want support multiple method proof given register example might one proof based simple shaofcanonicaljson another based objecthash could supported xjsonserver however would impose ordering wouldnt necessarily agree one another xjsonserver primary data store specifically treat ordering document primary order entry register primary data store data entry consequence review way handle proof given mint maintaining ownership order entry number could implement merkle tree based idea certificatetransparency could submit document xjsonserver contain ordering accept ordering xjsonservers ordering though broadly agree also refer data item hash rather storing complete item within xjsonserver reference
graphql api query language via apollo server way populate neoj database via api layer graphql library server api graphql increasing popularity maturity lately provides flexible api query layer compared rest based interaction specifically able perform arbitrarily structured query optional subelements query parameter apollo server popular well documented implementation consequence write api server javascript similar typescript
artifact deployment nexus nexusupload step shall upload deploy build artifact nexus repository manager nexus version supported per module artifact multiple subartifacts deployed unit optionally together project descriptor file pomxml mtayaml nexus contains repository different type example release repository allow updating existing artifact snapshot repository allows multiple build snapshot version notion latest build depending type repository certain directory layout obeyed mavenmetadataxml file maintained order compatible tool consuming artifact nexus may also mechanism place example automatically purge old build snapshot release make important make compatible deployment apache maven deploy plugin maven lifecycle phase deploy uploading artifact manually pro con apache maven deploy plugin deploydeployfile consider goal deploydeployfile official maven plugin deployment perfect care whether artifact deployed correctly knowledge artifact deploy obtained manually list parameter generated plugin including artifactid version case uploading artifact manually maven project parameter obtained evaluate goal mavenhelpplugin however performance impact since maven command line executed parameter multiplied number module problem maven lifecycle phase deploy credential info stored settingsxml introduces additional implementation credential passed via environment variable maven lifecycle phase deploy default maven lifecycle phase deploy bind goal deploydeploy apache maven deploy plugin apache maven deploy plugin dont obtain pas parameter apache maven deploy plugin package phase executed implicitly make parameter ready deploy phase support multimodule maven project project structure case apache maven deploy plugin handling credential cannot nonmaven project mta maven phase list phase triggered implicitly phase including compile test package follow buildonce principle phase skipped however possible skip maven goal binding certain phase example packaging tag pomxml set jar jarjar goal apache maven jar plugin bound package phase unfortunately however apache maven jar plugin provide skip jarjar goal may solution seems require modifying pom could also different depending packaging main reason cannot uploading artifact manually file uploaded nexus simple http put request basic authentication necessary metadata file downloaded updated reuploaded successful upload artifact without pain handling credential mentioned apache maven deploy plugin section give full control implementation apache maven deploy plugin knowledge artifact deploy obtained manually apache maven deploy plugin list parameter prepared introduces complexity maintaining mavenmetadataxml example great difference release snapshot deployment later build number another directory structure nexus arbitrary number build per version metadata build version greatest maintenanceoverhead apache maven deploy plugin chosen maven lifecycle phase deploy conflict buildonce principle credential handling complex implement finegrained control needed artifact deployed maintains mavenmetadataxml correctly various type deployment
adr glob module adr proposes adding glob function toolkit first party action consistent glob experience related artifact uploaddownload new module create new module actionsglob versioned pace tied actionsio signature construct globber pattern param pattern pattern separated newlines param glob export function create pattern string globoptions promise match file directory export interface globber return search path preceding first glob segment pattern duplicate descendant path filtered example pattern foo bar return foo bar example pattern foo foobar return foo getsearchpaths string return file directory matching glob pattern order result guaranteed glob promise return file directory matching glob pattern order result guaranteed globgenerator asyncgenerator control globbing behavior export interface globoptions indicates whether follow symbolic link generally set false deleting file default true followsymboliclinks boolean indicates whether directory match glob pattern implicitly cause descendant path matched example given directory mydir following glob pattern would produce result mydir mydir mydir default true implicitdescendants boolean indicates whether broken symbolic ignored omitted result set otherwise error thrown default true omitbrokensymboliclinks boolean toolkit usage example follow symbolic link const pattern coregetinputpath const globber globcreatepatterns followsymboliclinks false const file globberglob example iterator const pattern coregetinputpath const globber globcreatepatterns await const file thisglobgenerator consolelogfile action usage action follow symbolic link default user optout example yaml job build step actionsuploadartifactv path targz pkg followsymboliclinks false opt default true hashfiles function hash file follow symbolic link default user optin specifying flag followsymboliclinks example yaml job build step actionscachev hash hashfilesfollowsymboliclinks packagelockjson glob behavior pattern globstar supported following behavior file name begin may included result case insensitive window directory separator supported window note refer information bash glob pattern refer information bash glob tilde expansion support basic tilde expansion current user home replacement example macos may expand usersjohndoe foo may expand usersjohndoefoo note refer information bash tilde expansion form tilde expansion supported oshomedir resolve home path root normalize path unrooted pattern rooted current working directory prior searching additionally search path normalized prior searching relative pathing removed slash normalized window extra slash removed two side effect rooted normalized path always returned pattern include working directory result side effect diverge bash behavior whereas bash designed shell designing api intended improve predictability api result note bash result rooted pattern relative bash result normalized example result may look like foo bar bash result pattern include working directory however result foo would include directory foo also result foo would include directory foo comment pattern begin treated comment exclude pattern leading change meaning include pattern exclude note multiple leading flip meaning escaping wrapping special character escape literal glob character file name example literal file name helloaz escaped helloaz linuxmacos also treated escape character consequence publish new module actionsglob publish doc module add link readmemd new doc packagesglobreadmemd
pizzly backend problem statement adr manager backend look considered python back end dont back end pizzly backend outcome chosen pizzly backend come best see pro con python back end good github interaction achieved bad hard maintain dont back end bad cant authorize github without back end pizzly backend pizzly handle oauth dance hosted heroku back end good work writing back end scratch good dont handle authorization process
ruby new application manage offender custody language across hmpps hmpps active development four language including service significant prisonstafffacing component four ruby python javascript java hmpps live service passed service assessment built ruby python ensuring support existing user top priority essential maintain skill language live service one advantage microservices approach team work separate service different language http apis share data functionality service built language already approach across hmpps clear vision strategy moment changing number language across hmpps position decide hmpps team skill four language active across hmpps represented varying degree skill set current member team ruby common team worked together live service built ruby time mojhmpps still service continuously improve alongside work manage offender custody although spending majority time latter primary language skill hmppss civil servant developer technical architect significant proportion team ruby python unrealistic expect people equally proficient many language time team already committed learning kubernetes new cloud platform see adr learning java collaborate apis built sheffield see adr already significant proportion unfamiliar technology team learn developing application involves much standard library language ecosystem library tool around language often take much work time become familiar basic language although team know javascript experience building serverside application would therefore lot learn choose javascript related separate service time constraint offender management custody programme fixed timeline national rollout next year although committing delivering particular service set month advance reduce opportunity learning smaller set real user national rollout ready take advantage wale pilot begin january know allocation first several area programme likely support timescales tight anticipate complexity building service lie managing quality data available across nomis delius oasys rather representing data user choosing familar language developing application top already learn would put significant risk delivering working software several month first user code reuse language group similar service make easier provide coherent experience user allowing presentation code shared easily service however html structure page produced service written different language since committed progressive enhancement see adr clientside javascript solely enhance functionality page javascript reused across service regardless language server example approach strong active crossgovernment community develops research support design pattern style component service built many different language httpsdesignsystemservicegovuk base userfacing application established design system case already variety design approach across prisonstafffacing service best chance standardising well align crossgovernment approach approach supported extensive user research several year across many service department starting point reduces undertake duplicate research understand effectiveness existing pattern expect extend pattern develop others inspired meet user contribute learn back hmpps crossgovernment community since agreed service nomis api migrate custody api see adr api client library build ruby reused ruby service ease migration operational consideration team considerable experience operating live service built ruby scale anticipate scaling significant concern allocation expect couple hundred user day new cloud platform make easy quick cheap scale ruby new application build london part manage offender custody consequence build knowledge team already ruby ecosystem significantly deepen knowledge third language well ruby java familarise different ecosystem library decide learn another set tool order make progress able govuk design system basis making service look consistent government hmpps service may able reuse library built team sheffield intended particular javascript framework write client code ruby custody api apis could extract library ruby service migrate apis maintain strong level ruby knowledge within hmpps help ensure continue support significant proportion live service future hmpps want ensure civil servant strong skill language currently across service focus hiring area rather expecting existing developer able work equally productively across language
config environment variable feel create guideline config variable environment variable cloudbuild short code going executed cloud function aka project deployed receive configuration variable config file cloudbuild step environment variable stored cloudbuildyaml external file elaboration developing cloud function store variable config file variable easy read developer dont build anything project run unless something variable build move project deployed variable code cloud function stored within project config file project receive variable cloudbuild file merged project build way around building something might variable going buildingdeployment might external project get variable variable given environment variable cli flag variable could stored file placed inside repository easy access put build environment file example configuration stored repository merged project environment way around like example configpy python index token aaaaaaaabbbbbbbb mainpy python config import index token configuration environment variable build specific step like example yaml substitution venv venv name cloud entrypoint bash args source venvbinactivate
server side caching user story easi certain type call easi make considered expensive usually take form something like party api call cedar core example database call caching often good way effectively reduce number time expensive call made cost data considered application memory caching caching database caching redis outcome chosen application memory caching redis caching later right likely dont engineering staff implement infrastructure redis instance would require since implementing inmemory cache relatively simple task especially compared massive benefit get seems worthwhile implement come back replace redis later time additionally main con inapplication memory caching shared across multiple task huge deal time since typically running task time due workload relatively low open question way avoid minimize amount time user feel load time expensive call potential periodically seed cache rather populating request made data upside always user hit cache directly downside wed write scheduled code periodically seed cache lambda cache never expire always return data cache instead refreshing cache returning data frontend refresh cache return data upside also always returning cache fast major downside potentially data cache old pro con application memory caching easy implement see poc branch example implement requires change infrastructure likely lowest response time available easily temporarily introduced later replaced another solution cache shared across multiple server exists per task caching database requires change infrastructure persistent across multiple server caching logic would manually written column track timestamp cleaning old data etc going slowest term response time doesnt solve caching query caching redis fast response time submillisecond solves caching lot different api query query etc redis purposebuilt solve caching support lot different box requires introducing new infrastructure
divorce sdk firebase much discussion whether sdk implement firebaserelated service token refresh notification handling leave consuming app sdk handle setup consumer however come cost much flexiblity end decided lack flexibility supporting register first launch registerunregister log log model warranted removing service sdk implemented demo application instead consequence may want create code sample beyond demo app implement service however highly consumingapp dependent may best implementation completed
erb embedded ruby view template march original team developing application decided slim templating engine view template switch erb template instead happen incrementally either add new template existing template modified pro erb part ruby standard library default rail likely familiar ruby rail developer erb consists plain html file small amount ruby code added tag likely familiar content designer interaction designer particularly also nunjucks govuk prototype kit slims templating language confusing particularly managing whitespace inadvertently rendered space tag past adding class name contain character requires generic attribute syntax instead dot notation generally fractionally faster parse templating language although may negligible con switching incrementally mean well mixture template format within project time may cause confusion sticking slim discounted reason could also switched another framework haml mustache felt strong benefit following rail default consequence developing new feature refactoring existing code convert existing slim template erb whenever practicable
embed content app app primarily display information medical staff working hospital information come somewhere download content bucketwebsite could pull information app somewhere web kind bucket website file hosted would obvious choice make easier quickly information app would require build infrastructure architecture support also could mean internet connection hospital crisis information isnt already cached app would unavailable user embed content app method embed information app information included downloading app architecturally much simpler mean content available offline internet subsequently new version app released update information initial version application embed content app situation stabilises provide support hospital revisit decide want download content consequence updating content app little harder change codebase deploy update playapp store however initial version app much simpler faster produce
adr prefer configurable dev tool acceepted people involved sublimesneaks issue dev tool building linting formatting etc dev tool configurable candidate two side spectrum explored candidate fixed dev tool script minimal config example running reactscripts build support configuration pro simplicity prevent developer argument config script behaviour easier sync consistent dev tooling across many repos con unable difficult tweak configure candidate exposed dev tool script full configuration example buildjs command similar exposing step allowing configuration pro easy tweak configure con complex developer may argue best configuration however following rule help stick default behaviour unless clear objective reason change difficult sync consistent dev tooling across many repos however still possible git copy paste another repo regenerate scaffolding existing app manually choose keep discard change manual time consuming allows greater control exposed dev tool script full configuration carry con ability easily tweak configure app important app unique different requirement frustrating locked unconfigurable fixed script despite pro
function component mapping technical story issue problem statement implement eai pattern combination generic component handle communication kafka faa solution business logic eai pattern message splittingaggregation transformation provided via function hosted faa solution generic component communicates kafka deserializes message mean wire instance generic component function user want insert message splitter two messagebased component realize instance generic component combination splitting faa function generic component address faa gateway function name httpaddressfunctionmsgpayloadsplitter call function provide necessary information instance generic component considered following technique driver must supported languagetechnology implement generic component must easy integrate mico well known proven solution considered environment variable function registry control topic function composition function proxy configuration file outcome chosen environment variable mico already support easy implement generic component pro con environment variable environment variable store necessary information variable controlled mico good mico already support setting environment variable good language support reading environment variable good environment variable anyway provide kafka configuration good well known proven solution good follows twelvefactor app methodologyhttpsfactornetdeconfig bad configuration changed fly want function registry implement separate component store mapping function instance generic component could evaluate apache zookeeperhttpszookeeperapacheorg etcdhttpsgithubcometcdioetcd fit purpose good mapping change fly good support approach language bad developmentevaluation overhead control topic already kafka could follow dynamic router pattern control channeltopic configure instance topic could compaction feature always retain last known configuration message key good already decided kafka good provides log configuration change bad configuration kafka could provided via method bad developmentevaluation overhead function composition dont implement generic component separate component function hosted faa solution kafka connector openfaas compose function composer like follow workflow technique described openfaas documentation good basic component approach already exist good separate generic component necessary bad composer seem mature proven function proxy api gateway instance generic component call api gateway handle routingmapping function good instance generic component call gateway therefore configuration bad dont proxy therefore add development overhead configuration file generate configuration file per instance generic component deploy instance pro con like environment variable complexity file generationparsing deployment
sys pick documentation language polish development team business related communication polish team member prefer write code english much business facing documentation bfd bfd artifact english session system diagram etc developer facing documentation artifact english code adr diagram etc consequence maintain low friction communication domain expert feedback possible
utilize browser caching needed make sure overloading server excessive request wanted find way serve fresh resource keeping backend happy page preview leverage browser cache rather maintaining rely grade browser implementing http caching correctly vendor making accessing efficient possible order avoid incurring incidental complexity writing cache javascript well set appropriate cachecontrol http header mediawiki api via maxage smaxage main module parameter restbase page summary endpoint help service team consequence resource fetched mediawiki api cached minute public cache browser cache unlike mediawiki api resource fetched restbase endpoint cached day public cache
fragment result api problem statement modern android application single activity pattern infrastructure based fragment dialog bottom sheet taken account communication fragment important place several come communication taking result fragment project mostly callback disadvantage like increasing coupling able handle recreation fragment problem stated decided handle communication google recommended fragment result api due several advantage provides compared communication method detail please visit page fragment result api
writing project code ive realized constant probably heavyweight rendering leave javafxtornadofx constant renderinganimation framework rationalization although probably better frameworksengines unity opengl configuring learning would probably take time dont javafx seems nice opportunity relatively little learn
architecture record enhanced validation much possible arachne application defined configuration something wrong configuration way application expected work correctly therefore desirable validate configuration correct greatest extent possible earliest possible moment important two distinct reason ease developer friendliness config validation return helpful error point exactly whats wrong instead deep failure lengthy debug session program correctness type error configs might discovered testing development aggressively failing invalid configs prevent issue affecting end user production two kind config validation first ensuring configuration data structurally correct adheres schema includes validating type cardinality expressed arachnes core ontology system second ensuring arachne runtime constructed given configuration correct runtime component instance returned component constructor correct type likely work arachne perform kind validation disambiguate since logically distinct term structuralschema validation configuration validation validation runtime object runtime validation style validation extensible module module specify additional validation necessary configuration validation configuration validation ensuring arachne configuration object consistent schema ultimately validating set datomic style eavt tuples natural form checking tuple data datalog query query rule search locate data incorrect logical validation validator function take config query either return throw exception validate config passed every validator final step building module set validators open defined configuration add new validators module transact entity configuration building phase runtime validation runtime validation occurs runtime instantiated started validation happens component level component may subject validation unlike configuration validation runtime validation spec spec applied component defined configuration keywordvalued attribute spec may defined individual component entity type component entity component validated validated spec defined supertypes proposed consequence validation opportunity find error return clean error message structure config runtime instance validated configuration describes validated module complete flexibility add new validation user write custom validation
starting commit main project looking various possibility writing braincognitive simulation gui pick tornadofx kotlin main simulation framework rationalization lot possibility around place winning one simbrain tornadofx kotlin seemed modern hence robust extendable furthermore reduction amount increase readability code framework provides especially important opensource project
domain model rest interface proposed deciders daniel stefaniuk jonathan pearce matthew begley capacity api built django web framework framework offer number module feature utilised building api adr discus concept made determining django feature essentially come three distinct part rest interface view controller serialization broker request domain model domain model response domain model information kept capacity api required take capacity information update specific service containing following information capacity capacity put service readable format red amber green reset minute setting capacity either red amber state number minute service persist state time service automatically set back green capacity note free text field requester set update capacity information core following information capacity enumerated format reset time timestamp specifying service revert back green capacity note modified user updated capacity information modified timestamp specifying capacity information last updated respond capacity information requested service containing following information service uid uid identifying service service name human readable name service capacity red amber green reset time note modified modified rest interface interface decided upon django rest framework extension drf extension provides vast number useful module component form part modern restful api leveraging component keep code clean understandable easy maintain addition easy plugin api documentation framework majority documentation automatically generated code therefore keeping documentation maintenance minimum extension come already defined view automatically configure give api set standard rest endpoint would require capacity api require get put endpoint automatically configured drf retrieveupdateapiview view default endpoint functionality provided drf also easily modified suit specific business api serialization django provides component known serializer deal everything concerning transfer data client requestresponse domain model serializer deal validation data conversion data json domain model visaversa capacity api deal three stream information capacity information coming capacity information held data model capacity going stream information contains slightly different view capacity information therefore decided adopt threeserializer approach dealing case separate well defined serializer information stream serializer configured set validation rule specifically catered handle specified data stream serializer also defined mechanism deal passing data along next information stream give clear separation concern serializer therefore payload serializer responsible consuming json payload request validating data converting data format data model serializer expects data model serializer responsible consuming data payload serializer validating data updating domain model also responsible retrieving capacity information domain model response serializer responsible consuming data data model serializer validating data converting data json response domain model capacity api comprises two domain model capacity model user management model capacity domain model represents capacity information every service core extending user permission able view manipulate capacity information collection related table make model stored maintained within core database part model relating capacity information user permission coupled data model serializer api allows api able retrieve update capacity information django framework thus keeping api code clean removing bespoke orm code although introduces tight coupling part core database api consider low risk since probably change area core considered low part model relating user permission able update capacity information also resides core database retrieval data performed dedicated module capacity api call mechanism interfacing discussed adr driving purpose module reduce coupling concern core api thus maintaining integrity apis core code base finally user management model created maintained api stored database decouples concept api user specifically api key known user core approach taken django manage data model performed djangos built database migration tool approach completely decoupled type database django automatically apply correct driver whatever database choose also mean database migration script created handled django consequence framework take away vast majority boiler plate code api documentation automatically generated endpoint serializers vastly reducing overhead creating maintaining api documentation clear separation concern handling data flow api clear separation handling retrieval update service dealing user permission management authentication api tightly coupled core database storing retrieving capacity information although immediate case acceptable risk database scripting maintenance required user management domain model
cacheawarepropertyinfostore caching method adr propertyinfostore interface wbpropertyinfo table holding information wikibase property cacheawarepropertyinfostore store whole wbpropertyinfo table single cache key wikibase wiring setup provide cacheaware store default cache memcached wmf cacheawarepropertyinfostore high number read method storing whole table single key result lot traffic single memcached instance described amount traffic memcached key steadily grown number property store grown traffic also move memcached server wmf deploy cache key change layer apc caching per server added top shared memcached caching done service wiring wrapping cacheawarepropertyinfostore another cacheawarepropertyinfostore apc cache short ttl avoid actively think purging adding extra layer caching chosen rather anything drastic trivial code change reworking cacheawarepropertyinfostore work consequence request could end slightly propertyinfostore new property created updated would soon fixed short ttl ever increasing traffic individual memcached server decreased httpsphabricatorwikimediaorgt work area either split cache per property request memcached overall data retrieved much better distribution key server introduce cache key data spread traffic load cache key could still end server duplicating data evil increase ttl web server caching slowly lead increased time server sync
adr handling utc timestamps application relational database proposed author damir murat damirmuratgit gmailcom reviewer none handling time time zone easiest task java many reason probably relate history datetime api evolution jvm new java datetime api introduced java big step forward explicitness correctness unfortunately api quite complex requires careful study correctly moreover adding database picture make thing even difficult since additional player like jdbc driver orm framework like hibernate database new player idea nuance datetime handling dealing timestamps application database utc zone standard best practice sensible approach ideally neither application database depend anymore local time zone execute freely move executables time zone quite common today cloud era always function correctly furthermore utc additional advantage primary time standard base reference regulates world clock time stable since never change daylight saving time dst standard textual representation parsable platform without ambiguity modeling utc timestamps application level java datetime api class represent utc timestamp javatimeinstant instant represents single moment specific point time utc timeline therefore misinterpreted confused moment history short simplest probably best choice model utc timestamps application level javatimeoffsetdatetime offsetdatetime perceived instant generalization offsetdatetime also model single moment time also includes configurable offset relative utc therefore offsetdatetime offset logical equivalent instant javatimelocaldatetime localdatetime often misused modeling utc timestamps problem localdatetime represent single moment time rather represents wallclock time always highly coupled time zone conceptual wallclock running depending time zone stand different moment simultaneously course attached utc time zone strong relation local time zone always pop one way usage might considered advantage localdatetime generally avoided modeling utc timestamps also zoneddatetime class brings nuance time zone handling real world example zoneddatetime handle daylight saving time dst including tracking latest political conceptually however zoneddatetime instant assigned zoneid best choice storing utc timestamps might handy case like presenting timestamp user time zone reason described choosing javatimeinstant modeling utc timestamps let discus hibernate handle instant utc timestamps hibernate timestamp column following discussion assume postgresql database usage corresponding jdbc driver internal working might different database general mechanism quite similar mapping instant database hibernate javasqltimestamp writing database hibernate convert instant javasqltimestamp pass timestamp jdbc driver default hibernate via preparedstatementsettimestampint timestamp method mechanism offsetdatetime localdatetime note also appropriate preparedstatementsettimestampint timestamp calendar method hibernate unless explicitly configure time zone hibernate communicating database next jdbc driver convert javasqltimestamp string representation last part string time zone offset since settimestamp method two parameter explicit time zone provided jdbc driver local application time zone calculate offset although may look like local time zone cause issue still good path problem really happens targeted database column accept time zone offset information timestamp column case offset part string simply discarded loss time zone offset leading cause problem written local application timestamp database reading database hibernate resultsetgettimestampstring method also resultsetgettimestampstring calendar method unless explicitly configure hibernate therefore jdbc driver interpret fetched string database timestamp local application time zone finally hibernate convert passed timestamp instant via epoch second hand instant application ironically everything seems work correctly application perspective wrong timestamp written database application work right well work move another time zone happens previously recorded timestamps invalid application perspective new one stored shifted relative old one word application data invalid timestamp timestamptz standard sql data type timestamp commonly misused column intended store utc timestamps unfortunately timestamp sql data type cannot keep time zone offset information evident consider full name timestamp without time zone database support always sql type timestamp time zone preserve time zone offset postgresql timestamp stand timestamp without time zone data type timestamptz describes timestamp time zone going postgresql data type name brevity avoid problem described previous section simply timestamptz column instead timestamp column even move application andor database time zone continue work correctly drawback still remain first dont setup work timestamptz timestamp column avoid possible second kind database viewer tool timestamptz column display data local time zone database data correct includes offset always convert utc head finally rely direct query execution without hibernate jdbc driver mediation database display result local time zone example postgresql internally store timestamptz utc format however display direct query purpose always convert utc timestamp local time zone database displaying result fixing inconsistency fix issue timestamp column instructing hibernate utc time zone handling timestamps leverage hibernatejdbctimezone configuration property example spring boot application put following line applicationproperties file springjpapropertieshibernatejdbctimezoneutc configuration set hibernate settimestamp gettimestamp method calendar parameter calendar instance created configured utc time zone avoid issue direct query data display database management tool configure utc database default time zone exact procedure highly dependent concrete database postgresql examine supportdockerpostgrespostgresqlconf supportdockerdockercomposeinfrastructureyml file klokwrkproject one thing aware database management tool exploring data tool correctly display content timestamptz column experience pgadmin idea database tool work correctly dbeaver configure utc local time zone case dbvisualizer currently support distinguishing timestamp timestamptz column unfortunately display format data type architectural system klokwrkproject following recommendation handling utc timestamps javatimeinstant type modeling utc timestamps configure hibernate utc time zone handling javasqltimestamp via hibernatejdbctimezone configuration property configure default time zone database utc time zone postgresql timestamptz sql data type utc timestamp column consequence positive consistent correct unambiguous handling utc timestamps system level obvious timestamp represents much harder misinterpret timestamp anything else utc timestamp neutral requires minimal change infrastructure like configuring default database time zone negative already existing data present might require data migration considered ignoring problem reference httpsstackoverflowcomquestionswhatsthedifferencebetweeninstantandlocaldatetime httpswikipostgresqlorgwikidontdothisdateftimestorage httpswwwtoolboxcomtechdatamanagementblogszoneofmisunderstanding httpsmediumcombuildingthesystemhowtostoredatesandtimesinpostgresqlbdad httpskaiwerncompostswhatyouneedtoknowaboutpostgresqltimezone httpskbobjectrocketcompostgresqlpostgresqlsettimezone httpsvladmihalceacomhowtostoredatetimeandtimestampsinutctimezonewithjdbcandhibernate httpsvladmihalceacomdatetimestampjpahibernate httpsvladmihalceacomwhatsnewinjpajavadateandtimetypes httpsgithubcomhibernatehibernateormblobmainhibernatecoresrcmainjavaorghibernatetypedescriptorjdbcinstantastimestampwithtimezonejdbctypejava httpsgithubcomhibernatehibernateormblobmainhibernatecoresrcmainjavaorghibernatetypedescriptorjdbctimestampwithtimezonejdbctypejava httpswwwtimeanddatecomworldclockconverterhtml
scala programming language proposed problem statement hybrid objectorientedfunctional language scala ideally suited developing latis driver merit functional programming language merit strongly typed language availability developer consensus community scientific programmer suitability processing large data set concept involving code correctnes transformation data explicit reasoned support dsl domain specific language considered java python haskell outcome chosen scala languageofchoice latis development driver alignment fact python preferred language scientific programmer positive consequence immutable data type scala reduce challenge introducing parallelism extensible library like latis functional programming language like scala provides better abstraction tool reason transformation large data set strongly typed language like scala help prevent code rot reduces chance defect slip code base well designed scala application based sound software engineering principle even though may take effort build similar java python program said scala program tend easier maintain refactor actually minimizes effort life project latis primarily framework transforming large datasets performant manner mesh nicely functional approach emphasizes creating abstraction thing data rather creating specific recipe specific case apache spark written scala leading framework processing large amount data becoming primary framework implementing machine learning algorithm scala support creation dsl allow user latis specify processing instruction datasets without nedding learn scala full gamut java libraies available scala developer many successful java library eventually get rewritten scala scala encourages software craftpeople follow sound engineering principle instead developing something get job done probably important factor choosing scala hardest document negative consequence scala developer common python developer especially field scientific computing python clearly dominant language scientific programmer pro con java original version latis written java pro java mainstream programming language pro newer version java becoming functional con java still focused objectoriented paradigm con despite improvement made java java many inherent design limitation python python currently leading language scientific programming machine learning pro python mainstream programming language pro pyspark support apache spark con python dynamically typed language result code fragile maintainable dependant good unit test suited building robust framework con python created lower learning curve programmer software engineer haskell haskell pure functional programming language may time become language choice future version latis pro pure functional language haskell potential supplant scala reference implementation functional data model pro haskell around longer scala may outlive scala con haskell currently framework support scala java spark con even haskell developer available scala developer
cache setting participant brice schaffner christoph bcklin jrgen hansmann updated added proposal servicestac currently static cache setting request api request min configured per staging asset download configured per staging asset download cache setting set uploading asset coming new functionality different cache setting depending least collection even maybe fine grained selection itemsassets diemo service stac update asset every minute see change asset download cache setting asap march coming scenario realtime asset changed every minute diemo frequent change changed every minute even meteoschweiz frequent asset update every hour twice day daily weekly weekly update new asset immediately available daily update update afford wait cached data expiration daily update midnight infrequent update either define low frequency every month every year sporadic update update new asset immediately available update afford wait cached data expiration never theory scenario doesnt exists potentially every asset might somewhen updated currently support scenario important fact cache setting cachecontrol header cannot changed set unless object uploaded possibility copy place implement preconditional request http expires header discouraged aws recommend cachecontrol maxage directive instead expires header field control object caching specify value cachecontrol maxage expires cloudfront value cachecontrol maxage http expires header ignored implementation cachecontrol maxage smaxage present stac api specification caching management stac updated created field text created updated different meaning depending field available item property identify creation update time metadata field item asset refers creation update time actual data linked asset object see stac spec warning currently implementation field always refer metadata data data stac spec created updated field collection level implementation collection item updated field automatically updated child metadata updated item asset asset upload automatically update checksummultihash therefore update updated field collection item asset stac specification extension timestamps extension specification field type description published string time corresponding data see published first time utc expires string time corresponding data see expires valid longer utc unpublished string time corresponding data see unpublished utc currently asset update new upload automatically update asset metadata field checksummultihash update checked asset update changed checksummultihash sure update field also updated depends django framework andor drf framework code doesnt check write data update field automatically updated django cloudfront cache invalidation take time independent path invalidate every cache invalidation cost cloudfront nocache mean low cache proposal proposal add new field transactional api create asset updateinterval field would type int second first step would part transactional api read endpoint saved together asset visualization field left next step might existing stac extension like timestamps extension specification create new extension tbd example json body asset create request post httpdatageoadminchapistacvcollectionscollectioniditemsfeatureidassetsassetiduploads json title thumbnail description string type imagetiff applicationgeotiff projepsg eogsd smrkgrstiff updateinterval value field could checked via admin interface read field field saved assetupload model copied asset model asset upload complete action similar checksummultihash field warning field act cache setting asset data api asset endpoint asset upload automatically update asset metadata new checksummultihash updateinterval mean instantly change happens infrequently second several hour day week setting updateinterval would mean never case default value field would default cache setting would applied value would compute cache setting asset data follow disable cache set cachecontrol public maxage rate max day rate rate cache rate cache rate cache might issue case rate min cache might issue case rate min cache might issue case rate cache might issue case rate cache might issue case based value say solution would cover case case would another mechanism smaller max cache setting expires http header also recommended aws could expires data maxage api metadata low value chris recommend mechanism cachecontrol instead expires case first idea would service deliver data set cachecontrol dynamically cache invalidation case case solution manual cache invalidation cloudfront start propose manually via aws cli aws console depending future case come often provide api endpoint cache invalidation based collection andor item path possible next step next step would provide read info updateinterval one possible solution would timestamps extension specification expires asset field would set based update time updateinterval field would updated time asset upload either started completed tbd extension keep mind collectionitemasset publication flag see bgdiinfsb proposal updated implementation proposal two different linear approach updateinterval show issue updateinterval updateinterval jump actually really good quick experimentation excell came mathematic expression text maxage roundlogupdateinterval logupdateinterval result graph logarithmic approach give better caching timeout number linear approach number updateinterval maxage keep api independent implementation proposal case case discussed future needed updateinterval readonly admin interface consequence implement deploy int int diemo developper notified chris spec brice implementation proposal reference http specification expires header http specification freshness cloudfront managing long content stay cache expiration timestamps extension specification stac spec
title redis cart persister area checkout tag checkout cart redis performance last benchmark became clear cost intensive loading saving shopping cart database detailed analysis revealed two problem every time shopping cart loaded written back database validation however lead write connection cause lose support masterslave database setup ensure best possible performance shopping cart written database serialized object however turn lead rather high amount data sent internal network solve problem implemented shopwarecorecheckoutcartrediscartpersister php namespace shopwarecorecheckoutcart class rediscartpersister extends abstractcartpersister var redisrediscluster private redis private eventdispatcherinterface eventdispatcher private bool compress public function loadstring token saleschannelcontext cart public function savecart cart saleschannelcontext void public function deletestring token saleschannelcontext void public function replacestring oldtoken string newtoken saleschannelcontext void store cart inside redis configured via config configpackagesyaml yaml shopware cart redisurl redisredis redis connection configured redis cart persister removed container done inside shopwarecorecheckoutdependencyinjectioncompilerpasscartrediscompilerpass php namespace shopwarecorecheckoutdependencyinjectioncompilerpass class cartrediscompilerpass implement compilerpassinterface public function processcontainerbuilder container void containergetparametershopwarecartredisurl containerremovedefinitionshopwarecartredis containerremovedefinitionrediscartpersisterclass return containerremovedefinitioncartpersisterclass containersetaliascartpersisterclass rediscartpersisterclass addition reduce network traffic cache compression significantly reduces amount data sent however compression deactivated via configpackagesyaml yaml shopware cart compress false notice currently migration path transfer shopping cart one storage
depend linux recommended depend running unix environment support command depend linux therefore reduce overhead maintaining linux window support consequence shared library cannot completely window environment window slave testing etc may fully supported
heroku team week engineer complete work hackney already least service report repair repair managament heroku hackney playbook includes aws container hosting platform choice httpsgithubcomlbhackneyitapiplaybookhosting hackney currently procuring heroku account host containerised service dxws heroku account consequence spending money deferring operation heroku instead team however enable save significant amount time getting set instead focus meeting user within application
postgres make howwhere host freely managed postgres heroku consequence managed throughout project
title app script product pricing area core tag appscript product pricing want provide opportunity manipulate price product inside cart within store cart manipulation already hook integrated allows accessing manipulating cart right allowing manipulate price directly creating discount new price object add new line item cart however different business case require direct price manipulation like get sample product free following code manipulating price productpricing hook php foreach hookproducts product allow resetting product price productcalculatedcheapestpricereset productcalculatedpricesreset allowed reset default price otherwise valid get control default price calculation set price servicespricescreate default gross net usd gross net eur gross net directly change price fix value productcalculatedpricechangeprice manipulate price subtract provided price object productcalculatedpriceminusprice manipulate price add provided price object productcalculatedpriceplusprice following example show deal percentage manipulation productcalculatedpricediscount productcalculatedpricesurcharge get control graduated price productcalculatedpricesreset productcalculatedpriceschange price servicespricescreate default gross net price servicespricescreate default gross net null price servicespricescreate default gross net hook walk price fix fromto value productcalculatedcheapestpricechangeprice productcalculatedcheapestpriceminusprice productcalculatedcheapestpriceplusprice productcalculatedcheapestpricediscount productcalculatedcheapestpricesurcharge endforeach following code manipulate price product inside cart php manipulate price product inside cart set product servicescartgetmyproductid set price servicespricescreate default gross net productpricechangeprice productpricediscount productpricesurcharge
validation team rewrite fundraising formed discovered team member different approach validation established library like symfony validation write validation logic argument favor writing logic dont want bind domain layer concrete validation library implementation individual validation checking required field case simple external library would make validation complicated dont know maintenance cycle library either constantly update library maintained properly every developer would learn api external library start project know put validation logic frameworkpresentation layer forcing create valid fully formed domain object input case case layer making validation part case case write validator class check request value object case validator class must ensure case create valid domain object request object validator class simple check external framework return result data structure validation class result data structure way communicating framework layer input caused validation error necessary one input one validation error validation error name languageindependent unique string snakecase translate error code put translation file validationsjs content repository dont map every error translation write frontend layer code summarizes error map different way consequence manage introduce consistent interface validators validation result took inspiration constraintviolation class symfony validation created funvalidators repository contains abstracted lowlevel validators validationresult class collecting constraint violation sometimes validators return booleans fieldname error pair instead subclassing validationresult result approach would simplest solution work implemented business rule validators others check case class see also adr clientside validation
heroku rundetached static site build moment set scheduled task heroku run every minute hour day range building static site every minute reporting stalled build every hour refreshing database production data devstaging every night main job building static site started fail occasionally run longer minute heroku scheduler allow scheduled instance live long interval task heroku therefore killing instance finish leading incomplete build frequent report stalled instance killed build schedule static site build way remove strict time constraint always finish building continue heroku scheduler tenminute interval instead heroku cli run management command managepy buildstaticsite separate detached worker dyno worker dyno lifespan hour limited interval scheduled job command heroku rundetached appname managepy buildstaticsite pro easy implement allow static site build take hour greater reasonable build length con remain unable responsively schedule static site build moment needed rely scheduler kick build expose heroku api key install heroku cli buildpack main publisher app could create separate repositoryapp pipeline attached scheduler run management command would let isolate heroku cli buildpack api token away main webserver would mean managing another pipeline slightly decrease visibility whats going unlikely wed looking pipeline often also feel like significant isolate buildpack api key someone access apps environment server already compromised another spin detached apps directly web server could remove scheduler entirely python heroku lib run relevant management command time theyre needed user published new page would make app responsive build fragile wouldnt anything check whether build requested regular basis also would tie app closely heroku cause peculiarity running dev machine third implementation would build queueing system scheduler submit job worker process would likely involve additional infrastructure redis support job queue well require writing worker code would additional monitoring maintainenance testing moment work problem requires solve satisfactorily many mature infrastructure manner queueing system async processing system offload longrunning iobased workload time feel like still function without functionality given limited mostlyinternal userbase tolerant process happening scheduled interval rather nearreal time consequence three token linked rdu developer heroku account one devstagingproduction token expiry build continue checked minute schedule publisher heroku apps contain heroku cli buildpack actually web server scheduler run app slug
bring advance passenger info code main service began advance passenger info api work going stand webservice could provide value php drt drtv separate project focus dont separation bring api service codebase main project consequence easier grow itchange learn port requirement api poll atmos bucket airport service
redisbacked draft background service frequently take user journey involves asking series question multiple page playing answer back user finally submitting answer intervention service api mean somewhere store user answer progress journey journey intervention service provides storage example journey submitting referral intervention service provides endpoint creating updating draft referral however journey intervention service provide storage example assigning referral caseworker cancelling referral journey application provide storage intervention service store everything could make intervention service provide storage data every page every journey however would tied user journey generalpurpose intervention api reserve intervention service storage long journey user might want complete multiple sitting solution far pas data page page page journey making sure http request page includes data submitted page either accepting data previous page data encoded request url query passing get request subsequent page placing data previous page query url thats navigating next page accepting data previous page applicationxwwwformurlencoded form data passing post request subsequent page placing input typehidden field page replaying data previous page problem solution get request limit amount data user submit page since many client server support url byte long post request mean cannot redirect different page journey example check answer based user input since redirect response cannot instruct browser make post request also approach embedding data html laborious make sure every possible route page journey preserve data becomes particularly easy get wrong nonlinear sequence page example link check answer page allows user edit previous answer requirement solution solution must also make sure user able access data entered different user prevent user performing journey multiple time concurrently example able assign two different intervention time different browser tab preserve data user entered previous page browser back button give maximum flexibility deciding meet wcag success criterion timing adjustable example making sure data kept least hour expires would also good solution could introduce new dependency service example database allow continue kind coding pattern interacting intervention service api creating updating resource allow identify clean old data well application existing redis server storage allows store essentially unlimited amount data redis well store draft object container arbitrary json data along globally unique identifier unique identifier user created draft timestamps creation last update identifier explaining type data draft represents well provide crud api creating fetching updating deleting draft object include draft url journey allow draft created get request tag link journey prefer post pas data page instead get dont worry body size constraint aforementioned api enforce access control making sure user allowed access draft created make sure draft automatically removed longer accessed certain amount time example day rediss expiry functionality make sure draft consume storage redis indefinitely might consider redisbacked express session object however object expires hour inactivity insufficient dont want increase timeout since security implication increasing amount time user remains logged service consequence draft data lost period inactivity inform user happened start journey time limit prof problem may reconsider expiry duration url page service become longer draft data secure redis instance
redis redis server key redis server aliyun redis redis redis index redis aliyun redis aliyun aliyun redis consequence aliyun redis index aof rediscli xxxredisrdsaliyuncscom xxpipe appendonlyaof aof bgrewriteaof swap instance index ref persistencehttpredisdoccomtopicpersistencehtml back restore redis data ubuntu httpswwwdigitaloceancomcommunitytutorialshowtobackupandrestoreyourredisdataonubuntu swapdb redis command httpsnewsycombinatorcomitemid storing data redis httpwwwmikeperhamcomstoringdatawithredis
aleph interaction assumption item june item assumed aleph always provides list newupdated item occurred within range provided consequence application minimal processing list new updated item returned aleph two request made caiasoft one new item one updated item lastsuccess file determine start time next request always updated unless caiasoft cannot contacted either request caiasoft indicates request failed returned success flag currently provision resubmitting item rejected error currently expected handled manually
translation backend one api endpoint fetch translation frontendgettranslations take parameter load relevant translation config flow relevant translation translation currently loaded integration plus integration config flow many integration config flow api call getting huge current dev response main translation file stringsjson keyed area config config flow flow deviceautomation device automation state translation state domain example entity zwavebla state alive stringsjson integration also platform specific translation file stringssensorjson file merged integration offering platform value stringssensorjson merged sensorstringsjson provide state useful sensor text value moon season title integration sometimes requires translated mainly internal integration part translation file however made mistake putting title config even would open api allow fetching one area would still fetch config flow info integration case render name single domain drop title stringsjson integration product whose name require translation remain equal title manifestjson example zwave hue backend move integration title config key load independently current drop title stringsjson manifestjson translated remove support integration providing platform translation fetching title integration manifest name title provided translation file change frontendgettranslations allow specifying area interested start reference write specific translation right integration defines alreadyconfigured etc syntax frontend keystatebinarysensorbatteryoff update scaffold script reference start state stringsjson going dictionary default entry one entry per device class like frontend json state binarysensor default keystatedefaultoff keystatedefaulton battery normal low import existing state key translation frontend add new stateattributes stringsjson allow offering translation state attribute json stateattributes climate hvacaction heating heating cooling cooling drying drying idle idle fan fan import existing state attribute key translation frontend replace many existing translation possible reference convert moon season sensor entity stringsjson translation frontend load part backend translation necessary page load load state fetch integration title opening config dev tool panel fetch config flow translation config flow started handler picked fetch flow translation flow started fetch device automation string opening scriptautomation editor remove builtin translation domain domain backend provided string instead remove builtin translation state state backend provided string instead remove builtin translation state attribute stateattributes backend provided string instead adopt cleaning key script backend see remove state state attribute key translation imported backend consequence frontend load faster memory couple translation integration integration instead frontend release breaking change season moon entity config
adr adding navigation override much usage lrud lovely horse ended laundry list thing want lrud doesnt support also desire maintainable codebase utilises uptodate terminology expected behaviour lrud list desired functionality currently sits real tree structure cleanereasier understand grid functionality supporting concept column spancolumn width real definition node root node focusable node maintain index easier understanding sorting better handling unregistering decided rewrite lrud ground maintaining many concept addressing list desired functionality also give opportunity rewrite lrud typescript increasing maintainability codebase future approved consequence user land usage lrud update code order make new version planning keep breaking change minimum change necessary slightly increased library size affecting response payload size increase size small enough increase minified deem acceptable furthermore change mean current workaround code service land removed reducing payload size area slightly increased runtime computation usage real tree memory requires extra computation dedicated testing take place ensure lrud still performant enough low powered device initial testing test case suggests well within limit reading paper doc discussing lrud want change thing
dont ship example yet supersedes adr second thought shipping example one next main thing cljdoc second clojurespec integration would huge feature longer sure impact proportional many people suggested example feature cljdoc think might due familiarity site like clojuredocsorg rather library author actively looking way add structured example library various hypothesis would support addition example havent tested verified sufficiently example useful library usefulness mostly proven regard standard library function tiny scope mostly operate plain data library often require complex setup library author add example library communityrepository necessary mostly introduced allow adding example clojure dont ship example yet cljdoc great library author dont anything get great looking documentation let keep way focus broader adoption feature deliver value without requiring extra work library author consequence example also freed time directed towards feature scale proportional user rather alreadybusy library author even work day work sunk progress preserved branch example appendix reapproached later stage consider example testable way seems way ensure library author keep example maybe repl transcript could interesting approach
cpu cpucpu svn cpu aliyun consequence ref httpwwwjianshucompfbfccbebe httpszhuanlanzhihucomp httptechmeituancomstresstestbeforepromotionhtml httpweibocomttarticlepshowid mysql httpwwwcnblogscomaiapplephtml
unified terminology easy different term meaning thing code common aphorism difficult thing coding naming terminologymd document created collect official term project naming diverts terminology considerd bug consequence new code adhere term found terminologymd document become augmented project progress term found terminology document
component separation frontend backend connector converter problem statement given upload file process commit kafka set component separation driver usability user wait long get good overview progress made understand indicate data upload processed reliability uploaded data always committed kafka marked erroneous performance data processing scalable considered frontend connector separate frontend connector integrated backend frontend backend converter connector frontend separate backend data conversion processed connector frontend backend connector converter frontend backend keep track uploaded file connector number supported converter frontend backend converter job system connector frontend backend keep track uploaded file start conversion job connector commits processed data kafka outcome chosen frontend backend connector converter keep backend free issue connector connector scale wish setup similar frontend backend converter job system connector except job system integrated connector make connector bit heavier code internal management keep amount setup configuration low positive consequence user responsive backend give update data processed backend connector charge conversion avro schema handling connector restart without interruption user interface severe conversion error cause backend fail negative consequence converter reside backend backend know converter available make configuration bit heavier connector configuration become involved configuration converter
dsl creation representation goal tree work lot goal tree example siebenapp testing current api allows create goaltree stepbystep make hard point border test setup test action create declarative dsl allows define goal tree exists test action unit test consequence test became readable clean
build setup build tool necessary various task compile test packaging deploying code maven build backend uniprot rest api component consequence maven automates building task frequently development production plethora plugins library enable easy customisation configuration
pipeline api rewrite proposed alex black discussed sham paul adam konduit serving concept step represents one component machine learning deployment example modelstep contains neural network model pythonstep run arbitrary code executed one step chained together user via jsonyaml configuration api create konduit serving deployment execution output one step input next step output final step returned user perhaps post processing proposal proposes significant change format data passed pipeline step well proposing change userfacing api rest endpoint result change background number key class pipelinestep interface configuration step much jsonyaml user write deployment related configuring pipelinesteps pipelinesteprunner interface actually handle execution pipelinesteprunner instantiated pipelinestep inferenceexecutioner inferenceexecutionerfactory machine learning neural network model modelsteps pipelinesteprunner inferenceexecutionersteprunner inferenceexecutionersteprunner creates inferenceexecutionerfactory one implementation samediff tensorflow dlj pmml onnx kera inferenceexecutionerfactory creates initializedinferenceexecutionerconfig inferenceexecutioner internally one inferenceexecutioner implementation dlj samediff tensorflow etc inferenceexecutioner generic type outputtype executeinputtype input indarray inout dlj onnx listmapfieldname object pmml summary modelstep inferenceexecutionersteprunner xinferenceexecutionerfactory xinferenceexecutioner present highestlevel internal api pipelinestep schema pipelinesteprunner transform method based datavec follows dataframe type api ultimately everything converted datavec record end pipeline step example case neural network model record indarray model indarray record happens modelstep inferenceexecutors note datavecs record object simply listwritable internally writable object value datavec support example doublewritable ndarraywritable text imagewritable etc link also concept output data format prediction type schema type schema defined following enumsclasses inputdataformat numpy json ndj image arrow outputdataformat numpy json ndj arrow outputpredictiontype classification yolo ssd rcnn raw regression optional output adapter applies output schematype string integer long double float categorical time byte boolean ndarray image note distinct datavec columntype value minus image schema datavec schema object note inputdataformat outputpreductiontype also impact rest api endpoint format predictiontypeinputdataformat furthermore simply internal detail user understand order createconfigure pipeline example user set inputdataformat outputdataformat serving configuration link though oddly doc show setting serving input data format java servingconfig setting output config present user set inputdataformat outputdataformat value pythonsteps link user optionally specify outputpredictiontype server configuration however user set yaml config according doc servingconfig outputpredictiontype configuration calling endpoint manually via client user understand predictiontype inputdataformat issue current design multiple problem current design api verbosity pipelinestep interface method related input output typesschemas confusing type weve got datavec schema schematype inputdataformat outputdataformat outputpredictiontype thing think developer know aboutsetconfigure user pipelinesteprunner defines separate transform method object writable object writable record record usage objectobject highly ambiguous error prone note largely equivalent practice record listwritable internally basesteprunnertransformobject transformobject unwrapconvert call transformrecord internally anyway note none suitable sequence without ugly hack like embedding sequence ndarray note even added datavec sequencerecordlistlistwritable support sequence still way mix sequence nonsequence data without ugly hack sequence different length datavecbased api significant blocker adding programming language happens want pipeline step based swift javascript there datavec api communicating language vms pipeline split processesvms microservice datavecbased api add significant serialization overhead support dynamic schema optional return value example classification optionally return probability based user request writing custom java pipeline step requires user familiar datavecs apis well conversion tofrom indarray etc inputdataformat outputdataformat contain languagespecific feature numpy ndj inputdataformat outputdataformat restrictive example there niceeasy way return string arbitrary byte image segmentation model least without hack like wrapping ndarray multioutput network really supported example multitask classification regression model single predictiontype setting doesnt work invalid combination configuration easy produce yolo prediction type json arrow outputdataformat mean similarly python client able handle outputdataformat ndj link way return metadata user short issue usability performance maintainability support case current design requirement new api data format suppose redesign api handling data consequence throughout codebase change impacting pipeline pipelinestep apis yamljson configuration serving client step rest endpoint client api requirement extensible language principle allow interop language might one day deploy javascript matlab etc support efficient serializationdeserialization ideally zero copy possible suitable microservices type split pipeline step step run different processescontainers efficient monolithic deployment paying serializationdeserialization memory cost everything running jvm like suitable communication approach deployment scenario grpc mqtt iot kafka etc flexible doesnt restrict case explicitly builtin library support optional value good usability easier write maintain pipeline step json serializable nice metadata support optionally present absent support batch one recordexample object binary serializable suitable longterm storage example recording value compliance manual labelling purpose longterm storage schema evolution backward compatibility load old serialized value new library version efficient binary storage readable multiple language would also nice example write java read python proposal starting point remove datavec entirely pipelinestep pipelinesteprunner apis remove concept predefined fixed schema pipelinestep pipelinesteprunner regard current pipeline definition record record replaced something else proposed call data class thus pipeline defined data data operation two aspect consider api user developer interact writing pipeline step storage actual data structure store serialize data instance discussing number aspect apicodebase discussed api data class api proposed mapdictionarylike semantics data proposed maplike hold set keyvalue pair key string type value one predefined datatypes see data instance would hold one example batch represented array list data data listdata allows dynamic schema different schema different example batch dynamic schema example image classification one example batch inference request may request predicted class schema class string whereas another example may request class probability schema class string probability ndarray also allows optionalmissing input value data similar dataframe type design different column map entry one set predefined data type however unlike dataframe allow multiple example different schema per examplerecord value proposed one following type value type ndarray string byte image double integer int boolean collection type data nested data instance allowed possible given limitation chosen storagedata structure arraylist including multidimensional listsarrays additionally data metadata support datatypes standard type term implementation metadata nested data instance dedicated key perhaps metadata something note data type easily converted json binary format also ndarray image multiple possible json representation raw text multidimensional json array base byte ndarray ndarray base image file byte jgp png etc image client could easily specify ndarray image encoding type want request via client config input data metadata proposed data api java tojson string key list keyint string typestring datatype enum listtypestring datatype enum type list entry getters getarraystring ndarray getstringstring string getliststring datatype list getdatastring data etc default getters get present provided default value getarraystring ndarray getstringstring string getbooleanstring boolean etc put method format column name value putstring string putstring indarray putstring byte etc metadata method hasmetadata boolean getmetadata data setmetadatadata void serialization savefile void writeoutputstream void asbytes byte static method fromjsonstring data fromfilefile data fromstreaminputstream data frombytesinputstream data singletonstring object data builder databuilder data databuilderputmyvalue vbuild frommapmap data note dynamically typed language like python may simply single getstring setstring object method instead overload example custom pipelinesteprunner api implementation one method replace pipelinesteprunnertransform method java public data transformdata data indarray arr datagetarrayfeatures indarray modeloutput mycustommodeloutputarr return datasingletonoutput modeloutput example custom samediff model optional input value optional return value attention model java public data transformdata data boolean withattnweights datagetbooleanreturnweights false user requested attention weight array output mapstringindarray new hashmap phputin datagetarrayfeatures phputmask datagetarraymask string output withattnweights new stringoutput attention new stringoutput mapstringindarray map sdoutputph output return datafrommapmap storageserialization data structure data api interface multiple implementation underlying data structuresstorage java main storage format monolithic deployment scenario running one jvm interprocess communication like simple map type structure avoids paying unnecessary serializationdeserialization overhead interprocess communication persistent storage format flatbuffers protobuf advantage including multilanguage support efficient creationserialization efficient space utilization support zerocopy access array data course apis language user friendly already noted well api top underlying storage issue summary map based storage within single jvm case current konduit serving monolithic deployment flatbuffers protobuf data structure serialization ipc required enable conversion two internally ifwhen required far appears either flatbuffers protobuf fine rest endpoint mqtt endpoint grpc endpoint see protobuf flatbuffers serialization longterm storage support schema evolution schema validation present konduit serving implement degree schema validation pipeline define schema inputoutput type checked however runtime schema validation isnt useful might first appear something wrong schema validation exception runtime input data match schema step without schema validation exception runtime exception step input data key found input data consequently proposed konduit serving allow dynamic schema pipeline step may input return anything including different data key type different example individual pipeline step responsible interpreting format input konduit serving runtime schema validation beyond step check get required input post processing output configuration currently outputpredictiontype classification yolo ssd rcnn raw regression outputprediction post processing raw default setting post processing currently predictiontypeinputdataformat endpoint example get output localhostclassificationnumpy endpoint pas numpy data get processed classification data note current classifieroutputadapter return information default set classifier label maximum predicted class index integer full set probability double proposal would similar postprocessing mechanism different design consider example image classification image want return one depending user request predicted class probability array top class probability list class label following proposed outputpredictiontype removed entirely api predictiontypeinputdataformat endpoint removed entirely api keep existing output adapter refactored pipeline step additional configuration add support postprocessing subset output especially useful multitask multioutput network add support configuring default behaviour classification predicted class probability default add ability pipeline step get initial input metadata allow user request output format want pipeline step would existing output adapter different type class however pipeline step may simpler user one type thing learn plus flexible example classification output adapter transform method java public data transformdata data indarray output datagetarrayoutput data inputmetadata inputmetadata method defined basepipelinesteprunner everything extends basepipelinesteprunner boolean retprobabilities inputmetadatagetbooleanreturnprobabilities configisreturnprobabilities boolean retclasses inputmetadatagetbooleanreturnclasses configisreturnclasses data ret datacreate note data interface hence cant new data ifretprobabilities retputprobabilities output ifretclasses retputclasses getclasses return ret feature note input metadata metadata come original user request available pipeline step matter many step precede deployment split separate microservicesprocesses etc default configuration step set user applicable user override configuration step directly client internally via metadata setting allows optional return value configured client impact endpoint designproposal would longer type specific endpoint one predict endpoint binary applicationoctetstream mime type inout protobufflatbuffers encoded data object would main method builtin client handle conversion tofrom data internally json applicationjson mime type inout json encoded data object secondary method user interacting konduit serving manually without one client json reason current predictiontypeinputdataformat endpoint would removed refactor model execution noted earlier current machine learning model class heirarchy complex konduit serving modelstep inferenceexecutionersteprunner xinferenceexecutionerfactory xinferenceexecutioner proposed flatten heirarchy simply level modelstep set xsteprunner class one dlj samediff tensorflow onnx etc based inferenceexecutioner utility data indarray mapstringindarray etc conversion normally change magnitude done separate given scale api change suggest time dataapi change reason simple dont want waste time getting existing heirarchy modelstep inferenceexecutionersteprunner etc working new data api remove newly refactored code right away consequence advantage considerably simplified api pipeline step fewer method complication schema datatypes etc greater flexibility extensibility performance etc support sequence possible present combination sequence nonsequence data easier development maintenance new pipeline step konduit developer user make future enhancement easier including running pipeline step different processescontainershosts nonmonolithic deployment inputoutput recording proposal satisfy requirement mentioned earlier extensible language via probufflatbuffers encoding suitable microservices type split pipeline step support efficient serializationdeserialization ideally zero copy possible efficient monolithic deployment via java mapbased data implementation without serialization cost suitable communication approach deployment scenario grpc mqtt iot kafka etc via json binary encoding flexible doesnt restrict case explicitly builtin library data flexible enough support type returned value support batch one recordexample object partial via data support optional value good usability yes imo easier write maintain pipeline step json serializable ideally yaml serializable also metadata support optionally present absent inputrequests output binary serializable suitable longterm storage via flatbuffers protobuf tbd disadvantage schema mismatch determined runtime one step output array ndarray next step expects feature double feature double however worse current design schema check trigger runtime anyway potential mismatch pipeline step mapped manually user example preprocessing step produce array name mask model expects array name inputarray maskarray probably solved combination guessing single input array ambigious even name differ extra user config data object single example may introduce ambiguity user could still sneak batch single data object via ndarray via listdouble batch double etc potential performance overhead batching data execution data indarray worse current record batch record approach however write converter utility tofrom data worse current tofrom record conversion however discussion micro service deployment remote endpoint background planned allow single konduitserving deployment spread along multiple container case wed like ship something already existing deployed service effectively becomes sort rpc call yes split multiple container something well frequently deployment situation require consider example following scenario pipeline model face detector run edge device powerful face verification model run powerful remote server idea edge device initial detection face detected pas data remote server cant andor dont want run entire pipeline one machine pipeline requires multiple docker container isolation cant embed every language ksjava like python case well split thing multiple docker container matlab swift etc come mind thing might deploy separate docker image even image run one machine situation nonlinear scaling pipeline step example first step filtering like face detection example multicore cpu machine filtering case actually make one gpu machine deployment cpu gpu gpu arent something right think inevitable well run deployment scenario current single process monolithic design wont work schema validation wouldnt possible make step queryable input output want definition time checker schema validation would quite nice guess could added another step doesnt built right thats bad idea would optional step really know inputsoutputs runtime inputsoutputs dynamic wont though example model step wont know placeholderinput name even number inputsoutputs load specific model yes let revisit metadata like input meta data available step wouldnt nice meta data addable step yes dont think covered something like mind example image loading step could return metadata original image format dimension filename etc back user matter many step present image loading step mapping model step end acknowledge naming mismatch may problem maybe easiest way instead guessing make explicit reusable mappingstep map one name another input mask feature featuremask type labeling problem yes dont see unambiguous case like single array input etc
katas follow described formatting come back katas formatting style currently changed make sense adapt katas every time katas longterm thingy live long time defined settled kata look like following describereflect basic function test description proper english sentence start upper case describereflect special different object function itits type object function const expectedtype function const expectedtype object assertequaltypeof reflect expectedtype file end empty line unnecessary space new line also assert rare case new line really help readability exception line short possible overall important consistent consequence katas look alike user one new one file
multitenancy approach marain tenancy always first class citizen marain service however enough make system truly multitenanted order determine tenant created managed within marain world would like deploying marain either managed service hosted licenced user paas offering client deploy private instance cloud subscription also want give client managed service data stored storage account database still run compute aspect platform behalf also extends client marain implement multitenanted service client also able isolate client storage addition able differentiate marain service available client directly one dependency service example workflow service make operation service result client licenced workflow service operation service indirectly despite fact may licenced directly define tenancy model support scenario implemented maraintenancy service support made following every client marain instance marain tenant created remainder document referred client tenant every marain service also marain tenant created remainder document referred service tenant make tenant hierarchy group client tenant service tenant toplevel parent mean toplevel tenant called client tenant parent client tenant equivalent one called service tenant parent service tenant shown diagram client access marain service licenced tenant whilst marain service expect supplied part endpoint path nothing prevent api gateway azure api management put front custom url mapped tenant tenant passed header marain service depends another one part operation pas tenant subtenant service tenant subtenant specific client making original call example workflow service dependency operation control service two client tenant workflow service corresponding subtenant workflow service tenant make call operation service approach allows dependedupon service behalf client without making available direct usage tenant client service clientspecific subtenants service tenant hold configuration appropriate expected case normally required storage configuration service plus subtenants created service could also include thing example suppose two customer contoso litware customer able marain must create contoso litware tenant also two marain service available workflow operation also tenant created following diagram service tenant shown cap client tenant normal sentence case servicespecific client subtenants mix indicate relate root tenant client tenant contoso litware service tenant workflow operation contoso licenced workflow litware licenced workflow operation mean contoso tenant contain storage configuration workflow service configuration onboarding process default standard marain storage data siloed tenant shared storage account single cosmos database containing collection per tenant however client supply storage configuration required litware tenant contain storage configuration workflow operation service directly addition client licenced workflow subtenant workflow service tenant containing storage configuration operation service operation service subtenants dependency marain service root tenant client tenant contoso workflow storage configuration workflowcontoso subtenant workflow service litware workflow storage configuration workflowlitware subtenant workflow service operation storage configuration service tenant workflow workflowcontoso operation storage configuration workflowlitware operation storage configuration operation seen tenant hold appropriate configuration service directly case client tenant also hold subtenant workflow service calling operation service behalf necessary avoid costly search correct subtenant notice litware end two set configuration operation storage employed operation service directly calling workflow service thus operation service indirectly give client maximum flexibility controlling data stored let look slightly complex example imagine scenario third service well call foobar service workflow operation service dependent addition contoso licenced directly dependency graph look like workflow contoso operation litware foobar order support start additional service tenant foobar tenant root tenant client tenant contoso litware service tenant workflow operation foobar enroll contoso workflow service cause chain enrollment whereby subtenant created workflowcontoso enrolled operation service creating subtenant operation operationsworkflowcontoso enrolled foobar service since foobar dependency create sub tenant workflow service also directly dependent foobar workflowcontoso also enrolled foobar resulting storage configuration foobar added leaf tenant hierarchy looking like root tenant client tenant contoso workflow storage configuration workflowcontoso subtenant workflow service litware service tenant workflow workflowcontoso operation storage configuration operationsworkflowcontoso subtenant operation service foobar storage configuration operation operationsworkflowcontoso foobar storage configuration foobar enroll contoso foobar service since additional dependency result subtenants created add storage configuration foobar contoso tenant first example contoso two set storage configuration foobar service one direct one indirect root tenant client tenant contoso workflow storage configuration workflowcontoso subtenant workflow service foobar storage configuration litware service tenant workflow workflowcontoso operation storage configuration operationsworkflowcontoso subtenant operation service foobar storage configuration operation operationsworkflowcontoso foobar storage configuration foobar repeat process enrolling litware workflow service root tenant client tenant contoso workflow storage configuration workflowcontoso subtenant workflow service foobar storage configuration litware workflow storage configuration workflowlitware subtenant workflow service service tenant workflow workflowcontoso operation storage configuration operationsworkflowcontoso subtenant operation service foobar storage configuration workflowlitware operation storage configuration operationsworkflowlitware subtenant operation service foobar storage configuration operation operationsworkflowcontoso foobar storage configuration operationsworkflowlitware foobar storage configuration foobar since litware licenced foobar litware client tenant hold configuration service finally enroll litware operation service example operation depends foobar create another subtenant operation call foobar litware operation directly enroll new subtenant foobar leaf following root tenant client tenant contoso workflow storage configuration workflowcontoso subtenant workflow service foobar storage configuration litware workflow storage configuration workflowlitware subtenant workflow service operation storage configuration operationslitware subtenant operation service service tenant workflow workflowcontoso operation storage configuration operationsworkflowcontoso subtenant operation service foobar storage configuration workflowlitware operation storage configuration operationsworkflowlitware subtenant operation service foobar storage configuration operation operationsworkflowcontoso foobar storage configuration operationsworkflowlitware foobar storage configuration operationslitware foobar storage configuration foobar consequence expected subtenants created configured part process enrolling tenant specific service licenced mean expected happen covered adr without appropriate tooling managing necessary tenant configuration would complex errorprone minimum necessary script basic process assist setting process also necessary ensure appropriate level logging place code read configuration order allow setup problem quickly diagnosed moving lot service configuration tenant mean also produce tooling set service tenant default configuration part deployment process take place existing deployment process arm template add configuration directly host function application
bootstrap copying adrtools source code writing fast part hackday want app like adrtools command line tool store data project version control system want builtin help like adrtools copy source adrtools delete script dont make sense pottery bulk findandreplace adr pottery bish bosh consequence get first version working fast actually took two hour idea first working version pottery inherits technical underpinnings adrtools advantage disadvantage particular mean implemented bash unix commandline tool tested approval testing bash script output configuration help packaging project easily package tool distribution
implement workarounds capi logcache unblock global strict mtls turn strict mtls component mesh however component currently incompatible mode capi incompatible init container run migration init container come sidecar unable establish mtls connection capi database cause init container fail prevents capi coming see issue capi logcache incompatible configured establish connection incompatible mtls sidecar attempting establish provided configuration workarounds form policy placed cfforks repo owned respective team manage troublesome component pull request consequence component accept plain text communication dont consider significant issue already implement encryption form would best long run could stop exception though logcache capi team care istio configuration eventually make change component eliminate workarounds however work longer blocked change consider absolute win way
deciders prala problem device might contain data dont want public example often turn light bathroom solution add boolean field isprivate device hide data see private device data data visible owner admins world map device name location visible everyone world map data
user maintenance page content project team wanted able edit frequently different variety textual page contentwelcome message instructional text readme text tool tip forth system html page created loaded via angularjs plugin admin user edit static file directly edited file saved disk included page load time consequence page thus managed version control application code creates backup page mean text content site amenable method requiring text still must edited source repository user little insight text editable others
aspnet core introduction net core decide whether aspnet net aspnet core aspnet core consequence application machine running linux macos window rather restricted window net core implementation tooling still evolving may result certain net core release requiring change project structure commonly library entity framework specific version net core case apis differ net version library yet carried work necessary compatible net core possible library required work completed
introduction title introduction franklin whats franklin stac ogc api feature compliant web service focused easeofuse endusers franklin import serf stac catalog storing data postgres goal enable import querying stac catalog simple possible get franklin publishes docker container available publicly deployed anywhere docker deployed run container supply postgres database franklin connect running franklin running franklin requires one command serve start api server database configuration default franklin attempt connect database named franklin localhost password franklin following cli customize database connection bash dbuser string user connect database dbpassword string database password dbhost string database host connect dbport integer port connect database dbname string database name connect database connection also set environment variable dbuser dbpassword dbhost dbport dbname example command following example show get started franklin importing local catalog starting database first step find database connect handled pgstac bringing new pgstac database done dockercompose migration necessary bare pgstac image includes already bash dockercompose pgstac start database container pgstac background want see still running docker command want stop point command docker stop pgstac importing data car fuel run franklin data useful pgstac come small python library aimed simplifying data import example import provided library development purpose load collection noaa imagery centered joplin missouri joplin carry example import run scriptsingestdata pgstac container running bash scriptsingestdata running service point ready run service start service default port run serve command docker run bash docker run link franklindatabasefranklindatabase quayioazaveafranklinlatest serve dbuser benjamin dbname franklin dbpassword franklinsecret dbhost franklindatabase additional api functionality also configured via franklin cli passing serve command externalport port usersclients hit request internalport port server listens different externalport service started behind proxy apihost hostname franklin hosted localhost apipath path component root franklin instance stacapi apischeme scheme server exposed end user defaultlimit default limit item returned paginated response withtransactions whether respond transaction request like adding updating item withtiles whether include tile endpoint api also set environment variable apiexternalport apiinternalport apihost apipath apischeme apidefaultlimit apiwithtransactions apiwithtiles docker compose example illustrate separate command running franklin via docker run command however familiar dockercompose configuration get started quickly first copy file locally dockercomposeyml file yaml version service database image quayioazaveapostgispostgresslim environment postgresuserfranklin postgrespasswordfranklin postgresdbfranklin healthcheck test cmd pgisready franklin interval timeout retries startperiod franklin image quayioazaveafranklinlatest dependson database condition servicehealthy command serve volume optfranklin environment environmentdevelopment dbhostdatabaseserviceinternal dbnamefranklin dbuserfranklin dbpasswordfranklin awsprofile awsregion link databasedatabaseserviceinternal port second run dockercompose run franklin migrate set database next import local dataset copying directory dockercomposeyml file created assuming root catalog catalogjson command would dockercompose run franklin importcatalog catalogroot optfranklincatalogjson lastly import finished start webserver localhost view catalog
kotlinbased dsl source truth discussed paul dub alex black raver october code generation experiment meant starting point api unification ndj samediff multilanguage support reason define ops interface language neutral way initial idea language workbench like discarded bug limitation encountered trying define language would work simple example next idea ops defined json file would allowed define ops human readable data read write file programming language however drawback approach writing json manually invite many problem written manually typo bad structuring look proper key order rectify drawback would create custom tooling would maintain contributor would java builder pattern based approach verbose kotlinbased dsl define ops consequence full programming language platform build dsl advantage drawback drawback contributor install jvm order able run code generation get serialized graph serialization one way road output json dont read contributor definition learn dsl maybe kotlin contributor dsl learn kotlin advantage utilize java knowledge existing team writing code generator kotlin twoway interoperable java jvm language utilize intellij ides supporting kotlin existing editor ops definition provides benefit like code completion error highlighting get compile time check freeing trivial error like typo utilize base feature kotlin like variable assignment simplify implementation kotlin first class dsl definition support allowing make definition almost easy read full language workbench would allowed
aleph interaction assumption circrequests june superseded alephcircrequestsdeniedentrieshandlingmd circrequests assumed aleph always provides complete list hold hold considered valid long list provided aleph consequence aleph always provides complete list hold application track hold sent caiasoft well hold caiasoft denied denied hold resubmitted possibly updated information aleph response long still appears list aleph
separate ecf npq calculation engine hash inputoutput interface currently two different training scheme scope trackandpay project rumour possible third future similarity many difference input output math payment training scheme example fixed payment allow pulling fixed payment earlier setup payment cashflow output payment different detail different banding system people tim abell pavel lisovin track pay developer discussed issue amongst came time build two payment engine share code similar inputoutput interface ruby hash structure later easily converted json similar pattern engine gherkin bdd driven unit test plus normal rspec unit test consequence becomes easier difficult risk introduced change mitigated keeping separate allow iterate fast even payment calculation rule diversify making sure dont put engineeringdriven constraint policy training scheme payment system consistent inputoutput interface allow integrate engine whatever larger flow end
corvustenancy create storage container automatically corvustenancy various storagetechnologyspecific library corvusazurestoragetenancy could dynamically create new container first time asked one problem caused definition type blobstoragecontainerdefinition needed include information required able create new container demand example blob container meant specifying container public access type great idea muddied role definition type primarily logical name also ended containing default configuration setting autocontainergeneration scenario tenant onboarding process process enabling new tenant application particular piece application functionality necessarily includes step determining storage account relevant credential picking suitable container name ensuring proper tenant isolation creating container application control first case second third handled corvustenancy last two unhelpfully tied together unfortunate comingling concern happened due good misguided intention aiming enable application single configuration serving multiple logical container certain kind storage azure blob storage common application split data across multiple container putting user profile detail one container todo list entry another container nontenanted application youd expect configure setting account name credential onceit wouldnt normally make sense percontainer configuration setting youd expect account across logical container came tenanted storage library tried support approach offering conventionbased mechanism enable multiple container definition logical name refer underlying configuration however inextricably linked letting storage library pick container name problem arose one thing tried map logical container name definition type blobstoragecontainerdefinitioncontainername actual container name enable isolation data across tenant even shared storage account container name mapping would typically incorporate tenant real container name however naming scheme initially undocumented implementation detail preventing application anticipating container would actually called application doesnt know container name cant create container prior first tenanted storage provider also automatically created container ended definition type blobstoragecontainerdefinition meant logical identifier needing include information required able create new container demand technically possible application code take control three step listed problematic could disable tenanted container name generation giving control container name making possible application know right container name unfortunate side effect new tenant ended needing create one configuration every logical container take control container creation unavoidably meant complex configuration make change enabling application predict name would could get ahead hindsight ended regretting ever making tenanted storage library create container first place another problem automatic createonfirstuse behaviour problem would prevent creation became visible rather late day might think youd successfully onboarded new tenant discover later everything going work corvustenancy application responsible creating container new tenanted storage client library never create container also application determine strategy picking tenantqualified name ensure isolation case multiple tenant sharing storage account tenancy library provide mechanism work main change application opt explicitly consequence application always create storage container part tenant onboarding process following benefit logical container name separate storage account setting onboarding complete application confident created everything needed new tenant wont surprise error later first try storage tenant downside application code pick name create container migration there problem migration possible app created tenant defined storage configuration yet attempted configuration logical container app library thing get created demand switch library fail encounter one thing transitional mode step upgrade look like running fully library making sort ensurecontainerexiststosupporttransitionfromv call every time get container without making modification tenant configuration adding new vform tenant configuration property run tool walk entire tenancy tree ensuring container exist disableremove transition support remove old configuration entry
backend language framework backend web framework significantly eas amount boilerplate necessary application handle web request additionally provides scalable box welltested solution common feature user management authentication database interaction public api project mostly require common component described backend web framework familiar speed development project unknown integration asynchronous bicycle network analysis task mentioned adr team familiar python django django rest framework due project constraint desired functionality backend framework considered project team django django rest framework plugin written python team familiarity stack much positive pas addition django provides many thirdparty solution integrating asynchronous bicycle network analysis task allows team flexible choosing solution without sacrificing development efficiency conesquences expect consequence relatively minimal team considerable experience python django provide large amount flexibility future project scope change
map routing library provider deciders orleifur bjarnason technical story implementation web client map interface viewing analyzing traffic cost timedistance defined group people based workplace location map routing engine provide following calculation time distance two address drawing route two address problem statement want base user interface map software calculation routing engine map provider driver since research project free software require map usage must free required map supporting library generate draw actual route two point required map supporting library method calculate actual route time driving cycling walking two point considered google map service provided google location api google direction api openstreetmap service provided osrm routing engine jais service provided gagnatorgjais outcome chosen openstreetmap service provided osrm routing engine free implementatation require registration kind product research intended installation production jais provide documentation routing engine tile cannot considered accept usage google map would lot easier implement google map host maintain required apis geographical data google direction api seems better geographical data iceland see accessable osrm routing profile product intended production must add conideration price google map compared cost hosting maintaining osrm routing engine positive consequence pay usage map negative consequence install host maintain osrm routing engine update maintain routing info local osrm routing engine avoid outdated map data route calculation pro con google map bad free routing engine bad free map without limitation requires credit card registration profile good popularity feature comparison similartech good contains better information rely real time traffic good contains large community large number data provider good hardware software installed hosted routing engine openstreetmap good free routing engine good free map without limitation bad popularity number data provider httpswwwsimilartechcomcomparegooglemapsvsopenstreetmap bad installation locally osrm routing engine maintenance routing engine data bad cost hardware hosting routing engine jais bad map openstreetmap openstreetmap directly bad documentation expose type subscription routing api routing api provided good tile file iceland outstanding satilite street view bad tile file iceland seem exposed usage third party link reference compare google map openstreetmap similartech template licence provided architectural record content copyright orleifur bjarnason right reserved
tachyons foundation primary component cljdoc web application part work web application regularly implement new element flow support overall product development frontend work requires usage specify positioning text style many variable common problem developer try generalize class reused see bem arguably intention great inevitably time come constraint change component modified time people may component place relying current implementation programming language breaking collaborator expectation like mitigated assertion automatic test easily done working order avoid problem outlined adopt approach atomic immutable utility class promoted tachyons library tachyons provides safetoreuse singlepurpose class help achieving consistent scale whitespace fontsizes modifying definition class anymore safely build component class without needing worry breaking someone expectation consequence tachyons bit weird familiar general approach believe enable contributor move confidently quickly long run might extra mile make buy approach previously reuse level class approach like tachyons reuse get elevated component level appendix scalability insightful article utility class good idea author tachyons quote article monolith model never stop writing refactoring hard time consuming deleting unused hard time consuming often work people excited happens people keep writing tachyonstldr super helpful tool look class provided tachyons via attribute affect dwyllearntachyons nice repository another pitch various example outlining basic usage
title specify priority translation dal write payload area core tag dal translation dal allows write translated value multiple way directly translated field plain string language current array indexed either language isocode indicating language value translation association indexed array current priority overwrites accidental never formally specified lead unexpected behaviour case formally specify priority translation overwrites dal work expected developer rely priority general encourage isocodes writing translation multiple language following advantage payload either understand error easier catch looking payload payload compatible multiple system language different besides common understanding providing translation value translated field treated default value value specified association take precedence two observation deduced following rule priority translation overwrites translation indexed isocode take precedence value indexed languageid translation specified translationsassociation take precedence value specified directly translated field note rule important rule therefore translation value indexed isocode field directly overwrite value translationsassociation indexed languageid consequence update dal handle translation overwrites specified add test case ensure implementation adheres specification
adr layered architecture table content consequence since planning eventdriven architecture may face difficulty defining microservices develop common either break much little defining software boundary challenging pay extra attention since dealing complex domain going layered architecture help solve problem nutshell layered architecture break system four layer presentation layer responsible showing user element interaction application layer responsible handling user interaction processing accordingly domain layer accountable core business contains business logic control entity required resource infrastructure name suggests layer responsible handling infrastructure interacting database handling memory forth pattern like russian doll drilldown inside microservice presentation layer presentation application domain infrastructure likewise layer also talk layer except infrastructure layer example presentation layer interact application layer infrastructure layer forth deprecated check update consequence adopting going improve software stability increase complexity architectural solution increase rampup time new engineer pattern make easier develop highcohesive lowcoupled software update update adr valid anymore since backend updated following hexagonal ddd pattern still lack adr
graphql api open lobby server written api first design frontend application based api graphql api standard like rest graph api client friendly approach graphql query language easy validated self documenting graphql allows client get everything one request without overhead needed data important mobile frontends graphiql tool also provides easy way developer inspect try api easy adopt frontend application developer api user consequence client api effectively graphiql tool free save lot time writing api documentation
design principle project want achieve achieve design principle project recruiter provide printable resume recruitment process easy develop maintain based latest web technology easy share automaticallly deployed hosted best aws demo current skill consequence refer design principle develop project
update transaction success failure state approved possible payment transaction change state success failure thought transaction successful could fail however case capture transaction assumption work due flow capture work adyen capture stage capture request coming adyen capture request coming adyen bank capture notification success true indicates capture request valid example authorisation expired balance available submitted bankthirdparty processor capture notification success false indicates capture request adyen failed could due number reason example insufficient balance payment first stage passed still possible bank refuse call made trigger notorious capturefailed reason youll find reason field additionaldata notification case adyen retry capture lead successful captured booking allowed update transaction state success failure
dont memory cache anymore across handler wegwijs memory cache across event handler memory cache however built certain projection example organisation name cache built organisationdetail projection memory cache outside inprocess event handler organisationdetail projection built cause dependency projection mean want rebuild projection organisationdetail fully built memory cache incorrect state defeat purpose memory cache reevaluate memory cache fully isolated within containing handler consequence rethink caching caching mssql table longer hidden dependency projection resulting reliable projection
useherokuforhosting superceded usegovukpaasforhosting set phase beta investigated long term hosting agreed government platform service gpaas strategic platform digital service within beis moving unable get access beis gpaas account set platform value real service hosted soon possible would like done first sprint team live product iterate dxws heroku account host staging production environment migrate service gpaas later consequence pay heroku short term set simple invest much time early platform may repeated future migration gpaas eventually happen flagged risk deputy directory beis digital risk increase complex service becomes real user start service concious investing much time heroku setup avoid repeating container deploy heroku aid stable migration gpaas also support container
adr notification hook runner adr detail design change supporting custom configurable hook various runner event long requested user feature user information runner observability ability run cleanup teardown job feature mainly intended self hosted runner administrator hope solve feature runner admininstrator able add custom script cleanup runner environment start end job runner admininstrator able add custom script help setup runner environment beginning job reason like caching runner administrator able grab custom telemetry job running self hosted runner dont think solve policy feature require certain step run beginning end job would better solved central place setting rather decentralized runner proposed notification hook runner limited self hosted runner dont beileve policy feature reuse scenario job covered composite action resuable workflow security application security handled policy side server decentralized runner hook expose variable user set enable hook actionsrunnerhookjobstarted actionsrunnerhookjobcompleted set variable absolute path file execute pwsh fallback powershell bash fallback appropriate file execute args pathtofile file execute args command pathtofile set standard flag typically set run command want set pipefail bash example script want ensure experience user invoking workflow good hook take long may feel job delayed broken much like set job generate two new step automatically job one configured hook set runner complete runner step contain output invoking hook visibility runtime also provide information path hook shell invoking much like run step running hook job may helpful script access standard default environment variable variable step specific like githubaction case set pull full webhook event payload githubeventpath command expose command environment file yes imagine scenario runner administrator deprecating runner pool warn user swap different pool support however limitation savestate supported traditional step pre post action setoutput supported traditional step environment file also enable environment file support setup scenario runner environment self hosted runner admin set env variable apply job enabling ability add path set env give runner admins ability dynamically based workflow environment variable empower setup scenario exit code synchronous hook block job execution run exit code indicate successful run hook proceed job exit code fail job appropriate annotation support continueonerror key expose variable user set enable hook actionsrunnerhookjobstarted actionsrunnerhookjobcompleted user set variable path file execute job started completed output added new step startend job named set runner complete runner step generated run hook hook always execute env variable set file execute runner user outside container specification job synchronous hook runner admins execute background process async hook want fail job halt execution exit code runner admin responsible returning correct exit code ensuring resilency includes runner user access file env file must exist continueonerror type launch timeout launch consequence runner admins ability tie runner job execution publish telemetry perform cleanup setup new step added showcasing output hook
deploy heroku application deployed somewhere many container orchestration platform configuring cluster machine running docker container managing deployment image container setting tool involves managing cluster machine hosting cost associated machine heroku platform service paas provider help deployment application container registry solution handle deployment docker image suitable container heroku several pricing tier machine application run including free tier heroku provides free hosted postgresql handle setting databaseurl environment variable containing information required connect database free tier database limited row want setup process simple possible host application heroku container registry solution hosted postgresql database consequence cost associated hosting application suitability free tier investigated performance becomes issue database setup seperately suitability free database tier investigate performance quantity data becomes issue
doctrine collection extension getting available locale active channel shop user problem statement customer access locale available channel considered doctrine collection extension good consistent actual approach modifying response content good work rest api extension like pagination bad locale dont relation channel doctrine collection extension complicated data provider good easy implement bad data provider omits extra doctrine extension like pagination outcome chosen doctrine collection extension consistent current approach omit doctrine extension like pagination reference original adr problem implementation changing approach
useredisforareadcache service way build resilience external contentful api becoming unexpectedly unavailable service single point failure dxw often rail redis together recommend technical choice add redis read cache consequence contentful becomes unavailable disruption user mitigated another dependency exists within infrastructure manage easily hook redis session manager type caching future
title cache stampede protection area core tag core cache performance cache stampede protection mechanism prevent several user try update cache entry time cache entry longer hot mechanism useful lot load store cache entry expired invalidated cache stampede protection system several user call category listing time longer cache user would let database server could collapse load integrated protection service symfonycontractscachecacheinterface symfony mechanic mainly cached store api route another positive side effect code become much concise since much done within symfony cachedruleloader php namespace shopwarecorecheckoutcart psrlogloggerinterface shopwarecorecontentrulerulecollection shopwarecoreframeworkcontext symfonycomponentcacheadaptertagawareadapterinterface class cachedruleloader extends abstractruleloader public const cachekey cartrules private abstractruleloader decorated private tagawareadapterinterface cache private loggerinterface logger public function constructabstractruleloader decorated tagawareadapterinterface cache loggerinterface logger thisdecorated decorated thiscache cache thislogger logger public function getdecorated abstractruleloader return thisdecorated public function loadcontext rulecollection item thiscachegetitemselfcachekey try itemishit itemget thisloggerinfocachehit selfcachekey return itemget catch throwable thisloggererroregetmessage thisloggerinfocachemiss selfcachekey rule thisgetdecoratedloadcontext itemsetrules thiscachesaveitem return rule cachedruleloader php namespace shopwarecorecheckoutcart shopwarecorecontentrulerulecollection shopwarecoreframeworkcontext symfonycontractscachecacheinterface class cachedruleloader extends abstractruleloader public const cachekey cartrules private abstractruleloader decorated private cacheinterface cache public function constructabstractruleloader decorated cacheinterface cache thisdecorated decorated thiscache cache public function getdecorated abstractruleloader return thisdecorated public function loadcontext rulecollection return thiscachegetselfcachekey function rulecollection return thisdecoratedloadcontext however since service recognize whether cache hit miss removed corresponding logging
released composite run step last year started journey reusing step across different workflow file continue journey want expand composite run step composite action want support step workflow composite action including container action javascript action composite action limit course pre post step action generate guiding principle composite action function single step action matter many step composed many level recursion future may add configurable make longer case workflow author understand inner working composite action order composite action leverage input get value full access object secret available composite action user pas value input action work inside composite action without code change composite recursion limit start supporting recursion limit composite action deep free bump limit future code written require updating variable graph evaluates beyond recursion limit job fail prejob phase set job step composite action interface input output nothing else carried invoking recursively prepost step nested action plan adding ability configure customizable pre post step composite action time however execute pre post step action referenced composite action composite action generate single prestep poststep entire composite action even multiple presteps poststeps referenced action step execute following ordering rule today first run pre step run first post step run last example composite action two pre step two post step action composite action order execution would prestepaction prestepcomposite prestepcompositefirstactionreferenced prestepcompositesecondactionreferenced prestepaction job step poststepaction poststepcomposite poststepcompositethesecondactionreferenced poststepcompositefirstactionreferenced poststepaction setstate composite action individual combined prepost action setstate command shared setstate command composite step action originally called setstate access env variable post run step prevents multiple action set state interfering execution another action post step resolve action endpoint change resolve action endpoint validate policy ensure given workflow run access download action older ghesghae customer newer runner locked composite step upgrade instance local action local action expand tree perform policy check download action time step running like current local action support presteps action running local time know time run presteps already passed continueonerror timeoutminutes considered time continueonerror timeoutminutes could supported composite runuses step value originally supported composite run step implementation browsing community forum runner repo hasnt lot noise asking feature hold value passed input composite action carried input individual step composite action run default considered time action idea default allow specify shell working directory one location rather step however shell currently required composite run step regular run step optional default different value based want prioritize right experience consumer make action author continue explicitly set value consider improving experience future consequence workflow reusable across multiple workflow file composite action implement existing workflow run step room expand future feature flag control rollout
double encoded url url humanreadable slash allowed encoded slahes enabled default due security reason information encoding available devencodingmd considered namespace prefix url singleencoded url forcing environment reconfigered doubleencoded url outcome chosen doubleencoded url pro con namespace prefix url encoding issue globally unique url change user reconfigures namespace prefix singleencoded url nice url hosting environment configured accordingly lead security issue running application parallel doubleencoded url nearlynice url hostingenvironments reconfigured doubleencoding might cause headache implementation license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
adr screen architecture supersedes intermediate architecture step screen architecture however still problem uistateproducer still sort god class since reponsible business logic happen effect change system make testing cumbersome since test integration test end verifying business logic implementation detail architecture heavily dependent rxjava rxjava good lot thing current architecture encourages everything eventually lead test production code becoming increasingly harder maintain refactor addition rxjava steep learning curve requires significant onboarding effort new contributor able reach acceptable level productivity current architecture scalable framework build screen let manage business logic effect receptive change goal separate business logic presentation logic effect tested independently make state explicit saverestore manually instead depending hidden behaviour restrict rxjava managing event effect let business logic implemented pure function choosing framework evaluated many pattern framework common industry including limited android recommended architecture android recommended architecture depends architecture component work together viewmodel retain state across configuration change livedata provide lifecycleaware reactive notification lifecyle automatically manage subscription reactive notification livedata instance provided via viewmodel architecture make sense new codebases codebase already existing architecture lend well specific setup problem lifecycle component designed work screen built top activity fragment class however current architecture single activity setup individual screen implemented view subclass livedata component give much benefit unless transition view based screen fragment instance already rxjava reactive notification livedata would mean would either replace usage rxjava livedata neither feasible desirable point mvrx airbnb mvrx library built top rxjava android viewmodel architecture component good architecture couple limitation stopped choosing core model based rxjava already issue overuse rxjava across app part goal new architecture restrict usage rxjava limited section codebase support custom view designed fragment based screen suffers problem android recommended architecture mvi mvi modelviewintent one promising architecture reviewed problem mvi however generally set principle architecture mean many implementation mvi industry implemented differently based project oneway implement took look core principle mvi implementation based similar redux single source truth state readonly change made pure function decided look librariesframeworks based principle build new screen architecture based result looking framework available android world built redux principle found mobius reactive framework managing state sideeffects spotify objective framework also aligned well architecture thus decided basis screen architecture basing new screen architecture framework let satisfy following goal separation concern satisfied mobius since enables separate concern even granular level three core component update responsible deciding business logic effecthandler responsible making change system real world uirenderer responsible updating response change state component responsible discrete part system smaller focused thereby making easier test maintain making state explicit support state restoration handled mobiusdelegate class enforced since class expects model parcelable default restricting rxjava usage update component solely responsible business logic implemented pure function usage rxjava limited setting event source feed mobius loop perform asynchronous operation effecthandler component usage two thing consider look architecture implementation perspective create new screen mobius core component created component top order build screen architecture component mobius documented page migrate older screen new architecture migrating newer architecture involved process requires follow deliberate measured step migration process detailed document reference reference implementation complete architecture found commit consequence legacy controller event cached replayed soon screen inflated without waiting attached view hierarchy architecture event forwarded binding screen attached view hierarchy lost ignored correct way implement event older screen controller dependent behaviour might take effort migrate current architecture migrating architecture architecture process take time understand get migration completes new developer onboarded onto architecture codebase maintained time creating document mobius framework maintained production scale single company spotify event company stop framework might either take maintainenance move something else architecture boilerplate code compared earlier architecture
title refund handling area checkout tag payment refund capture shopware offer way unified refund handling result every payment extension either implementing want implement following structure offer unified refund handling extension type new refund data structure payment extension persist actual capture refund handling capture bound specific ordertransaction capture amount allows saving external reference ordertransactioncapture capture directly associated transaction relation ordertransactioncaptures ordertransaction database table type field name reference binary binary transactionid ordertransactionid binary stateid statemachinestateid varchar null externalreference longtext amount longtext null customfields entity type property name string string transactionid string stateid stringnull externalreference float totalamount calculatedprice amount arraynull customfields ordertransactionentitynull transaction statemachinestateentitynull statemachinestate ordertransactionrefundcollectionnull refund ordertransactioncapturerefund refund directly associated capture relation ordertransactioncapturerefunds ordertransactioncapture database table type field name reference binary binary captureid ordertransactioncaptureid binary stateid statemachinestateid varchar null reason longtext amount longtext null customfields varchar null externalreference entity type property name string string captureid string stateid stringnull externalreference stringnull reason float totalamount calculatedprice amount arraynull customfields statemachinestateentitynull statemachinestate ordertransactioncaptureentitynull transactioncapture ordertransactioncapturerefundpositioncollectionnull position ordertransactioncapturerefundposition refund position optional refund positionspecific relate ordertransactioncapturerefundpositions ordertransactioncapturerefund database table type field name reference binary binary refundid ordertransactioncapturerefundid binary lineitemid orderlineitemid int quantity varchar null reason longtext refundamount longtext null customfields entity type property name string string refundid string lineitemid stringnull reason int quantity float refundprice calculatedprice refundamount arraynull customfields orderlineitementitynull lineitem ordertransactioncapturerefundentitynull ordertransactioncapturerefund change existing entity paymentmethod add refundhandlingenabled computed field payment method handler implement refundhandlerinterface ordertransaction add onetomanyassociation ordertransactioncapturecollection capture orderlineitem add onetomanyassociation ordertransactioncapturerefundpositioncollectionnull refundpositions state machine add new state machine ordertransactioncapture ordertransactioncapturerefund ordertransactioncapture want add following state new ordertransactioncapturestate state machine pending completed failed ordertransactioncapturerefund want add following state new ordertransactioncapturerefundstate state machine open inprogress cancelled failed completed paymentrefundhandlerinterface add interface outlined php public function refundstring orderrefundid void paymentrefundprocessor paymentrefundprocessor get triggered via corresponding adminapi action contains method processrefund outlined php public function processrefundstring refundid response apps whole refund handling available apps plugins following change required allow apps handle refund shopwarecoreframeworkappmanifestxmlpaymentmethod add refundurl manifest paymentmethod also change xsd accordingly apprefundhandler add apprefundhandler assembles payload talk app refund endpoint capture apps capture written adminapi endpoint
dont build top codox superceded utilize codox read clojurescript source want derive data clojure project render api documentation well plain text documentation tutorial codox popular tool create kind documentation html file since codox render html instead well defined data format hard turn codox output format due problem building top codox viable path forward consequence tool needed create data apis documentation
decided implement automatic data scraping backend customly built system deployed heroku rather specialized platform scraping apify think backend system eventually outgrow mere data scraping see message preceding message thread
optimize testability readability rather performance given brute force algorithm determining winner choose hand possible per person one playing board five community card every player enumerate possible hand enumerate hand given hand absolute score calculated linear time match hand pattern possible hand match found hand doesnt five card make note kicker value player sort hand absolute score choose highest hand player sort score highest scoring hand dont know algorithm node sorting would determine complexity step step except last one single sort operation overall complexity somewhere around logn number player probably say performance likely big consideration absence factor testability readability good architectural value make respond change collaborate optimize something else later easy optimize testability readability consequence implement whatever objectoriented design easiest think test given choice performance optimization readability choose readability discover performance issue ill revisit
realigning timed text evaluated deciders pietro james problem statement user edits timed text transcription might lose timecodes information time number edits deleting paragraph line rewriting scratch word might time information associated find straightforward way either preserve restore time information associated word corrected transcription driver easy reason around computational intensive realignment operation performed client side approach flexible granularity realign whole text paragraph sentence considered resync audio waveform transpose timecodes stt transcript interpolate timecodes word within sentence levenshtein distance sentence level outcome still evaluated resync audio waveform example description pointer information good argument good argument bad argument example description pointer information good argument good argument bad argument example description pointer information good argument good argument bad argument link link type link adr
replace old model zoo proposed adam gibson jan deeplearningjzoo module around long time provides model box also relies manually implementing model allow deeplearningj benefit innovation happening space also samediff support current model zoo proposal replace model zoo omnihub migrate existing model azure hosting omnihub github repo httpsgithubcomkonduitaiomnihubzoo allow user selectively download pretrained model deeplearningj zoo redirect url call old zoo new one prevent disruption user workflow extend deeplearningjzoos zoomodel support new omnihub zoo provide bridge interface zoomodel omnihubzoomodel allowing seamless transition expansion new model migrate azure storage model saving cost reducing complexity consequence advantage reduced maintenance cost increased model availability user allows support samediff reuse existing model zoo increase support new model disadvantage potential bug new infra mean manually uploading new model ensure smooth migration zoomodel interface seamlessly work new model zoo
service layer controller responsible receiving request executing returning appropriate response service layer added remove knowledge operation performed controller allowing focus responsibility mentioned service layer ensure controller contain business logic consequence controller responsible pulling required information request calling appropriate service layer method returning appropriate response controller direct access pocket apis data repository service layer responsible executing action behalf controller may involved communicating pocket apis andor storingretrieving data database
testing testing language issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
adr screen architecture superceded current screen architecture bunch problem recreate application state state depends hidden behaviour rxbinding initial value observables emit current event immediately widget screen save restore state properly entire event stream replayed system setup way begin emission event like screencreated entire event handling loop setup controller handle business logic view logic come together make hard test maintain screen addition screen perform lot business logic memory require lot working around fact architecture depends state saved either persistence platform mechanism goal separate presentation business logic tested independently make state explicit saverestore manually instead depending hidden behaviour make easy migrate architecture existing screen implementation split controller two discrete piece responsibility uistateproducer responsible performing function controller related business logic uichangeproducer responsible performing function controller related presentation logic addition introduce helper class viewcontrollerbinding tie state producer consumer together event stream reference implementation reference implementation complete architecture found commit terminology event generated event typically event generated user interface might also include event generated platform like sensor camera etc generally represent kotlin data class implement uievent interface uistate kotlin data class represents everything needed render content given screen interface represents functionality actual screen provide controller uichange kotlin lambda signature unit screen setup process define uistate whatever viewscreen built create uistateproducer observabletransformerevent uistate class responsible business logic transforming stream event stream state create uichangeproducer observabletransformeruistate uichange responsible presentation logic transforming stream state stream lambda executed create controller observabletransformeruievent uichange compose uistateproducer uichangeproducer internally viewcontrollerbinding tie event stream view sample kotlin inject lateinit var uistateproducer shortcodesearchresultstateproducer inject lateinit var uichangeproducer shortcodesearchresultuichangeproducer lateinit var binding viewcontrollerbinding override fun onfinishinflate inject screen binding viewcontrollerbindingbindtoviewthis uistateproducer uichangeproducer newpatientbuttonsetonclicklistener bindingoneventsearchpatient goal review separation concern testability since business logic presentation logic separated two discrete component testing simpler since tested independently addition test behaviour business logic value testing asserting generated state readable verifying behaviour mock state savingrestoration since state screen represented data class saving restoring state easy two step make uistate class implement parcelable interface viewcontrollerbinding expose two function lateststate restoresavedstate conjunction platform lifecycle method migrating older architecture one major concern moving architecture breaking existing feature moving code around since architecture expose overall interface observabletransformerevent uichange replace controller test older screen composition state producer state consumer verify behaviour changed migrating consequence legacy controller event cached replayed soon screen inflated without waiting attached view hierarchy architecture event forwarded binding screen attached view hierarchy lost ignored correct way implement event older screen controller dependent behaviour might take effort migrate current architecture
category adr tag analysis visualization ccjson title adr decide tech stack codecharta analyze visualize code facilitate code audit many great tool exist one want incorporate analysis tool finding new quality code metric something want beginning hand visualizing code something feel confident want tackle keep codecharta becoming tangled two concern analysis visualization separated would rather embarrassing code quality tool become tangled bugridden codecharta divided two tech stack also folder analysis visualization communicate via json file runtime analysis jvm picked java main programming language audit java metric tool also written java runtime visualization web browser provides flexibility many user try codecharta without install anything incorporated web frontends code quality tool like sonar ship desktop version well interchange file format json file extension ccjson browser support directly many library exist jvm consequence many benefit already listed couple tradeoff though probably write maintain code two different programming language jvm metric tool programming language web might able provide performance visualization providing two different stack analyzation visualization userfriendly providing single program
create combat completed create basic structure combat involving character know fight middle man referee ensures everyone get turn work ensure character interact properly create basic mean game function combat module specific character overarching combat entity handle mediation
adr support adding custom label runner config approved since configuring selfhosted runner commonly automated via script label able created configuration runner currently register builtin label arch registration accept label via command line args extend set registered see issue httpsgithubcomactionsrunnerissues another version adr adr proposes add label config could add custom additional label configured runner example add single additional label operator could run bash configsh label mylabel note current runner command line parsing envvar override algorithm support single argument key would add label mylabel runner enable user select runner workflow label yaml runson selfhosted mylabel add multiple label operator could run bash configsh label mylabelanotherlabel note current runner command line parsing envvar override algorithm support single argument key would add label mylabel anotherlabel runner enable user select runner workflow label yaml runson selfhosted mylabel anotherlabel would possible remove label existing runner configsh instead label would removed github label argument split comma trim discard empty string effectively mean dont comma unattended config label name alternatively could choose escape comma nice replace existing runner exists replace chosen interactively via unattended scenario label replacedoverwritten merged overriding builtin label note possible register builtin hosted label like ubuntulatest considered error effective way orgrunner admin dictate policy registration set runner without edit workflow file future also make restriction limiting explicitly adding osarch label validating assume explicit label added reason restricting offer flexibility futureproofing compatibility consequence ability add custom label selfhosted runner would enable scenario job runner selection based runner capability characteristic required
asciidoctor pdf converting jupyter notebook pdf november pending want autoflow support creation pdf report jupyter notebook nbconvert provides method converting jupyter notebook pdf format however pdf conversion nbconvert requires full latex installation size keep size autoflow container smaller desirable find doesnt require latex installation asciidoctor pdf tool converting asciidoc document pdf format without generating interim format latex since nbconvert convert notebook asciidoc format asciidoctor pdf second half twostep process convert jupyter notebook pdf via asciidoc twostep process convert jupyter notebook pdf report autoflow convert notebook asciidoc format nbconvert convert resulting asciidoc document pdf asciidoc pdf consequence autoflow docker image require full latex installation would increase image size current image size asciidoctor pdf ruby package add nonpython dependency autoflow user automates notebook produce latex output equation displayed properly resulting pdf
store license readmemd respective entity root folder csar problem statement license readmemd stored standardized location csars exported driver standardized csar structure considered store file root folder respective entity store file separate folder root folder respective entity outcome chosen store file root folder respective entity visual clutter repository file separated stored together definition file positive consequence standardized access license readmemd file wineryexported csar negative consequence put additional restriction csars structure license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
api minio already api allow administration file bucket existing client library api nontrivial proxy large file uploads armadillo server armadillo client written highlevel library top existing api consequence open minio local data manager minio instance accessible local data manager armadillo server exposed larger audience expose access file system minio api exposed local data manager federate minio provider local data manager log minio minio federate provider provider specify access policy claim token free local data manager minio free work general purpose know cohort version metadata access policy access policy configured minio configuration instead code config pretty verbose precanned one armadillo client part api free library work multipart upload work box becomes harder switch file storage nons implementation
create derivative viewing different file type web large video file nonstandard file may display well browser common solution create derivative better user experience also include thumbnail sample picture resource look like managing creating derivative hard requires careful architectural consideration however modern web adapted larger file generally handle wider array file type past also thumbnail work image video format generic iconbased image file type informative scholarsphere create derivative file icon represent file type original uploaded file rendered applicable consequence user may expect thumbnail representative imagery playback large file might tax system
adrsadr title adr luxon library description architecture record adr luxon library formatting day ago calculation common within backstage useful feature supported standard javascript object popular momentjs library commonly fill gap suffers large bundle size mutable state issue top momentjs sunset project recommends one modern library see rfc standardized time library luxon standard library within backstage luxon provides similar feature set api momentjs improves design immutability usage modern javascript apis intl result smaller bundle size providing full feature set avoids additional library common time task consequence core package plugins within backstage luxon manipulation formatting cannot easily accomplished native javascript object single library avoids learn multiple library apis single library reduce bundle size
flask site security proposed live flask part servicefront ensure secure enough immediately static page ultimately form first form rolled follow owasp guideline secure flask site immediately obvious security protection scan python code owasp top flask site broken access control initial release consists static page public first form also public ultimately aim share session information php site point test required ensure relevant content cannot accessed without logging except public resource deny default happen extent flask site nginx actively configured proxypass page however careful wildcard instruction nginx cryptographic failure formerly known sensitive data exposure keep secret repository protected secret management service accessed code security scan precommit hook check secret order reduce chance committed see opg security policy injection category includes cross site scripting worth addressing form submit already header place see consideration section insecure design new category includes error message reveal much info server code variable saying whether user authenticated code could fail check become issue check develop flask site security misconfiguration includes port open shouldnt default config open default account password issue yet authentication error handling reveals stack trace avoided fact flask development mode switched default stack trace appear log user would shown error install unnecessary feature framework base flask container basic docker image including irrelevant component vulnerable outdated component ensure version component kept initial release older version flask pinned story get necessary component working later flask ultimately stop pinning version dependabot keep component updated identification authentication failure formerly broken authentication aim share session info php happen get form require authenticating view software data integrity error new address ensuring security circle cicd pipeline security logging monitoring failure formerly insufficient logginng monitoring page access automatically logged nginx flask get point authenticated page log login attempt serverside request forgery addressed restricting asset server pulling anything external future allow select google analytics still tightly restricted consideration csrf provided form framework flaskwtforms make question asked whether flask uniwttingly expose environment variable discussion found online flasktalisman provide protection including form header verified chrome inspector following recommended header automatically set done php site contentsecuritypolicy xcontentsecuritypolicy set default strict mean asset domain served later relax allow google analytics story backlog arent currently set php site also story backlog xcontenttypeoptions nosniff force browser honour response content type instead trying guess could lead crosssitescripting attack done php site xframeoptions sameorigin prevents external site embedding site invisible iframe clickjacking done php site xxssprotection set modeblock try prevent attack preventing page loading request contains something look like response contains data done php site stricttransportsecurity http set nginx already php set flask dont ask user upload file therefore shouldnt vulnerable security issue around yet however could become issue future example modernise requiring uploads document generally jinja rather handcrank html jinja template generate safety tested html always quote attribute quote jinja expression prevent attacker inserting custom javascript handler consequence con following security standard cause development slow give complex code flask outofthebox extra dependency csrf protect pro secure flask site
implement phoenix required create demo app show component part decode working together order able prove system work earlier version implemented python flask flasksocketio largely worked prone weird socket failure wasnt happy maintaining extending may required finished service easy deploy somewhere public heroku system amenable extended add functionality support logging dashboard reimplement demo service elixirphoenix rather pythonflasksocketio version previously worked consequence entail rewriting bunch code largely successfully operating time barely spare third service implemented elixirphoenix becoming comfortable productive environment feel much confident taking forward feature may required experience deploying phoenix apps heroku straightforward port across
adr refactoring modelviewviewmodel mvvm architecture initial version codebase built without specific architecture mind led problem new flow proposal incompatible previous assumption different view bound together fragile difficult change integrating large piece androidcomponents library caused many regression partly state management distributed throughout different part testing app state especially browseroverlay homescreen difficult side effect action spread throughout app rather consolidated formal architecture needed provide clarity changeadd code number people working codebase grows formal architecture address problem explicitly decoupling state common one mvcmvp mvvm mvi decided google mvvm architecture component addition satisfying requirement separating state view also allowed incremental change important switching new architecture would extend past single sprint possibility wed respond critical issue refactor also familiar welldocumented architecture integrates well android viewmodel livedata also considered mvi would make testing easier state immutable mvi didnt allow incremental change steeper learning curve also decided mvp doesnt enforce clear separation model presenter often lead bloated presenter could complicate android lifecycle management model different repository hold state component app old state logic handle action change model viewmodel observes change repository update view call action exposed model interaction fragment connect model fragmentonviewcreated setting observer model consequence refactor mainactivity mvvm architecture future code addition mainactivity made mvvm architecture mainactivity tightly coupled mvvm choose abandon mvvm architecture without refactoring existing code could potentially confusing mvvm code expected maintainable greater clarity testability separation mvvm provides mvvm code take marginally longer write least short term learn best way express pattern merge architectural change master early sprint give enough time test regression
adr asynchronic call updating smart fridge kiosk system system know discount provide user update system every time create account eligible discount introduce new discount existing account eligible scenario originate client application action create account create discount block action well update system well finish action update system asynchronously update system asynchronously original action create account create discount dependant fail system api failure consequence might delay user discount one decided user rarely creates account buy food
record trailing slash http resource currently http resource many url representing thing ideal scenario search engine indexing caching example record resource accessed via get recordsgb get recordsgb get recordsgbjson get recordsgbjson get recordsgbcsv get recordsgbcsv adr proposes canonical url way consolidate around canonical path resource must trailing slash alias must redirect canonical path also link header alias add canonical url relcanonical rfc example record canonical path recordsgb canonical json resource recordsgbjson alias like recordsgb recordsgbjson must redirect respective canonical resource paginated resource paginated resource behave similar way trailing slash alias equivalent without trailing slash notice adr postpones canonical path first page mean record canonical alias record recordspageindex canonical alias recordspageindex approved consequence change expected make caching caching invalidation easier without disrupting user
artifact deployment deploying artifact nexus done plugin bug reported reading child pom without version example retrieve information inherited parent pom investigate apache maven deploy plugin maven lifecycle phase deploy nexus artifact uploader pro con apache maven deploy plugin deploydeployfile consider goal deploydeployfile official maven plugin deployment perfect maven project care whether artifact deployed correctly list parameter generated plugin including artifactid version case nexus artifact uploader credential info stored settingsxml introduces additional implementation let assume user saved credential jenkins server may inject list server tag server tag credential info global settingsxml make secret mvn encryptmasterpassword password executed afterwards maven lifecycle phase deploy default maven lifecycle phase deploy bind goal deploydeploy apache maven deploy plugin apache maven deploy plugin dont pas parameter apache maven deploy plugin nexus artifact uploader package phase executed implicitly make parameter ready deploy phase case apache maven deploy plugin handling credential maven phase list phase triggered implicitly phase including compile test package follow buildonce principle phase skipped however possible skip maven goal binding certain phase example packaging tag pomxml set jar jarjar goal apache maven jar plugin bound package phase unfortunately however apache maven jar plugin provide skip jarjar goal main reason cannot nexus artifact uploader without pain handling credential mentioned apache maven deploy plugin section promising plugin properly apache maven deploy plugin list parameter prepared nexus artifact uploader chosen maven lifecycle phase deploy meet buildonce principle nexus artifact uploader situation regarding parameter apache maven deploy plugin handle credential jenkins plugin
architecture record try crux neoj suffers number problem rather restrictive licensing due older open core open source release model retain firstclass notion time maintain full history transaction log modern database neoj clojure library probably require maintain though relatively light hundred line code giving serious consideration replacing neoj crux launch confident clojure crux mature clojure year decade however crux built existing mature technology rocksdb jdbckafka datalog licensing mit much liberal neojs speaking length project owner jon jeremy httpsjuxtpro seems reasonably safe bet still ten year also easily migrate away crux since retains data ever written immutable transaction log transaction log mean crux treat concept time firstclass citizen database neoj older database architecture dont however find crux lacking always switch back neoj quite easily since datalog cypher comparable language case crux also offer basic architectural benefit neoj layer provide method adding stricter database schema data type require pali word day card today tab requires little flexibility looser schema data type dont newsletter may include arbitrary metadata search engine crux also builtin fulltext search would require elasticsearch service running top neoj continued path pending consequence firstclass notion time builtin bitemporality firstclass graph query datalog open standard firstclass clojure entity modular library built clojure lightweight deployment direct line support juxt
cart guest logged customer problem statement cart processing one key aspect sylius turned vulnerability possible anonymous user override cart logged customer email entering email addressing step customer email assigned cart simple way distinguish cart created guest logged user question distinguish cart solve vulnerability driver provided solution solve initial problem overriding cart logged customer anonymous user break backward compatibility code business behaviour considered forcing logging checkout good solves initial problem bad change current expected behaviour checkout bad break backward compatibility business perspective changing priority cart good solves initial problem bad solve case logged customer cart bad change current expected behaviour keeping cart logging bad break backward compatibility business perspective introducing flag order entity mark order created guest adding flag order entity allows distinguish cart created guest logged customer mark cart soon possible solve case initial problem flag set syliuscomponentcorecartcontextshopbasedcartcontext customer logged user also set cart definitely proper service operation however consistent current approach sylius setting value logging would enough doesnt resolve situation already logged user creates cart similar setting flag addressing step doesnt resolve problem cart logged user marked late addressing cart couldnt distinguished belongs good solves initial problem good break backward compatibility good additional feature future bad requires set flag syliuscomponentcorecartcontextshopbasedcartcontext outcome chosen introducing flag order entity mark order created guest straightforward solution resolve initial problem introduce break solution could additional feature future reference approach changing priority chosen approach introducing flag
cli dependency launching proposed alex black discussed sham multiple way user might want konduit serving serve model sake adr ill refer two case immediate deployment case deploy server pipeline right machine via cli deployment artifact case create artifact jar docker image etc deployment somewhere else adr packagingsystemdesignmd dealt create deployment artifact case however build system current form well serve immediate deployment case particularly well mainly due uberjar design cause usability problem deploying pipeline different module dlj samediff cpu gpu requires building uberjar uberjar build take long time second plus download time either always rebuild slow launch uberjar cache potentially lot unnecessary disk space old api cli dependencylaunching approach case also hadhas following problem requiring user build jar ahead time manually include module able launch example cpu gpu server simultaneously without rebuilding whole konduit serving uberjar launching different server clibased deploy right case proposed immediate deployment via cli scenario create uberjar instead konduit serving build tool work dependency download return list dependency list jar file path konduit serving server launched similar ides like intellij work consider example command intellij launching unit test etc part omitted cprogram filesadoptopenjdkjdkhotspotbinjavaexe dfileencodingutf classpath cprogram filesjetbrainsintellij idea community edition libideartjarcdljgitkonduitservingkonduitservingmodelskonduitservingdeeplearningjtargettestclassescusersalexmrepositoryorgndjndjapisnapshotndjapisnapshotjarcusersalexmrepositorycomjakewhartonbyteunitsbyteunitsbyteunitsjarcusersalexmrepositorycomgoogleflatbuffersflatbuffersjavaflatbuffersjavajarcusersalexmrepositoryorgndjprotobufsnapshotprotobufsnapshotjarcusersalexmrepositorycommonsnetcommonsnetcommonsnetjar comintellijrtjunitjunitstarter ideversion junit aikonduitservingdeeplearningjtestdljstep note classpath list jar path component practice wont pas list jar file path directly due constraint maximum command line length window instead small jar containing manifest file list absolute path dependency httpswwwbaeldungcomjavajarmanifest single manifest jar passed via classpath path arg launch note exact manifest jar approach also intellij command line shortening work around maximum command line length problem key aspect design static cli jar cli jar static jar without modulesdependencies needed run pipeline step never get modified rebuilt etc matter type pipeline launched konduit serving build tool downloads resolve dependency user launch server based konduit serving pipeline configuration following occurs cli call build tool build tool resolve dependency included run pipeline direct transitive dependency downloaded normal via gradle stored usual location build tool creates required manifest jar introduce concept device profile cli practice allow user switch different target launching cpu cuda instead xavx needed reason specifically first run konduit serving cli automatically create set appropriate device profile based hardware software available system also set default device profile cuda profile present practice usually cpu profile highest level supported avx avx etc cuda profile cuda device present system cuda profile well also detect cuda installed well javacpp presets cuda redist binary provide runtime avoiding manual install running well default profile unless user pass profilename launch konduit serve configjson cpu practice user wont worry device profile unless run cpu gpuenabled device rarely ever downgrade target example instead xavx avx compatible system workaround issue avx higher binary example workflow launch locally suppose user want deploy server inference system without konduit serving installation here could look like text pip install konduitserving easy installation method apt yum etc etc konduit serve configjson konduit serving konduit serving first run initialization detecting hardware done cpu arm aarch core cuda gpu cuda installation found cuda usrlocalcuda creating device profile profile cuda arm cuda installed profile cpu arm cpu execution creating device profile complete setting default profile cuda set default profile pas launching override first run initialization complete launching server default device profile cuda acquiring dependency done note user line brand new system install hosting model server optimal hardwareconfiguration device cuda highest supported avx level system etc furthermore slow build uberjar step delay launching server second top dependency downloading launching deployment artifact case manifest jar approach likely situation docker could either uberjar switching assemblyjar style embed originalunmodified dependency jar instead uberjar rpm deb per docker standalone exe continue uberjar approach decide assemblyjar style approach useful deployment artifact implement later also principle add extra dependency top uberjar may especially elegant design combining uberjars extra classpath dependency may possible ever really however wont something support detecting hardware creating profile detecting cpu detail straightforward least xbased system library oshi httpsgithubcomoshioshi well oshi support armbased platform something explore though raspberry armhf support seem available httpsgithubcomoshioshiissues falling back system utility cat proccpuinfo similar also possibility detecting presence absence compatible cuda gpu may harder cuda installed available path becomes easier cuda install assume cuda device present parse output nvidiasmi cuda installed cuda gpu available case oshi may show may command line based approach find like cpuinfo principle solveable problem additional work required find robust solution detecting hardware including cuda gpus maybe gpus future work across device operating system expect deploy practice consequence advantage command konduit serving server launched faster build uberjar build disk space uberjars redundant copy dependency easily allows mixing cpu gpu deployment one system distribute prebuilt binary variant idea adaptable osgi ifwhen disadvantage relying jar gradlemaven cache rarely might cause problem user try install similar command server running relies build tool hence gradle maybe problem offlineno network space restricted deployment scenario network deployment probably bundle gradle gradlew gradle offline however still uberjar style deployment instead clistyle deployment scenario
sys theme adrs supercedes sys record architecture issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
location specified geojson implement pubsub implement event sourcing large numer event odh contain location specific data usefull standardize usage location event geojson xyz location odh xyzt data needed geojsonevents considered consequence none
map api choice project api map interface search marker placement satellite road map imagery several map primary mode interacting site google map openlayers tomtom mapbox mapfit main factor cost ease documentation api google map highly customizable style appearance configerable marker placement information window interfacecontrols upon examining google map considered mature easytouse wellsupported api excellent documentation example code interface familiar majority site user consequence google map several modular apis place route etc single api key work cost project purpose exceed free threshold view per day click rate credit limit scalability project commercial project google cost would severely limit size website could grow without justifying profitibility party map api requires url javascript page expose api key http request
aim document record orphan mitigation service instance service binding implemented reasoning behind taken osbapi defines orphan mitigation attempt made platform cloud controller clear resource may created service broker operation eventually failed consequence lingering resource broker may include higher cost resource quota consumption etc scenario one two thing happen platform record resource case way platform list failed operation resource tracked result possible operator ignores resource may created even operator realizes failed operation actually created resource service broker destroying resource would include direct interaction service broker platform provide tool delete resource doesnt track platform still keep record failed service resource case platform choose whether perform defer choice clean failed resource operator deferring operator beneficial allows troubleshooting document cloud controller aim comply osbapi specification specification state platform may choose leave happens operator case troubleshoot scenario whether cloud foundry performs scenario osbapi outline requiring choice long another mechanism platform operator remove failed resource later stage delete vserviceinstances delete vservicecredentialbindings cloud foundry shouldnt perform scenario osbapi say needed fully compliant osbapi version regarding change needed compliant backwards compatible difficult introduce without releasing major version spec changed osbapi thus even made compatible version scenario behave also scenario choice made give opportunity operator troubleshoot automatically mitigate orphan resource scenario choice taken implement complicated logic place command available delete resource clean deferred user also document specifies shared community although effort put time keep accurate reflection really api operation require broker communication done asynchronously one main difference api result approach always record resource created deleted broker operation fails still keep record resource create binding operation fails keep record resource set state create failed allows operator manually remove failed resource mean resource service broker created record however chosen keep performing orphan mitigation many case order keep level consistency expected behaviour satisfy requirement issue raised user provisioning scenario perform code response body osbapi advice note malformed yes malformed happens would able record broker response might include important property continuing async flow operationid yes unexpected error resource created however attempting risk yes client timeout yes scenario perform code response body osbapi advice note malformed malformed malformed requires appasyncconcurrency error binding scenario perform code response body osbapi advice note bad data happens would able record broker response safest assumption delete resource broker allow operator start malformed yes bad data happens would able record broker response safest assumption delete resource broker allow operator start malformed happens would able record broker response might include important property continuing async flow operationid yes valid error code post request resource created however attempting risk unexpected error resource created however attempting risk yes client timeout yes scenario perform code response body osbapi advice note malformed malformed bad data malformed bad data requires appasyncconcurrency error case internal error related broker response perform even case failure record resource user able delete resource failure handling service instance binding last operation broker response cloud foundry attempt response instance binding last operation request decided give operator possibility troubleshooting delete resource see fit line behaviour user depend deprovisioning unbinding event failure cloud foundry keep record resource user attempt delete clear benefit implementing logic straightforward scenario change possible kept implementation case diverged documented doc type binding including service credential binding apps key service route binding behaviour consequence document description reasoning current implementation time writing behaviour usecase might change osbapi advice new behaviour customer request change
reframe handler author hukka handling event sideeffects reframe architecture allows separation sideeffects event handler code way cofx input consists event vector event name parameter map coeffects output called effect effect common word event handler pure function coeffect map event vector effect map reframe suggests thing clojure avoid rfregeventfx sendrequestdecision key deciders applicationid comment requestdecisioneffect deciders applicationid comment second indirection rfregfx requestdecisioneffect deciders applicationid comment fetch apiapplicationsrequestdecision sideeffect params deciders deciders applicationid applicationid comment comment handler rfdispatch decisionresults actionbutton actionformid text text tactionsrequestdecision onclick rfdispatch sendrequestdecision first indirection listed reason cognitive load function later reader longer reason locally testing becomes difficult involves mocking test http get right url mocking mocked bad omen event replayability lost rem relatively simple spa found added indirection actually cause cognitive load find click handler find effect handler coeffects effect referred keywords jumping definition slower also necessarily colocated also unit testing event handler anyway part straightforward important logic split helper function easy test regular clojurescript test functionality furthermore havent time travelling debugger anything else benefit replayability therefore decided cause simple sideeffects fetching data backend directly within event handler therefore write handler like clojure rfregeventfx sendrequestdecision key deciders applicationid comment fetch apiapplicationsrequestdecision sideeffect without second indirection params deciders deciders applicationid applicationid comment comment handler rfdispatch decisionresults particular want mix sideeffects effect handler flow please avoid mixed model even confusing either solution clojure avoid rfregeventfx sendrequestdecision key deciders applicationid comment doanotherkindofsideeffect sideeffect without indirection requestdecisioneffect deciders applicationid comment sideeffect indirection handling user interaction component could also launch fetch directly component button onclick handler always dispatch reframe event consistency since quite often something else fire api call one common case set kind loading toggle turn show loading spinner data hasnt yet arrived usecases might setting purely internal state sorting moving page instead clojure avoid actionbutton actionformid text text tactionsrequestdecision onclick doafetch sideeffect write clojure actionbutton actionformid text text tactionsrequestdecision onclick rfdispatch sendrequestdecision indirection
technology stack framework deciders daniel stefaniuk jonathan pearce matthew begley identified development api enable uec service provider lead change rag also known capacity service api authenticate user via modern authentication approach establish whether user authorised able update state service api full api documentation fully automated testing deployment cloud platform adr concerned technology stack api written following three python web application framework considered evaluated flask django tornado flask django considered best development api tornado seemed inappropriate dealing long running query process neither dealing hundred thousand request flask offer light touch framework whereby anything basic functionality brought flask plugins extension django much prescriptive framework come majority functionality straight box framework well established maintained come good documentation active community group made implement api django framework although django prescriptive framework therefore potentially steeper initial learning curve module functionality provided framework handle bulk apis boiler template code django framework developer focus business logic api leaving django take care rest leading much cleaner code reducing concern whether one particular extension would play nicely another said initial learning curve django perhaps steeper flask leveraging django framework much possible envisaged api adhere django standard meaning django developer would able understand far fewer bug teething problem deal encourage rapid code development post learning curve documentation django framework excellent supported good example making finding framework django offer relatively simple although django come majority functionality required api django configurable extension utilised technology stack python django django rest framework add additional rest framework component rest apis django request add unique request identifier every line log file associated request call api django request logging add logging capability django rest framework api key add api key authentication functionality django rest framework yet another schema generator add api documentation capability consequence slightly steeper learning curve front learn django framework everything except api business logic abstracted away framework leaving developer focus business code logic api code cluttered boilertemplate type code leading clean easy understand maintain code api conforms djangos prescriptive framework approach making understandable django developer django framework offer support making api documentation easy create django well established testing framework cover type testing unit module django rich documentation coding example making learning framework relatively simple task django encourages rapid development understanding framework gained
title file type weight problem statement docspell currently support pdf file simplified early development design lot helped starting project handling pdf file usually easy view extract text print etc pdf format chosen pdfs file common viewed many tool many system nonproprietary tool docspell also document archive perspective important document viewed year hope pdf format best suited therefore document docspell must accessible pdf trivial solution requirement allow pdf file support document type must take care following extracting text converting pdf access original file text extracted source file case conversion lossless since docspell already extract text pdf file ocr text also extracted converted file fallback original file must always accessible main reason uploaded data accessible without modification since conversion may always create best result original file kept driver people expect software like docspell support common document type like office document docx rtf odt xlsx image many people common create file instead pdf older scanner may able scan pdf file image file considered adr evaluate different rather document feature realized thought lead implemented realization data model attachment table hold one file another table attachmentsource hold original file look like sql create table attachmentsource varchar null primary key fileid varchar null filename varchar created timestamp null foreign key fileid reference filemetaid foreign key reference attachmentattachid primary key associated attachment creating relationship well correct attachment attachmentsource always attachmentsource record every attachment record original file pdf already table fileid column point file user change filename attachment original filename preserved attachmentsource must possible user change anything attachmentsource attachment table touched order keep current code mostly unchanged simpler data migration downside data model allows attachment record without attachmentsource record otoh foreign key inside attachment pointing attachmentsource also correct allows attachmentsource record associated many attachment record would even harm opinion migration creating new table altering existing one simplify data migration since pdf file allowed user could change anything attachment table existing data simply inserted new table present trivial case attachment source processing first step processing converting file pdf already pdf nothing done step text extraction text first tried extract source file fails supported text extracted converted pdf file remaining step untouched conversion supported input file skipped conversion fails error propagated let retry mechanism take care type file type supported first step major office document common image plain text markdown html supported term file extension doc docx xlsx odt html txt jpg png tif always preference jvm internal library order platform independent reduce external dependency always possible like ocr figurefileprocessfilespng conversion office document doc docx xlsx odt unoconv see adr html html wkhtmltopdf see adr textmarkdown txt javalib flexmark wkhtmltopdf image jpg png tif tesseract see adr text extraction office document doc docx xlsx apache poi office documends odt apache tika including source html supported extract text converted pdf image jpg png tif tesseract textmarkdown pdf apache pdfbox tesseract link convert html file convert plain text convert office document convert image file extract text file
templatesoverjsframeworkmd decide want develop maintain service fact require different user interface tap project grant application external company individual apply grant grant management internal tap team member help organise approvalrejection process admin interface manage inner working tap service right development team consists developer experience backend development therefore take simpler solution making development grant application service available public via govuk domain therefore required styling development team constraint standard html template view served django grant management grant management portal available internal tap team member approved grant administrator tcp itas grant management portal adr decided viewflow create grant management portal viewflow frontend library utilise provide frontend grant management portal minimal development work required development team constraint viewflow frontend library admin built django admin panel administration service consequence mentioned choice frontend try maximise development efficiency simplicity therefore able iterate quickly frontend build course brings restriction flexibility uis build restricted library pattern html component
attaching caption video modeling case video found case documentation point video figgy needing relationship closed caption file discussed filesets extra filemetadata user upload contains caption label caption language caption filesets descriptive property contains many nested caption model resource fileset caption fileset transcriptforid property point video transcript compared ease implementation ease reasoning flexibility anticipated case potential performance decided ease reasoning important filesets extra filemetadata user upload contains caption label caption language caption model match existing mental model way fileset contains original file supporting file consequence develop functionality upload delete userdefined filemetadata user deletes fileset upload two file original file caption recreate
title archive file weight problem statement docspell support file contain actual file matter like zip file thing extract content automatcially since docspell never drop modify user data archive file must present database must possible download file unmodified hand file text analysed converted pdf file outcome currently table attachmentsource hold reference original file file uploaded user converted pdf archive file add subtlety case archive attachmentsource original nonarchive file inside archive archive file stored separate table attachmentarchive example uploading fileszip zip file containing reportjpg attachmentsource reportjpg attachment reportpdf attachmentarchive fileszip archive may contain archive inner archive saved archive file extracted recursively known archive file found initial support initial support implemented zip eml email file file
preauthorisation authorisation adjustment approved adyen integration allows frontend create preauthorisation payment makepaymentrequest preauthorisation possible update payment amount extend preauthorisation period frontend ready charge customer make manual capture request also implemented adyen integration add new payment handler amountupdates endpoint adyen amountupdatesrequest custom field payment extension module update preauthorized amount save response amountupdatesresponse consequence
display server library deciders andreas tennert problem statement window manager kind display management system get notified opening closing window generally handle function display inputoutput xcb initially additional functionality needed covered xlib library mixing two system became hazard considered xcb xlib wayland outcome chosen xlib already additional tooling there lot documentation example positive consequence direct compatibility additional tool library xpm handling lot resource openbox complete sense icccm ewmh possible template negative consequence refactoring code wayland might modern xcb faster time due asynchronous pro con xcb good faster due asynchronous fine granular handling bad missing functionality available xcb library xlib good lot functionality library good broadly bad old easy due lacking specification additionally icccm ewmh wayland good new maybe better gaining popularity bad dont know dont want learn also right
launcher auto update process version author seph directionless october supersedes launcher auto update process superseded launcher autoupdate process version current update process several flaw lead towards unreliable autoupdate process existing autoupdate functionality work follows posix new version downloaded staging area new version moved replace current binary new binary execed window new version downloaded staging area current exe moved way new exe moved place service restarted inherent problem design running binary longer appear disk file disk longer match installed via package manager window failure condition new binary isnt moved place next service restart cause service failure httpsgithubcomkolidelauncherissues lead needing new update process assumption tuf additionally implementation must work within assumption tuf tuf simple model designed notice remote metadata change single file download given location trigger callback function single file model cannot easily store version furthermore update happen tuf metadata change binary mismatch mean local launcher executable change refreshed tuf metadata change make testing somewhat harder instead replacing running binary create directory store update update launched new flow look like new binary downloaded staging area moved update directory stored spawned update directory implementation documented part pkgautoupdate godoc consequence replacing binary disk want execution update hook main function thus subsequent execution find latest download support store update configuration agnostic fashion binarypathupdates remove old update cleanup routine run part finding current binary
library image loading write image loading code considered picasso glide none write code outcome chosen picasso produce highly performing image loading code one try reinvent wheel library open source well maintained year positive consequence code cleaner code high performance highly adopted negative consequence dependency ever deprecated work needed pro con picasso good lower footprint good lower footprint method count good load image slightly faster bad memory glide bad higher footprint bad higher footprint method count bad load image slightly slower good memory bad contain bug bad maintained bad wont perform well good dependency link picasso glide comparison picasso glide
aws event driven architecture problem statement select platform implement event driven architecture well machine learning hurdle lower google offer serverless biotech company currently aws driver learning material community fit biotech requirement cost easy considered aws gcp outcome chosen aws want get started therefore basic enough work cost learning low positive consequence lower cost work stack searched biotech startup negative consequence later check gcp private project pro con aws good lot biotech startup also searching skill good many blog post good work bad mnany box solution lot adminstration bad tech leader google better gcp good many serverless data implementation bigquery dataflowbeam remove admin overhead let focus logic good many open source component apache beam airflow good low cost private project good many example provided google bad community setteled around aws bad biotech startup mostly aws also search aws bad gcp cloud function support python well environment varibales feasable develop application bad work link
simple composition component technical story depends generic component requirement related issue problem statement simple composition component generic component follows concept certain enterprise integration pattern invoking userdefined predefined openfaas function acting upon result contrast complex integration component effort maintaining state needed implementing corresponding simple composition component driver want list enterprise integration pattern implemented simple composition component reasonable amount effort considered theoretically enterprise integration pattern could implemented simple composition component outcome want implement routing pattern following table describes routing transformation management pattern implemented simple composition component defined following assumption made two generic component generic transformation component provide message userdefined function forward result predefined target topic generic routing component provides message userdefined function forward result topic returned userdefined function component read single topic external resource available storing state name implementation strategy return value possible simple composition component contentbased router rule implemented userdefined function topic routed yes message filter rule implemented userdefined function either nothing topic routed yes dynamic router rule implemented userdefined function topic routed recipient list recipient hard coded userdefined function topic message shall forwarded yes splitter splitting rule implemented userdefined function sub message contain splitted content original message yes aggregator would require user provides message storage message stored aggregated aggregated message resequencer would require user provides message storage message stored forwarded right order correct sequence message composed message processor could implemented combining splitter router aggregator composed message since aggregator considered simple scattergather could implemented combining aggregator multiple transformer topic transformer subscribe transformed aggregated message since aggregator considered simple routing slip probably complex simple composition component process manager probably complex simple composition component message broker probably complex simple composition component transformation pattern name implementation strategy return value possible simple composition component content enricher userdefined function contains information may eventually added message transformed message yes content filter userdefined function implement whole process filtering content message filtered message yes envelope wrapper content enricher wrapping message envelope content filter unwrapping yes claim check combination special content filter replacing message data claim content enricher recovering data also data storage storing data recovered normalizer combination router set translator transformed message yes canonical data model userdefined function implemented way receivesreturns message canoncial data format message canonical data format yes system management name implementation strategy return value possible simple composition component control bus would necessary receive one topic detour would require control bus wire tap special case recipient list topic message forwarded yes message history every userdefined function add reference message history function modified message yes message store would require data storage available smart proxy would require data storage storing return address test message would require test data verifier receives two topic channel purger would feature implemented generic component planned yet
graphql implementation size discussion participant roanna philipp vahid daniel implemented problem statement api size well relation sizerangesizegroup product complete graphql schema implementation discussed mainly two design schema implement variation second see considered driver fulfill frontend easy api user closeness current database structure complexity implementation risk lockin technical debt later refactorings whether design business logic reflective real operation query performance considered original plan size graphql enums stored varchars graphql schema enum size graphql enums dont allow value start number type sizerange label string size size type product sizerange sizerange type box size size potentially nullable size size type mutation createboxcreationinput boxcreationinput box input boxcreationinput size size potentially nullable size size database level sizeranges table label varchar size table sizerangeid sizeranges sizevalue varchar enum value representation value naturally repeat since enum value might across least size range box table size varchar enum value representation value naturally repeat since enum value across lot box sizeid size proscons pro user friendliness easier documentation user interact api via graphql explorer potentially slightly better performance probably making difference user experience con restriction enum value leading number value sure extension future size unitdimensions would look like requires complexity enum value different current size value dropapp well human readable name new related even design database way save enum value box directly boxstock table resolving reference table likely would keep current database structure change dropapp logic enums full type graphql schema type size value int type sizerange label string size size type product sizerange sizerange type box size size potentially nullable size size type mutation createboxcreationinput boxcreationinput box input boxcreationinput sizeid database level sizeranges table label varchar size table sizerangeid sizeranges sizevalue varchar box table sizeid size proscons basically inversion pro con written explicitly pro database change needed former point risky easier change later api heavily partner extended future also support unit size see full freedom regarding naming size value mapping needed enum value user friendly name con potentially small performance disadvantage compared additional reference table querying box auto completesuggestions possible value user interact api graphql explorer variation support fine grained detail size differentiating nonnumeric numeric size adding unit numeric size potential extension future graphql schema type nonnumericsize value string enum numericsizeunit type numericsize value int unit numericsizeunit union size nonnumericsize numericsize type sizerange label string size size type product sizerange sizerange type box size size potentially nullable size size type mutation createboxcreationinput boxcreationinput box input boxcreationinput sizeid database level would follow kind polymorphic association pattern single table inheritance able connect polymorphic size type could type nonnumeric numeric box sizeranges going size case typical plainolddata case strong reason making concept first class citizen graphql besides bit user friendliness regarding autocompletion graphql console fact also shortcoming enum approach naming constraint graphql dont allow enums start wit number woudl affect lot size value also seem low risk lockin couldnt extendedovercome future want also add size unitsdimensions regarding raised concern worse query performance additional reference table dont see high performance risk since still normal query complexity level indexed foreign key kind operation exactly relational database made reflect currently known reality operation partner organization difference concrete behavior api involved data structure compared also doesnt require additional mapping enum value human friendly value keep implementation complex initial time investment well maintenance complexityeffort change current structure needed moment dont signal complex structure necessary extended future easier needed later want enrich size data size unit would require complex graphql type consequence easier easy elegant implementation full flexibility actual size value difficult auto complete feature graphql console available size value api user would run small additional extra query get available sizegroups size
message timing information decide whether message timing information exposed via api timing information refers important point time throughout lifecycle message initial rationale exposing timestamps business logic depends time way explicitly include timing information within message call logic timebased approach including explicit timing information modeling time section focus message role respective timestamps interest made case command message believe existing requirement application model time still appropriate command message time command message created enqueued irrelevant time information relevant domain logic included message decided expose command creation time event message time event recorded fundamental property event put another way every event occurs time regardless whether domain timebased furthermore time event occurs may relevant ancillary domain logic triggered event even aggregate produced event timebased logic inclusion occurred time fundamental property event supported implementing domain driven design chapter modeling event section decided include recordedat method processeventscope projectioneventscope actuality time method already added projectioneventscope without supporting adr method renamed timeout message time timeout message scheduled handled fundamental property timeout concept definition timeout message indicates timebased logic seems like unnecessary imposition require application developer include scheduled time message decided include scheduledfor method processtimeoutscope consequence result adr easier application developer implement timebased logic engine implementation must record time event occur necessarily true likely engine would done anyway
engine imageserver thumb proposed deciders donald gray jack lewis issue problem statement dlcs engine currently array single value generated confined thumbnail thumbnail generation done appetiser time jpeg generation allow engine produce thumbnail based valid iiif imageapi size parameter introduce imageserver avoid replicating resizing logic elsewhere identify best way available imageserver engine without affecting live assetrequest traffic driver deployment deployment remain straightforward simplicity refactoring engine imageserver thumbnail creation shouldnt make code considerably complex scaling time high usage engine scale many instance imageserver cope additional considered run cantaloupe sidecar fargate engine task sharing ephemeral storage run cantaloupe separate service shared engine instance host sharing local disk run cantaloupe separate fargate service sharing efs storage run cantaloupe separate fargate service sharing object storage dockerized iiifprocessor npm package rather cantaloupe outcome chosen run cantaloupe separate fargate service sharing object storage similar specialserver run could specialserver dont want put additional load public imageserving traffic cantaloupe streaming performant reading disk shouldnt issue ingest time user waiting byte load origin accessible imageserver either optimised origin copied dlcs storage exception thumb channel without iiifimg would require temporary upload see bottom document working notessequence diagram work problem positive consequence engine infrastructure remains unchanged cantaloupe already serve image consistent processing across ingest delivery docker image different configuration scale separate instance independant engine cantaloupe per engine cantaloupe handle reqs etc scavenging issue shared storage effectively limitless negative consequence additional service manage requesting thumb channel without iiifimg require temporary file thumb generation cleanup lifecycle rule distributed call generate thumb may automatic retry backoff avoid failing ingest single request fails pro con run cantaloupe sidecar fargate engine task sharing ephemeral storage positive consequence simplest arrangement http call made locally addressed cantaloupe scaling consistent approach appetiser currently reading local disk performant reading negative consequence basic engine task would resource even lightly run cantaloupe separate service shared engine instance host sharing local disk positive consequence multiple engine single cantaloupe negative consequence management overhead manage instance patching etc bigger starting stake majority time resource unused scaling could get complicated run cantaloupe separate fargate service sharing efs storage positive consequence multiple engine single cantaloupe manage infrastructure fargate negative consequence unsure efs would operate load would thorough testing dockerized iiifprocessor npm package rather cantaloupe positive consequence dockerized npm package much lightweight cantaloupe negative consequence ingest imageserving different technology different processor could result error subtly different output rounding issuescolour cast working note working note made work whether able cover required ingest permutation imageoptpolicy origin type origin format happens engine iiifimgthumbs default http download origin call appetiser convert uploads converted call cantaloupe generate thumb uploads thumb iiifimgthumbs default http imagejp download origin call appetiser convert would noop uploads converted call cantaloupe generate thumb uploads thumb iiifimgthumbs default soptimised download origin call appetiser convert uploads converted call cantaloupe generate thumb uploads thumb iiifimgthumbs default soptimised imagejp download origin uploads converted call cantaloupe generate thumb uploads thumb iiifimgthumbs useoriginal http download origin upload origin call cantaloupe generate thumb uploads thumb iiifimgthumbs useoriginal soptimised download origin call cantaloupe generate thumb original upload thumb thumb http download origin upload origin call cantaloupe generate thumb upload thumb thumb soptimised call cantaloupe generate thumb origin upload thumb filethumbs http origin already sdlcsstorage call cantaloupe generate thumb upload thumb filethumbs soptimised call cantaloupe generate thumb origin upload thumb http sambient thumb without iiifimg would thumb uploaded dlcsstorage location transient store known prefix lifecycle remove cleanup non optimised origin iiifimgthumbs mermaid sequencediagram participant imageworker participant origin participant appetiser participant cantaloupe participant dlcss originimageworkerdownload image byte alt imageoptimisationpolicy default imageworkerappetiserconvert appetiserappetisergenerate appetiserimageworkerjp path end imageworkerdlcssupload derivative original loop per thumb size policy imageworkercantaloupeget iiifsoriginfullsizedefaultjpg dlcsscantaloupe read derivative original cantaloupeimageworker thumbnail byte imageworkerdlcss upload thumbnail jpeg end optimised origin iiifimgthumbs mermaid sequencediagram participant imageworker participant origin participant appetiser participant cantaloupe participant dlcss originimageworkerdownload image byte alt imageoptimisationpolicy default imageworkerappetiserconvert appetiserappetisergenerate appetiserimageworkerjp path imageworkerdlcssupload derivative loop per thumb size policy imageworkercantaloupeget iiifsoriginfullsizedefaultjpg dlcsscantaloupe read cantaloupeimageworker thumbnail byte imageworkerdlcss upload thumbnail jpeg end else imageoptimisationpolicy useoriginal loop per thumb size policy imageworkercantaloupeget iiifsoriginfullsizedefaultjpg origincantaloupe read cantaloupeimageworker thumbnail byte imageworkerdlcss upload thumbnail jpeg end end nonoptimised origin thumb mermaid sequencediagram participant imageworker participant origin participant cantaloupe participant dlcss originimageworkerdownload image byte alt optimisedorigin imageworkerdlcssupload original temp thumb note imageworker imagepolicy end loop per thumb size policy imageworkercantaloupeget iiifsoriginfullsizedefaultjpg alt optimisedorigin origincantaloupe read else optimised dlcsscantaloupe read end cantaloupeimageworker thumbnail byte imageworkerdlcss upload thumbnail jpeg end
adr python orm discussion participant roanna david katie philipp implementation complete database change managed phinx php sql query written string php since migrating old php code base dropapp new codebase python react needed decide handle reading writing going forward graphql solve still hook graphql interface somehow driver learning curve community support power reliability considering production environment considered pure sql string python orm would require backend fullstack devs pick sql david strongly recommended run contrary best practice interpolating sql string python code mean cant read parsed debugger formatters utility sqlalchemy clear industry leader within python community web application development across many framework including flask django however although david also professionally recommends project given structure looselyaffiliated developer different experience level sqlalchemy properly requires significant upfront investment understanding complexity including mastering concept session management relationship loading peewee orm driven primarily single maintainer stable release designed simpler smaller hackable sqlalchemy still remaining expressive composable generated controversy open source community account main contributor behavior open contribution still significant community github fast release ponyorm mature peewee release come useful utility data diagram modeler like peewee mostly driven single contributor peewee despite sqlalchemy gold standard orms longterm volunteer mastered library aside david difficulty ramping everyone sqlalchemy maintaining outweighs difficulty potential volunteer familiar sqlalchemy pick one easier orms comparing release note peewee ponyorm david commented peewee recent release relate support edge case new technology stack whereas ponyorm release still appear involve developing functionality fixing bug around core case therefore concluded peewee productionready solution consequence easier philipp peewee professionally place work reactive robotics indicates concern sqlalchemy industry gold standard move towards big issue peewee come flask integration difficult harder people already fluent sql python orms audit query
order make scraping result gatsbygenerated climatescape website decided push scraped data back airtable background worker addition storing data postgres database approach connect gatsby postgres via gatsbysourcepg plugin chose pushing data airtable backend simplify gatsby setup considering data pushing backend airtable needed anyway enable sorting organization airtable content management interface according weight rank one goal scraping automation project see message
flow component crud time writing explorer emitter receiver three main flow component resemble wellknown crud apis crud bread based therefore match three named flow component emitting receiving entity also differently sends data one portal node received another portal node emitter receiver could send command instead entity previously mentioned deletion flow component receiver could receive entity custom deletion command previous version heptaconnect discouraged possible already seen implementation receive data dont write anything api portal resembles misuse similar described scenario looking existing flow component also webhooks reporter related crud limited crud receiver meant everything receiving command receiver meant entity grouping explorer emitter receiver deleters single crud flow component enforces structure probably dont benefit apis fall pattern grouping flow component helpful know possible group beforehand therefore cant done right every transfer new flow component route connect emitter receiver learn decide flow component route described different adr consequence pro new data flow implemented custom integration without misusing existing component could lead unexpected behaviour separating different flow unique component allows clear code structure con new data flow new flow component developed integrated route implemented route configured per flow scenario
usecasedefinition title case define initial case mlaoi spec expose assumption reasoning specific layout choice providing training data source raster vision model training process mlaoi stac item represent reified relation feature raster groundtruth label machine learning training dataset mlaoi item roughly correspond scene training example justification new extension current known stac extension suitable purpose closest match stac label extension label extension provides way define either vector raster label area however provide mechanism link label feature image link rel type source point imagery label derived sometimes imagery feature input model training always concept source label imagery input feature imagery semantically distinct instance possible apply single source groundtruth building label train model either landsat sentinel scene catalog lifetime mlaoi item link raster stac item label stac item relationship source raster label item static long lived several mlaoi catalog contrast mlaoi catalog somewhat ephemeral capture training set order provide model reproducibility provenance number mlaoi catalog linking raster label item varying selection trainingtestingvalidation split class configuration adopt development mlaoi extension future machinelearning project consequence longer attempt label extension sole source training data model continue development tool produce consume mlaoi extension catalog
launcher autoupdate process version author rebecca mahanyhorton rebeccamahany october change rolled nightly channel october change rolled beta channel november slow rollout stable channel began january supersedes launcher auto update process version current autoupdate process several area wed like improve upon first update currently stored end user device timestamp downloaded allow launcher know version update corresponds second release channel currently implemented copying recent version autoupdatable binary binarychanneltargz publishing copy notary would like flexible implementation require storing binary twice third would like location update configurable fourth want remove reliance notary gotuf implementation tuf instead see begin work autoupdate next generation detail created new update directory life default root directory location configurable via flag new system launcher retrieves latest build release channel inspecting custom metadata stored known target binaryosarchchannelreleasejson metadata point target downloaded target filename contains version taking format binaryosarchbinaryversiontargz allows store releasejson perchannel instead copy tarball additionally allows launcher know version binary downloading downloading verifying launcher store update update directory version allows launcher perform version selection based releasejson target rather always picking update recent timestamp give ability roll back release quickly needed launcher version library roll back stable launcher switch running local update immediately without perform new download fetch newest stable new system also gotuf client rather previous client implementation perform metadata download verification consequence legacy autoupdater discovers location legacy update directory based current executables path putting new update different directory result legacy autoupdater putting update incorrect location result ive chosen run legacy autoupdater alongside new autoupdater new autoupdater version selection result riskier rollout ive attempted mitigate risk cutting new system several way store error occur new autoupdate process kolidetufautoupdatererrors table review address unexpected error perform rollout nightly nightly beta test new system limited number device perform gradual rollout stable expand tuf checkup flare fetch data local remote state enable troubleshooting autoupdate issue add automated test suite exercise validates autoupdate functionality
application architecture servicestac new service case different one existing service specially fully crud create read update delete rest interface therefore choice application structure cannot simply borrowed existing service case service involve heavy readwrite access data via json rest api interface substantial amount asset metadata object ten hundred million additionally data must editable manually least startmigration phase following taken regarding application architecture programming language python python backend service programming language thats best known within devs reason change application framework django django application framework django mature wide user community come excellent documentation powerfull orm futhermore wellsupported maintained extension designing rest apis considerably reduce amount boilerplate code needed serializing authentication asset storage since service run aws asset stored object store metadata storage postgis since metadata contain arbitrary geojsonsupported geometry postgres along postgis extension storage metadata application architecture initially involve syncronous operation async task reconsider certain write operation dont meet performance requirement anymore consequence developer familiar django walk django tutorial get started development
api customization internationalization proposed problem statement big chunk resource available sylius part locale aware product description name payment shipping method translated customer provide best user experience right resource returned available translation store proper localization content left frontend developer solution consistent endpoint already embeds part translatables provide clear easy consistent way handling customer locale considered returning possible translation frontend update coherent moment resource always returning possible translation leave fronted render proper one good simplest fastest solution moment writing document good leaf proper content localization frontend developer guarantee flexibility bad data overfetching locale case wont needed bad leaf proper content localization frontend developer additional work required frontend app order provide localization functionality taking advantage jsonld specification string internationalization researched pamil take advantage jsonld processor return data according specification leave proper data structure jsonld processor good follows external standard may allow take advantage standard ecosystem good solves overfetching problem yet leaf flexibility developer decide fetch one locale single request good suggested good direction content internationalization api platform core team bad bounded one standard may solve internationalization issue format jsonld bad part api platform yet significant effort would done order provide proper solution ref httpsgithubcomsyliussyliusissues httpsgithubcomapiplatformcoreissues flatting translatable part resource structure main resource approach side side default sylius architecture way treat sylius resource internally case supported outofthebox easily achieved default resource served default locale channel administrator term admin panel may fallback app wise default locale good follows current behaviour good solves overfetching problem good straightforward implement bad allow fetching one locale bad become internal standard outcome first approach admin section api third one shop section way receive best world minimal effort worth mentioning sylius two distinguish entry point api admin shop concerned different thing resolve different problem unified view product shop make easy straightforward build product page time translation approach admin provide full control translation resource treat therefore every resource translation linked main resource iri translation resource may subject crud operation accessible throughout http verb
implement state machine handle transition service user story easi map flow system request grows larger complicated keep endpoint testable maintainable secure currently many transition api endpoint example updating draft system intake submitting system intake deciding system intake systemintake update endpoint however different authorization permission side effect important endpoint service become bloated idea floated implement finite state machine would capture information transition map structured way however determined goal refactor security maintainability readability could accomplished without overhead necessary state machine considered nothing refactor service smaller part without building state machine implement state machine outcome chosen refactor service smaller part without building state machine pro con nothing work involved service continue get bigger bug remain harder locate fix refactor service smaller part without building state machine service smaller component easily testable service implementation easily pluggedandplayed unify transition one location code force transition one format build state machine implement transition map way structure transition readable way allows easy modification transition map requires significant overhead set state machine would section state machine endpoint service without compelling reason enforces rigidity transition may counterproductive since different transition take different input produce different output
layout layoutspagenjk title adr external document management system pagetitle adr external document management system pagedescription path blueprint permalink blueprintadrsadruseexternaldocumentmanagementsystemhtml eleventynavigation parent architecture key adr external document management system order sought determine whether deliver document management capability content management platform natively integration external document management platform digital bloomreach looked implementation document management functionality bloomreach delivered part work digital httpsgithubcomnhsdigitalwebsitehippo project provides good view native bloomreach document management publishing look like delivers flexible content model publishing html document office addition look current usage office determine whether platform would suitable integration bloomreach futurenhs finally looked futurenhs collaboration platform see whether would suitable integration bloomreach whilst platform current state would good candidate integration discovered time writing platform due rewritten believe microsoft office sharepoint provide good basis platform document management capability proved successfully integrated looked requirement lks staff particularly around ability support range document type spreadsheet presentation belief would better placed integrate external document management system digital publishing platform provides excellent html publishing model workflow however extending support broader range document type would complex futurenhs may provide good candidate integration future however time writing difficult recommend product process rewritten consequence integration external system brings additional complexity requires wiring external system however move responsibility providing broad range document management capability dedicated platform
time estimation based text voice deciders eimi pietro rob technical story investigate voiceover time buffer edl fcpx investigation better signpost voice overlink problem statement people want include time taken voice over estimate time rough cut driver ease implementation accuracy time estimated extensibility considered word per minute calculator reading time calculator record word get time audio stt service get time audio outcome chosen simplest implementation standardised way calculating voice estimation within company positive consequence fairly easy implementation negative consequence accurate would require change icon description voice feature misunderstood point raised investigation better signpost voice overlink pro con word per minute calculator calculate aggregate time based second per word good simple calculate doesnt require additional tooling implement good vouched someone strong editorial experience bad basic wont give accurate time estimate reading time calculator calculate aggregate time based read time per word good similar simple implement bad even accurate reading time speaking time record word get time audio recording audio retrieving time audio good produce accurate time estimate bad audio recorded likely replaced also probably change time estimate also bad recording audio completely new feature require additional development feature storage transfer transcoding based different platform device stt service get time audio stt estimate time word retrieving time audio bad similar reason bad also would stt service mean adding library potential dependency external service based platform device
circleci analysis sandbox analyzing untrusted clojure code mean loading done kind sandboxed environment docker image created help still requires run monitor job execution bad actor could still trigger many build run bitcoin miner computestealing stuff running docker aws lambda probably similar computestealing issue hacking continous integration service job detail found note isolation first version cljdoc circleci run analysis result analysis made available build artifact laoded trusted environment import data grimoire build html documentation frontends consequence circlecis free tier come minute buildtime sufficient building documentation entire clojure ecosystem first dozen project probably fine point well reach cap point might want ask circleci sponsorship look
ashlar concept map summary document outline current understanding ashlar capability relationship driver project based understanding also outline potential future project propose next step development note terminology document ashlar mean ongoing open source project working summer want refer specifically current implementation project ill ashlar instead referencing current name repo distinction strike relevant since appears important part ashlar development process involve deciding software functionality precisely constitute ashlar well determining functionality organized implemented code current understanding component comprising ashlar see ashlar project currently comprised five interesting component span three repos ashlar driver djsonb component include schema editing web app implemented angularjs app driverschemaeditor expose admin control active schema driver record dashboard web app implemented angularjs app driverweb allows user browse filter download geospatial data standalone django app ashlar expose restful crud api retrieving updating geospatial record schema composing geospatial record standalone django app djsonb provides python api performing query arbitrarily nested postgres jsonb field django data collection mobile app implemented android app driver produce form saving record based active schema driver record understanding component schema editor dashboard mobile app interoperate component ashlar update retrieve record manage schema record component djsonb provides python api filtering querying record ashlar provides restful version api future direction based component see possible future ashlar seem compelling involves moving project different direction ashlar integrated development toolkit building apps flexible schema future seems closest thing direction development currently moving ashlardriver future ashlar likely still django app although possibly backends postgres provides admin backend well automatic form managing schema would tightly integrated implementation opinionated relatively heavy lift installdeploy although time would offer feature one package may android toolkit sitting top ashlar lightweight jsonbacked database server dynamic schema future away present involves slightly abstracted version ashlar future ashlar woulnt django app would simply database server speaks json level creatingupdating record also managing schema could implemented anything talk like database server ashlar data model specification many possible implementation future furthest away also abstract ashlar would specification managing flexible schema record nothing could implementation variety different language framework addition direction ashlar also see possibility separate repos portion djsonb simple syntax querying json rest api filtering querying json url parameter seems like solved problem trouble finding anything good space current ashlardjsonb syntax bit rushed could imagine putting effort designing nice spec could plug number different backends relational long store query json portion ashlardjsonb automatic filter generator based jsonschema component ashlar pretty cool seems like could thing possibly part related curious hear future seem useful also curious whether future ive missed next step fellowship website list three phase developing ashlar create data specification ashlar data modelling convention evaluate lowcost nosql provider serve data layer create proofofconcept app top ashlar either static demo site data collection mobile app thinking forward would make sense engage rapid development cycle three phase instead treating linear sequential could imagine development plan would look like build quick demo app top existing implementation ashlar refine want ashlar including spec backend develop ashlar direction repeat build second draft demo app new version ashlar test app get feedback refine ashlar spec develop based feedback finally time permitting polish demo app build android version
adr parallel experimental track plan deprecated component superseded adr stage approved adopted work maturity component sometimes build component parallel trackbundle without breaking existing component eventually new component would replace old one main bundle proposed stage stage start new component outside main bundle folk want try explicitly import draft bundle import actionmenu primerreactdrafts contract consumer opting rewrite old component might cover case old component yet old new version component different page paying additional bundlesize cost note replacement useful keep component name consumer internally would want call filename actionmenutsx call actionmenu doc stage confidence component better old version swap component move old component main bundle breaking change officially recommended consumer start new component theyd like push effort future give easy way import actionmenu primerreactdeprecated deprecated component accept new feature request reason single bundle component pick component want upgrade result additional unrelated work stage month living deprecated bundle component retireddeleted codebase also breaking change point consumer expected plan migration work suggested change detangle draft component lifecycle draft component collocated main bundle component documentation page section recommended yet
adr step outcome conclusion adr proposes adding stepsidoutcome stepsidconclusion step allows downstream step run based whether previous step succeeded failed reminder currently step contains stepsidoutputs step completed populate stepsidoutcome stepsidconclusion one following value success failure cancelled skipped continueonerror step fails outcome failure even though final conclusion success example yaml step experimental continueonerror true run buildsh experimental stepsexperimentaloutcome success run publishsh experimental terminology run api term conclusion therefore different term outcome value prior continueonerror following snippet run api response payload json step name set job completed conclusion success number startedat completedat consequence update runner update doc
layout page title removeproducedestination deprecate ultimately remove destination deciders lewin chan aaron mcgrath paul higginson sebastien belin matt warman problem statement consider something like jmstopicproducer configure produce destination contains topic traditionally wanted metadata driven destination would done via metadatadestination messagemetadatakey expression language would configuredproducedestination everywhere however isnt necessarily obvious user additionally cannot destination isnt string producer mandatory piece information would considered destination instance aws kinesis producer requires streamname partitionkey kind requirement doesnt lend well producedestination cant make destination return delimited string since value essentially arbitrary either completely ignore producedestination destination stream name something else entirely partition key already producer ignore destination entirely sap idoc producer jetty response producer two immediately spring mind isnt mandatory edit proposal also remove consumedestination well producedestination driver confusion new user clean configuration take advantage new feature make thing predictable considered quo always deprecate producedestination introduce implementation producedestination outcome deprecate remove quo army consequence good there work apart new producer dont fit existing producedestination paradigm bad arent simplifying object model configuration deprecate destination deprecate destination deprecate destination member producer consumer adaptrismessageworker well ensure producer consumer provide method specifying destination fsconsumer might directoryname string messagedirectory ditto fsproducer might different producerconsumer type deprecate producerequest method main producer interface default null make sure notnull mean longer display destination create new producer configured present deprecated warning jmsreplytodestination finally special jmsreplytodestination object metadata derive javaxjmsdestination handled specially jms producer impls change jms producer implementation object metadata exists usejmsreplytoifavailabletrue jmsreplyto value deprecate jmsreplytodestination consequence neutral crossover period style valid message change existing user without massive kerfuffle good ultimately simplifies configuration leaving work configbean translation good allows producer define configuration fact nonstring based destination neutralbad change producerequest contract adaptrismessageproducer additional producedestination implementation kinesis produce could introduce new kinesisproducedestination contains additional getpartitionkey method make generic add getqualifier method consequence good arent modifying object model bad cast producedestination bad still support situation user configured configuredproducedestination similar
invalidate parsercache backwards incompatible frontend change adr change markup entity page made often end outdated content parsercache result user facing error either backend code attempting perform processing parsercache output frontend javascript attempting access part dom changed example backend attempting fill placeholder doesnt expect frontend looking newly introduced dataattribute isnt present historic parser cache entry distant past solved problem introducing custom rejectparsercachevalue hook operationsmediawikiconfig httpsgerritwikimediaorgrcoperationsmediawikiconfig reject cache entry made deployment time weve also done stage leaving invalid entry cache avoid increased load marking entry invalid worked past typically applied discovering problem even way gradually reject historic invalid cached result user facing error time record thing impact parseroutput content version code generate parseroutput parser parser marked generating parsercache key rejectparsercachevalue two version parseroutput content cannot coexist backwards compatibility possible way split parsercache old new version example trialled introducing new mobile termbox see httpsgerritwikimediaorgrcmediawikiextensionswikibase event tracking new part code doesnt currently corresponding may necessary ensure introduced parseroptions calculate parsercache key determined existing cache entry thus introducing new key new key value custom rejectparsercachevalue hook may still required see httpsgerritwikimediaorgrcmediawikiextensionswikibase example already exists hasnt last year entitycontent entityhandlerparserversion may useful change however currently applies entity general usually make change one type entity time needed consequence followed avoid user facing error making breaking frontend change able serve without additional hack current old version parsercache output mean test feature gradually roll feature across entity revert broken feature however feature suddenly turned user entity may see spike parsercache size application server load initially always miss cache therefore big bang breaking change done caution gradual rollouts preferred
time handling sdk decided currently momentjs handling time related type sdk unfortunately moment quite big size project recommends new project httpsmomentjscomdocsprojectstatusrecommendations considering move future native library temporal proposes abstraction type handle odata edmdatetimeoffset temporalzoneddatetime edmdatetime temporaldatetime edmtime temporaltime edmdate temporaldate edmduration temporalduration edmtimeofday temporaltime stage proposal time likely reach stage still official timeline stage reached planned become standard allow configure different serializers deserializers maybe even field type provide adapter moment string temporal serialization switch default implementation moment either string temporal depending state proposal time switching provide adapter moment temporal initial release default implementation moment temporal reached stage provide string adapter temporal part node standard possible switch adapter globally exemplary code snippet api yet decided const bupa await businesspartnerrequestbuilder getall executedestination bupadate moment const bupa await businesspartnerrequestbuilder getall transform edmdatetime temporalmiddlewaredatetime executedestination bupadate temporal consequence allow user easily switch implementation see best fit case even allow write transformer consider moment moment handle time example temporal therefore transformation handled separately case also url payload serialization differ quite similar therefore approach always consider two transformer url payload serialization solution migrate different library first declined would mean introduce breaking change twice accept stage proposal risk declined think risky potentially early user adopt sdk stage proposal downgraded stage past wait temporal reach stage declined planning release version sdk first half unlikely would fit timeline unless keep old implementation version implement sdk wrapper abstract different library declined would probably mean quite high implementation effort flexible enough summary poc new api design instead original idea creating new function transform middleware passed via existing function optional parameter building entity requestbuilder see example default entity builder usage const testentitybuilderintpropertybuild default create request testentityrequestbuildercreateaexecute transformed entity builder usage const testentitybuilderserializersintpropertytestbuild transformed create request testentityrequestbuilderserializerscreatebexecute middleware structure like define deserializers edm type example two edm type considered interface deserializationmiddlewareinterfacet edmstring serializer val string deserializer ori string edmint serializer val string deserializer ori string please note api design applying replacing moment lib introduce multiple generic type entity requestbuilder testentity testentityrequestbuilder make code complicated user affected number generic type depends number related edm type example odatav edm type edmdatetimeoffset edmdate edmduration edmtimeofday relevant mean introduce generic type class mentioned poc example stringnumber example look like two generic type two edm type edmstring edmint export class testentitytemporalt string number extends entityvt implement testentitytypet stringproperty intproperty assumption request builder complexity serializer complexity deserializer url converter serializer might part middleware odata complexity odata advanced data type like complexcollection type handled like basic edm type scope mentioned poc example two generic type mapping edmstring edmint type test entity created entity builder withwithout middleware testentitytemporalstring number const entity testentitytemporalbuilderintpropertybuild testentitytemporalstring string const entity testentitytemporalbuildercustommiddlewarefull intproperty build type test getallrequestbuilder withwithout middleware testentitygetallrequestbuildertestentitytemporalstring number string number const requestbuilder await testentitytemporalrequestbuildergetall testentitygetallrequestbuildertestentitytemporalstring string string string const requestbuilder await testentitytemporalrequestbuilder custommiddlewarefull getall type test return value executing getallrequestbuilder withwithout middleware testentitytemporalstring number const await testentitytemporalrequestbuilder getall executedefaultdestination testentitytemporalstring number const await testentitytemporalrequestbuilderdefaultmiddleware getall executedefaultdestination testentitytemporalstring string const await testentitytemporalrequestbuildercustommiddlewarefull getall executedefaultdestination testentitytemporalstring string const await testentitytemporalrequestbuildercustommiddlewarepartial getall executedefaultdestination implementation unit test custom deserializer affect return value getallrequestbuilder get rid moment lib prerequisite middleware pattern implemented sdk support custom deserializer middleware addition default one temporal lib ready replace moment default deserializer step switch default deserializer moment temporal sdk core moment dependency temporal breaking change release new package contains prebuilt constant moment deserializer middleware moment dependency user switch deserializer demand allows latest sdk core moment instead default deserializer next step refactor middleware structure align design mentioned addition getallrequestbuilder handle kind request builder addition deserializer handle serializer uriconverter addition odatav handle odatav addition basic edm type handle advance type like collection complex type release new package sapcloudsdkdatetimetemporalsapcloudsdkdatetimemoment middleware component user consume directly
data provider getting available locale active channel shop user rejected problem statement customer access locale available channel considered doctrine collection extension good consistent actual approach modifying response content good work rest api extension like pagination bad locale dont relation channel doctrine collection extension extremely hard data provider good already approach older resource good easy implement bad data provider omits extra doctrine extension like pagination outcome chosen data provider shop shouldnt many locale channel lack pagination smaller problem creating overcomplicated query doctrine collection extension
geometry shaders tbd deciders lithiumtoast communication httpsgithubcomcraftworkgamesextendedissues problem statement extended support geometry shaders driver metal support geometry shaders performance geometry shaders implementation consistent accross hardware vendor performance problem geometry shaders generating primitive stored slower access medium chip another stage graphic pipeline competing resource could effectively somewhere else vertex fragment stage practical function geometry shaders effectively done instead vertex shaders advanced technique compute shaders tesselation instancing monogame support geometry shaders resulting developer unfamiliar geometry shaders work even purpose considered support geometry shaders support geometry shaders allow specific graphic apis feature flag developer would responsible deciding whether geometry shaders enabled available app desired target platform hardware outcome none taken yet link vertex shader trick bill bilodeau gdc fistful frame klonan posila factario video game blog geometry shaders slow unless youre intel joshua barczak
eclipse orion editor editor provide syntax highlighting work browser considered eclipse orion eclipse che codeanywhere cloud codiad theia outcome chosen eclipse orion reason extension ides either time consuming possible communication ides winery unclear eclipse orion already project detail see ultimate comparison license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
remove precheck function implemented problem statement number selects trivial precheck function anywhere seems remnant something old driver primary driver minimize cruft extra code useful considered keep posterity possible reuse remove tpcs except one remove concept code refering tpcs meaning one getlastimportstatement renamed outcome chosen remove concept tpcs simplifies code clarifies purpose single tpc actually
offer copying file source file folder force source code versioned winery support scripting language processing copied support compiled language processed copying considered copying source file require external tooling source file outcome chosen copying source supporting compiled language relied external ide see adr ide store file source folder manages copying file folder thus left support scripting language case source directly file binary artifact template pro con copying source easy implement sufficient scriptsfiles compilation intuitive user since source target user interaction required ide support upload file mean java file must first downloaded compiled uploaded file require external tooling source file one click user copy compile file runtimecompiler see adr
tachyons tag design tooling primary component openbounty web application part work web application regularly implement new element flow support overall product development frontend work requires usage specify positioning text style many variable common problem developer try generalize class reused see bem arguably intention great inevitably time come constraint change component modified time people may component place relying current implementation programming language breaking collaborator expectation like mitigated assertion automatic test easily done working order avoid problem outlined adopt approach atomic immutable utility class promoted tachyons library tachyons provides safetoreuse singlepurpose class help achieving consistent scale whitespace fontsizes modifying definition class anymore safely build component class without needing worry breaking someone expectation consequence tachyons bit weird familiar general approach believe enable contributor move confidently quickly long run might extra mile make buy approach previously reuse level class approach like tachyons reuse get elevated component level appendix scalability insightful article utility class good idea author tachyons quote article monolith model never stop writing refactoring hard time consuming deleting unused hard time consuming often work people excited happens people keep writing tachyonstldr super helpful tool look class provided tachyons via attribute affect dwyllearntachyons nice repository another pitch various example outlining basic usage
url support client metadata value author philpennock partially implemented tag client motivation tbd overview nats url able encode information required connect nats server useful manner except perhaps content certificate url encoding consistent across client language fully documented making explicit commaseparated list url hostnames within url ensuring compatible across client included plus order randomization anything tuning connection behavior might establishing connection specifiable url anything doesnt fit authority information url probably query parameter optfoooptbar documentation establishing name behavior unrecognized value unrecognized ignored possible fragoptfoooptbar instead clearly define draw line sent server reconnect timing information fragment consistency query thing configurable include limited ocsp checking jetstream domain various timeouts verification level support anything verify always server cert pinning per hexshaspki
docker hackney preference container across digital service httpsgithubcomlbhackneyitapiplaybookcontainers build run service docker docker compose heroku container hosting consequence team greater parity environment work locally high confidence work heroku project move heroku future containerised service make process easier term time complexity
adr completed flipbook viewer may support nontranscription project multiimage subject built flipbook viewer feature pfe frontend app subject viewer display workflowconfigurationviewer undefined subject one location location image viewer assumes image location subject dimension catered toward landscape oriented square image plan add finegrained choice subject viewer project builder future relevant change flipbook viewer discussed another adr feature configurable project builder handled flipbook viewer number play iteration default workflowconfigurationplayiterations autoplay automatically start looping page load default false workflowconfigurationflipbookautoplay allow volunteer switch separate frame view default false workflowconfigurationenableswitchingflipbookandseparate choose whether clone drawn mark frame default false workflowconfigurationmultiimageclonemarkers flipbook control thumbnail frame navigation button next previous button navigation frame play speed selection five playpause button button switch separate frame view drawing task clone marker frame checkedenabled project builder drawn mark circle appear every frame flipbook viewer frame index volunteer added mark still recorded annotation volunteer drag mark new position new position display frame clone marker frame uncheckeddisabled project builder drawn mark appear frame initially drawn frame index volunteer added mark recorded annotation volunteer drag mark new position new position apply dragged mark consequence implement drawing tool flipbook viewer refactoring interactionlayers handling current frame needed interactionlayer displayed top subject image aware showdrawedit mark current frame however pull current frame value subject viewer store mark drawn subject viewer fem current frame recorded annotation currentframe local state variable flipbookviewer want viewer allow drawing tool config explained current frame instead handled store adr regarding separate frame viewer similar consequence implementation drawing tool viewer include explanatory adr
integration map provider proposed application integrated party geolocation provider help user reach location smart fridge currently consider map provider integrate application provider pricing criterion pro link openstreet map free nocost opensource documentation tomtom free request daily subsequent better navigation documentation mapbox free request daily subsequent custom map feature documentation map free request monthly subsequent request monthly better visualization service documentation based business model volume data near future subscribed user know location precisely decided integrate map good market reach first request free consequence transaction per month look decent business model business grows ready upgrade premium solution governance maintaining application constant surveillance number request per month avoid additional expenditure
adr http transport middleware approved flashheart although useful become difficult maintain extend due feature coupled client httptransport mitigates middleware extend rest client behaviour middleware comparable plugin based artitecture allows user add change behaviour without make change core client conforms openclosed principle decided koa middleware via koa compose library rather creating custom implementation opted library well tested library extensively production environment aid implementation caching layer see example familiar syntax expresskoa support asyncawait example middlware stack async function middlewarectx next const req ctxres handle request await next invokes next middleware const ctxres handle response etc async function middleware async function middleware register httptransport usemiddleware usemiddleware usemiddleware would unwind stack way expresskoa middleware middleware middleware http request middleware middleware middleware http response aid module caching transformation caching middleware function modifyheadersreq next function rediscachereq next httptransportusemodifyheaders userediscache middleware execution order modifyheaders rediscache http request modifyheaders rediscache http response ensures caching module cache request enters pipeline requires minimum amount processing recreate cache key despite transport modifying terminating middleware chain terminating chain achieved suppressing call next async function cachingmiddlewarectx next const req ctxres iscachedreq return await next call next middleware allowing chain continue const ctxres handle setting caching response consequence support node ability existing middleware party module developmentmaintenance required middleware library flexibility via middleware rather limited signiture like req next control execution order middleware chain request handling easily terminated due recursive call stack response handling terminated however queried conditional response handling required
category adr tag analysis kotlin title adr pick analysis stack language noted adr codecharta jvm analysis stack havent decided language program though language familiar developer language allow quickly start developing especially relevant team member change frequently kotlin expressive choice java syntax feel familiar developer familiar latter also great interop support java great benefit since many metric parsing tool also based java consequence similar java kotlin different enough require getting transition shouldnt take longer couple week though every tool available java development also available kotlin edition part might production ready break unexpected moment case analysis real time restarted may google announced firstclass support kotlin android make previous point bit likely true
calculate prior root distribution based user input prior distribution specified accurately calculate probability prior calculated many different way hopefully reflects least surprising result user prior calculated follows specified command line calculate poisson distribution specified lambda specified command line user specified root distribution issue warning user also specified poisson lambda specified command line estimate poisson distribution family provided otherwise uniform distribution issue warning reasonable prior consequence user may confused ordering may unforeseen circumstance combination input flag still surprising
structure cli supercedes indexing command flow current command line interface awkward contains considerable amount business logic rather listing every command adr provide guideline adding new command mario command collection subcommands global value truly applied every subcommand attached subcommand provide reasonable default value make sense example mario ingest index aleph sbucketkeymrc mario reindex url httpexamplecom aleph aleph additionally maingo file kept small business logic reside elsewhere application consequence maingo file significant rewrite order pull business logic currently cli also likely change index currently global make sense subcommands change cli propagated automated ingest workflow process
bulk import primary goal current data upload refactoring project includes enabling user upload data bulk producing multiple new data object userside operation mean introducing interface handle following step selecting several data file concurrently import new data object launching would amount several import job bulk import operation monitoring state job restarting necessary viewing result job currently work done user one cell time app cell generated desired data file upload timeconsuming cluttering narrative new design support bulk operation author briehl background app cell cell built jupyter front end extension framework application page load framework allows overriding customization component specifically narrative framework cell jupyter notebook thus narrative cell come three type code markdown raw kbase cell extension operate jupyter code cell easiest think subclassing app cell code cell specialized running narrative apps extension activated creating cell specific metadata component describes cell treated example adding following block code cell metadata tell extension machinery treat kbase app cell kbase type app app cell far complicated extension cell type several component serve different purpose finite state machine fsm thats determine cell state core system render cell based state message bus thats communicate rest application well kernel get job state interpreter manager app spec turn app spec set input form element code translator turn various set input code executed run app reason app cell extension code cell last point essence primary component app cell serve fancy code generator user interaction form element generate code start apps view result thus anything app cell done programmatically advanced user also noted regardless choice made may alter app spec made interpreted rendered bulk import design various input output listed horizontal row existing app spec rendered vertically there notion rowscolumns app spec right visually display various input along grid pattern order effectively match design may one following alter app spec support multiple inline parameter retaining backward compatibility including documentation etc distinct app spec importer include hardcode import apps look feel narrative interface decide update app spec work mean working narrativemethodstore catalog repos well internal documentation considered implement existing app cell codebase implement new cell type dont cell interface outcome bulk import developed new cell type based existing app cell point discussed considered different interface cell decided changing entire paradigm right would heavy burden design product team would push back development effort also clear consensus whether thats desired result discussed implementation impact importer app parameter layout decided something internal narrative repo opposed modifying app spec general final implementation left later discussion consequence team develop new cell type mean building new jupyter notebook extension mostly startup code loadipythonextension function thats common among extension team also spending time extracting component app cell embedded making easily shareable new cell type pro con implement existing app cell code base would entail adding different mode current app cell likely based additional metadata feature reduce spread additional yet similar cell type similar code reuse existing cell control mechanism currently place minimal modification reuse existing wrapping element cell title icon tab etc work done app cell made backward compatible existing functionality breaking work refactor etc complete release possible making intermediate release possibly challenging adding yet another mode app cell increase maintenance burden already complex code base see especially fsm draft complex may turn existing code deep series nested logic implement new cell type create new nbextension serve new cell type extension code cell would mean working fresh codebase without existing constraint intermediate minimally functional change rapidly prototyped released stick dry principle would mean refactoring part current app cell make various component importable message bus response job state management tab menu etc instead integration really might want consider anyway much structure mockup already function similar existing app cell might become duplicated work additional maintenance burden would mean updating component make narrative static narrative interface search dashboard example introspect narrative handle cell based type dont cell interface bulk importer work mocked cell becomes part narrative workflow could change would mean interface rather cell implement bulk import work discussed especially narrative intended work repeatable record analysis discussion generally importing file data object isnt useful trying repeat work especially dont access file also happen file expire server longer available case including one import cell misleading cell cannot run implying analysis narrative performs cannot completely reproduced unimpeded constraint around cell architecture imposed jupyter notebook kbase codebases keeping import job consolidated one place outside cell would reduce narrative length narrative object size removing import cell separate interface would positive impact load time entrypoint interface would something entirely new new work would done make app state management system kernel communication reference jira ticket draft design dataup jupyter notebook front end extension
aws amplify cli toolchain requested functionality api endpoint would synchronize specified route either add replace main route table custom route table triggered log event resource managed programmatically optimal possible user experience aws amplify cli toolchain programmatically creating updating destroying project resource endpoint defined aws api gateway synchronization functionality defined lambda function consequence end user aws cli nodejs awsamplifycli package installed detailed instruction required
library lookup launcher look version run osquery first look local tuf metadata see know version run given release channel version already downloaded run version otherwise look recent version downloaded update library mermaid flowchart alibrary lookup bdo local tuf repo cget recent version update library dreturn path recent version executable hend yes ereleasejson target metadata exists yes ftarget indicated releasejsonnis downloaded update library yes greturn path selected executable update library
import implemented proposed adam gibson discussed paul dub currently gap way samediffndj operation implemented framework represent model kera tensorflow pytorch attribute based format name interop onnx tensorflow kera tends follow following formula map name equivalent name framework operation configuration name name associated attribute operation convd stride kernel size map inputoutput tensor equivalent tensor type framework setup complete graph equivalent framework sometimes framework concept dont map output equivalent result regardless though order sometimes framework addremove operation order produce equivalent output different graph tensorflow onnx import good example samediffndj internal representation set ordered argument execution form argument floating point argument float double integer argument integer argument long integer boolean argument boolean argument data type argument data type inputoutput input argument ndarrays input output argument often optional dynamically created output ndarray argument user want pas output control memory allowed axis argument integer argument represent dimension operation executed reference implementation map well enough execution file format related work may encourage future work done samediff file format implementation serialization file format via flatbuffers found note prior work current code generation httpsgithubcomkonduitaidljdevtoolsblobmastercodegensrcmainopsorgndjcodegenopscnnktl definition kotlin dsl found intended description kotlin specific available small subset ops precreated object created specific operation goal adr expand upon make language agnostic providing information neutral file format code generation current code generation effort augmented file format making found proposal expose symbol based mapping libndj protobuf format similar framework bridgeintermediary format make easier implement interop framework add necessary information needed able define direct mapping could future file format depending framework evolves considered work around making writing import code easiermore portable similar onnx tensorflow protobuf express attribute based file format map samediffndj operation format translation layer handle mapping attribute ordered argument approach reflected samediffndj operation define mapping process tofrom attribute format order based execution format separate similar set rule mapping ndarrays attribute based format intermediary representation compile equivalent call libndj format definition found consequence migration attribute based import format make working deep learning framework easier future drawback yet another file format risk migrating new file format future lot front manual work index set current operation backwards compatibility yet another thing maintain wrote converter forward compatibility address specifying opset schema scheme similar onnx advantage easy maintain backwards compatible easily interops existing deep learning framework additional dependency whats already normal protobuf allows easy code generation language industry standard convention proprietary tooling reducing friction adoption people coming framework straightforward mapping argument import provide easy bridge existing libndj allow automation descriptor language would understand pas data library appendix comparison framework implicit explicit find existing attribute convention libndj code base libndj convdcpp file contains following declaration auto inputshapeinfo inputshapeat auto weightsshapeinfo inputshapeat sdlongtype const biasshapeinfo blockwidth inputshapeat nullptr int intarg intarg staticcastshapesizeatweightsshapeinfo filterkernel width int intarg stride width int intarg padding width int intarg dilation width int paddingmode intarg valid int isncw blockgetiargumentssize intarg intarg nwc ncw int wformat blockgetiargumentssize intarg see macro libndj code base reflect argument accessed list argument expected order explicitly map parseable structure comparison onnx convolution operator explicit attribute various type list ints named tensor shown concept exist internally operation layer ndjsamediff exposed directly user theoretical descriptor libndj follows java private string name private int ninnouttargsiargs private boolean inplaceable private list inargnames private list outargnames private list targnames private list iargnames private list bargnames private opdeclarationtype opdeclarationtype public enum opdeclarationtype customopimpl booleanopimpl listopimpl logicopimpl opimpl divergentopimpl configurableopimpl reductionopimpl broadcastableopimpl broadcastableboolopimpl contains declaration field associated descriptor libndj code base represent descriptor type implicitly validation well different macro present code base representing execution look like validation present various name found set macro declaration libndj found appendix format comparison framework add tensorflow look like name add inputarg name typeattr inputarg name typeattr outputarg name typeattr attr name type type allowedvalues list type dtbfloat type dthalf type dtfloat type dtdouble type dtuint type dtint type dtint type dtint type dtint type dtcomplex type dtcomplex type dtstring onnxs add found httpsgithubcomonnxonnxblobmasterdocsoperatorsmdadd onnx tensorflow purely attribute based format
interface application bar consistent way access application bar update caption change hamburger menu homeasup create interface implemented activity due single activity architecture base fragment cast fragment attached interface set member variable also method exposed fragment extended fragment make method consequence new interface necessary change base fragment made
model hub zoo download implementation discussion proposed adam gibson jan following work downloading model able interop different ecosystem adr address spec implementing interop following ecosystem onnx tensorflow huggingface pytorch model zoo kera application proposal proposal broken separate section detailing work implementation needed implement loading model ecosystem section cover implement download loading model download workflow described downloading model also cover handle staging model framework onnx onnx pretty straightforward github repo download model special structure beyond zip file downloader focus already uncompressed model ease simplicity tensorflow tensorflow hub web service access focused uncompressed model handling conversion code freezing model reused purpose staged model frozen model directly imported pytorch pytorch converted onnx pytorch serving model archive tool handling model storage unfortunately requires bit integrate pytorch serve archive vary format typically want extract model manipulate separately pytorch various model zoo official community provided example community provided torchvision model zoo pytorch hub end want convert model onnx considered staged model consumable framework huggingface huggingface space git repository store model url accessible huggingface hub sdk huggingface hub support framework pytorch tensorflow jax initial support focus pytorch tensorflow jax come later implemented jax model import framework loading model know model type running convert onnx know letting user specify model type download tensorflow pytorch storing model respective framework reusing staging technique tensorflow onnx framework huggingface path repository frameworkname specifier automodelpytorch autotfmodeltensorflow converting model onnx savedmodel respectively kera kera application simple archive contain file kera application library download cache model consequence advantage greatly strengthens ability test execute model needed different case allows flexible enable user framework starting point build work downloading model greatly increase testing allowed model import framework disadvantage different work needed ecosystem apis may change updated preprocessing model mean guaranteed imported additional work done model import allow model execute come additional validation work comprehensive solution user still know thing like input output may still refer underlying doc given model effectively user may still understand preprocess different kind model
shell scripting implement create software defined everything unix shell commandline interpreter shell provides command line user interface unixlike operating system shell interactive command language scripting language operating system control execution system shell script within linux exnvironment bash bourne shell popular within environment shell script comply checkcheck linter consequence bash shellcheck
dot prefix configuration file adr record standardise configuration file path location standardising configuration file detectable regular expression devazazyaml user home directory current working directory currently facilitate extensibility two location searched devyaml devyaml additionally exists includes property allows file include file current implementation convention global configuration file prefixed period want able writebacks configuration exact example would dev add repo repourl current implementation make messy configuration file anywhere made configuration file look like devazazyaml application search user home directory current working directory includes property removed consequence possibly reduces extensibility removing possibility custom inclusion constraint however come benefit standard dev configuration immediately recognisable filename configuration file prefixed period hopefully
toml config file stentor pick config file format consideration yaml toml human readable writable allow easy parsing structured data supported well maintained library yaml benefit straightforward write especially nested structure however toml intended config file provides stricter parsing box stentor toml config file consequence toml provides strict parser return error unrecognized field make validation easier allows stentor provide hint user correct typo downside tomls syntax array table complicated yaml easier write incorrectly mitigated stentor case array table needed customizing section
preference data storage issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
title convert image file weight problem statement convert image file properly pdf since thousand different image format never support common container supported though jpeg jfif exif png tiff baseline single page focus document image maybe digital camera scanner considered pdfbox library imagemagick external command imgpdf external command tesseract external command screenshots doesnt make sense since look screen instead look file property input file input file identify input inputjfifjpg jpeg bit srgb inputletterenjpg jpeg bit gray inputletterenpng png bit gray inputletterentiff tiff bit grayscale gray size jfifjpg letterenjpg letterenpng letterentiff pdfbox java library preferred quality good enough example exact case sample code scala def imgtopdffile string exitcode val jpg pathsgetfiletoabsolutepath filesexistsjpg syserrorsfile doesnt exist jpg val new pddocument val page new pdpagepdrectanglea pdaddpagepage val bimg imageioreadjpgtofile val img losslessfactorycreatefromimagepd bimg val stream new pdpagecontentstreampd page streamdrawimageimg pdrectangleagetwidth pdrectangleagetheight streamclose pdsavetestpdf pdclose exitcodesuccess pdfbox twelvemonkeys running time identify pdf jfifjpgpdf pdf bit srgb letterenjpgpdf pdf bit srgb letterenpngpdf pdf bit srgb letterentiffpdf pdf bit srgb size jfifjpg letterenjpg letterenpng letterentiff imgpdf python tool add image pdf without reencoding version running time identify pdf jfifjpgpdf pdf bit srgb letterenjpgpdf pdf bit srgb letterenpngpdf pdf bit srgb letterentiffpdf pdf bit srgb size jfifjpg letterenjpg letterenpng letterentiff imagemagick well known imagemagick tool convert image pdfs version running time identify pdf jfifjpgpdf pdf bit srgb letterenjpgpdf pdf bit srgb letterenpngpdf pdf bit srgb letterentiffpdf pdf bit srgb size jfifjpg letterenjpg letterenpng letterentiff tesseract docspell already relies tesseract ocr contrast candidate create pdfs searchable course yield much longer running time cannot compared time tesseract docjpg deu pdf also create output one tesseract docjpg deu pdf txt tesseract running time identify pdf tesseractjfifjpgpdf pdf bit srgb tesseractletterenjpgpdf pdf bit srgb tesseractletterenpngpdf pdf bit srgb tesseractletterentiffpdf pdf bit srgb size jfifjpg letterenjpg letterenpng letterentiff tesseract external tool imagemagick imgpdf chosen even though imgpdf show best result fastest pdfbox library would favorite result good twelvemonkeys library support many image priority avoid external command possible since already dependency tesseract create searchable pdfs tesseract pdfs image converted searchable pdfs image text extraction required anyways
adr haskell reason building project experiment different architecture video game particularly interested functional programming applies game since personal project fun right find functional programming fun paradigm find static type fun dynamic type additionally trying get better haskell therefore haskell seems like obvious choice haskell consequence game written haskell
configuration environment variable updated application configured differently depending running example backend running locally different configuration backend running production environment variable configure application consequence environment variable allows easily configure application consistently good support cloudgov configuration via environment variable also frontend easy configure frontend library allow setting environment variable env file note
architecture record asset pipeline addition handling arbitrary http request would like arachne make easy serve certain type wellknown resource static html image javascript static asset generally served user file directly without processing time served however extremely useful provide preprocessing convert asset one format another format prior serving example transformation include scssless coffeescript javascript clojurescript javascript fullsize image thumbnail compress file gzip additionally case several transformation might required resource example file might converted coffeescript javascript minified gzipped case asset transformation form logical pipeline applying set transformation known order resource meet certain criterion arachne module defines way specify asset transformation ought apply order like everything else system open extension module provide custom processing step development production regardless asset pipeline implemented must provide good development experience developer see change immediately user modifies asset file automatically reflected running application near realtime keep development cycle time low provides fluid lowfriction development experience allows developer focus application production usage however different set priority able reflect change important instead minimizing processing cost response time paramount production system generally want much processing ahead time deployment cache aggressively deployment distribution development simple deployment arachne capable serving asset however whatever technique implement asset pipeline also capable sending final asset separate cache cdn served statically optimal efficiency may implemented separate module core asset pipeline however entirely static site large class website actually require dynamic behavior built entirely static asset associated preprocessing example framework cater specifically type static site generation include jekyll middleman brunch many including asset pipeline module http pedestal module arachne also ought able function capable extensible static site generator arachne boot provide abstract asset pipeline boot builtin support immutable filesets temp directory management file watcher everything arachne pipeline specified pure data configuration specifying input output transformation explicitly module participate asset pipeline develop welldefined api built around boot filesets proposed consequence asset pipeline fully specified data arachne configuration adding arachne support asset transformation involve writing relatively straightforward wrapper adapting library work boot filesets program boot internal apis although alan micha suggested would willing factor fileset support separate library
graphql api project going delivered beta project end year likely grow feedback real user begin filter new idea conceived new platform required source funding renewed order accommodate concern chip simple flexible yet powerful api well situated change feature requirement change technology graphql specification traditional rest apis provides declarative development experience tell program want happen graphql library handle initially developed facebook announced since grown exponentially likely see new apis written graphql rest absinthe library fullyfeatured speccompliant graphql implementation elixir phoenix application project consequence graphqls key benefit include declarative approach writing code say rather rapid iteration frontend dont rest endpoint dependent upon uiux prevents overunder fetching ask get better analytics insight data requested strongly typed schema serf contract front back end built validation built api explorer provides foundation easily expanding app new data new platform thing developer aware panacea silverbullet make sense create rest rpc endpoint handle particular request dont try force graphql though facebook year still new technology grand scheme thing many developer still havent even heard though expect changing quickly throughout
jupyter notebook automated notebook execution report generation autoflow november pending autoflow aim provide method automating workflow involving flowapi query executable document jupyter notebook provide medium user define workflow flowclient communicate flowapi familiar analysis environment supply workflow autoflow scheduled executed additionally jupyters markdown cell inline display output including image markdown make jupyter notebook suitable candidate producing static report nbconvert another advantage jupyter notebook automated workflow error occur execution error displayed inline within notebook aiding debugging automate running notebook come parametrise notebook execution time otherwise would repeatedly running identical notebook getting output autoflow papermill parametrise execute jupyter notebook additionally scrapbook formerly part papermill library persist data notebook reused later notebook allows building workflow multiple notebook example produce daily pdf report compiles result multiple separate analysis autoflow jupyter notebook central userdefined component workflow defining query run producing content output report papermill parametrise execute notebook scrapbook also installed autoflow deployment user share data several notebook workflow consequence allow lot flexibility autoflow usage since anything done jupyter notebook automated autoflow analyst typically familiar jupyter notebook already process prototyping workflow eventually automating autoflow fairly userfriendly remain alert potential security consequence since allowing user provide jupyter notebook principle allows execute arbitrary code within autoflow container
mount clojure tool namespace clojure normal work flow repl problem reload appliction state die mount preserve clojure superpower powerful simple fun making application state enjoyably reloadable depending application state managed development three superpower either stay somewhat completely mount libray clojure tool space mount component made afer review bouth solution feeling mount clojure dialect oriented mount namespace component record made compliler control dependency mount contagious consequence change projectclj start define state
uniform bucketlevel access storage implement implement security design related single confidentiality level per data component motivated single confidentiality level per data component access level granularity kept data component level bucket mean uniform bucketlevel access fine grained objectlevel acls uniform bucketlevel access storage consequence clear transparent access data however additional bucket sometimes needed store data another accesslevel
config config file superceded environment variable override config file application configuration overridden command line flag environment variable something want take advantage configuration limited configuration file sake simplicity single way configure application consequence command line parameter environment variable ignored taken account starting application
maven build plugin maven plugin needed build tool compile test package maven gradle viable decided maven felt better fit maven build maven plugin rather gradle consequence verbose dependency management build manifest committers project maven plugin familiar build framework gradle learning curve
convert template database model snippet template historically combination html javascript jinja variable template saved database snippettemplate django model upon save django would extract jinja variable list autogenerate snippet admin snippet admin user would select dropdown template list input image textareas booleans would appear represent jinja variable selected template upon save value input would combined json blob saved database snippet django model system allowed fast iteration template without redeploying application served well year imposes large number limitation shortcoming like template form dynamic real django form thus cannot take benefit excellent django form validation bogus input daily problem snippet editor fight review converting template real model would allow validate type input text link url enforce secure link icon validate type size dimension image thus increase quality snippet complex validation like require input another input set give better error message overall better admin snippet editor reupload icon since image saved part blob gallery snippet bundle huge include full blob moving image outside bundle would drastically decrease bundle size reduce cdn transfer cost also expect benefit cpu memory requirement server side faster activity stream page client side due reduced size indexeddb possible deploys painful also template code part firefox dont change often decide move template real django model asr template get django model entry django admin similarly image moved new django model named icon template link icon asrsnippet link one template obj djangos model inheritance change affect asrsnippet model preasr jsonsnippet implementation remain decommissioned script migrate current system new system asrsnippets created consequence new template require work get integrated system since also get coded firefox ride train impose real problem better experience snippet editor snippet cost many many happy face related issue milestone httpsgithubcommozmeaosnippetsservicemilestone httpsgithubcommozmeaosnippetsserviceissues httpsgithubcommozmeaosnippetsserviceissues httpsgithubcommozmeaosnippetsserviceissues
move image webroot svg image throughout application public incident form well backoffice part web application svgs inlined text referenced url production bundle signalsfrontend application serve one tenant see multitenant architecture make sense able overwrite image client level instance municipality den bosch provide image different type trash container different image content set django admin applied feature flag fetchquestionsfrombackend see appschemajson set case question configuration retrieved api overwrite image configured downside image text available svg image time present signalsfrontend production bundle unnessarily increase size bundle also image cannot cached browser cannot preloaded would required able maintain different image mean case django required since image hardly ever change provided application deployed first time correct dockerfile asset overwritten build time see instance dockerfile weesp domain summarize moving svg image application web root allow decrease production bundle size image cached browser reduce complexity code image referenced url instead import convert import string overwrite image docker container level svg image referenced url moved web root putting assetsimages folder time image optimized store different folder copy buildtime web root time optimize image content
create two observation comparators whale observation variety quality may require sorting research purpose two distinct sorting method proposed sorting observation require two unique comparison method implement comparableobservation create default field compareto method observationid long nested comparator class field sightingtime observation consequence nested comparator class best choice program due wide availability reusability future iteration program versus oneuse nature anonymous class lambda expression
adr support continuous discrete input support discrete continous input discrete input detection individual keypress discrete input support movement game menu state transition one keypress one action scenario continous input detection state input ongoing basis continous import support linear movement game notably movement toad currently sdl retrieve discrete input mechanism continous input one implementing continous input would sdlgetkeyboardstate function sdl could call function every frame make result available every scene interpretation another would consume existing input event stream fed sdlpollevent transition inputstate based keypressed keyreleased event moment prefer maintaining state instead letting sdl reduce number possible key combination want support type system support continous discrete input existing poll event architecture new state machinery consequence input layer refactored expose capability
wicked multistep form create activity form large complex arguable much single page form therefore break manageable chunk additionally govuk service manual recommends starting one thing per page approach wicked gem build multistep form activity consequence gem multisteps form service code managing multistep form complex single page form benefit user experience make worth
scala programming language amplified akka decide programming language write api code currently team member mostly familiar java programming language therefor might want stick java learn new language focus new tool problem domain address however support akka much better scala might also eager learn new language scala program monitoring part application consequence learn new language mean considerable overhead choice scala facilitates akka nice get know new language future
amaps map core early written aug normally save time boilerplate generic component available starting new project important piece application map component map provides starting project bennie van der wel little experience map application datapunt generic component called amaps generic map component tailored amsterdam based leafletjs core map component since lot feature already buildin also amaps meant relatively small application one consequence amaps work box feature like street search grayscaled map zoom feature however amaps come quite large footprint mainly due amsterdamstijl also amaps wrap part leaflet making part hard reach
elixir backend language project going delivered beta project end year likely grow feedback real user begin filter new idea conceived new platform required source funding renewed order accommodate concern chip simple flexible yet powerful backend well situated change feature requirement change technology elixir modern language built rocksolid foundation erlangotp runtime year running highly critical system little downtime possible erlang reputation arcane elixir introduces elegant new syntax many new feature created vibrant enthusiastic following commercially within dev circle phoenix defacto web framework elixir capitalizes feature elixir erlangotp provide rich developer experience capability develop kind app could imagine traditional mvc rest graphql realtime streaming etc consequence elixir key benefit include functional immutable language bring host benefit like referential transparency reduced cognitive load understanding data flow easier write unit test eliminates entire class bug introduced mutableoop paradigm allows better optimization compiler safely make assumption arguably best languageplatform concurrent distributed program web incredibly lightweight isolated process thousand upon thousand running concurrently machine vertical scaling instrinsically actor model process communicate process machine within network single machine multiple core threadsafe manner distribution horizontal scaling phoenix channel presence conflictfree replicated data type easily build reliable distributed realtime system nerve embedded iot device retain benefit allow sophisticated modern iot solution unique approach faulttolerance let fail mantra largely ignore exception handling due ability supervisor process utilize monitor process event exception choose number strategy restart process related process last known valid state highly performant consistently delivering response microsecond even heavy load think concurrent websockets actively transmitting realworld data elegant syntax drawn ruby many veteran ruby programmer moving elixir combination familiar syntax improved horsepower thing developer aware though gaining lot traction battletested underpinnings still relatively new language ecosystem finding runofthemill developer drop hat may difficult youll also likely attract better talent may stick around longer market bear longer hiring process deployment little trickier requiring manual tooling beyond simple git push master style deployment getting easier tool like distillery functional immutable language developer familiar oop mutable data paradigm may make initial effort order successfully shift mindset though welldefined elixirerlangotp unique software pattern learned reward learning paradigm however certainly worth effort though unlikely developer may learn bit erlang advanced thing library want doesnt exist elixir yet
uri requested functionality synchronize specified route either add replace main route table custom route table triggered log event would limited information available construct request isnt obvious fit official rest api uri specification vpcsvpcidroutetablesroutetableid uri vpcid vpc routetableid main route table consequence end user must know vpc main route table construct uri
adr screen navigation supersedes currently navigation framework built top flow order provide singleactivity navigation setup individual screen built androidviewview instance approach work well case bunch issue inbuilt support modal framework inbuilt support modal bottom sheet dialog etc currently workarounds see adr app grown increasingly reliant bottom sheet workaround tedious add lot friction building screen good example moving app different screen based result selected bottom sheet requires open bottom sheet start activity result flow reading result instead directly loading screen required inbuilt support lifecycle component currently library framework depend android lifecycle component officially supported activity fragment view current framework built workarounds available increasingly harder integrate library depend component longer wait opening screen expecting result come screen expected send result back previous screen current framework fall woefully short currently implemented ioreactivexsubjectspublishsubject sometimes lead issue result delivered correctly based subtle race condition conjunction bottom sheet described earlier layout editor preview broken current framework setup expect individual screen added xml layout file inflated system easy make building nontrivial uis hard editor framework cannot instantiate class screen depends normally initialized dependency injection framework requires deploy real device testing increase time feedback loop overall impact current navigation framework illsuited build complex navigation flow especially involve modal like bottom sheet application moment heavily reliant bottom sheet add additional complexity whenever work navigation flow incorporate since requires implement several workarounds order support correctly goal new navigation framework one better suited fulfill following requirement inbuilt support modal bottom sheet dialog ideally minimal difference modal normal screen support android lifecycle component support opening screen returning result without requiring workarounds support overriding back press screenmodal level support layout editor preview ide easy incrementally migrate current navigation architecture without requiring lot upfront work solution build new navigation framework based fragment inspired simplestack designed work screen architecture see adr high level description framework core component described framework framework overall three primary component screenkey abstract class inherited class represent individual screen similar current implementation parcelable save restore backstack activity state restoration mechanism triggered history class represents overall backstack encapsulate list screenkey instance expose helper method manipulate backstack also parcelable save restore necessary router class externally push pop screen backstack manage converting history fragment transaction applied order update usage instantiating router simple kotlin val router router firstscreenkey initial screen supportfragmentmanager ridcontent reference fragment container viewgroup pushing new screen onto stack performed push method kotlin nextscreenbuttonsetonclicklistener routerpushsecondscreenkey going previous screen done pop method kotlin previousscreenbuttonsetonclicklistener routerpop building screen implementing screen quite simple standard fragment kotlin class firstscreen fragmentrlayoutscreennavigationfirst override fun onviewcreatedview view savedinstancestate bundle superonviewcreatedview savedinstancestate set event parcelize object key screenkey override fun instantiatefragment fragment return firstscreen passing argument screen quite easy framework put instantiated screenkey instance fragment argument argument key screenkeyargskey easily retrieved within fragment standard argument call overriding back press framework provides interface handlesback screen wish override default back behaviour popping stack implement handle back press required work normal screen well modal kotlin class secondscreen fragmentrlayoutscreennavigationsecond handlesback private val router router unsafelazy requireactivity navigationtestactivityrouter override fun onviewcreatedview view savedinstancestate bundle superonviewcreatedview savedinstancestate nextscreenbuttonsetonclicklistener routerpushthirdscreenkey override fun onbackpressed boolean routerpushconfirmationdialogkey return true parcelize class key screenkey override fun instantiatefragment fragment return secondscreen opening screen result router provides two method pushexpectingresult popwithresult expectsresult interface order implement request response flow screen accepts result kotlin class thirdscreen fragmentrlayoutscreennavigationthird expectsresult private val router router unsafelazy requireactivity navigationtestactivityrouter override fun onviewcreatedview view savedinstancestate bundle superonviewcreatedview savedinstancestate confirmscreenbuttonsetonclicklistener routerpushexpectingresultentertext textentrysheetkey override fun onscreenresultrequesttype parcelable result screenresult requesttype entertext result succeeded val enteredtext textentrysheetreadenteredtextresult thirdscreenlabeltext thirdscreenlabeltexttostring enteredtext parcelize class key screenkey override fun instantiatefragment fragment return thirdscreen parcelize object entertext parcelable screen return result previous one kotlin class textentrysheet bottomsheetdialogfragment companion object fun readenteredtextresult succeeded string return resultresult resultdatatext private val router router unsafelazy requireactivity navigationtestactivityrouter override fun oncreatesavedinstancestate bundle superoncreatesavedinstancestate setstyledialogfragmentstylenormal rstyleclinicvthemebottomsheetfragment override fun oncreateviewinflater layoutinflater container viewgroup savedinstancestate bundle view return inflaterinflaterlayoutscreennavigationtextentrysheet container false override fun onviewcreatedview view savedinstancestate bundle superonviewcreatedview savedinstancestate donebuttonsetonclicklistener routerpopwithresultsucceededresultdatatextentryfieldtexttostring parcelize private data class resultdataval text string parcelable parcelize class key screenkey override fun instantiatefragment fragment return textentrysheet override val type screentype get screentypemodal support modal marking particular screen modal easy overriding screentype property screenkey implementation returning screentypemodal value kotlin class textentrysheet bottomsheetdialogfragment override fun oncreateviewinflater layoutinflater container viewgroup savedinstancestate bundle view return inflaterinflaterlayoutscreennavigationtextentrysheet container false parcelize class key screenkey override fun instantiatefragment fragment return textentrysheet override val type screentype get screentypemodal incremental migration current architecture since current screen built androidviewview instance framework androidxfragmentappfragment instance intermediate solution switch framework new screen older screen continue function minimal change order facilitate framework provide wrapper fragment screenwrapperfragment accept older fullscreenkey property embed screen within change done way individual screen get access screen key screen argument screen static method provided fragmentmanager order get fragment instance encapsulates view get screen key argument fragment instance might choose provide helper method instead every screen fairly straightforward there particular case would require move screen fragment however situation autosubmit value text field based given length like pin entry screen would migrate screen specifically needed way screen state restoration work current screen architecture play well together wrapped fragment apart case migrate screen required misc comparing usage goal weve defined earlier one havent considered following support layout editor preview support lifecycle component given free screen architecture based fragment layout resource file provided fragment via constructor require embed custom class within layout resource file anymore addition since based fragment get access default lifecycle provided framework needed proof concept implementation available consequence fragment navigation fragment notoriously complicated given additional lifecycle decoupled one parent activity well separate lifecycle fragment instance child view however feel okay start couple reason work navigation directly router instance encapsulate complexity related fragment transaction screen write enforced participate flow enforce android tool team planning simplify fragment lifecycle time opt simpler fragment lifecycle available additional maintenance code write handle navigation additional code maintain however consider additional boilerplate write deal problem current architecture significantly lesser effort maintain try android recommended way handle navigation navigation component small section project decided couple reason navigation state defined multiple place create navigation xml file defines navigation destination action action trigger navigation flow code problem way navigation behaviour defined two different place hard get entire picture happening call site tradeoff lose ability get visual representation entire screen navigation graph acceptable tradeoff given simpler navigation code support opening destination getting result navigation framework support opening destination waiting result official recommendation viewmodel architecture component decided component project adding support would require additional workarounds could rather spend effort creating framework work
category adr tag analysis title adr pick analysis cli library noted adr codecharta pipe filter architecture defined user interact analysis codecharta analysis set commandline tool picocli picocli small powerful regularly updated work great combination kotlin consequence cli intuitive wellstructured graphical user interface would
adr screen controller superceded dont want put business logic inside android framework class like activity fragment cannot unit tested enable fast feedback loop test run jvm android separate screen controller mvi architecture pattern every screen one controller consumes user event performs business logic help data repository communicates change back screen user interaction happening screen abstracted inside data class type uievent event flow controller form rxjava stream kotlin create usernametextchanged event listening edittext rxtextview textchangesusernameedittext map text usernametextchangedtext event data class usernametextchangedtext string uievent screen sends single stream uievents controller get back transformed stream change flow data unidirectional merge multiple stream one rxjavas merge operator kotlin login screen observablemergeusernamechanges passwordchanges submitclicks composecontroller takeuntilscreendestroy subscribe uichange uichangethis controller uievents transformed per business logic uichanges sent back screen uichange simple lambda function take screen argument call method implemented screen interface kotlin typealias loginscreen typealias uichange loginscreen unit class loginscreencontroller observabletransformer fun applyevents observable observable eventsoftype map isvalidusernameittext map isvalid uisetsubmitbuttonenabledisvalid uichange lambda event observed across multiple function controller stream shared replay refcount event arent recreated every subscription replay share single subscription screen replaying event every observer refcount keep subscription alive long least one observer kotlin class loginscreencontroller observabletransformer fun applyevents observable observable val replayedevents eventsreplayrefcount return observablemerge enablesubmitbuttonreplayedevents loginuserreplayedevents fun enablesubmitbuttonevents observable observable fun loginonsubmitevents observable observable diagram source consequence event replayed beginning subscription uichange function must subscribe event exactly immediately controller constructed instance subscribing event stream flatmap result event getting replayed every time flatmaps upstream emits kotlin incorrect fun loginonsubmitevents observable observable val usernamechanges event oftype map ittext val submitclicks eventsoftype return submitclicks flatmap usernamechangestake culprit flatmap username username text always first text entered user latest one loginuserusername here correct way would look like care must taken writing code controller kotlin correct fun loginonsubmitevents observable observable val usernamechanges event oftype map ittext val submitclicks eventsoftype return submitclicks withlatestfromusernamechanges work flatmap username loginuserusername
multiple dot file make simpler contribute shell file make one big complicated file smaller self contained file mean new developer easily make useful change adding new file risk file one thing well consequence easier add new feature
ocsp peer verification metadata value author tbeets implemented tag server security release history revision description initial release problem statement many user nats highly invested certificate identify application certificate authority tooling policy ultimately handshake authenticate application environment solely combination nats user credential ocsp peer add nats server ocsp verify external peer peer certificate authority authority time negotiation ultimately accepting rejecting connection external peer nats client application establishing mutual mtls connection nats server mqtt websocket nats protocol nats leaf connection mtls two nats server ocsp peer allows operator allow revoke nats connectivity either finegrain leaf certificate coarsegrain level intermediate certificate tool ocsp responder capability adding dependency peerspecified ocsp responder service client connection necessarily add single point failure spof nats server point view case slow overall connection time mitigate ocsp peer paired local ocsp response cache whose main purpose minimize expensive network call external service also provide connection resilience happypath ocsp responder service offline reachable feature intended comply following standard standard description rfc internet public key infrastructure online certificate protocol ocsp ocsp responder specification section rfc internet public key infrastructure certificate certificate revocation list crl profile authority information access aia extension section prior work ocsp stapling server feature enables nats server prefetch staple verification ocsp response identity exchange inbound client handshake sorequested client nats server soconfigured also validates staple provided internal peer nats server cluster route connection supercluster gateway connection handshake negotiation initiate client note ocsp peer applies client leaf connection overlap supersede ocsp stapling feature design ocsp peer feature four main element ocsp verification check handshake truststore verification eligibility check based aia assertion trustchain certificate callout responder service eligible certificate response cache minimize callouts expiry period set configuration configuring ocsp peer verification nats server configuration file ocsppeer configuration may added respective configuration map following client leaf connection type client connection type map configuration handshake ocsp verify verify mtls required inbound nats root client yes inbound mqtt mqtt client yes inbound websocket websocket client yes inbound leaf hub leafnodes client yes outbound leaf spoke leafnode remote server ocsp verification check made handshake trustchain verification successful peer leaf certificate chain server trusted certificate specified cafile operating system default trust store unset default short long form ocsppeer configuration may specified short long form short form short form boolean value ocsppeer ocsp peer verification map true enabled equivalent long form verify true otherwise default false default unset enabled example nats server configuration snippet inbound nats connection text port certfile configscertsocsppeerminicaservertestserverbundlepem keyfile configscertsocsppeerminicaserverprivatetestserverkeypairpem cafile configscertsocsppeerminicarootrootcertpem timeout verify true ocsppeer true long form long form map customization text port certfile configscertsocsppeerminicaservertestserverbundlepem keyfile configscertsocsppeerminicaserverprivatetestserverkeypairpem cafile configscertsocsppeerminicarootrootcertpem timeout verify true ocsppeer verify true catimeout allowedclockskew warnonly false unknownisgood false allowwhencaunreachable false cachettlwhennextupdateunset customization description type default verify enable ocsp peer validation bool false catimeout ocsp responder timeout second may fractional float allowedclockskew allowed skew server ocsp responder time second may fractional float warnonly warnonly never reject connection bool false unknownisgood treat response unknown valid certificate bool false allowwhencaunreachable warnonly response obtained cached revocation exists bool false cachettlwhennextupdateunset response nextupdate unset set default cache ttl second may fractional thisupdate float configuring ocsp response cache nats server configuration file ocspcache configuration may explicitly enable serverscoped ocsp response cache cache listener enabled ocsp peer verification note ocspcache configured listener enabled ocsp peer verification nats server initialize cache ocspcache absent one listener enabled ocsp peer verification nats server initialize local cache default setting equivalent ocspcache true default short long form ocspcache configuration may specified short long form short form short form boolean value ocspcache ocsp cache behavior true default unset enabled equivalent long form type local otherwise default false disabled equivalent long form type none example nats server configuration snippet short form configuration text port ocspcache true certfile configscertsocsppeerminicaservertestserverbundlepem keyfile configscertsocsppeerminicaserverprivatetestserverkeypairpem cafile configscertsocsppeerminicarootrootcertpem timeout verify true ocsppeer true long form long form map cache customization text port ocspcache type local localstore preserverevoked false saveinterval certfile configscertsocsppeerminicaservertestserverbundlepem keyfile configscertsocsppeerminicaserverprivatetestserverkeypairpem cafile configscertsocsppeerminicarootrootcertpem timeout verify true ocsppeer true customization description type default type set cache implementation local none string local localstore set directory local cache persist cachejson relative path relative current working directory nats server executable string preserverevoked set true local cache implementation ignore command delete cached response revoke see also ocsp peer setting allowwhencaunreachable bool false saveinterval set often inmemory local cache persisted disk second default value minute interval save every second minimum value second enforced float peer ocsp verification trustchain prerequisite peer ocsp verification occurs handshake cycle successful trustchain verification peer connection immediately rejected trustchain verification fails peer rejection peer connection rejected due failed ocsp verification peer receive summary handshake error nats server handshake reject connection type client ocsp valid nats websocket mqtt client connection inbound leaf hub connection server ocsp valid outbound leaf spoke connection connection terminated log entry certificate fail ocsp verification could peer leaf certificate intermediate certificate logged warning level rejected peer connection logged error level whether ocsp verification enabled text wrn ocsp verify fail cnbaduseraotinghusltacomastwacus revoked err cid handshake error client ocsp valid advisory system event nats server also emit advisory system event corresponding log entry event type event subject event frequency ionatsserveradvisoryvocsppeerreject sysserverserverocsppeerconnreject per rejected connection ionatsserveradvisoryvocsppeerlinkinvalid sysserverserverocsppeerlinkinvalid per link evaluated invalid see document event payload example peer rejected event peer connection rejected due failed ocsp verification nats server emit advisory system event event carry information peer leaf certificate aid operator diagnosing configuration issue attempted exploit preventing successful connection note advisory event imply peer leaf certificate directly failed ocsp verification leaf certificate subject field toplevel peer identification rejection take place nats authorization binding nats useraccount peer link invalid event whenever certificate ocsp response obtained asserted good nats server emit advisory system event event carry information certificate subject identity well certificate identity corresponding peer leaf certificate event aid operator understanding root cause peer connection rejection specific certificate ocsp valid could leaf certificate peer intermediate certificate note typical case one peer link invalid event per peer rejection peer single trustchain ocsp invalidated immediately upon finding single invalid link however peer form multiple trustchains may multiple peer link invalid event time connection peer may ultimately allowed rejected ocsp peer verification criterion ocsp verified peer selfsigned certificate least one chain zero ocspeligible link least one chain one ocspeligible link good ocsp response eligible link ocsp verified peer none true criterion modifier nondefault configuration setting modify criterion follows unknownisgood true response unknown considered good applies allowwhencaunreachable true nonresponse considered good applies note allowwhencaunreachable true revoked response entry found cache even expired respect nextupdate corresponding chain verified respect peer ocsp eligibility trust determined least one verified trust chain connects leaf certificate nats server trustanchor chain evaluated link certificate ocsp eligible certificate considered ocsp eligible certificate issueing declares ocsp responder web uri http http certificate authority information access aia extension nonweb uri scheme supported ignored note practice ocsp responder usually reside nontls web endpoint http ocsp response intentionally public digitally signed hosting ocsp responder web endpoint http may create ambiguity certificate verification nats server attempt http endpoint encountered server host default trust store verify web server link trustanchor explicitly trusted nats server link evaluated ocsp eligiblity note trust chain may consist one link leaf certificate selfsigned trust case leaf certificate trustanchor ocsp eligibile certificate example following opensslstyle pretty print certificate extension sample client certificate declared authority information access aia web uri shown text extension subject key identifier afbefbeafeebccbbaffb authority key identifier bfbbbacbcedaad basic constraint critical cafalse netscape cert type ssl client smime key usage critical digital signature non repudiation key encipherment extended key usage web client authentication email protection crl distribution point full name urihttpcrltinghusnetintermediatecrlder authority information access ocsp urihttpocsptinghusnet subject name emailuserausernet ocsp responder callout evaluating eligible trustchain certificate ocsp validity ocsp response cache always checked first existing ocsp response entry found cache found entry effective time window nats server make synchronous call ocsp responder web endpoint note nats server must network access ocsp responder web endpoint well dns access resolve uri expressed hostname domain nats server wait default second http response ocsp responder timeout configurable catimeout response nonhttp response received nats server log error consider certificate ocsp valid purpose peer evaluation actual intent ambiguous advisory system event emitted successful http response received response payload parsed ocsp response response fails parse error logged certificate considered ocsp valid evaluation purpose advisory system event emitted response par ocsp response evaluated determine valid digital signature ocsp response either issuing signing delegate entitled issuing valid effectivity time window thisupdate nextupdate certificate set good revoked unknown successfully obtained valid ocsp response cached future ocsp response cache two implementation type ocsp response cache cache type description none noop cache implementation ocsp response cached local serverscoped inmemory cache periodic snapshot disk default cache type local none cache type exists testing purpose operating environment mandated ocsp check peer certificate every connection local cache local cache type serverscoped inmemory cache periodic snapshot disk persistent snapshot json document file named cachejson localstore cache configuration tell nats server find cachejson startupreload exists write latest snapshot periodically every minute default server shutdown default localstore value unset relative directory path snapshot frequency may configured saveinterval value second note setting fully qualified directory path localstore recommended eviction expired ocsp response cache passive sense cache entry evicted respective certificate evaluated constituent peer connection attempt cached entry found expired time evicted note cache preserverevoked enabled cached response represent certificate revocation never evicted although replaced newer response format persisted format essentially map certificate keyed certificate hash obtained ocsp response resp response stored base encoding raw byte returned ocsp responder additional field subject respstatus respexpires extracted stored humanreadable format operator convenience debugging purpose nonnormative runtime ocsp verification note whether ocsp response obtained cache directly web call identical response parsing validation performed runtime example cachejson file three cached ocsp response json ajpxcporoztxfmolhuxlemybwgujizzqfuyq subject cnuseraotinghusltacomastwacus cachedat respstatus good respexpires resp wyaafmycrtwbobqbotsrvgzumiigtgobakccbkcwggzdbgkrbgefbqcwaqeeggymiigmdcbkfymfyxczajbgnvbaytalvteqgcawcvexdzanaqwbwwgvgfjbhmrawdgernaombrpbmdodxmxfzavarlwdgmmdkduagumvzcguzgvygaymdizmdywntizmtmxnvowdzbmewcqyfkwdahofaaquyjaszqjkyqxbcyqqljxpefhsuxuoakwyigqeyzboqkprahrplussbbasxubivhahpkgiaaqmyabkarmhmaadqbefqaqgcsqgsibdqebcwuaaibaqagtedyjspqfouzkcfqnmhbyavahsvzklfcsjimakoouemxahqzezntmraassnddleovuezfpuuwragtkuvnhrvkovkypqvkowkxhwmoqnraevblvkzreysnjjqmfwxvxchneyfgjludiolhkddcujxgfxmkgfqrixgktsuajvpboevqpphjynskjwfuqqaxwldesvpjcevcrilqxewhjpnnbhtdxeprjluozzxivevxpmqpnbpfvjczgtbzljpjlrvrxgomwnikxnutkegsudzocjoiiemtccbcwggqpmiideaadagecahqxeaecxcregyeqhdbxzfyrmhghnjoaqqwvejjaccbgwfkkwoajbnrlcmlzglhdgugqewhhcnmjmwndemjemduwhcnmjqwndedqrqruasawwggeilimcaaefapraaqamiibcgkcaqeanevynmyvyrbzvswfhpmerrqafmpvxzgqydczbfueemnmyxlwrpckxajqjvtkhdzovyztaimtrtdliveswjkwazjbfyqswpfyloayjpmfgffdxlmcwmwdqmuctagxwnurzefckbltpopquknnrxwsttsmclszefqfyxujurxhhlvebuqlmkojcsmppdisrpvqeyllahuefcstowkznsvvyqqdxyqcukkecpneokavhihemeouqsnttpysxiblzufghgayqyfjcudlsyhnmnxmspdhzzjwidaqabohtmihqmbgauddgqwbbtttayybkuucwfojhbpxdavhtafbgnvhsmegdawgflhazqwdaydvrtaqhbaiwaivmbbpaqqbamcbbfggqdjqeqeawwcgyiibgaawkwpaydvrfbduwmzaxocglyyrahrcdovlnybciykulmldcpxvmkxnybckzxiwnbfkhaebbcgwjjakerammagggajdgjcaysgauegkrnfdhmuhalxcwzpiybsduqcakjvqceuhghyjnduroveuxftwnbbyufntxrqafizvoqkrviojvfyycmitlouwrjacgohispfcfghnvulqxdgxvsmtccjuqlvsalgrktoacmahvmbwndnjsmieswouejgbyignboacdquvjzonkzehkgemgummobtqrktkmzddpxiasdcttqczfmljfpqvfboeoziabragyogoykzatnbuauevgaczcfiolrzyqgnfawlnjsaxnugzbkvtrxrsueleuqwhq qsjckvhrrglrvtunsvmtwajjeumcqbbby subject cnbaduseraotinghusltacomastwacus cachedat respstatus revoked respexpires resp wyaafmycrtwblbqbmfxgzumiigzgobakccblwggzbbgkrbgefbqcwaqeeggzmmiigsdcbkfymfyxczajbgnvbaytalvteqgcawcvexdzanaqwbwwgvgfjbhmrawdgernaombrpbmdodxmxfzavarlweammdkduagumvzcguzgvygaymdizmdywntizmtqmowgywgyswttajbgurdgmcgguabbripzqzncmpjtbdsljlbcwpgnbqquextgsgctdigbzhatjngiooecfewadeldyobzmwjesvsrzkolorynadgmtgwnjemddaoamkaqenfhlbkarmhmaadubkfqaqgcsqgsibdqebcwuaaibaqbfodyezoovjmmxncdntwspmtswxoffykdustiulqtpktwsblsjveomhgremeytvxqxsunovlkrdcltytryaxccwxqbsrsmllxgswpitgummxlftqsrccsezdvdzvzwkeegepmejllufdknwzmfxbylhznjcyickikatxjamfxkwunfqmpgwlkfzaieuuzhzvqmfwgahlupfibgodemjhvbdmjeduodfxqsokyjtdckedvvapyjkltcxaqrtvicgnywudyknycvcrcttogaoiiemtccbcwggqpmiideaadagecahqxeaecxcregyeqhdbxzfyrmhghnjoaqqwvekgccbgwfklioajbnrlcmlzglhdgugqewhhcnmjmwndemjemduwhcnmjqwndedqrwruasawwggeilimcaaefapraaqamiibcgkcaqeanevynmyvyrbzvswfhpmerrqafmpvxzgqydczbfueemnmyxlwrpckxajqjvtkhdzovyztaimtrtdliveswjkwazjbfyqswpfyloayjpmfgffdxlmcwmwdqmuctagxwnurzefckbltpopquknnrxwsttsmclszefqfyxujurxhhlvebuqlmkojcsmppdisrpvqeyllahuefcstowkznsvvyqqdxyqcukkecpneokavhihemeouqsnttpysxiblzufghgayqyfjcudlsyhnmnxmspdhzzjwidaqabohtmihqmbgauddgqwbbtttayybkuucwfojhbpxdavhtafbgnvhsmegdawgfldaawdaydvrtaqhbaiwadaobgnvhqbdhaeawihgeuabblaraqddakbgijyyadctabgnvhrentazmdgglathitodhrwoivyjslnsjorqubmvllduyrfyjslmrlcjaeuocaqeekdammcqreawwayyydukmbnzcdjkacsapepezsdovdclbkjjlvaxrbwaolvajqcafiofkntvelcxffpccftiwdpvhqvwobjmcstwiluvhhwwhmsrblelpzyygjklwwacfpwverfzdvkailknouzxrqwbeqgbyyadxuxvcdenlzyhzdsimbtgjyvyfpxcqnmicrtleqzycywfndreqsbmmonjegcwnynajlcyukxylbvetahkgdlvascdligajlwrhkbpbogpqrwboltnzugwvpkqaxjcdcxepswbfsfezkepwhfhaxrvrspbgd lkmmdwazjrpuquqpsqizihcbauncymlazai subject cnintermediate caotinghusltacomastwacus cachedat respstatus good respexpires resp wyaafmycrtwbibqcqbyygzumiigrgobakccbjwggybgkrbgefbqcwaqeeggysmiigkdcbfbmfkxczajbgnvbaytalvteqgcawcvexdzanaqwbwwgvgfjbhmrawdgernaombrpbmdodxmxgjayarlweqmmeunbieduagumvzcguzgvygaymdizmdywntizmtmxnvowdzbmewcqyfkwdahofaaquulmfvfdgoincmpxbpkxkefmmiatoeihpzmepofamfxbzahrccecqfyunduubukikpaaaqmyabkarmnkaadqbefqaqgcsqgsibdqebcwuaaibaqdhlkdwahylswzywjabbzprbjvsfbzxvwvyyxwkivmvgduhezmrgwkzeypcuqnvfollioohhygkitizfmrahptutgxaleykmazvpcseugwfiyejtjtuxdxebgjjemmhihlzhbyvqxnobgodueejxbjjcphpqwgcjbhmgonitumkatjydkmibyksfpbbmucxlcdxbomkvsvwhwjdrifyobatqzlmelwafxnasumswraftquitkepganhwfsfpajgiwnveskxhgioydsvukdeepmsyoiiejjccbciwggqemiidbqadagecahrzwvltrlfhjozmdybavvamwsdoaqqwtemjmctuvawwhumvdcbdqtaefwymzamtcymjmndfafwzaqanaauaqvaesmmiibiieagabbqdqaepadccaqocggebapfecsvduwsmirsfzvtvrqqmtgmlpjcnudfpiztvvdqyeuyqivdueijylugcbufbgduvebxmpsnozxtpzonddyxusfdmepolsrbgbfdfujhpbmifponeycrzrzlqfbjrobwcxsljlqjtkehkgmhvpffvioygimpriabiczwuaepowfettlgstdyqiwrklnhfhcxbrkkfocijybpmyoblojbkygxvokmsewnhsgshvtdfnfqwbjtursvkuwmuwvzpivaiqcifwmauccaweaaaobzcbdadbgnvhqefgqummqfckevzekxkwdaosepmciwhwydvrjbbgwfobswgmmawgaudewebwqcmacfsgqddweogaqdageambybhgalaraqddakbgijradctabgnvhreltarmcmgjalhinodhrwoivyjslnsjhgubmvljvbrfyjslmrlcjaeuicaqeekjaomcyrugwwayyaeueqywjcayraaudakrkvdkkpsybdzjyzoniyewlqsgeoxjxfswpcocjsymrbtmxllvzljeodfhfmqogoaeztzsfnhnsnpugmngmvlsqirpzfwrmyjusitvxoswuaaswiiqxokljreapztoatyzuouznpbtjpjkqqttlqggcodzrasyvchxjdrclmmdassaecdxuxpuyvpbskrrflnvrztzoqavxwvbgzbpudgkurdilwgvotgsewmtvrssbqzawzlblqtvhelytryyoypojafeumipknbakdklbcyiabsqbhlecsorw monitoring addition visual indication operator new field appear varz json output wherever ocsppeer enabled map text tlsocsppeerverify true ocspcache enabled implicitly explicitly varz reflect current cache type provide updated cache statistic help operator understand cache effectiveness text ocsppeercache cachetype local cachemisses cachedresponses cachedrevokedresponses cachedgoodresponses debug logging following debugenabled log output show log entry example server startup rejected peer connection due revoked certificate server shutdown text dbg starting ocsp peer cache dbg loading ocsp peer cache hometoddlabmtlsocsptestrccachejson dbg ocsp peer cache found starting empty cache inf ocsp peer cache online type local inf server ready dbg cid client connection created dbg cid starting client connection handshake dbg peer ocsp enabled client chain evaluated dbg chain ocsp eligible link dbg checking ocsp peer cache cnuseraotestnatsltacomastwacus key xlsuhljnomxrnmpzvmtajvycrfgxhvjinei dbg ocsp peer cache miss key xlsuhljnomxrnmpzvmtajvycrfgxhvjinei dbg trying ocsp responder url http dbg caching ocsp response cnuseraotestnatsltacomastwacus key xlsuhljnomxrnmpzvmtajvycrfgxhvjinei dbg ocsp response compression ratio wrn ocsp verify fail cnuseraotestnatsltacomastwacus revoked dbg invalid ocsp response revoked dbg ocsp valid chain thus peer invalid err cid handshake error client ocsp valid dbg cid client connection closed handshake failure inf initiating shutdown dbg client accept loop exiting dbg system system connection closed client closed inf server exiting dbg stopping ocsp peer cache dbg ocsp peer cache dirty saving dbg saving ocsp peer cache hometoddlabmtlsocsptestrccachejson dbg saved ocsp peer cache successfully byte advisor system event example example bad peer attempt client connection text subscribing sysserverocsp received sysservernaxqddgfvzangjtobbmhpydehsyozdhnbejzarwopdoklwwocsppeerlinkinvalid typeionatsserveradvisoryvocsppeerlinkinvalididcdlwmjvknnaaqmqcmttimestamptzlinksubjectcnbaduseraotinghusltacomastwacusissuercnintermediate caotinghusltacomastwacusfingerprintqsjckvhrrglrvtunsvmtwajjeumcqbbbyrawmiiexdccasgawibagiurbpqsnjagfkzcmsyyvotrmiuwdqyjkozihvcnaqelbqawvzelmakgauebhmcvvmxczajbgnvbagmaldbmqwdqydvqqhdazuywnvbwexedaobgnvbaombrpbmdodxmxgdawbgnvbammdludgvybwvkawfzsbdqtaefwymzamtcymzantjafwyndamtyymzantjamfexczajbgnvbaytalvtmqswcqydvqqidajxqtepmagauebwwgvgfjbhmrawdgydvqqkdaduawnahvzmriweaydvqqddalcywrvcvyqtewggeimagcsqgsibdqebaquaaibdwawggekaoibaqcrswvelanelkzhwnuixkuosdgxysewmnenrcsxcawszhvcfoatxjltkyvpqdddptadzcgwbibvzqixwrggbxcgyoqffucspavmrnlsxbtoljcmzsqyaxrufracugfkatmaaxllauznawrzplmkgmzrkjcoxzbzmyjdbomovntxqzrfqfnslpdabzwebqvnbmcdyjmbfzkaovwkshvzmstcpolrwztmigmlnhjknjfmkmiaymwdpknrncwcavvgnyrhhkedzqkxgmdysdbynhiggtrsulrovagmbaagjggekmiibidadbgnvhqefgqueoammhdtjireyxsfdjmziuedklwhwydvrjbbgwfoauextgsgctdigbzhatjngiooewdaydvrtaqhbaiwadarbglghkgbhvhcaqeebamcbaawdgydvrpaqhbaqdagxgmbgaudjqqwmbqgccsgaqufbwmcbggrbgefbqcdbdabgnvhrentazmdgglathitodhrwoivyjslnrpbmdodxmubmvlludgvybwvkawfzvjcmwuzgvymdqgccsgaqufbwebbcgwjjakbggrbgefbqcwayyyahrcdovljcaudgluzhcyuzxqvmbogaudeqqtmbgbdvzzxjbmubcvylmlddanbgkqhkigwbaqsfaaocaqeadgtiltcdngwwlcjritwpfhsyccpzqfbbqeputwpfyevgcouezciiabltcpncwmsxierjcgmkmyqmrpvzsdffldqoyduqszmmikyxegqorqugbodmheumhkjuqlbkxxbpinauwqvbifxwhjnbirhacrpqmdktkhwgrhegicvgdhhrytgaesciwpzinbxaccazczzwitkkylnoxdneosdhtpfehctppdhuczkynjaqlbebuhsqayqgcrwfanpvkeqcbicymqvxavigtpxtvapeersubjectcnbaduseraotinghusltacomastwacusissuercnintermediate caotinghusltacomastwacusfingerprintqsjckvhrrglrvtunsvmtwajjeumcqbbbyrawmiiexdccasgawibagiurbpqsnjagfkzcmsyyvotrmiuwdqyjkozihvcnaqelbqawvzelmakgauebhmcvvmxczajbgnvbagmaldbmqwdqydvqqhdazuywnvbwexedaobgnvbaombrpbmdodxmxgdawbgnvbammdludgvybwvkawfzsbdqtaefwymzamtcymzantjafwyndamtyymzantjamfexczajbgnvbaytalvtmqswcqydvqqidajxqtepmagauebwwgvgfjbhmrawdgydvqqkdaduawnahvzmriweaydvqqddalcywrvcvyqtewggeimagcsqgsibdqebaquaaibdwawggekaoibaqcrswvelanelkzhwnuixkuosdgxysewmnenrcsxcawszhvcfoatxjltkyvpqdddptadzcgwbibvzqixwrggbxcgyoqffucspavmrnlsxbtoljcmzsqyaxrufracugfkatmaaxllauznawrzplmkgmzrkjcoxzbzmyjdbomovntxqzrfqfnslpdabzwebqvnbmcdyjmbfzkaovwkshvzmstcpolrwztmigmlnhjknjfmkmiaymwdpknrncwcavvgnyrhhkedzqkxgmdysdbynhiggtrsulrovagmbaagjggekmiibidadbgnvhqefgqueoammhdtjireyxsfdjmziuedklwhwydvrjbbgwfoauextgsgctdigbzhatjngiooewdaydvrtaqhbaiwadarbglghkgbhvhcaqeebamcbaawdgydvrpaqhbaqdagxgmbgaudjqqwmbqgccsgaqufbwmcbggrbgefbqcdbdabgnvhrentazmdgglathitodhrwoivyjslnrpbmdodxmubmvlludgvybwvkawfzvjcmwuzgvymdqgccsgaqufbwebbcgwjjakbggrbgefbqcwayyyahrcdovljcaudgluzhcyuzxqvmbogaudeqqtmbgbdvzzxjbmubcvylmlddanbgkqhkigwbaqsfaaocaqeadgtiltcdngwwlcjritwpfhsyccpzqfbbqeputwpfyevgcouezciiabltcpncwmsxierjcgmkmyqmrpvzsdffldqoyduqszmmikyxegqorqugbodmheumhkjuqlbkxxbpinauwqvbifxwhjnbirhacrpqmdktkhwgrhegicvgdhhrytgaesciwpzinbxaccazczzwitkkylnoxdneosdhtpfehctppdhuczkynjaqlbebuhsqayqgcrwfanpvkeqcbicymqvxavigtpxtvaservernametesterhostidnaxqddgfvzangjtobbmhpydehsyozdhnbejzarwopdoklwwverbetaseqjetstreamtruetimetzreasoninvalid ocsp response revoked received sysservernaxqddgfvzangjtobbmhpydehsyozdhnbejzarwopdoklwwocsppeerconnreject typeionatsserveradvisoryvocsppeerrejectidcdlwmjvknnaaqmqcpltimestamptzkindclientpeersubjectcnbaduseraotinghusltacomastwacusissuercnintermediate caotinghusltacomastwacusfingerprintqsjckvhrrglrvtunsvmtwajjeumcqbbbyrawmiiexdccasgawibagiurbpqsnjagfkzcmsyyvotrmiuwdqyjkozihvcnaqelbqawvzelmakgauebhmcvvmxczajbgnvbagmaldbmqwdqydvqqhdazuywnvbwexedaobgnvbaombrpbmdodxmxgdawbgnvbammdludgvybwvkawfzsbdqtaefwymzamtcymzantjafwyndamtyymzantjamfexczajbgnvbaytalvtmqswcqydvqqidajxqtepmagauebwwgvgfjbhmrawdgydvqqkdaduawnahvzmriweaydvqqddalcywrvcvyqtewggeimagcsqgsibdqebaquaaibdwawggekaoibaqcrswvelanelkzhwnuixkuosdgxysewmnenrcsxcawszhvcfoatxjltkyvpqdddptadzcgwbibvzqixwrggbxcgyoqffucspavmrnlsxbtoljcmzsqyaxrufracugfkatmaaxllauznawrzplmkgmzrkjcoxzbzmyjdbomovntxqzrfqfnslpdabzwebqvnbmcdyjmbfzkaovwkshvzmstcpolrwztmigmlnhjknjfmkmiaymwdpknrncwcavvgnyrhhkedzqkxgmdysdbynhiggtrsulrovagmbaagjggekmiibidadbgnvhqefgqueoammhdtjireyxsfdjmziuedklwhwydvrjbbgwfoauextgsgctdigbzhatjngiooewdaydvrtaqhbaiwadarbglghkgbhvhcaqeebamcbaawdgydvrpaqhbaqdagxgmbgaudjqqwmbqgccsgaqufbwmcbggrbgefbqcdbdabgnvhrentazmdgglathitodhrwoivyjslnrpbmdodxmubmvlludgvybwvkawfzvjcmwuzgvymdqgccsgaqufbwebbcgwjjakbggrbgefbqcwayyyahrcdovljcaudgluzhcyuzxqvmbogaudeqqtmbgbdvzzxjbmubcvylmlddanbgkqhkigwbaqsfaaocaqeadgtiltcdngwwlcjritwpfhsyccpzqfbbqeputwpfyevgcouezciiabltcpncwmsxierjcgmkmyqmrpvzsdffldqoyduqszmmikyxegqorqugbodmheumhkjuqlbkxxbpinauwqvbifxwhjnbirhacrpqmdktkhwgrhegicvgdhhrytgaesciwpzinbxaccazczzwitkkylnoxdneosdhtpfehctppdhuczkynjaqlbebuhsqayqgcrwfanpvkeqcbicymqvxavigtpxtvaservernametesterhostidnaxqddgfvzangjtobbmhpydehsyozdhnbejzarwopdoklwwverbetaseqjetstreamtruetimetzreasonclient ocsp valid event ionatsserveradvisoryvocsppeerlinkinvalid json type ionatsserveradvisoryvocsppeerlinkinvalid cdlwmjvknnaaqmqcmt timestamp link subject cnbaduseraotinghusltacomastwacus issuer cnintermediate caotinghusltacomastwacus fingerprint qsjckvhrrglrvtunsvmtwajjeumcqbbby raw miiexdccasgawibagiurbpqsnjagfkzcmsyyvotrmiuwdqyjkozihvcnaqelbqawvzelmakgauebhmcvvmxczajbgnvbagmaldbmqwdqydvqqhdazuywnvbwexedaobgnvbaombrpbmdodxmxgdawbgnvbammdludgvybwvkawfzsbdqtaefwymzamtcymzantjafwyndamtyymzantjamfexczajbgnvbaytalvtmqswcqydvqqidajxqtepmagauebwwgvgfjbhmrawdgydvqqkdaduawnahvzmriweaydvqqddalcywrvcvyqtewggeimagcsqgsibdqebaquaaibdwawggekaoibaqcrswvelanelkzhwnuixkuosdgxysewmnenrcsxcawszhvcfoatxjltkyvpqdddptadzcgwbibvzqixwrggbxcgyoqffucspavmrnlsxbtoljcmzsqyaxrufracugfkatmaaxllauznawrzplmkgmzrkjcoxzbzmyjdbomovntxqzrfqfnslpdabzwebqvnbmcdyjmbfzkaovwkshvzmstcpolrwztmigmlnhjknjfmkmiaymwdpknrncwcavvgnyrhhkedzqkxgmdysdbynhiggtrsulrovagmbaagjggekmiibidadbgnvhqefgqueoammhdtjireyxsfdjmziuedklwhwydvrjbbgwfoauextgsgctdigbzhatjngiooewdaydvrtaqhbaiwadarbglghkgbhvhcaqeebamcbaawdgydvrpaqhbaqdagxgmbgaudjqqwmbqgccsgaqufbwmcbggrbgefbqcdbdabgnvhrentazmdgglathitodhrwoivyjslnrpbmdodxmubmvlludgvybwvkawfzvjcmwuzgvymdqgccsgaqufbwebbcgwjjakbggrbgefbqcwayyyahrcdovljcaudgluzhcyuzxqvmbogaudeqqtmbgbdvzzxjbmubcvylmlddanbgkqhkigwbaqsfaaocaqeadgtiltcdngwwlcjritwpfhsyccpzqfbbqeputwpfyevgcouezciiabltcpncwmsxierjcgmkmyqmrpvzsdffldqoyduqszmmikyxegqorqugbodmheumhkjuqlbkxxbpinauwqvbifxwhjnbirhacrpqmdktkhwgrhegicvgdhhrytgaesciwpzinbxaccazczzwitkkylnoxdneosdhtpfehctppdhuczkynjaqlbebuhsqayqgcrwfanpvkeqcbicymqvxavigtpxtva peer subject cnbaduseraotinghusltacomastwacus issuer cnintermediate caotinghusltacomastwacus fingerprint qsjckvhrrglrvtunsvmtwajjeumcqbbby raw miiexdccasgawibagiurbpqsnjagfkzcmsyyvotrmiuwdqyjkozihvcnaqelbqawvzelmakgauebhmcvvmxczajbgnvbagmaldbmqwdqydvqqhdazuywnvbwexedaobgnvbaombrpbmdodxmxgdawbgnvbammdludgvybwvkawfzsbdqtaefwymzamtcymzantjafwyndamtyymzantjamfexczajbgnvbaytalvtmqswcqydvqqidajxqtepmagauebwwgvgfjbhmrawdgydvqqkdaduawnahvzmriweaydvqqddalcywrvcvyqtewggeimagcsqgsibdqebaquaaibdwawggekaoibaqcrswvelanelkzhwnuixkuosdgxysewmnenrcsxcawszhvcfoatxjltkyvpqdddptadzcgwbibvzqixwrggbxcgyoqffucspavmrnlsxbtoljcmzsqyaxrufracugfkatmaaxllauznawrzplmkgmzrkjcoxzbzmyjdbomovntxqzrfqfnslpdabzwebqvnbmcdyjmbfzkaovwkshvzmstcpolrwztmigmlnhjknjfmkmiaymwdpknrncwcavvgnyrhhkedzqkxgmdysdbynhiggtrsulrovagmbaagjggekmiibidadbgnvhqefgqueoammhdtjireyxsfdjmziuedklwhwydvrjbbgwfoauextgsgctdigbzhatjngiooewdaydvrtaqhbaiwadarbglghkgbhvhcaqeebamcbaawdgydvrpaqhbaqdagxgmbgaudjqqwmbqgccsgaqufbwmcbggrbgefbqcdbdabgnvhrentazmdgglathitodhrwoivyjslnrpbmdodxmubmvlludgvybwvkawfzvjcmwuzgvymdqgccsgaqufbwebbcgwjjakbggrbgefbqcwayyyahrcdovljcaudgluzhcyuzxqvmbogaudeqqtmbgbdvzzxjbmubcvylmlddanbgkqhkigwbaqsfaaocaqeadgtiltcdngwwlcjritwpfhsyccpzqfbbqeputwpfyevgcouezciiabltcpncwmsxierjcgmkmyqmrpvzsdffldqoyduqszmmikyxegqorqugbodmheumhkjuqlbkxxbpinauwqvbifxwhjnbirhacrpqmdktkhwgrhegicvgdhhrytgaesciwpzinbxaccazczzwitkkylnoxdneosdhtpfehctppdhuczkynjaqlbebuhsqayqgcrwfanpvkeqcbicymqvxavigtpxtva server name tester host naxqddgfvzangjtobbmhpydehsyozdhnbejzarwopdoklww ver beta seq jetstream true time reason invalid ocsp response revoked event ionatsserveradvisoryvocsppeerreject json type ionatsserveradvisoryvocsppeerreject cdlwmjvknnaaqmqcpl timestamp kind client peer subject cnbaduseraotinghusltacomastwacus issuer cnintermediate caotinghusltacomastwacus fingerprint qsjckvhrrglrvtunsvmtwajjeumcqbbby raw miiexdccasgawibagiurbpqsnjagfkzcmsyyvotrmiuwdqyjkozihvcnaqelbqawvzelmakgauebhmcvvmxczajbgnvbagmaldbmqwdqydvqqhdazuywnvbwexedaobgnvbaombrpbmdodxmxgdawbgnvbammdludgvybwvkawfzsbdqtaefwymzamtcymzantjafwyndamtyymzantjamfexczajbgnvbaytalvtmqswcqydvqqidajxqtepmagauebwwgvgfjbhmrawdgydvqqkdaduawnahvzmriweaydvqqddalcywrvcvyqtewggeimagcsqgsibdqebaquaaibdwawggekaoibaqcrswvelanelkzhwnuixkuosdgxysewmnenrcsxcawszhvcfoatxjltkyvpqdddptadzcgwbibvzqixwrggbxcgyoqffucspavmrnlsxbtoljcmzsqyaxrufracugfkatmaaxllauznawrzplmkgmzrkjcoxzbzmyjdbomovntxqzrfqfnslpdabzwebqvnbmcdyjmbfzkaovwkshvzmstcpolrwztmigmlnhjknjfmkmiaymwdpknrncwcavvgnyrhhkedzqkxgmdysdbynhiggtrsulrovagmbaagjggekmiibidadbgnvhqefgqueoammhdtjireyxsfdjmziuedklwhwydvrjbbgwfoauextgsgctdigbzhatjngiooewdaydvrtaqhbaiwadarbglghkgbhvhcaqeebamcbaawdgydvrpaqhbaqdagxgmbgaudjqqwmbqgccsgaqufbwmcbggrbgefbqcdbdabgnvhrentazmdgglathitodhrwoivyjslnrpbmdodxmubmvlludgvybwvkawfzvjcmwuzgvymdqgccsgaqufbwebbcgwjjakbggrbgefbqcwayyyahrcdovljcaudgluzhcyuzxqvmbogaudeqqtmbgbdvzzxjbmubcvylmlddanbgkqhkigwbaqsfaaocaqeadgtiltcdngwwlcjritwpfhsyccpzqfbbqeputwpfyevgcouezciiabltcpncwmsxierjcgmkmyqmrpvzsdffldqoyduqszmmikyxegqorqugbodmheumhkjuqlbkxxbpinauwqvbifxwhjnbirhacrpqmdktkhwgrhegicvgdhhrytgaesciwpzinbxaccazczzwitkkylnoxdneosdhtpfehctppdhuczkynjaqlbebuhsqayqgcrwfanpvkeqcbicymqvxavigtpxtva server name tester host naxqddgfvzangjtobbmhpydehsyozdhnbejzarwopdoklww ver beta seq jetstream true time reason client ocsp valid
orid jul service shall emit consume applicable orid orid shall conform specification version custom field follows field mapping sample value custom custom custom accountid issue motivating influence constrains mdscloud ecosystem expands longer assumed consumer service know internal apis issue command example current state machine implementation task definition attribute resource url invoke function internal address port known consumer service needlessly tightly couple system compounded operational concern operator may shuffle reconfigure system maintenance operation consequence becomes easier difficult risk introduced change mitigated moving orid supported system allow many concern mitigated
commandquerybased api git repos interacting git repos involves many finegrained operation independent others there shared state life repo disk handled independent function rather modelled method class anticipate application grows number operation likely grow maintain openclosed principle way add new operation whithout modifying much existing code also useful able test operation independently since quite involved test case single test test one class would get pretty lengthy finally would helpful able compose finegrained operation higherorder one combining operation creating branch making commit pushing origin pushcommit operation weve implemented commandbus package provides typescriptfriendly way build single dispatch function take different type message object dispatch message appropriate handler function consequence made test set git repos example easy read may possible serialize deserialize message schedule git operation background task mocking interface repo may tricky possible well want push outside core put facade around small set operation actual domain want also possible pattern confuse people although client code easy read code set dispatch function example maybe nice newcomer
fastapi web framework application supply web endpoint healthchecks select web framework multitude choose preference want something well maintained community want something decent performance learning experience want one many async framework front contender seems sanic fastapi tornado vibora quart tornado seems somewhat dated created python async built vibora relatively new project uncertain community adoption quart api compatible flask common nonasync web framework sanic seems popular async framework fastapi far performant fastapi performance interesting feature consequence since application going relatively simple possible switch framework relative ease allows experiment find framework prefer fastapi give api documentation automatically write code right way nice bonus
remove nostdoptions nostdoptions seems superflous seems intended prevent reading optionssettings project standard setting file usually user home directory remove consequence assuming optionssettings project defined single place downside risk command line script makefile rejected unknown message
termbox parsercache integration adr new termbox introduces external ssr service wikibase generates serverside markup section showing label description alias item property page section contains userspecific content preferred language likely determined babel extension whether language section expanded collapsed page load userspecific configuration result loggedin state information persisted anonymous user sessioncookies time writing following parameter influence result termbox service would consequently taken account caching result entity accounted parsercache entity revision accounted parsercache interface language accounted parsercache user preferred language toggle state language section typically nonuserspecific markup entity page added mediawikis parseroutput cached within parsercache placeholderemittingentitytermsview php version termbox work around parsercache injecting marker place userspecific markup added parseroutput replacing marker userspecific markup page rendered outputpagebeforehtmlhookhandlerdooutputpagebeforehtml viable new termbox would split logic injecting replacing marker across two service would require new service able produce result individual component contradicts architectural reality decides display cue application renderer parsercache drastically reduces time take render entity page consequently leveraged whenever possible wikidata item property page hit time per minute total measured january time per minute request logged user measured january influence preferred language dimension warranting customized result number may reduced considering preferred language set something preferred interface language number user language toggled nondefault state available time writing assumed small portion user request customized toggle state nonuserspecific version termbox cached part parseroutput user userspecific configuration identical default value cached result served user userspecific configuration different default value request performed termbox service later request life cycle outputpagebeforehtmlhookhandlerdooutputpagebeforehtml result served case ssr service produce usable result reachable empty element served replaced clientside rendered version termbox complex fallback scenario conceivable part adr product management request depending value focusing consequence parseroutput kept free userspecific markup cache splitting avoided user custom configuration potentially slower render time due uncached request ssr service order viable termbox ssr service sufficiently performant logging information closely observed future ensure default configuration resulting nonuserspecific version page fact constitutes largest share page request maximize cache hit rate minimize termbox service request
firebase platform help following requirement crossplatform connection input form information collection happen phone tablet real time entered manually computer later stage database able connect input medium collate information type text video photograph etc making observation sea researcher capture picture video along textual information weather condition distance able bring together different type data greatly reduce postcollection maintenance effort work around intermittent internet connection given environmental condition boat middle ocean consistent internet connection given thus tech stack must provide offline capability minimaltono data loss inexpensive scalability move different form information collection drone possible size data becomes exponentially bigger today thus datastore able handle storage data also put cost overhead bmmro firebase mobile web application development platform currently owned maintained google weve decided firebase offer variety service google ecosystem leveraged including hosting database authentication cloud storage analytics etc along beta feature translate email trigger also free plan seems enough link firebase pricing plan
jetstream republish metadata value author derekcollison tbeets implemented tag jetstream server update history author description tbeets fix typo json boolean headersonly example problem statement case useful subscriber monitor message ingested stream captured store without incurring overhead defining consumer stream case include limited lightweight stream publish monitor dashboard dont require overhead atleastonce delivery sideeffect workqueue interestbased stream publish monitoring object store update event watch cache invalidation design stream republish configured stream evaluate published message ingests republish source subject filter upon match stream republish message special message header new republish destination subject derived subject transformation republish occurs original published message ingested stream quorum stream atmostonce qos republish configuration republish republish consists three configuration field field description json required default source published subjectmatching filter src destination republish subject template dest header whether republish header body headersonly false following validation rule republish apply single token wildcard allowed source meaning taken streamingested subject destination must least nonwildcard token destination may match subset subject filter stream source destination must otherwise comply requirement specified adr subject transform example stream configuration republish specified text name stream subject one four republish src one dest uno headersonly false retention limit omitted configuration published message onefoobar ingested stream onefoobar republished unofoobar published message fourfoobar ingested stream republished republish configuration may edited stream creation republish transform republish destination taken together republish source form valid subject token transform rule resulting transform applied ingested message match source configuration determine concrete republish subject see adr subject transform description subject transformation republish republish header republished message following message header header value description natsstream stream name scope stream account natssubject message original subject ingested stream natssequence message stream sequence natslastsequence stream sequence last message ingested original subject none deleted headersonly true also header value description natsmsgsize size byte message body applicationadded header original published message preserved republished message loop prevention valid destination configuration check insures republished message immediately ingested original stream causing loop scope loopdetection immediate stream caution possible create loop condition two stream sharing overlap republish destination subject filter within single account
retain data one year original adr concerning data retention resides outline approach february point time decided retain data email alert api exception email archived deleted week since weve come realise revision data retention policy needed generating data never system initially prompted recent work migrate subscriber daily digest email lead increase amount unmanaged data produce store locally email alert api consequently provoked worry perpetually keeping data could result capacity issue due rapid increase data stored example generate digestrunsubscriber record day eight time amount compared ten month ago weve also gained insight data analytics original plan documented previous retention policy retain much data possible enable much analysis needed future however much data never analysis doesnt serve purpose email system contrary previously thought storing lot unused data indefinitely actually complicates pollutes auditing analysis example seen look subscriber list list active subscriber last week alone weve accumulated list dont subscription ended active unused list prevent simple auditing task easily like finding list report knowing thought could cleanup unused data keep email alert apis database manageable going forward couple different approach consider including storing unused data cloud storage away system database like archiving email subsequently deleting data locally setting mean removing data dont system entirely decided historic unused data removed periodically system entirely concluded data system longer exist maximum year removal sometimes analyse historic data year ago evidence needing data analytics beyond year following list document approach different data system contentchange message digestrun remove createdat value year old matchedcontentchange matchedmessage digestrunsubscriber removed automatically parent contentchangemessagedigestrun deleted subscription remove subscription theyve ended year based endedat value subscription ended cant currently made active deleted previously subscribed subscriberlist remove list active subscription latest ended subscription year old possible list deem historic subscribed however seems unlikely due list active subscription year happen list deleted new subscriberlist record generated unused subscriberlist remove list never subscription day old scenario happen user quits signup journey midway day chosen retention period allow user complete signup journey day limit confirm subscription mentioned section unused subscriber list pollute analytics remove regularly subscriber remove subscriber createdat year old dont subscription active ended subscriber without subscription historic subscription deleted mean able delete subscriber year old dont subscription however dont delete subscriber prevent removing new subscriber lack subscription due flaw code example unintentionally possible end subscriber subscription found email associated subscriptioncontents one place already manage retention held locally day also archived athena indefinitely still low retention email order manage size table however archiving athena inconsistent delete unused data entirely originally thought athena might serve data source analytics happened practice archive data stored entirely unused therefore decided remove archiving mechanism email since value consequence historic deletion worker implemented worker run periodically every day midday removing data deemed non urgent deleting day hour seemed sufficient first historic deletion run first run worker handle deleting historical data removed million record breakdown amount deletion per model found contentchange matchedcontentchange message matchedmessage digestrun digestrunsubscriber subscription subscriberlist subscriber restrict analytics year unused data restrict unused data analytics period year mean query looking data ended subscription year old met result dont expect issue due current expectation data well future analytics modify nullify process retire deactivated concept documenting data retention policy described adr found difficult understand document tangential concept deactivating nullifying subscriber give concept nullifying subscriber mean update address subscriber record nil unsubscribed subscription day deactivating subscriber concept revolves around deactivatedat field subscriber model field populated subscriber unsubscribes last active subscription mean determine subscriber nullified however obtain information held within deactivatedat endedat field recent ended subscription unsubscribed user meaning deactivated concept superfluous subsequently didnt want spend energy documenting process didnt make much sense begin decided would easier beneficial whole remove deactivated concept completely removing deactivated concept modified nullify process endedat described instead deactivatedat also updated process nullify subscriber subscription active ended older day prevents system storing user personal data longer needed whatever reason subscriber created without subscription see example happened deprecate archiving email athena planned work remove future meantime consider archiving athena deprecated updated documentation around reflect
release one configuration file historically two way configuring verify service provider environment variable yaml file environment variable application verifyserviceproviderenvyml file resource directory inside jar yaml file would pas path different file command line parameter usually people would example one thats contained repo couple reason extra complexity managing two file due restriction java buildpack cloudfoundry possible specify command line argument java buildpack cant specify path config file werent confident way cloudfoundry manages static file didnt want rely one also philosophical point factor application configured environment made hide configuration jar everything env var way appealing remove verifyserviceproviderenvyml file srcmainresources application default verifyserviceprovideryml file thats included zip command line argument provided application started without command line argument specifying yml file environment variable set startup error gracefully tell user configuration field specified example error configuration field found either set environment variable specify configuration file command line argument server pathtoverifyserviceprovideryml establish path verifyserviceprovideryml asking java path jar file containing application class looking parent folder consequence play story make default configuration file work way thats compatible current environment variable based solution going forward maintain one configuration file instead two user learn dichotomy configure env var configure file application still run paas default java buildpack
adr javascript user defined transformation possible list front define different transformation user might want apply dataset user defined transformation therefor important feature lumen must decide kind data transformation language want transformation couple could create custom dsl perhaps inspired excel formula custom dsl could made powerful non turing complete could mean easier learn user easier sandbox system also existing scripting language clojure javascript obvious advantage language already developedtesteddocumentedoptimized etc challenging securely sandbox execution language isnt tailor made particular case well javascript running sandboxed nashorn environment transformation language lumen proposed consequence user code must run sandboxed environment security reason must guard nontermination via timeout mechanism lumen relies typed column javascript dynamic language somehow ensure result user defined transformation doesnt result inconsistent column type
adr dont inquiry notification working towards private beta pay working towards implementing handling worldpay refund notification made previously make inquiry api call worldpay receiving notification main motivation security case forged notification worldpay confident getting accurate information calling worldpay robustness notification missed reason inquiry allow catch new regarding refund determined worldpay api support inquiry specific refund order sample response inquiry refund occured xml xml version encodingutf doctype paymentservice public worldpaydtd worldpay paymentservice ven httpdtdworldpaycompaymentservicevdtd paymentservice version merchantcodemerchantcode reply orderstatus ordercodeebfecaaefffd payment paymentmethodvisasslpaymentmethod paymentmethoddetail card typecreditcard paymentmethoddetail amount value currencycodegbp exponent debitcreditindicatorcredit lasteventrefundedlastevent refundreferencerefundebfecaaefffdrefundreference referencerefundebfecaaefffdreference authorisationid cvcresultcode descriptionnot sent acquirer avsresultcode descriptionnot sent acquirer cardholdernamecdatamr paymentcardholdername issuercountrycodenaissuercountrycode balance accounttypesettledbibitcommission amount value currencycodegbp exponent debitcreditindicatorcredit balance balance accounttypesettledbibitnet amount value currencycodegbp exponent debitcreditindicatorcredit balance riskscore value payment dayofmonth month year hour minute second orderstatus reply paymentservice inquiry command return information last event order lasteventrefundedlastevent case order two partial refund there race condition inquiry could return information different refund conducting inquiry notification add significant complexity codebase particular open possqibility lot edge case example enquiry might indicate different notification could theory legitimate two change occured quick succession first notification delivered could indicate bug issue hard know sensibly handle edge case dont really evidence happen practice there issue current implementation performs inquiry thread handle notification http request mean notification doesnt get http response inquiry roundtrip worldpay also completed could potential source bug finally worldpay advise order modification inquiry guide although order inquiry useful tool recommend order notification find change transaction youre set notification work notification sent automatically transaction change inquiry call notification neither order notification refund notification consequence agreed possible benefit performing inquiry justify significant added complexity removing simplify codebase test vigilant unexpected change might indicate missed notification detected charge transition state machine currently raise unhandled exception trigger error probably want change error logged return code regarding payment gateway smartpay doesnt support order inquiry relevant integrating gateway reconsider appropriate approach casebycase basis
config folder root folder becoming larger due many configuration file placed create config folder include dotfiles configure different tool consequence start adding new configuration file whenever possible folder progressively move existing file folder toolsci script might work default careful explicit look config file
hardcode dependency superceded dependency injection superceded autofac dependency injection issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
implement minimal api abstracting grimoire grimoire great single source truth due well designed datamodel apis grimoire expose following drawback however clojure specific language reimplement storage abstraction tedious work bugprone slightly unwieldy case seems common tooling author want build top grimoire data give information artifact namespaces defs version etc artifact could something like bidi order make grimoire data easy possible wide variety language implement minimal cache api top api following property filebased single file contain different bundle grimoire data file encoded transit reduce cost duplicate string similar file regenerated time initial implementation cache fund cljdoccache fccb spec written cljdocspec cache follows basic form clojure cacheid cachecontents cache storage could also implemented storage implementation grimoire benefit would grimoire operation supported given want expose api small subset grimoire multiple language utility immediately apparent consequence cache map may extended future especially timestamp generated could useful validate bundle regenerated certain point time since cachemap generation structure may change course time also become primary api versioning also considered could simple additional field cacheformat get incremented time cache format change
usedotenvformanagingenvironmentvariables accessing env directly without wrapper limited introduce problem want tooling help guard missing environment variable nil accidentally provided start process preferable fail fast explicit message without nil passed stack cause strange behaviour code designed dependency instead adding nil guard throughout codebase required environment variable envfetchfoo default managed centrally previously figaro purpose deprecated httpsgithubcomlaserlemonfigaro supported gem ensure get support form fix security patch also want able stub environment variable test suite easy example environment variable feature flag mechanism want stub value test scenario without influenced real value loaded mutating actual env value allowenvto receivewithboxidandreturn possible may unexpected consequence part process test variable figaro handy abstraction layer could stub allowfigaroto receiveenvwithfooandreturnbar consider stub environment variable dotenv load environment variable consequence docker docker compose added project environment variable loaded dockercompose envfileenvdevelopment rather dockercomposeenv pattern file managing environment variable env dockercomposeenv undesirable due overhead keeping sync dotenv load environment variable doesnt offer interface figaro dotenv youd access writing envfoo rather dotenvfoo make supporting climate control support testing
mongodb datetime representation representing rfc mongodb cloudevent jackson sdk allow query problematic mongodb internally represents millisecond resolution see internally object stored signed bit integer representing number millisecond since unix epoch jan since java cloudevent sdk offsetdatetime well lose nanosecond precision timezone converting offsetdatetime really bad since understandability transparent goal occurrent create cloudevent offsetdatetime containing nanosecond timezone europestockholm would expect get value back read possible convert weve thus decided store zonedatetime rfc string mongodb mean range query time horrendously slow probably work expected string comparision instead comparision eventstorequeries api currently support sorting event natural order ascendingdescending much faster since timestamp generated mongodb object note sort timeasc timedesc still retained api reason may allow customizations serialization mechanism nanosecond resolution required timezone always utc future worth considering would add additional field serialization process example retain time rfc string add additional field mongodb store fast time query ive decided though following reason code simplicity would needed handle time query specially example probably would like compare time field want compare field combination gte becomes even problematic time query fast index would needed would introduce additional complexity user mongodb eventstore index would created fast query creating index automatically would good idea since might required every user user may never query time case storing extra field simply unnecessary reason weve decided better user simply add custom extension field himherself create custom query field eventstorequeries api event support querying custom field right though could expand api allow custom sortby field instead hardcoding time natural consequence quite sad since still common represent time java application case would perfectly fine native isodate mongodb converting offsetdatetime would possible get best world store mongodb one nice benefit cloudevents lost
adr prefer multiple config file people involved sublimesneaks issue configuration stored within packagejson multiple file best choice prefer multiple config file storing configuration file extension allows additional feature comment merging computing based environment reduce git conflict within packagejson easier sync project simply copying configuration file storing extension yml json provides syntax highlighting easier find configuration easier ide tool discover improved seperation concern
add support fro advanced checkout flow adyen web component version new endpoint session introduced allows merchant create payment session shopper selects payment method drastically simplify checkout flow detail please refer adyen documentation hand api call web component advanced checkout flow detail please refer adyen documentation add required api payment call able support advanced checkout flow consequence commercetools extension utilized advanced checkout flow implementation migration checkout web component easier since advanced flow support keep backward compatibility
architecture record architecture record adrs simply record collection record architecturally significant record short markdown file specific lightweight format folder contains recorded knot knot record organization index categorized following folder architecture general architecture code structure coding convention common practice arc fog architecture stage architecturearcfogarchitecturestagemd arc fogcloud syncarchitecturearcfogcloudsyncmd arc amqp exchange namearchitecturearcamqpexcnamemd api knot api design sdks knot sdks engineering engineering practice including cicd testing release creating new record new record file named category prefixsequence number categorydescriptive titlemd categoryprefix architecturearc apiapi sdkssdk engineeringeng record contain following field proposed implemented rejected design discussion description consequence impact may create implementation implemented corresponding doc updated following information applicable release version associated test case
cli also respect environment variable one goal stentor integrated system requires flexibility user set commandline particular system easier change environment variable change commandline flag stentor commandline set via corresponding enviroment variable consequence writing new commandline also require adding documenting sourcing new environment variable
plantuml diagramming stdlib amends plantuml diagramming issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
project structure openfido project mediate access workflow service run gridlabd job frontend react application access resource permission access via organization create flask rest service since microservices suite service also flask based keep kind infrastructure common utility shared openfidoutils maintenance simplified organize database logic simplified cqrsinspired style code structure since anticipate many conceptual resource resource module appresourcemodelspy contains model resource appresourceroutespy contains rest route specific resource appresourceschemaspy contains marshmallow schema specific route resource appresourceservicespy command modify database state appresourcequeriespy query database additional library anticipate marshmallow since many rest api endpoint take nested body alembic manage database schema migration thought design http error intended human via openfido client message verbose showing generic message specific field validation message appropriate structure openfidoworkflowservice project reference consequence
configuration title configuration server configuration run startup command introduction franklin start default default endpoint query extension stac api specification available however two additional flag enable additional functionality case additional endpoint included server openapi specification hostopenapispecyaml configuring database connection two configuring database first whats shown example startup command case specify user host port password separate argument alternatively specify complete connection string connection string look something like jdbcpostgresqlhostdatabasenameuseruserpasswordpassword general safer configure database connection one component time allows ensure value individually correct leave assembling strange looking string franklin however there one circumstance jdbc url instead cloud provider internal system resulted database requires ssl connection jdbc url configuration start server case like applicationrun serve dbconnectionstring jdbcpostgresqllocalhostfranklinuserfranklinpasswordfranklinssltrue constraint originally discovered google cloud platform environment appears relevant azure setting well withtiles enabling withtiles flag add different sort tile rendering item raster tile item cog asset get additional link relationship tile tile information include available tile matrix set webmercatorquad service url template franklin serve png tile url item collection item footprint tile collection get additional link relationship tile link include information item raster tile instead raster tile franklin serve mapbox vector tile mvt footprint item collection mvts include withfield query parameter property item label style client pas multiple withfield parameter include multiple field vector tile output field missing underlying item rendered resulting mvt label item data footprint label item imported static catalog get asset role datacollection asset collection also footprint start server withtiles flag mvts include withfield query parameter property item label style client pas multiple withfield parameter include multiple field vector tile output field missing underlying item rendered resulting mvt withtransactions enabling withtransactions flag add endpoint creating editing deleting item creating collection endpoint useful deployment scenario dont data youll want serve front transaction extension documented stac api specification franklin added endpoint creating collection well
import node pre processing discsusion proposed adam gibson discussed paul dub ndjs model import framework support different protobuf based framework importing executing model introduced importirmd one problem importing model compatibility different version framework oftenmigrations needed handle compatibility version node pre processor proposed combined model import framework allows annotation based automatic upgrade graph order handle preprocessing node handle thing like upgrade end user specify pre processor via combination interface annotation specifying class implement relevant rule processing automatically discoverable via annotation scanning similar framework annotation look follows kotlin annotation class nodepreprocessorval nodetypes array val frameworkname string information include nodetypes operation type scan upgrade graph framework name relevant multiple import module classpath filter rule intended framework import necessary pre processing hook handle processing node may modify graph graph modification maybe necessary add new node compensate modification node attribute moving input kotlin interface nodepreprocessorhooktype generatedmessagev tensortype generatedmessagev attributetype generatedmessagev attributevaluetype generatedmessagev datatype datatype protocolmessageenum fun modifynode node irnodenodetype tensortype attributetype attributevaluetype datatype graph irgraphgeneratedmessagev generatedmessagev generatedmessagev generatedmessagev generatedmessagev generatedmessagev protocolmessageenum irnodenodetype tensortype attributetype attributevaluetype datatype discussion consequence advantage automatic way extending support model import providing user hook mechanism handling graph modification extends model import process handle node specific way allowing way handling specific interaction simplifying maintenance aspect import framework disadvantage add kind hook model import thus user learn difficult implement user doesnt know work graph may unforeseen consequence testing due graph modification creation
generate idempotency key approved retry refund capture required idempotency key request header current setup user take care generating adding idempotency key request present additional work user take care implementation adyenintegration take care generating idempotency key passing refund capture request process happen background result would possible user retry refund capture request without knowledge idempotency key idempotency key requires following property unique reproduciable idempotency key recreatable transaction reason picked transactionid idempotency key
one application experiment intake publishing visualization author kate hudson deciders nimbus team product delivery team cirrus team tldr problem change course towards consolidating web console function experimentation intake publishing visualization one tool yes consolidatating function experimenter problem statement experiment platform described project nimbus three part web console intake publishing lifecycle management realtime monitoring visualizing result client sdk interpreting experiment configuration activiating experiment data pipeline etl processing cleaning applying automated statistical calculation experiment data generating alert building everything scratch would reason build single website web console given want reflect single user experience built highly coordinated team however existing infrastructure satisfies function single website rather several toolsprojects owned several team experimenter intake reporting function normandy normandy devtools leanplum others publishing lifecycle management graphana realtime monitoring redash amplitude cirrus project visualizing experiment planned yet built significant cost maintaining separate tool also changing direction existing improvement effort considered quo maintain separate tool build seperate visualization tool consolidate intake publishing lifecycle management one tool consolidate intake visualization normandy normandy devtools one tool consolidate publishing lifecycle management visualization experimenter one tool build scratch outcome decided adopt build one tool consolidate publishing lifecycle management visualization experimenter immediate impact roadmaps several existing project including normandy devtools cirrus felt longterm cost maintaining separate application significantly outweighs shortterm impact includes overhead deployment security review buildsystem repo maintainance maintaining cohesive across app boundary overhead authentication api endpoint communicating across apps impact development workflow run make change multiple application furthermore despite increased coordination team building different part felt architecture better reflects user experience cohesive team structure really want experimenter choose consolidate experimenter existing architecture functionality closest needed function crossplatform web console web application front end integration serverside tool public api link architectural overview project nimbus technical overview experiment firefox desktop
diode httpsgithubcomsuzakuiodiode diode provides consequence make easier reason state give easily testable function nice separation view model model update
adr container hook background job hook given user ability customize self hosted runner run job user also want ability customize run container scope job rather locked docker implementation runner may want podman kubernetes even change docker command run give publish example create hook guiding principle extensibility focus make sure flexible enough cover current future scenario even cost making harder utilize hook args map directly yaml value provided user example current runner override home hook shouldnt pas hook env envs user set user input runner invokes container interface set variable actionsrunnercontainerhooksusersfoorunnerhooksjs entrypoint hook handler partial opt must handle every hook pas command args via stdin exit code success every exit code failure support runner command support job hook timeout send sigint process fail terminate within reasonable amount time send sigkill eventually kill process tree example input look like json command jobcleanup responsefile usersthbooprunnerworkguidjson args state efeadcfdafdbdbddfbac command command expect invoke responsefile file write output command output args specific argument command state json blog pas around maintain state covered detail writing response file text written stdout stderr appear job step log mind support way actually return data wrapping json unique tag processing like command writing file user typically view logging information safe action worry someone accidentialy logging unsantized information causing unexpected unsecure behavior eventually plan move stdoutstderr style command favor runner cli investing area doesnt make lot sense time writing file communicate isnt ideal pattern existing pattern runner serf well let reuse output output must correctly formatted json example output look like state container efeadcfdafdbdbddfbac network githubnetworkbdbfbc service redis daaebdadabbdcdfeeedbabb port network githubnetworkbdbfbc alpine true state unique field command return empty store state pas future command overwrite next hook invoked return unique state field dependent upon command run versioning version hook launch needed always major version split hook future ship beta allow breaking change month job job currently variety field correspond container consider allowing hook populate new field job scope original release however hook hook implemented high level map action runner rather specific docker action like docker build docker create mapping runner action create extensible framework flexible enough solve user concern future providing first party implementation give user easy starting point customize specific hook like docker build without write full blown solution would provide hook mirror every docker call make expose hook help support user expectation user may noop multiple hook dont correspond case dont want way feel clunky user understand hook implement ignore isnt great doesnt scale well dont want build solution may add hook mapping runner action updating hook painful experience user overwhelming easier tell user build hook track data rather hook runner certain information provide information back hook expose container create return container created container run container give image say create run container dont store container runner map better scenario dont really container preparejob hook preparejob hook called job started pas job service container job expect prune anything previous job needed create network needed pull job service container start job container start service container write response file information required container alpine otherwise optional field want set job otherwise unavailable user return health check succeeded jobservice container started hook always called container hook enabled even service job container exist job allows fail job implement default job container want job container provided example input command preparejob responsefile usersthbooprunnerworkguidjson state args jobcontainer image node workingdirectory wthbooptestthbooptest createoptions cpu environmentvariables nodeenv development usermountvolumes sourcevolumepath mydockervolume targetvolumepath volumemount readonly false mountvolumes sourcevolumepath homethomasgitrunnerlayoutwork targetvolumepath readonly false sourcevolumepath homethomasgitrunnerlayoutexternals targetvolumepath readonly true sourcevolumepath homethomasgitrunnerlayoutworktemp targetvolumepath wtemp readonly false sourcevolumepath homethomasgitrunnerlayoutworkactions targetvolumepath wactions readonly false sourcevolumepath homethomasgitrunnerlayoutworktool targetvolumepath wtool readonly false sourcevolumepath homethomasgitrunnerlayoutworktempgithubhome targetvolumepath githubhome readonly false sourcevolumepath homethomasgitrunnerlayoutworktempgithubworkflow targetvolumepath githubworkflow readonly false registry username foo password bar serverurl httpsindexdockeriov portmappings tcp udp service contextname redis image redis createoptions cpu environmentvariables mountvolumes portmappings tcp udp registry username foo password bar serverurl httpsindexdockeriov field description arg field jobcontainer optional object containing information specified job container image required string containing docker image workingdirectory required string containing absolute path working directory createoptions optional optional create specified yaml environmentvariables optional map key value envs set usermountvolumes optional array user mount volume set yaml sourcevolumepath required source path volume mounted docker container targetvolumepath required target path volume mounted docker container readonly false required whether mount read mountvolumes required array mount mount container field sourcevolumepath required source path volume mounted docker container targetvolumepath required target path volume mounted docker container readonly false required whether mount read registry optional docker registry credential private container registry username optional username password optional password serverurl optional registry url portmappings optional array sourcetarget port map container service array service container spin contextname required name service job image required string containing docker image createoptions optional optional create specified yaml environmentvariables optional map key value envs set mountvolumes required array mount mount container field sourcevolumepath required source path volume mounted docker container targetvolumepath required target path volume mounted docker container readonly false required whether mount read registry optional docker registry credential private container registry username optional username password optional password serverurl optional registry url portmappings optional array sourcetarget port map container example output state network githubnetworkbdbfbc jobcontainer efeadcfdafdbdbddfbac servicecontainers redis daaebdadabbdcdfeeedbabb container efeadcfdafdbdbddfbac network githubnetworkbdbfbc service redis daaebdadabbdcdfeeedbabb port network githubnetworkbdbfbc alpine true cleanup job cleanupjob hook called end job expects stop running service job container equiavalent pod stop network one exists delete job service container equiavalent pod delete network one exists cleanup anything else created run input look like example input command cleanupjob responsefile null state network githubnetworkbdbfbc jobcontainer efeadcfdafdbdbddfbac servicecontainers redis daaebdadabbdcdfeeedbabb args args provided output expected run container step runcontainerstep called per container action job expects pull build required container fail cannot run container action return exit code container stream step log output stdout stderr cleanup container executes example input image command runcontainerstep responsefile null state network githubnetworkbdbfbc jobcontainer efeadcfdafdbdbddfbac servicecontainers redis daaebdadabbdcdfeeedbabb args image node dockerfile null entrypointargs devnull entrypoint tail workingdirectory wthbooptestthbooptest createoptions cpu environmentvariables nodeenv development prependpathfoobar barfoo usermountvolumes sourcevolumepath mydockervolume targetvolumepath volumemount readonly false mountvolumes sourcevolumepath homethomasgitrunnerlayoutwork targetvolumepath readonly false sourcevolumepath homethomasgitrunnerlayoutexternals targetvolumepath readonly true sourcevolumepath homethomasgitrunnerlayoutworktemp targetvolumepath wtemp readonly false sourcevolumepath homethomasgitrunnerlayoutworkactions targetvolumepath wactions readonly false sourcevolumepath homethomasgitrunnerlayoutworktool targetvolumepath wtool readonly false sourcevolumepath homethomasgitrunnerlayoutworktempgithubhome targetvolumepath githubhome readonly false sourcevolumepath homethomasgitrunnerlayoutworktempgithubworkflow targetvolumepath githubworkflow readonly false registry null portmappings example input dockerfile command runcontainerstep responsefile null state network githubnetworkbdbfbc jobcontainer efeadcfdafdbdbddfbac service redis daaebdadabbdcdfeeedbabb args image null dockerfile wactionsfoodockerfile entrypointargs hello world entrypoint echo workingdirectory wthbooptestthbooptest createoptions cpu environmentvariables nodeenv development prependpathfoobar barfoo usermountvolumes sourcevolumepath mydockervolume targetvolumepath volumemount readonly false mountvolumes sourcevolumepath mydockervolume targetvolumepath volumemount readonly false sourcevolumepath homethomasgitrunnerlayoutwork targetvolumepath readonly false sourcevolumepath homethomasgitrunnerlayoutexternals targetvolumepath readonly true sourcevolumepath homethomasgitrunnerlayoutworktemp targetvolumepath wtemp readonly false sourcevolumepath homethomasgitrunnerlayoutworkactions targetvolumepath wactions readonly false sourcevolumepath homethomasgitrunnerlayoutworktool targetvolumepath wtool readonly false sourcevolumepath homethomasgitrunnerlayoutworktempgithubhome targetvolumepath githubhome readonly false sourcevolumepath homethomasgitrunnerlayoutworktempgithubworkflow targetvolumepath githubworkflow readonly false registry null portmappings tcp udp field description arg field image optional string containing docker image otherwise dockerfile must provided dockerfile optional string containing path dockerfile otherwise image must provided entrypointargs optional list containing entry point args entrypoint optional container entry point default image entrypoint overwritten workingdirectory required string containing absolute path working directory createoptions optional optional create specified yaml environmentvariables optional map key value envs set prependpath optional array additional path prepend path variable usermountvolumes optional array user mount volume set yaml sourcevolumepath required source path volume mounted docker container targetvolumepath required target path volume mounted docker container readonly false required whether mount read mountvolumes required array mount mount container field sourcevolumepath required source path volume mounted docker container targetvolumepath required target path volume mounted docker container readonly false required whether mount read registry optional docker registry credential private container registry username optional username password optional password serverurl optional registry url portmappings optional array sourcetarget port map container output expected currently build container action start job hook move time building hook could expose hook buildpull container action called start job would require hook author track build container state could painful run script step runscriptstep expects invoke provided script inside job container return exit code stream step log output stdout stderr example input command runscriptstep responsefile null state network githubnetworkbdbfbc jobcontainer efeadcfdafdbdbddfbac servicecontainers redis daaebdadabbdcdfeeedbabb args entrypointargs runnertempabcsh entrypoint bash environmentvariables nodeenv development prependpath foobar barfoo workingdirectory wthbooptestthbooptest field description arg field entrypointargs optional list containing entry point args entrypoint optional container entry point default image entrypoint overwritten prependpath optional array additional path prepend path variable workingdirectory required string containing absolute path working directory environmentvariables optional map key value envs set output expected limitation support linux launch hook set runner admin thus supported self hosted runner consequence support non docker scenario self hosted runner allow customer customize docker invocation shipmaintain doc docker hook open source repo example support hook add enough telemetry able troubleshoot support issue come
migration exchange current onchain approach handle demand certificate matching scalable enough prone frontrunning hard extend new feature change provides new way tradingmatching certificate offchain order book matching engine consequence demand private onchain component new offchain matching engine provides superior throughput extensibility transition orderbook make matching much easier reason make buyer onboarding easier case dont even interact blockchain end active development package marketmatcher marketmatchercore market
displaying lobster news issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
postcodesio get postcode coordinate approved get postcode coordinate get browser postcodesio instead geocoder gem make simple ajax call browser consequence avoid creating endpoint server therefore reducing load manage side rely service trusted google map open source based open data
gcp example cloud platform issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
firebase infrastructure deciders eimi james alli susie related previous adr see modular architecture adr technical story evaluating firebase backend replacing aws infrastructure except pstt client queue instance talk pstt problem statement quite component build backend get dpe stable point although initially decided development aws working aws quite challenging steep learning curve single project cycle weve reached point infrastructure microservices setup unfortunately resource removed project priority shifted research backend development halted picking development task half baked microservices difficult relearn weve developed complete integration order simplify backend development looking firebase google cloud platform since firebase plaftorm target development startup provides many feature box could speed developing backend namely realtime database authentication keeping possibility open offline mobile multiuser solution must consider technical security development transfer upfront learning nontechnical legal cost since weve designed react component reusable question whether aws gcp make easier transfer previous project rebuilt scratch including infrastructure realistically matter cloud provider description microservices name technology description firebase gcp firebase hosting main component hosted solution firestore gcp firestore database database additional capability realtime audio converter function gcp function serverless serverless service strip audio original content aws uplaoder function gcp function serverless serverless service uploads file stt client aws pstt sqs consumer consumes message send platform stt third party forward updating message topic pstt stt client queue aws sqs sqs service take new job message send pstt client notification function function serverless serverless service take notification message pubsubs serice update firestore stt topic aws sts topic anything subscribe notification help collecting notification message created stt client audio converter function listening storage change aws proxy function listening storage change stt client listening message job creation queue step user uploads file storage firebase audio converter function detects file upload strip audio file upload file storage aws proxy function detects file upload retrieves key gcp assumes role aws iam uploads file event trigger sent queue stt client creates new plaform stt job upload file platform stts bucket send message file loaded platform stt forward notification platform stts stt notification aws notification subscription function update firestore firestore listener update firebase driver security authentication pstt integration legal transfer technical feasibility dpe technical feasibility reproduceability cost time money engineering opportunity considered aws firebase aws outcome firebase aws combined pstt integration feasible even cross acount complication feature authentication user specific data retrieval integration database without migration already completed firebase provides abstraction around security integration database well function save time around project feature realtime database easy api let progress firebase still thing deployment management worked stretch goal believe save time simply overall architecture code positive consequence faster turnaround development authentication realtime database beneficial dpe requirement managed service many abstraction secondary positive consequence growing knowledge gcp bbc login stretch goal monitoring given box consolelog map logging gcp logging console negative consequence upfront cost learning developer many unknown looked security concern redesigning architecture redesigning database model transfer possible infrastructure pro con discus pro con needed clear idea component far socalledcompletion aws gcp pro con technology describe currently anywhere noted indicator stretch goal client user view alter data initiate transcription process aws gcp integration api work aws gcp deployed web endpoint endpoint secured form authentication aws certbased authentication set individual user data file upload setup access gcp already authentication set gcp whitelisting based user specific data retrieval file upload easy way showing progress uploading file storage access see security rule setup open default potential bbc login integration user friendly var storageref firebasestoragereffoldernamefilejpg var fileupload documentgetelementbyidfileupload fileuploadonchange functionevt var firstfile evttargetfile get first file uploaded var uploadtask storagerefputfirstfile uploadtaskonstatechanged function progresssnapshot consolelogsnapshottotalbytestransferred progress upload api database api connects database crud operation api invokes audio conversion api invokes transcription service api notified pstt client update transcription secure connection database audio conversion transcription service aws gcp api incomplete connect aws buggy late aws deployed api deployed postgres full integration database migration setup local environment setup environment set complete gcp local environment setup setup firebase emulator tool deployed firestore realtime nosql full integration database migration necessary nosql database also possible store reference specific data simplifies certain aspect file retrieval setup client also simplified abstraction database connection remove settimeout setup client data retrieval firestore offer realtime data retrieval audio converter convert input audio store output accessible online location handle long form content aws gcp deployed uploads audio content storage integration pstt client aws integration api queue message sent api audio converter queue environment set complete gcp integration client ive done currently operating due cost free tier environment set complete follow instruction doc pstt client send content url pstt send notification change api send output back user getting content bucket currently aws gcp deployed logic functional unknown tested gcp iam aws gcp integration requires account creation credential one access pstt client queue another pstt client update database json transcription blob store key gcps create iam aws part pstt client store credential iam gcps gcp service assumes iam role something datalab already done knowledge aws continuing development aws mean picking left currently setup around every single microservice difficult say far setup jenkins integration could provide challenge good best practice ensured infosec approved good microservices infrastructrually bad best practice mean jumping many developmental step could time consuming bad currently dont integration api bad api connect faulty moment bad easy way setup local testing environment bad migration set gcp aws mean firebase aws combined see eimi spoken several people clear unknown around crossacount integration deployment pipeline etc good simplifies code client good authentication complexity handled good whitelisting system already place good give local test environment bad complexity around cross acount integration bad steep still learning curve secondary good realtime database link pro con lesson small firebase project lifecycle gcp function gcp environment set done following instruction doc
storybook business deciders pietro eimi sometime problem statement want easily able demonstrate component refactor group related component easily test new idea component problem demonstrate component currently clone run local server demonstrate component dpe easy solution individual would like quickly see catalogue tested usable component dpe problem refactor group related component overly complicated component difficult test break isolate component easier understand extend also easily define interface component help people contribute maintain dpe additionally post explains antipattern scenario want avoid here typical situation youre going spec new page develop component look familiar youve seen elsewhere plan task based understanding component already implemented agreeing timing starting new sprint dig around code bit horrified realize existing component appropriate reuse three none great copy paste existing component tweak copy suit creates tech debt nasty code smell fact kent beck martin fowler call number one code smell refactoring improving design existing code modifyimproveextend existing component experience suggests expensive become expensive modificationimprovementextension develop new multifunctional component take lot time organisation there case wanted reuse internal tool component simply possible wasnt isolated component surfaced catalogued anywhere cataloguing important step heavy project finding discoverable project open source help others symbiotic nature help return problem easily test new idea component currently cannot implement new idea component keep history unless separate branch transparent different implementation catalogue different implementation help showcase test certain component people easily driver easy reason around considered catalogue framework outcome going storybook reason stated positive consequence storybook positively effect ease demonstration discoverability documentation testability project future negative consequence require development work additional link site point
aws example cloud platform issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
usedotenvformanagingenvironmentvariables accessing env directly without wrapper limited introduce problem want tooling help guard missing environment variable nil accidentally provided start process preferable fail fast explicit message without nil passed stack cause strange behaviour code designed dependency instead adding nil guard throughout codebase required environment variable envfetchfoo default managed centrally previously figaro purpose deprecated httpsgithubcomlaserlemonfigaro supported gem ensure get support form fix security patch also want able stub environment variable test suite easy example environment variable feature flag mechanism want stub value test scenario without influenced real value loaded mutating actual env value allowenvto receivewithboxidandreturn possible may unexpected consequence part process test variable figaro handy abstraction layer could stub allowfigaroto receiveenvwithfooandreturnbar consider stub environment variable dotenv load environment variable consequence docker docker compose added project environment variable loaded dockercompose envfileenvdevelopment rather dockercomposeenv pattern file managing environment variable env dockercomposeenv undesirable due overhead keeping sync dotenv load environment variable doesnt offer interface figaro dotenv youd access writing envfoo rather dotenvfoo make supporting climate control support testing
make repository iterable observationrepository whalerepository implement iterablet enable searching respective list since observationrepository whalerepository implement interface repositoryt may make sense extend iterablet repository rather subclass extend iterablet repository remove iterablet observationrepository whalerepository consequence current future subclass repository iterablet built
automatic data scraping system deployed heroku organized follows worker dyno process job scraping task queue background scraping task populated queue via oneoff dynos scheduled run periodically via heroku scheduler example oneoff script pull data climatescapes airtable schedule initial scraping task newly added orgs background worker task queue driven heroku documentation justifies approach scalable reliable worker fetch scraping task background scraping access twitter api put result postgres database pull approach scraping task populated scheduled oneoff dynos push approach considered backend maintains web interface separate dyno climatescape website via netlify function zapier pullbased approach chosen following advantage dependency netlify function zapier avoided reducing number concept developer learn environment manage hand even push approach oneoff script heroku could needed anyway schedule periodic rescraping information organization backend doesnt expose post put interface worry protection authentication form backend web interface might eventually added monitoring number scraping task queue interface could probably readonly authentication might required background worker done see also preceding message thread pushbased approach decided pullbased instead pushbased approach discussion
module naming module package naming rule updated problem statement number module count increased new channel feature trendyol android application problem lead misunderstanding among team creating new module follow rule package name cannot contain architectural layer name unless feature multiple module different layer data domain nested module group except channel group channel name prefer kebabcase feature module name trendyol feature module repeat trendyol package name path impl module include impl package name module path channelgroupchannelnamefeaturenamearchitecturallevelapiimpl package name comtrendyolchannelgroupchannelnamefeaturenamearchitecturallevelimpl module name package name trendyolhome comtrendyolhome commonprice comtrendyolcommonprice mlbssetup comtrendyolmlbssetup trendyolcheckoutui comtrendyolcheckout mlbsmealcheckoutapi comtrendyolmlbsmealcheckout mlbsmealcheckoutimpl comtrendyolmlbsmealcheckoutimpl commonwidgetdomainimpl comtrendyolcommonwidgetdomainimpl
adr activity bottom sheet instead fragment superceded displaying nonpersistent bottom sheet materialio recommends bottomsheetdialogfragment unfortunately doesnt play nicely onscreen keyboard sheet includes input text field onscreen keyboard shown aligns bottom edge field everything beneath focused text field get covered keyboard standard behavior onscreen keyboard activity worked around panning resizing layout whenever keyboard shown reason changing softinputmode dialog doesnt affect dialog able align entire sheet keyboard activity called bottomsheetactivity instead bottomsheetdialogfragment mimic modal sheet translucent background consequence bottomsheetactivity doesnt support dragtodismissing could bottomsheetbehavior future add support
ouch solid caching construct solid cache updating property rendered item work look like caching item reference reference equality determined tried index issue instead updating field news item replace entirely new one different reference consequence becomes easier difficult risk introduced change mitigated
server language easi developer language support application server side considered language widespread web framework ruby python javascriptnode outcome chosen top reason selecting team house expertise application team immediately ready produce client value due familiarity language ecosystem also modern strong typed language provides compile time safety opposed common web app ruby python javascript benefit language mature web framework rail django outweighed flexibility frontend framework driven json api data retrieval latter provides excellent tooling standard library ecosystem building mature stable maintainable apis pro con familiarity team common tool across truss project static typed relatively immature compared rubypython web app ecosystem language widespread web framework ruby python easy bootstrap common application feature strong mature ecosystem community dynamically typed application team toolset javascript node frontendserver language single package system npm yarn dynamically typed application team toolset especially server side application
specific environment variable editor jan proposed user adt tool might want edit adrs editor thats default system editor adt introduce additional adreditor adrvisual variable user may choose editor adrs enhancement proposal project issue read editor command additional adreditor adrvisual variable custom variable set fall back reading editor visual variable extract editor command resolving code adr class move dedicated class improve testability make modification easier reflect adding new variable doc consequence adr tool behavior remains backwardcompatible editor command resolving move launcher class
support type definition tosca service template user story toscana support node type definition tosca service template considered support node type definition dont support node type definition outcome chosen dont support node type supporting node type definition would nice afford effort limited resource benefit small pro con support node type definition complete implementation tosca developed quite complicated dont support node type definition according tosca spec possible add additional requirement node template must added node type without custom type definition way modeller specify additional requirement
adr language source code documentation teet multisite project development work done oulu tallinn office developer customer native language code database api definition documentation english existing code reused project different source language may necessary domain concept must well defined updated glossary term consequence con customer communication difficult native term cant pro lock finnish speaking developer pro english facto code language
net core language log monolith one language platform must selected implementation decided net core platform new generation multiplatform fully supported microsoft opensource community optimized designed replace old net framework language popuplar language net ecosystem year commercial experience dont commercial experience consequence whole application implemented objectoriented language net core framework net core application executed window macos linux
drop entity service entity service created manage crud pipeline resourceproviders artifactstores practice minimal code intention smarter crud done via temporal facility amount code infra needed full service wasnt justified drop service move functionality apiserver consequence reduces cluster complexity moving part significantly improving maintenance usage
onnx runtime module implemented proposed adam gibson discussed saudet way providing ndj way running onnx module easily compatible onnx community gold standard onnxruntime javacpps onnxruntime binding similar manner ndjtensorflow allowing ndj ndarray format interops onnxruntime implement simple api similar graphrunner sit top javacpps lower level onnxruntime binding module follow similar structure ndjtensorflow module focusing indarrays data interchange format otherwise pas execution onnxruntime main api graph runner work follows java trygraphrunner runner new graphrunner mapstringindarray input new hashmap initialize input mapstringindarray output runnerruninputs process output core logic contain following component loading onnx file graph runner similar nature ndjtensorflow interop onnxruntimes version ndarraytensor different acceleratorsbackends similar ndjtensorflow javacpp specific version tensorflow module rely user picking right dependency link different build cpu gpu exist equivalent onnxruntime found user include version onnxruntime wish similar link particular implementation library include backend ndj happen via maven
operate first community cloud support process deprecated nolongerrelevant deciders goern technical story httpsgithubcomopenservicesgroupscrumissues problem statement general individual team onboards service often assumes sole role operating service indefinitely various issue associated member sre team unable offer sufficient support service support refer operational support improvement incident fix patch upgrade etc responding end user question via github slack mailing list pertaining service siloed knowledge result fewer team member able perform review pertaining service documentation appservice suffers since one person able writeunderstand one engineer responsible maintaining service devote large portion engineer time operate service opposed building new feature operate first proposed solution apply sre call procedure way alleviate aforementioned concern driver sre member operate first opportunity call rotation call rotation able scale work take large portion engineer sprint call person sufficient support perform call duty aiming call coverage maintain improve documentation call duty considered consider duration engineer spends call frequency rotation call rotation happen every week call rotation happen every day outcome selected could result major portion engineer sprint time spent call thus scale well process call list maintain call list engineer perform site reliability operate first cloud official list maintained schedule scheduled rotation happen every working day engineer call expected perform following call duty call duty call perform following duty respond enduser questionscommentsconcerns regarding operation operate first slack support operation general operate first mailing list operate first operation repos apps operation check notification operate first ocp console first responder issue incident operational issue service managed sre team follow documentation resolve issue documentation andor runbook exists ensure updated issue resolved document topic work oncalllog call engineer know resolve issue documentation exist onus call engineer reach rest sre team assistance event call engineer assisted another engineer still call engineer responsibility ensure resolution step fully documented form runbook next call engineer essential helping break knowledge silo handover via call chat inform next call engineer oncalllog move checkbox current call engineer last one list shuffle list oncalllog manually call duty requirement call engineer offer sufficient support call engineer call engineer know resolve issue document resolve issue
adr sdl support multiple resolution want support variety screen resolution planning fixed resolution tile render game classic frogger traditionally played grid tile extra space vertical space draw want something similar game internal coordinate represent grid renderer able map resolution one way ive seen solved multiple coordinate system one coordinate system reprersenting pixel screen one coordinate system representing physical location game world game logic would implemented term world coordinate would converted screen coordinate renderer another way solve target specific resolution game logic leverage sdls logical screen feature scale game given resolution attempted spike world coordinate found added lot complexity existing codebase given extra complexity going stick leveraging sdls logical rendering feature solve problem might something revisit future sdl support multiple resolution targeting internal screen consequence screen physic module updated support change
domain layout raster foundry web presence landing page customer acquisition blog curating content relevant project objective given still early product development process desire keep solution landing page blog simple also flexible easily iterated party involved building upon experience gained maintaining product like cicero hunchlab opentreemap following made regarding raster foundry domain layout canonical domain wwwrasterfoundrycom web application resides apprasterfoundrycom blog resides blograsterfoundrycom far platform drive landing page blog former static website built jekyll hosted via github page support amazon cloudfront http latter based medium consequence many successful product singlepage application follow appdomaincom naming convention keep landing page application separate including datadog librato fastly still could add additional overhead individual interacting raster foundry user bookmark navigate otherwise recall application domain regard landing page building jekyll increase barrier entry nontechnical user even though everyone currently involved raster foundry project familiar markdown markup language jekyll brings along additional concept front matter layout variable collection mastered order make meaningful change hosting jekyll website deferred github page alleviates burden assembling deployment pipeline relinquishes control build process github also support http create amazon cloudfront distribution github page origin lastly medium content creation platform accommodating content creator consumer come several limitation layout content organization restricted thirdparty solution web analytics allowed trading access growing content discoverability engine
serverside static data loading order support performant blocklevel redistricting state able quickly perform manipulation operation statespecific topojson object adr provides rationale topojson adr describes clientside approach storing data adr provides rationale approach storing data serverside current approach keep topojson file stored retrieved loaded memory application start increase startup time allows rapid access file loaded memory however size topojson object increase complexity districting geometry california particularly complex geometry requires approximately mib memory state complex upper bound memory required per state calculate memory requirement based assuming state requires much memory california get upper bound approximately mib gib reality amount memory required lower give worstcase scenario boundary additional constraint timeline time adr written planning launch support blocklevel redistricting state within week appropriate solution attainable within timeline considering upper bound gib keep state loaded memory would allocate additional memory order application continue serving request allocating approximately gib memory sufficient fargate also requires additional vcpus provisioned higher memory allocation add additional cost running task vcpus gib ram would cost approximately per month per task likely run one instance userfacing environment enable rolling deployment approach would implement external caching layer service like aws elasticache approach external shared inmemory data store good fit architectural perspective would require substantial integration effort application perspective term cost rlarge instance gib ram would cost additional per hour approximately per month would reduce amount memory allocate per application task though would still maintain baseline ability serve application compute district manipulation may desirable longterm solution situation able scale ability serve application beyond two task likely feasible current timeline worth additional engineering cost low scale could also define separate service individual state way distribute memory load appealing ongoing infrastructure cost perspective would allow separate userfacing application service data processing service introduces significant amount architectural complexity especially respect routing request particular state appropriate service also doesnt solve memory allocation problem fargate merely distributes would allow independent scaling busy tenant large amount generic application traffic doesnt tax individual tenant however optimization may premature without recent production metric usage pattern rely given time constraint desire minimize application development work decided provision memory fargate allow keeping topojson object state memory application service instance allocate memory per task start running minimum number task necessary two task production allow rolling release one task staging allow testing prior production release consequence approach couple application server topojson inmemory store mean add application service instance handle web traffic computation would scale inmemory store well rather scaling independently given allocating gib service instance additional instance cost additional per month could become expensive period high traffic usage may make external caching service appealing cost perspective may account data loading process application health check task declared healthy added load balancer rotation inmemory cache warmed state likely increase application startup deployment time however given intend run multiple instance application task primarily impact time recovery deployment time rather application availability deploy also keep mind fargate currently upper limit gib allocated ram task arent likely run shortterm could become problem introduce significant amount additional geographical unit processed districtbuilder offer support custom unit service support geographic unit beyond state district may merit alternate approach memory requirement reevaluated additional factor aware point may want able support multiple version data state example well launching state census data census data becomes available well load well would two version data state would effectively double amount memory needed
django project based django dont structure make project hard read handle thing store apps one place support different environment store project related configs make skeleton django httpsgithubcomhuifenqidjangoprojectskeleton consequence make new project skeleton apply structure old project refactoring
firestore database order store data provided user different form reduce amount integration complexity weve decided one database firebase offer firebase umbrella realtime database firestore similar many feature google recommends firestore new developer built upon success realtime database also purpose firestore better choice offer offline support android web client whereas realtime support android client onebigjsontree structure realtime become difficult maintain grows documentbased firestore offer better organisation provision collection scaling firestore automatic whereas scaling realtime database requires sharding link difference firestore realtime database
backend language issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
fetching incident update signal frontend application number different endpoint provide data render overview incident first one private signal endpoint second private search endpoint return data structure expectrequire different parameter another way retrieving incident geographyendpoint geographypublicendpoint endpoint accept geo location return incident lie within number occasion request made one private endpoint retrieve recent set data api occasion mount incidentmodule search query entered search form private signal endpoint queried search query entered private search endpoint queried component signalsincidentmanagement action requestincidents set filter applied selected filterform component picked filter container component dispatched store component signalsincidentmanagementcontainersfilter action applyfilter searchbar container receives submit event every time input searchbar submitted searchbar container dispatch action trigger another fetch submit event trigger redirect incidentmanagement module see detail component signalscontainerssearchbar action setsearchquery pagination item clicked incident overview page render pagination component every click pagination item result action dispatched action turn trigger fetch result either search endpoint signal endpoint depending presence search query component signalsincidentmanagementcontainersincidentoverviewpage action pagechanged column order changed incident overview page show table sortable column clicking column header dispatch action action similar pagechanged trigger fetch result either search endpoint signal endpoint component signalsincidentmanagementcontainersincidentoverviewpage action orderingchanged incident successfully patched individual incident patched incidentdetail container navigating back detail page overview page show change applied incident therefore patchincidentsuccess action dispatched new set updated incident retrieved component signalsincidentmanagementcontainersincidentdetail action patchincident
integration event store audit change feed purpose adr proposes solution several longstanding challenge marainworkflow solution currently provide kind audit log message received andor processed neither provide kind history workflow instance work done address latter described github issue associated pull request take approach storing previous version workflow instance time new version stored address audit log requirement allow external actor notified change occurred without feature much harder debug issue workflow instance cant see actionsevents brought current state whilst possible workflow action effect arbitrary change part transition experience implementing workflow led conclusion logic implemented way difference action required part state change action could happen result observing change taken place example expense claim workflow example shown core workflow concept submit transition take place claimant submitted claim approval part transition might require via action appropriate approver identified claim somehow marked thir attention cannot done transition cannot succeed however may also decide want management dashboard allow see statistic expense claim present would implemented adding action various transition update dashboard however core task submitting expense result would happy happen result observing state change take place rather part allowing external service observe state change taken place inside workflow engine act needed allows keep workflow definition focussed core responsibility ensuring model directly related activity also make workflow definition maintainable fewer reason change implement would useful equivalent cosmos change feed mechanism many azure service publish event event grid would allow service react event without explicitly integrated workflow present marainworkflow capable writing extensive log message appinsights hugely useful diagnosing problem led faulted workflow instance however easy way detect workflow instance enters faulted state uibased implementation normally manifest error message user interface followed complaint user longer trigger transition worflow instance faulted instance permitted accept trigger addition simple way detect faulted instance occur would greatly improve ability proactively address problem workflow engine problem addressed introducing following feature persistence event capturing fact workflow instance state change change taken place within workflow engine creation change feed workflow engine writing generic event cover workflow instance creation transition completion faulting update workflow engine reimplement workflow instance event sourcing pattern corvuseventstore integrated provide underlying event store workflow instance considered aggregate root always storage siloed tenant require additional configuration supplied workflow engine per tenant determine event data stored add mean publishing event interested party first instance aim keep simple possible implementing webhook based approach cloudevents standard publish event service statically registered workflow engine allow prove event publishing approach quickly simply future extended solution publish event external messaging system azure event grid service bus consequence complexity change add complexity codebase two area require additional storage event data configured part tenant onboarding additional infrastructure form event grid topic production support present workflow instance enters faulted state way recover manual modification workflow instance document storage event store approach implemented becomes impossible change effected adding event aggregate necessary provide tooling assist identification recovery faulted instance however change also make easier identify faulted instance handling event subscriber event must prepared handle sequence message must idempotent whatever mechanism choose publish event workflow engine adopt position cannot guarantee ordering message cannot guarantee message published exactly due possibility might publish event fail persist fact dispatched
public discovery access metadata work collection publicly viewable binary content file within work restricted based visibility permission grant discovery access public work collection creating appropriate acl work collection discovery access stipulates metadata viewable binary content downloadable consequence access controlled acl restrict individual work collection later needed also requires additional acl record per resource
configuration file prefer config file packagejson json yaml file extension supported prefer json yaml prefer yaml yml rationale ides often support schema validation config file individual config file improve discoverability avoids cluttering packagejson providing file extension allows config file formatted without whitelist map file parser json preferred yaml unless comment required json prescriptive provides room error yaml official extension recommended yaml yml filename
aleph item endpoint behavior june aleph endpoint item command query new updated accession item following behavior querying endpoint first time starttime parameter endtime result last successful source response provided last successful mean new updated entry source response successfully uploaded caiasoft endtime parameter must provided first request every source response include endtime result denotes end time query large number result aleph may return nonempty nextitem entry response indicates entry retrieve additional source request made making request additional entry starttime parameter initial request endtime parameter endtime entry previous source response nextitem entry previous source response provided first run item functionality previous source response derive starttime handled providing default source response default source response starttime simple datestamp without time order avoid timezone issue note first run timestamps starttime endtime parameter provided aleph avoids issue regarding outofsync clock server timezone issue aleph providing timestamps parameter consequence support nextitem continuation item step run multiple iteration result last iteration input next iteration iteration consists querying aleph newupdated item sending new item caiasoft endpoint sending updated item caiasoft endpoint storing last successful result next iterationjob iteration operate within single job continue long aleph response contains nonempty nextitem entry
generate pdfs prince background easi able export information pdf format looking specifically exporting system intake business case future expect range report grow overall scope easi driver pdfs accessible requires pdfua profile appropriate tagging pdf tooling doesnt good support accessibility feature choice somewhat limited project requires hosting everything privately rule saas generating pdfs docraptor wed like generate pdf html code allows develop pdfs workflow tool code currently existing user story easi chosen solution deploy commercial software product prince htmltopdf conversion commandline program deploy via aws lambda lambda accessible backend via public internet permission access service needed metric logging react frontend send html backend invoke lambda return resulting pdf user browser think best solution term providing highlyaccessible pdfs saving developer time building supported actively developed tool hosting prince within private lambda function minimizes potential attack surface pro con prince mature commercial software product convert html pdf best htmltopdf term creating accessible pdfs pdfua profile offer control pdf file tagged allowing reuse existing code workflow save lot development time commercially supported product long history readytogo lambda distribution requires infra work setup lambda function closedsource annual license required kyear already dhs government organization puppeteer remote controlled headless chrome allows chrome builtin pdf generator via node module provides level pdf tagging chrome new taggedpdf creates messy cluttered tag hierarchy cant customized requires infra work setup lambda function open source free unidoc docx docx isnt desirable pdf isnt clear docx fulfills accessibility requirement cant reuse existing application presentation run process doesnt require additional infra open source cost reactpdf pdfkit javascript library code run within frontend application support generating accessible pdfs support tagging doesnt require additional infrastructure open source free gotenberg dockerbased service created pdfs various document format doesnt support generating tagged pdfs docker image isnt immediately compatible running lambda open source free microsoft printtopdf component window allows window application create pdfs creates inaccessible pdfs embedding image webpage intuitive user print download file may installed default free work window application unidoc pdf library generating pdfs doesnt support creating tagged pdfs cant reuse existing application presentation run process doesnt require additional infra open source cost year
zero trust architecture proposed ordering system communicates upstream downstream system cloud environment cant rely assumption request subnetwork safe ordering system implemented modularized monolith module eventually extracted become dedicated service secure call early stage make easier migrate module service internal call module contain security info auth claim info beginning consequence applying approach add complexity communication module within domain may obvious many developer turn allows proper separation communication module readiness extracting module service suggested approach require involving identity service increase complexity internal logic within monolithic service simplify scaling dedicated service optimization within monolithic module required module incorporated reference zero trust architecture
naming constraint criterion namespaces tag object user named thing bfd simple url friendly convention needed endpoint readable accessible multiple locale candidate limited length limited alphanumeric url friendly character utf commentary rest based service end huge illegible url escape character limitation user wish share bfd related url url make obvious data theyre going get furthermore url related name easy write result name could found url limited way encourage readwriteability limiting length name ensures readability limiting alphanumeric url friendly character ensures url isnt full hardtodecypher escape sequence allowing utf mean alphanumeric includes wide range character nonenglishlatin character set approved limited length limited alphanumeric utf author ntoll
passpack companyname httpswwwpasspackcom companynameusername people tab transfer companyname transfer passpack httpswwwpasspackcomgettingstartedpasspackgettingstartedadminenpdf group owner name aliyunosscontractdocak consequence team leader team member
adr internationalisation panoptes translation api nextjs apps support localisation via locale passed page url panoptes translation api localises following resource project project page workflow tutorial field guide localised string given resource fetched specifying resource type language apitranslationstranslatedtypeprojecttranslatedidlanguagefr string identified unique key mapped localised text key translation api needed integrated nextjs apps library project could served locale enus english nextjs apps update getstaticprops fetch translation string alongside translatable resource project project page add map translation string project pas page prop projectstrings localised property converted computed property mobx state tree model backwards compatibility older code projecttitle map projectstringsgettitle clientside component add custom datafetching hook usepanoptestranslations fetch translation workflow tutorial field guide store map translation string resource workflowstrings workflow task given localised translation since task arent firstclass resource panoptes task string extracted workflow translation assigned workflow task consequence many localised property could converted computed property mobx state tree model backwards compatibility older code projecttitle map projectstringsgettitle react task component updated map previously accessed resource property directly taskanswerslabel becomes taskstringsgetanswerslabel ssred translation stalewhilerevalidate caching strategy built nextjs update become stale locale change clientside component fetch translation useswr hook reactquery modern translation string cached browser refetched become stale locale change
crowdsec lazy consensus implemented currently mechanism check harmful address implementing attack like bruteforce attack dictionary attack etc bruteforce attack hacker attempt guess user login credential dictionary attack dictionary attack try find list valid mail address end integrate james crowdsec crowdsec check james log based defined scenario crowdsec detect malevolent behavior block accessing james various level infrastructure firewall system applicative ease end user configuration propose bundled experience independent end user infrastructure implement crowdsec remediation application level willing user well set remediation based underlying infrastructure quick introduction crowdsec crowdsec security engine opensource lightweight software allows detect peer malevolent behavior block accessing system various level infrastructural system applicative achieve security engine read log different source file stream parse normalize enrich matching threat pattern called scenario crowdsec ship default scenario brute force port scan web scan etc adapted easily extend picking hub also easy adapt existing one create one set new maven project dedicated crowdsec extension allows embedded james server soft dependency externaljar loading mechanism way extension could dropped one james installation runtime dependency crowdsec apply many attack james via imap smtp jmap detected crowdsec crowdsec analyzes log james based pattern parser detect behavior james scenario yaml file allow detect specific behavior usually attack james detect bruteforce login attack dictionary attack line log event crowdsec event trigger condition crowdsec crowdsec send alert local api make ban james connects crowdsec via http protocol reactor http client query crowdsec consequence james secure blocking threat various level applicative system infrastructural document share crowdsec scenario thus allowing user benefit also get dangerous detected community via central api crowdsec natively support distributed deployment reference setting agent per node gathering log local container forwarding crowdsec api decides remediation applied architecture horizontally scalable already able analyse relevant log per second metric obtained discussing crowdsec team allow leveraging large scale james deployment failban detect attack however complex setup distributed system related underlying architecture thus hard document within community failban permit sharing peer underlying blocked data reference jira crowdsec
create one rest api module log expose api application outside world expect one client application frontend spa application possible solution create one net core mvc host application contains endpoint host application reference business module communicates directly hostapi reference administration module meeting module payment module user access module create one net core mvc host application multiple apis project per module api project endpoint handled particular business module host reference administration api reference administration module meeting api reference meeting module payment api reference payment module user access api reference user access module solution creating separate api project module add complexity little value grouping endpoint particular business module special directory enough another layer top module unnecessary consequence one api layermodule controller responsibility delegate commandquery processing appropriate module dont scan project host controller route mvc mechanism api configuration easier overall complexity api layer lower complexity controller little bit higher build time shorter project
adr classifier logic selecting subject viewer october big question subject viewer view given subject moment classifier try guess subject viewer see libclassifiersrcstoresubjectjs get viewer analysing subject subject multiple image show multiimage viewer subject video show video viewer method work majority project certain project extremely specific subject structure break generalised guessing logic else warp logic many clause collapse writhing mass nonsense example planet hunter subject look like subject location imagepng tessdatapng applicationjson tessdatajson tessdatajson add guess subject viewer logic stating subject json json coordinate light curve viewer wed trouble say future project similar jsons coordinate map viewer line graph viewer etc side note light curve viewer still also serve generic scatterplot viewer given proper tweak marked future dev json data generic data guessed choose subject viewer logic see libclassifiersrcstoresubjectjs get viewer first try check there workflow configuration stating preferred subject viewer specific configuration exist logic continue guess correct subject viewer per current system example workflowconfiguration project subjectviewer lightcurveviewer weve also decided specify customspecific subject viewer logic within subject since itll make subject complicated maintenance troublesome compare changing config field one workflow updating metadata json million subject something like tessdatajson type lightcurve discussed shaunanoordin srallen consequence zooniverse project may specify subject viewer choice modifying workflow configuration zooniverse project may course choose ignore well create documentation somewhere catalogue subject viewer available project owner build select specific subject viewer project builder additional note lcv expanded generalised scatter plot viewer select subject viewer logic handle generic situation detects subject json value
adr support conditionals composite action recently shipped composite action allows reuse individual step inside action however one requested feature way support keyword goal want keep consistent current behavior want support conditionals via keyword built function like success implementable without calling example jobstatus success rather success currently composite currently work currently limited conditional support composite action pre post step based job support keywords like always failed success cancelled however generic main step support conditionals default regular workflow step run success condition look job see successful run default composite action main step run single step fails composite action composite action halted early care job pre post step composite action job determine run forward well think composite action currently invoking main step checking current composite action successful let formalize concept real idea add actionstatus field github mimic job existing concept actionpath set composite action github composite action main step success function check actionstatus success rather jobstatus success failure work way pre post step composite action change continue check job nested scenario nested composite action follow existing behavior care current composite action parent example let imagine scenario simple nested composite action job regular step composite action run exit always child composite action success run echo print run echo also print success run echo print current composite action failed already child composite action step run example child composite action yet failed run step step fails consistent composite action currently work production main job fails composite action invoked withifalwaysorif failure explored could add currentstepstatus job rather step however come two major downside support field every type step non trivial remove field job added readonly action besides composite would every success weird currentstep value job also explored step required prevent colliding step felt wrong naming smooth fit current convention consequence github new field current composite action support conditionals composite action keep existing behavior user allow expand functionality
adr implementation language way government digital service make technology choice described service manual selecting language write data api performance platform experience running ruby railssinatra scala apps production choosing one ruby would allow rotate people across performance platform team excellent python developer develop ruby work community expect would interested working preferred language choosing python might way encouraging rotation people would leave organisation try new thing diversity lot people operated python application production knowledge architect write python application easy step deploying python production write data api python consequence write capistrano fabric code deploy python application
sys rdbms issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
write help file superceded generate help file issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
documented application architecture new backend service deciders ben bangert ryan kelly vijay budhram jody heavener danny coates dave justice problem statement fxa backend service stack contains application architecture adhoc documented missing modern feature dependency injection result following problem new developer struggle get speed must learn architecture reading code documentation application structure theyre structured way new component added fit backend service may vary adhoc architecture well adding new object needed route handler timeconsuming object must plumbed entire initialization chain elegant method like dependency injection clear wherehow add new component take time studyunderstand thing currently setup attempt mimic structure new component time consuming setup boilerplate component tooling work current adhoc application architecture adhoc architecture frequently mix concern business logic mixed request handling logic wart evolution time planned front new backend service evolve differently resulting adhoc application architecture learn shared component fxashared cant rely basic object lifecycles setup approach may multiple different adhoc application architecture choosing application framework mean choosen make adhoc application architecture continue exhibit problem assumed four newest fxa backend service adminserver supportpanel eventbroker gqlapi switched chosen approach consistency driver documented application architecture tooling reduces boilerplate creates consistent code architecture modern paradigm ease creation global object testability training material new developer understand work application feature easily ability migrate legacy application similar conventionssetup handle situation exception handling validation service instantiation etc authentication restful apis swaggeropenapi bonus graphql componentsservices easily script considered evolveimprove adhoc application architecture doc tool etc existing welldocumented popular application framework nestjs adonis loopback outcome chosen existing framework nestjs nestjs loopback two compelling however nestjs substantially better graphql support much larger userbase loopback userbase divided two version substantial change nestjs new project update newest service adminserver supportpanel eventbroker gqlapi nestjs reduce documentation address authserver reasonable migrate backport code organization scheme directoryfilename convention nestjs typedi system ease configurationtesting authserver possibly legacy package allow developer familiar nestjs project still locate easily work fxa legacy package positive consequence documentation create document difference legacy service nestjs graphql support match existing typegraphql paradigm closely minimal effort switch negative consequence effort involved migrate package nestjs document difference nestjs legacy service pro con evolveimprove adhoc application architecture doc tool etc existing adhoc structure typically involves chosen library basic directory structure error handling differs several backend service validation always provided joi library document adhoc application architecture would first make clear choice library structured application could write tooling documentation around choice pro could easier convert existing backend service likely closer libsstructure choosen structure desired choice exactly application architecture look like library con creating even portion documentation tooling training material already exists three incredible amount effortwork likely end copying many featureslayouttools already exist community contributers familiar application architecture since fxa existing framework nestjs nestjs modern framework built typescript year ago provides application architecture built top existing popular node ecosystem library express jest etc adapter switch preferred library pro build upon mature popular node library underlying httpgqletc implementation udemy course available extensive nestjs module ecosystem blog post architecture approach flexible swappable underlying implementation express fastify apolloserver etc builtin support restful apis graphql websockets microservices distributed processing modern architecture built typescript simple registration system github star popular measure three graphql implementation built almost identical typescript decorator make moving gqlapi adminserver nestjs fairly straightforward con reactive javascript approach advanced internal functionality developer familiar difference underlying implementation smoothed typescript adapter interface extensive underthehood customization could become annoying underlying implementation swapped remove useful boilerplate tooling assumes youre default choice express jest existing framework adonis adonisjs started opensource project intentionaly avoids library implement underlying functionality believing cannot integrated cleanly without crufty glue code pro latest version built typescript still preview release mode includes modern application approach inversionofcontrol container mature framework started integrates tightly orm tooling reduceavoid glue code star least three con implement functionality cannot harness community middeleware existing web library orms etc graphql support existing framework loopback loopback highlyextensible opensource nodejs framework enables create dynamic endtoend rest apis little coding loopback created group ibm large company including symantec three choice one clearly aimed making openapi based apis simple powerful possible pro includes modern application approach inversionofcontrol container built top express one popular node web library extensive documentation excellent builtins api development openapi star loopback loopback medium least popular depending version con loopback difference loopback doesnt seem widespread graphql support via unique openapi graphql bridge approach see httpsloopbackioopenapitographqlhtml requires api exist openapi first
adr run action shell runactions run script platform specific shell bash pipefail nonwindows cmdexe window shell override allow different flag completely different shellsinterpreters small example yml job bashjob action run echo hello shell bash pythonjob action run printhello shell python shell keyword shell shell either builtins explicitly supported keywords useful support least cmd powershell window cmd mycmdscript powershell mypsscript valid way many linuxcrossplatform interpreter bash myscript python myscript tool potentially others also require correct file extension run must run particular way get exit code consistently must first class knowledge provide default template keywords follows cmd default comspec eon voff call script name automatically appended cmd substituted note equivalent default window behavior shell given pwsh default pwsh command script automatically appended powershell default powershell command script automatically appended bash bash noprofile norc pipefail default behavior nonwindows shell given attempt first default behavior nonwindows shell given bash see located path python python note exact command ran may vary machine provide default argument command format listed shell behavior expected hosted machine private runner may vary example command may actually link bindash binbash template string command moreoptions file name temporary script templated give user control location relative script path first whitespacedelimited word string interpreted command python arg arg similar passing args needed shell require filename various reason note simply provides default executed mechanism temporary script file generated path file templated string first word formatted string assumed command attempt locate full path fully qualified path command plus remaining argument executed shell bash expands binbash noprofile norc pipefail runnerlayoutworktempfdfbbdeaccdsh private runner time list wellknown shell cmd window hosted powershell window hosted hosted platform pwsh hosted platform bash hosted platform python hosted platform setuppython configure python container container job shell work transparently simply exec command job container passing argument exit code error action preference builtin shell provide default make sense running within action executed runner bashsh failfast behavior set pipefail default bash shell builtins default given nonwindows platform user opt failfast take full control easily providing template string shell bash shlike shell exit exit code last command executed script default behavior thus runner report step failsucceed based exit code powershellpwsh failfast behavior possible pwsh powershell builtins prepend erroractionpreference stop script content append testpath literalpath variablelastexitcode exit lastexitcode powershell script get action reflect script last exit code user always opt builtins providing shell like pwsh file powershell command depending cmd doesnt seem way fully opt failfast behavior writing script check error code respond accordingly cant actually provide behavior default completely user write behavior script cmdexe exit return error code runner errorlevel last program executed internally consistent previous default behavior pwsh cmdexe default keep behavior consequence valid shell depend hosted image maintain tight image compat first class support shell require major version schema change modify cannot remove modify behavior wellknown supported however adding first class support new shell backwards compatible instance add wellknown python nonwellknown would always needed include python
hosting clojure application know security requirement hiding application would rather pay hosting host heroku free paas provider considered microsoft azure also offer free clojure hosting heroku preferred team already logins
webscraping architecture issue changelog initial version amendment add exception authentication phase webscraping code mimic user log website get data home assistant usually needed certain data sourcesintegrations offer api webscraping come following downside fragile break often website updated integration updated vendor like usps banned user integration rely beautifulsoup pythonbased others relying phantomjs headless browser meaning include whole browser proposal longer accept new integration relies webscraping identify deprecate release remove integration rely webscraping still possible custom integration provide information via webscraping exception generic integration parse html excluded exception made authentication phase integration allowed extract field form make robust data gathered scraping individual field instead scrape field consequence integration rely webscraping maintained custom integration
graphql apollo setting redesign deciders lauren zugai ben bangert wil clouser jody heavener orchard danny coates barry chen vijay budhram dave justice alex davis problem statement setting redesign project created new react application turn opened door ass certain piece technology stack graphql gql database query language instead query language apis describes data requirement powerful rest benefit gained top existing rest architecture apollo document refers apollo client apollo server piece apollo platform described unified data layer enables application interact data data store apis word allows write handle graphql client server apollo also give many tool box like caching adr serf lay pro con graphql apollo setting redesign project hitting conventional rest endpoint apollo also offer apollo graph manager apollo federation paid service read doc gql apollo server apollo client driver performance implication consideration around number network request data transferred ease setup clientside api call clarity around expected data react integration developer tooling development speed around initial setup new feature roll considered send standard crud request rest endpoint layer graphql apollo top rest architecture making direct database call basic operation full graphql apollo integration direct database call outcome chosen layer graphql top rest architecture gql offer performance optimization allowing consolidate network request sending data requirement single request asking needed client shifting burden figuring gather data client onto server server compensates overfetching sending back requested allowing developer query expect exactly needed endtoend typing declarative way thinking towards data requirement along keeping data requirement schema close theyre consumed make painfully clear whats sent received client server preclude replace supplement direct call fxa authserver line faster initial development also help mitigate risk around relatively novel piece technology fxa nice sideeffects include gql playground managing single api endpoint ability store local state network data apollo cache pro con send standard crud request rest endpoint description dont graphql send request corresponding endpoint pro novel tech additional setup time new technical debt rest api setup vetted year production con would avoid new technical debt would still want work towards optimizing setting page network call would likely spend additional time looking manually optimize call current rest pattern result sending many query overfetching data may figure ideal way organize api call fxapaymentsserver blueprint well turning benefit laid graphql section like clarity clientside around data sent received later choose graphql even approach well face lot refactoring later time could mitigated graphql apollo description section outline pro con graphql apollo general applies graphql novel tech fxa stack entirely novel fxa ecosystem say admin panel project fxaadminpanelfxaadminserver package served prototype experimenting gql apollo pro gql setting redesign wont mix gql rest gql consolidate network request even gql query fed authserver client relieved heavy network request burden instead single request client asks server perform request offer performance boost especially main setting page many sequential request must made since required data requested data returned wont overfetched like traditional rest architecture resulting smaller payload gql offer flexible declarative approach data developer focus describing data rather implementing optimizing numerous rest endpoint rest pattern tend define resource server data requirement schema gql closer client data consumed make painfully clear whats sent received client server improve visibility whats happening component graphql apollo gained lot popularity year substantial community support company backing airbnb facebook surveygizmo github many others stack promotes strong endtoend typing apollo offer great feature box like caching error handling optimistic rendering nice integration tool react even provides react hook react setting application manage interacting single endpoint apollo client make managing data react app straightforward apollo client creates internal redux store hood allows store local data apollo cache place data network request stored apollo also provides graphql playground graphical interactive inbrowser gql ide provides easy access schema selfdocumenting way allows developer write query mutation send server developer verify behaves expected copied directly application graphql make easier evolve apis time provides way deprecate schema member discourage usage certain part apis custom messaging graphql database agnostic graphql query easy write understand neutral query always return code even query errored query unsuccessful response instead error key associated error message stacktrace however error messaging quite detailed include resolvers refer exact part query fault con learning curve come introducing new tech initial setup time another service graphqlapiserver gql caching done database client level though apollo gql doesnt rely http caching method gql around long enough gain excellent community support rest around established pattern even longer layer graphql apollo top rest architecture making direct database call basic operation description allows begin working graphql apollo top rest architecture proxying existing authserver call except make sense interact database directly simple operation pro risk upfront work well still heavily reduce number initial network request performed setting frontend incremental approach apollo server orchestrate rest request sufficient fulfil query return exactly data requested apollo server proxy existing authserver call incrementally swap authserver api call direct implementation con creates tech debt wont fully integrated finish swapping authserver api call stack universal across fxa well rest nonsettings fxa page payment server refactoring done graphql database agnostic unable graphql subscription database support realtime data full graphql apollo integration direct database call description would extend complex operation routed authserver would directly implemented apollo server pro tech debt later would see performance boost allout dedication approach could open door evaluating database able work graphql subscription quickly pave path move backend mysql something else regional conscious architecture con increased risk well pushing new setting app staging production building setting redesign project already lot moving part incremental approach take ideal existing rest endpoint authserver arent query embed business logic wed duplicate logic graphql test tandem rest make sure dont break anything either side much time needed setup access control auth security already implemented authserver might expensive reinvent additional link setting redesign project jira adr setting redesign new react app graphql doc apollo doc graphql subscription graphql api technical specification doc setting redesign
api prefix materialized jetstream view metadatavalue author mhanel partially implemented tag jetstream client objectstore document describes design support api prefix materialized view api prefix allow client library disambiguate access independent jetstreams run either different domain different account specifying prefix api client program essentially pick one want communicate mechanism supported materialized view well overview jetstream listens default api subject prefix jsapi thus client jsapi communicates jetstream local account domain avoid traffic going jetstream following mechanism place account since api imported altered prefix request cross account boundary jetstream enabled account import without prefix set result error jetstream imported well error import overlap domain leaf node connection nats server add denies jsapi client library set api prefix api subject client publishes subscribes start instead jsapi result api traffic end local jetstream alway ever subscribes jsapi message subscription cross boundary following happens account crossing import api prefix stripped replaced jsapi domain crossing leaf node connection domain automatically inserted mapping strip api prefix replaces jsapi jetstream disambiguation mechanism added materialized view object store well specifically tag along api prefix setting different value reach jetstream non starter design first token api materialized view considered default api prefix mean local semantics thus concrete view treat token obj respective default api prefix publishes subscribes api replaces first token specified non default prefix share api access across account sufficient account exportimport take care rest access api account different domain natsserver maintaining leaf node connection add appropriate mapping domain specific api local api deny local api traffic example assume api prefix jetstream set jsfromacc jetstream specific api call local api prefix jsapi replaced jsfromacc jetstream specified api prefix differs jsapi api prefix specififed jetstream api api prefix jsfromacc resulting jsfromacckv thus order put key bin bin send jsfromacckvbinkey crossing account boundary translated back kvbinkey thus underlying stream still created subscription kvbinkey domain special case api prefix work way api prefix jsdomainnameapi lead jsdomainnameapikvbinkey leaf node connection domain crossed inserted mapping change subject back kvbinkey consequence proposed change backwards compatible materialized view already suggested prefixing one prefix across different apis avoid accidental api overlap going forward implication jetstream start first token api prefix specifically jetstream never expose functionality jsapikv version api prefix would look follows jsfromacckv clash subject side effect jetstream two token api prefix materialized view single token problem avoided unifying api name space alway two token second token api resulting jsapi kvapi objapi however backwards compatible testing server config test change jetstream prefix froma inbox prefix fori jetstream enabled account user user password jetstream enabled export service jsapi service stream fori user user password import service account subject jsapi froma service account subject fromakv stream subject fori account test jetstream connected account talking jetstream account nats account info natsiilocalhost jsapiprefix froma publishes subscribes support prefix well absent actual implementation simulated pubsub implementation able connect account access map ojbjects account nats natsaalocalhost sub kvmap sleep nats natsiilocalhost pub fromakvmapput hello world
record merging apps together first created beta register product created three separate apps mint indexer presentation number reason distinct user read write register register single authoritative custodian approve writes anybody request read one app accepts writes register another accepts read start imagine might manage read writes different network security zone allowed view domain different lens example mint database perform indexing content data item perform advanced query presentation app advantage disadvantage architectural approach primary approach interapp communication via integrating database caused apps tightly coupled however integrating database able give app database user restricted operation needed perform three separate apps made difficult iterate anything involved changing structure domain register entailed dance around multiple commits multiple apps choreographed deployment one particular thing painful integrate verifiablelog code may still desire perform update register secure potentially offline environment able present readonly view register internet however feel better way achieving would implement app able mirror register either reading read api reading serialized format entire register merge three register apps together mint indexer presentation repository merged preserving git history single repository openregisterjava consequence already able delete quite lot duplicated code code manage one place anticipate able move quickly put thought sensitive register enable offline update register verifiablelog capability along asyet unimplemented digital signature play key role signing key offline internetfacing register mirror able present bad data without breaking signature
adr serverless architecture farmacy food backend adr decided extract billing logic payment processing system let smart fridge kiosk handle leaf supporting hungry person web mobile client pick meal specific location leave feedback verified purchase create account get discount ghost kitchen web client manage food description client system view feedback report view inventory purchase report manage discount expected volume traffic hoping customer base early dedicated customer farmacy food serverless architecture based relatively low expected volume simple business logic make sense choose complex architecture even one monolithic architecture layered architecture would fine since farmacy food expecting scale dramatically coming year another advantage choosing serverless architecture low operational cost together easy maintenance perfect startup like farmacy food consequence disadvantage serverless architecture vendor example vendor lockin lack flexibility example optimize performance specific might become issue company grows decided way important support lean development test new feature fast cheap
wiremock stub engine open mokkas stub engine required provide set new feature allow better wider support request matching header cooky variety pattern proxying recording interaction considered development mokka stub engine continued research adopt one existing grown production ready solution wiremock httpwiremockorg chosen one popular mock server strong active open source community provides consistent reach api java http json year became one mostly chosen library mocking external service junit test also core part spring cloud contract library reusing wiremock standard mokka may benefit easier integration already existing solution product project table comparises feature mokka wiremock stubbingmocking engine please mind considers gui user management feature mokka provides considered change compared version wiremock version mokka version feature mokka wiremock stub management crud stub management disable soaphttp support basic matching request headerscookies multipart support rest support basic matching request headerscookies multipart support create stub openapi spec jms support embedded activemq proxying record playback simulating fault response templating groovy handlebar stub stored database json file stub modification history interaction log stored database stored memory file serving fake payment gateway bluemedia admin api json api java api wiremock already cover requirement main difference stub management disable stub mapping metada define active property todo create stub openapi spec implemented mokka wiremock anyway todo jms support verified todo response templating handlebar necessarily drawback seems far elegant easy groovy also safer security point view todo stub stored try provide databasebased custom implementation mappingssource stub modification history todo interaction log saving database may achieved providing custom implementation requestjournal todo fake payment gateway mokka implementation reused following solution considered continue mokka stub engine flexibility open architectural future large codebase maintain requires high contribution develop missing feature adopt wiremock source maintain fulfill requirement large set productionready feature provided start flexibility open architectural future large codebase maintain easy way upgrade wiremock support wiremock community adopt wiremock library possible extension point wiremock core implementation remains untouched new feature provided well designed extension point small codebase maintain wiremock bug handled community upgrading wiremock straightforward long breaking change introduced wiremock apis future architectural feature consideration may limited wiremock architecture unknown feature wiremock license may change community support may drop fully rely wiremock development lifecycle adopt wiremock library possible extension point consequence becomes easier difficult risk introduced change mitigated
language choice new development developing new system many possible language choice available mixture different language existing system including php supplier registration service contract finder miso java digit service python digital marketplace service government mixture php java python ruby scala picking one standard language service could restrict pool potential supplier could interact building new service conversely allowing unlimited selection language make future management support service complex expensive agreeing selection acceptable language allow greatest flexibility supplier choice also help minimise future ongoing support cost make language framework consider skill available current team current team comfortable experience skill future team large enough pool supplier contractor could support maintain service future external toolkits module useful toolkits module could reduce development effort govuk frontend toolkit cost cost developing way licence cost hosting would picking language restrict hosting also consider service manual guide choosing technology new service developed following language java python ruby javascript digital service also html json required salesforce work may continue salesforce apex language possible external web service component reduce volume apex new service language require architectural explain software development industry change quickly reevaluate month taking account current market trend industry move apply service comprised entirely software service saas solution affect system already exist also cover development native mobile application consequence new service developed language unless architectural overriding review month make sure relevant recruitment training procurement via digital outcome specialist take account
coding guideline implement create software defined everything coding convention set guideline specific programming language recommend programming style practice method aspect program written language convention usually cover file organization indentation comment declaration statement white space naming convention programming practice programming principle programming rule thumb architectural best practice etc guideline software structural quality software programmer highly recommended follow guideline help improve readability source code make software maintenance easier coding guideline result enhanced efficiency reduced risk mininized complexity maintainability bug rectification comprehensive look cost efficiency coding guideline language platform consequence coding guideline defined learned maintained however lot common standardized coding guideline exist coming tool simplify implementation reference httpsenwikipediaorgwikicodingconventions retrieved november httpswwwmultidotscomimportanceofcodequalityandcodingstandardinsoftwaredevelopment retrieved november
adopt graphql relay specification make api friendly client design pagination adopt graphql relay specification solves pagination dont reinvent wheel handy node interface refetching object way define input mutation graphene lib good support creating api following relay specification consequence easy write spa javascript relay client lib may require extra work fulfill relay specification
routing currrently routing complex inflexible cause number issue every time new page type added current format current complete route format defined questionnairequestionnaireidsectionidpageidconfirmationidtab regular expression defining optional app received url questionnairedesign always interpreted questionnaireid always interpreted sectionid even werent page found section must always provided url questionnairedesign would interpreted pageid url controlling layout render different component based url encountered currently control main editor layout combination final tab property panel combination final tab tab highlighted whole url must match left hand panel highlight whole url must match centralised url management currently url structure defined one grand url managed eqauthorsrcutilsurlutilsjs file complex change lot unintended consequence url request url parsed request time generate header sent every request server header called questionnaireid determine questionnaire load change read request route definition currently route defined eqauthorsrcappquestionnairedesignpageindexjs includes route lot entity type tab confusing component also lot logic controlling left hand navigation issue impossible add new entity type wanted add new entity sit within section survey introduction way current url format support generating correct url left hand panel requires url maintain tab entity support tab location complex error prone currently always work intended navigating page routing section always take first section switch generating uuids entity current structure page result long complex url questionnairebbaedafcfcaedeeeafeebdbaaaacabfedaadcaaeadesign new url format url format become qquestionnaireidentitytypeentityidtab mean easily changed new entity type entity type example design url section qsectiondesign page qpagedesign question confirmation qquestionconfirmationdesign survey introduction qintroductiondesign consequence new url format request middleware set questionnaireid header still work adding new entity becomes possible extension point obvious refactor everywhere app relying parent availble url get request graphql instead old bookmark broken could mitigate redirect rule old format new format
enable implementing binding separate crate deciders teshaq bdk mhammond technical story issue implementation testing implementation problem statement binding generator currently live uniffibindgen crate creates following difficulty binding live uniffi repository uniffi team maintain least review change make difficult support thirdparty developer writing binding language core team wish maintain change specific binding generator requires new uniffibindgen release accessible consumer even doesnt impact binding binding require complex build system test including build system uniffi would require developer install build system example type geckojs binding would require mozillacentral build system build test currently run test binding cargo test mean one binding target get outdated fails developer doesnt needed library installed one target test would fail also impossible write new binding live uniffibindgen crate adr proposes enabling thirdparty crate implement binding generator describes necessary uniffi change enable driver support firefox desktop javascript binding generation testability easy developer test binding care without navigate install unfamiliar library build system developer experience easier write maintain new binding generator currently release cutting release change one binding generator shouldnt harm another note version compatibility handled separate adr considered nothing mean keeping everything asis deciding binding generator least live uniffibindgen crate create public api external crate implement binding developer would trait exposed leverage implement binding generator live uniffibindgen uniffibindgen would still handle generic task related binding generation pro con nothing good make harder user accidentally different version uniffi scaffolding binding since implemented together crate good make easier make change multiple binding time case breaking change uniffi etc bad maintainability grow difficult especially binding added core uniffi team familiar bad testability also grow difficult binding added requirement test binding together one repository difficult maintain bad release binding generator tied release uniffibindgen create public api external crate implement binding good ownership clear member community opt maintain binding generator good would test core binding maintain others tested maintainer example geckojs binding generator tested mozillacentral good release external binding wouldnt impact internal one unless change internal uniffi behavior bad easier accidentally version mismatch see adr bad testability increase complexity required publish fixture example see overall preferred requirement implement binding geckojs cant tested endtoend without complex build system creates possibility community contributor writing maintaining binding generator repository increased risk version mismatch dealt see adr outcome chosen create public api external crate implement binding change expose trait bindinggenerator trait would following associated type implement bindinggeneratorconfig bindinggeneratorconfig would another trait binding generator implement configuration type purpose type carry binding specific configuration parsed uniffitoml function writebindings take componentinterface config writes binding directory outdir expose generic function entry point binding generator call generic function generating binding exposed uniffibindgen generic function parse udl parse configuration uniffitoml bindinggeneratorconfig trait consumer implement initialize bindinggenerator type consumer provides call writebindings generic type see implementation change expose fixture testing enable external binding generator implement test would publish fixture new uniffitesting crate helper consumer build consume fixture crate see implementation testing change
adr expose runner machine info pending provide mechanism runner include extra information set job step log include ossoftware info hosted image runner look file setupinfo runner root directory file json simple schema json group detail detail group software detail detail runner group endgroup fold detail info expandable group virtualenvironments selfhosted runner mechanism add extra logging info set job step log consequence change runner best effort readparse extrasetupinfo file runner root directory virtualenvironments generate file image generation change provisioner properly copy file runner root directory runtime
cedar caching user story easi easi heavily relies cedar core data systemcentric system profile view however cedar api response range hundred millisecond multiple second causing considerable wait time easi application cedar relies lownocode solution limited caching create caching solution end expedite call cedar data number solution listed considered main factor revolve around maintainability solution tenable foreseeable future scale solution handle increased traffic easi andor increased amount cached data development velocity solution allow team iterate quickly considered inmemory caching already present within easi server app ask cedar cache endpoint proxy server cache request nginx optimized external keyvalue store store data lieu making request rediselasticache outcome decided move forward implementing nginx proxy server application cedar since caching nginx happens automatically choice requires last amount integration code achieving desired result addition since almost entirely external easi app either shift another approach integrate solution easily future pro con inmemory caching already present within easi server app there additional architecture required one endpoint already cached way system summary would scale poorly cache inmemory essentially memory leak would make debugging production server difficult would analyze stack determine cache code causing problem ask cedar cache endpoint cedar easily cache endpoint end adjust cache time work required easi team except coordinating cedar cedar ability invalidate cache certain endpoint programmatically mean certain endpoint would likely remain uncached low cache time proxy server cache request nginx poc found easinginxcaching branch link proxy set get request cached automatically nginx performant requires least amount code written still providing cache invalidation capability solution purposebuilt caching cedar providing clear philosophy caching application separate easi making debugging management easier request invalidate number way sending purge method url path adding query parameter adding path parameter etc poc sends purge method accomplish cache invalidation opensource version nginx support caching natively community module must requires special dockerfile extend main nginx image note also explore varnish nginx support cache purging natively unfortunately support meaning would separate layer handle http traffic light opted nginx optimized external keyvalue store store data lieu making request rediselasticache poc found easirediscaching branch link allows control store store store value cache query etc easily integrated aws current workflow official redis docker image redis performant requires writing code retrievestore every cached api call following additional consideration manage key delete multiple value key prefix allows storing value outside cedar response introduces possibility bandaid slow query caching data redis example expensive solution term operating cost
regex user input implemented goal filter planned autolink subgoals feature rely data entered manually user two obvious way implement allow user type substring search goal containing substring allow user type regular expression search goal matching expression second solution seems much powerful also much dangerous uncontrolled evaluation userdefined regex may cause unexpected crash data loss potentially high cpu load seem undesirable allow entering userdefined regular expression sieben substringbased logic must allowed consequence expect following consequence would possible implement complex autolinking logic filtering autolinking work fast fewer bug logic comparing regex
timestamp format content summary issue detail assumption constraint position argument implication related related related requirement related artifact related principle note summary issue want able track thing happen timestamps consistent timestamp format work well across system thirdparty system interact system different timestamp format json message native timestamp format choose convert timestamp string convert string timestamp serializedeserialize application set local time rather utc time convenient project must adjust local time project trigger event based local time system different time precision capability time resolution second millisecond nanosecond example linux operating system command default time precision second whereas nasdaq stock exchange want default time precision nanosecond choose timestamp standard format iso nanosecond precision specifically yyyymmddthhmmssnnnnnnnnnz format show year month day hour minute second nanosecond zulu time zone aka utc gmt decided detail assumption handle timestamp text string convert timestamp string aka serialize convert string timestamp aka deserialize want format generally easy easy convert easy person read want compatibility wide range external system cannot control analytics system database system financial system constraint system time precision limitation example macos operating system command print time precision second nanosecond position considered range unix epoch one incrementing number terse text format yyyymmddthhmmssnnnnnnnnn local time zone utc time zone argument typical value easy readwrite human raw speedsize typical want format work fine machine system also work well manually writing sample data reading json output grepping log file etc atypical high performance computing expect well want optimize text format choose converting text faster format programming language builtin object type text format doesnt matter much hpc implication various text system time system converge format related related may want fasteasy way also track time delta aka duration easy unix epoch timestamps related requirement may want adjust related requirement specific kind logging message stamp splunk sumo elk etc related artifact language formatters parser datefns modern javascript utility library crono time library rust rosetta code example system time data format show epoch sixarm example nowstring related principle easily reversible change pretty easily different format unix epoch defer premature optimization typical dont care much handful extra character format dash colon note add note
betterdatatransformations proposed creating new updating existing data transformation whether apis database still pain point many refactors feel abstraction helping goal data transformation take data api database modify enrich save display result user achieve two abstraction rely hapi plugins interface defined hapi server add feature server object plugin helper hoc function decompose plugin action problem mixing concern data transformation server process different abstraction able change independently coupled together broken interface related first point hapi plugins interface make useful server trying creating data pipeline hacky open frequent change bug better way data transformation benefit different abstraction solving current problem opening new possibility two abstraction present transducer stream create programming interface allow chaining operation data set input next step output previous transducer abstraction implemented party library stream native nodejs practice would library either approach deal possible pain pointsnodejsstreamsreadablestreams lacking well established method build data pipeline javascript facing concern fragile data transformation stream large file since low memory footprint requestresponse stream consequence learn stream adopt appropriate library refactor data transformation stream
routing building web app one official url query params url searchqsearchterm believe future endpoint added complicated search request bidi parse route considered given simplicity url structure could get away routing compojure however feel reliance macro could harm future development
control server functionality control server feature enables launcher periodically query kolides saas app receive data update various subsystem launcher subsystem named component hash data launcher control service find new update subsystem notifies consumer registered handle update subsystem ping subscriber subsystem latest update subsystem cached control server avoid resending update previously sent launcher instance protocol mermaid sequencediagram participant participant controlservice participant consumer participant subscriber loop request interval controlservicek get apivcontrol kcontrolservice return map subsystem hash loop subsystem alt last fetched update still fresh controlservicecontrolservice skip next subsystem else controlservicek get apivcontrolobjecthash kcontrolservice return latest subsystem data end controlserviceconsumer updatedata loop subscriber controlservicesubscriber ping end controlservicecontrolservice cache hash update end end
deciders devs management problem statement islandis maintaining publishing content many different government agency institution technical skill may vary great deal content skill may also lacking therefore paramount system user friendly intuitive agency institution enough autonomy regard editing content responsible minimise manual labour required islandis editor system would best suit islandis driver content editable non technical user content accessible across multiple domain platform setup simple developer new project system manage flexible content structure limit system impact design system user friendly easy non technical person system offer suitable workflow ease content management multiple agency start contribute considered gather content prismic contentful content stack whitehall drupal wordpress strapi hosted solution outcome devs narrowed choice two contentful contentstack system meet required featureset management made contentful contentful deemed larger presence icelandic dev community contentful also believed stronger funding base contentful already implemented project pro con gather content good allows great deal workflow collaboration feature good function project management tool content good serve communication portal islandis various party involved good comprehensive access control bad basic api bad limited set feature bad designed publishing platform prismic good kind simpler version contentful good simple non technical user good image editing placement simple effective good builtin cdn image bad doesnt write api bad way import content web interface bad doesnt required field bad api somewhat limited contentful good best class api sdks good large ecosystem user good hybrid wysiwyg editor mix content type together regular rich text content good generic enough many different thing good writeapi create content programmatically good extended extension various party tool good rich access control good lot developer experience good builtin cdn image content good define workflow apply user permission across bad generic structure confusing new user bad depending content set may often deep drilldowns content entry bad complex billing structure making harder project cost contentstack good somewhat structured compared choice good sdk many language good generic enough many different thing good writeapi create content programmatically good extended widget various party tool good builtin cdn image content good rich access control good define workflow apply user permission across good easy understand billing structure bad fewer developer experience bad steep initial price drupal wordpress hosted solution good endless control type system good there huge ecosystem prebuilt stuff bad huge ecosystem huge quality control problem bad specialised knowledge system maintain get want bad host take care backup maintenance regular serious security breach system bad even though run headless mode uis apis really geared towards headless usage strapi good endless control type system good there huge ecosystem prebuilt stuff good writeapi create content programmatically bad specialised knowledge system maintain get want bad host take care backup maintenance regular serious security breach system bad system missing feature deemed critical content internationalization granular access control whitehall good manages workflow bad built around gov would fork project safely bad lot upfront work would required adapt system stack bad fulfill project requirement link gather content acl tab gather content acl tab
create adaptive goal tree enumeration currently fixed mapping inner goal identificator actually index goalsgoals dictionary uservisible goal number selecion also called enumeration easy implement seems significant downside goal number grow grow make longliving tree look ugly may open goal tree could digit number big amount closed goal also generate enumeration make difficult create nested goaltrees see issue seems reasonably nested goaltree enumeration starting current enumeration function flexible enough support naturally decide extract enumeration function idmapping goal class transformed wrapper transforms actual goal identificators uservisible number respectively keep backward mapping goal selection consequence expect following consequence user interface visible goal number may change significantly user close deletes change view hope disappointing enumeration nested goaltrees look naturally hidden selection allowed currently possible select invisible goal enumeration global code structure field selectioncache may also moved new enumeration class class goal become smaller easier testing existing test rely current enumeration function must refactored
flask superceded replace flask django choose webserver flask server simple pretty much graphql endpoint graphiql consequence flask battery included rely thirdparty libs want extend server later
move service top level initially directory structure language top folder service however make harder different language version service together keep monorepo easier handling project never grow large maintained different team move service top level language version service consequence setup make easy maintain project also make easier service different language together
allow permissive file name proposed generalizedby given adr flow tool intended dropin tool integrate well tool repository aim also adr file created outside tool naming convention tool generally work file system looking adr dir enumerating file etc existing naming convention rather strict function looking file rely regular expression thats create would like extend file enumeration file name change regular expression thats enumerate file include hypens space file still extension reside adr dir directory identified adr file file template still remains consequence file name recognized adr file function relying withalladrfiles affected
remove obsolete api call web component deprecated adyen web component version new endpoint session introduced allows merchant create payment session shopper selects payment method drastically simplify checkout flow detail please refer adyen documentation hand api call web component still existing integration payment making payment paymentdetails submitting additional payment detail api call longer required adyen web component add handler send request session merchant provide createsessionrequest custom field commercetools payment remove handler making payment submission additional payment detail support custom field makepaymentrequest submitadditionalpaymentdetailsrequest anymore otherwise feature change bug fix future apply creating session flow existing making payment flow duplicate effort implement change make integration hard maintained consequence user bug fix enhanced feature adapt web component breaking change
subject mapping transforms stream metadata value author jnmoyne implemented tag jetstream client server problem statement subject mapping transformation available core nats level meaning order define modify mapping one either access server config file access account key operator security mode core nats subject mapping place scaling single stream writes partitioning traffic routing canary testing many case subject mapping happen stream core nats serveraccount level define subject mapping quite limiting easy application programmer able define mapping heshe even access account key hand allowing application subject mapping transforms stream level make easy application developer nats administrator define manage mapping one place stream message flow subject mapping transforms applied enables interesting new functionality bucket sourcing prior work see adr core nats subject mapping description available subject transform function feature introduced new feature introduced version nats server allow application subject mapping transformation multiple place stream configuration apply subject mapping transformation part stream mirror apply subject mapping transformation part stream source amongst case enables ability sourcing bucket name bucket part subject name bucket stream therefore transformed sourcing name sourcing bucket different name bucket sourced apply subject mapping transformation ingres input stream meaning received core nats mirrored sourced another stream limit applied get persisted subject mapping transformation filter message transforms subject message matching subject mapping source enables ability insert partition number token message subject also apply subject mapping transformation part republishing message subject mapping transformation seen extension subject filtering subject mapping transformation without associated subject filter subject filtering mapping transform composed two part subject filter source part transform destination transform destination part transform empty destination transform mean transformation subject like stream consumer one single subject filter mirror source one set subject filter transform destination like consumer either specify single subject filter optional subject transform destination array subject transform configs composed source filter optionally empty transform destination addition possible source different stream also stream define single source multiple subject filter transforms case ordering message guaranteed preserved overlap filter define multiple source stream subject filter overlap source thereby making possible duplicate message sourced stream order message source guaranteed preserved example stream contains message subject foo bar baz want source foo bar stream could specify two subject transforms empty destination single source source twice stream foo subject filter second time bar subject filter stream config structure change user perspective feature manifest new field stream configuration request stream info response message mirror source additional subjecttransforms array source array mirror containing object made two string field src dest note subjecttransforms array also single string subject filter dest empty case transformation filtering top level stream config additional subjecttransform field stream config containing two string src dest bucket sourcing subject transforms stream open ability sourcing bucket client library implement automatically adding subject transform source configuration underlying stream bucket sourcing transform question map subject name sourced bucket name sourcings bucket name bucket source transform config source stream stream following transform subjecttransforms array streamsource src kva dest kvb example stream mirror sourcedstream stream two subject filter transform example foo transformed bar json name sourcingstream retention limit maxconsumers maxmsgspersubject maxmsgs maxbytes maxage maxmsgsize storage file discard old numreplicas duplicatewindow mirror name sourcedstream subjecttransforms src foo dest footransformed src bar dest sealed false denydelete false denypurge false allowrolluphdrs false allowdirect false mirrordirect false stream source sourcedstream stream twice time single subject filter transform json name sourcingstream retention limit maxconsumers maxmsgspersubject maxmsgs maxbytes maxage maxmsgsize storage file discard old numreplicas duplicatewindow source name sourcedstream subjecttransforms src foo dest footransformed name sourcedstream subjecttransforms src bar dest bartransformed sealed false denydelete false denypurge false allowrolluphdrs false allowdirect false mirrordirect false stream source stream subject transform json name foo retention limit maxconsumers maxmsgspersubject maxmsgs maxbytes maxage maxmsgsize storage file discard old numreplicas duplicatewindow source name source filtersubject streamfoo name source filtersubject streambar name source subjecttransforms src streamfoo dest foo src streambar dest bar subjecttransform src foo dest mappedfoo sealed false denydelete false denypurge false allowrolluphdrs false allowdirect false mirrordirect false client implementation jsmgo natsgo natscli
aspnet platform apis previous apis hackney written variety language framework including ruby rail aspnet nodetypescript aspnet hackney clean architecture framework specified api playbook application intended robust part hackits platform iterated upon hackit team mostly skillset consequence choosing stack mean hackit team able carry application forward future iteration support
game hosting current version game user friendly requires knowledge acces linux command line create web interface host hunt keep cost low let host github page consequence easier user experience wider player base gui complex build
fragment view decides happen user click edit menu viewmodel responsible data tried attempt notify viewmodel within view user clicked edit menu item viewmodel exposed livedata object observed view trigger navigation edit fragment editing workout clicked saved edit fragment opened instantly caused viewmodel triggered edit event view detailviewworkoutfragment longer notifies viewmodel edit action directly call navigation component open editworkoutfragment therefore decides done edit action clicked normally view make kind consequence special case solution direct access argument contains necessary workout load workout case might store data directly view bad practice viewmodel
start console app console appication siple app come mind creates console app send data via parameter consequence
allow tft token drop freetft tfta token sdk completely drop freetft tfta currency dont ask always tft consequence flow becomes much easier easy reason
layout default title adr navorder permalink record efficient retrieval cocina object deciders andrew berger infrastructure team problem statement work motivated improving performance argo especially cocina object large number file cocina object file timed second render argo due time taken retrieve object database timed second time instantiate validate cocina object dsa argo time send cocina object network argo making request cocina object render single item detail page driver performance improvement rendering cocina object argo amount new machinery infrastructure must put place address problem opportunity reuse new machinery infrastructure address case considered add graphql endpoint dsa support partial retrieval extend existing rest endpoint support partial retrieval caching cocina object argo partial retrieval improves performance retrieving large part cocina object viz structural needed partial improving strategy requires change cocina model gem allow cocina object omit required attribute caching improves performance reducing number time cocina object must retrieved outcome add graphql endpoint dsa partial retrieval core feature graphql graphql wellsupported rail engine rubygraphql adding dsa rail app significant burden graphql possibility reused address case positive consequence graphql endpoint reduces rendering cocina object large number file second negative consequence additional component added dsa already large codebase pro con add graphql endpoint dsa support partial retrieval graphql endpoint allows client request part cocina object needed turn graphql server retrieves requested part database pro partial retrieval core feature graphql pro graphql wellsupported rail engine pro future graphql may address possible case including patching cocina object instead current approach updating entire cocina object providing facade multiple apis service reduce number call required retrieve data cocina object reduce client complexity make easier split service con requires adding additional component dsa con infra team familiar graphql con rubygraphql split freepro version usage increase may necessary license pro version similar licensing sidekiq pro extend existing rest endpoint support partial retrieval pro require adding additional component dsa con address possible case caching cocina object argo rail integration caching solution provides approach caching cocina object minimize number request made dsa pro confines change argo pro machinery already part rail con way argo deployed multiple process multiple server recommended approach memcache however memcache system significant infrastructure supported ops
timesource zeroarg function returning instant want way decouple code depends current time source time make easier write test run code different time common way make easier combine fork library jvm javatime package contains clock type however abstract class interface function type therefore cannot easily proxy clock function composition define new kind clock clock name taken name suggestion included clock put name clash timesource klock clokk clockk timepiece chronometer itellyouthetime itellyouatime type defined interface method return time kotlin interface timesourcetype fun timetype typealias function return time kotlin typealias timesourcetype timetype interface extends type function return time kotlin interface timesourcetype timetype making timesource interface extends function mean cant pas lambda timesource needed cant function composition define new type time source make interface cant reference clocknow timesource verbose treat plain function pas generic higherorder function typealias ability play side debate dont typealias dont want people dont want declare bare function type dont people clocknow easy ditch abstraction completely always real clock everywhere defeating purpose always call clockstandardclocknow new instant static reference cant stop people worth creating bit friction increase learning opportunity new concept time returned instant zoneddatetime javatimeclock class return time instant timezone property doesnt type called timesource source bit suggests time information life outside code something people seem forget return instant defined typealias kotlin typealias timesource instant timek provide implementation return current system time consequence code define timesources lambda function composition function reference client code explicit converting instant zoneddatetimes client code typealias
adr raster map algebra operation part research geotrellis rest service spending time learning raster operation aim gain clearer sense kind operation available occasion might useful adr aim summarize map algebra ops catalogued dana tomlins book cartographic modeling preparation deciding api endpoint implement book segment operation three subset local operation return value cell based value cell different raster focal operation return value cell relation cell within defined neighborhood zonal operation return value cell reation cell within defined zone watershed local operation generates new map layer every location set value computed specified function location value one existing map layer geotrellis package geotrellisrastermapalgebralocal operation local calculation calculate new cell value arithmetic function cell raster local classification calculate new cell value classifying value cell raster local combination calculate new cell value based combination value raster local majority calculate new cell value based value occurring frequently raster local maximum calculate new cell value based highest value cell raster local mean calculate new cell value based average value cell raster local minimum calculate new cell value based lowest value cell raster local minority calculate new cell value based value occurring least frequently raster local variety calculate new cell value indicating number dissimilar value cell raster focal operation generates new map layer every location set value computed specified function value distance andor direction neighboring location certain operation apply neighborhood extend well beyond immediate vicinity location neighborhood distance measured term physical separation travel cost line sight geotrellis package geotrellisrastermapalgebrafocal spreading phase distance neighborhood focus measured accumulation cost associated locationtolocation movement radiating phase distance neighborhood focus measured unobstructed line sight operation extended neighborhood focal bearing calculate cell value indicating direction nearest nonnull cell location neighborhood focal classification return new cell value indicate combination zone neighborhood focal combination calculate new cell value indicates combination zone occurring neighborhood cell focal distribution calculate new cell value indicating inversedistanceweightedaverage neighborhood cell focal insularity return new cell value uniquely match value assigned cell neighborhood also zone focal interpolation return new cell value indicating inversesquaredistanceweightedaverage neighborhood cell focal majority return new cell value indicating cell value occurring frequently neighborhood focal maximum return new cell value indicating maximum value neighborhood cell focal mean calculate new cell value indicating average neighborhood cell focal minimum return new cell value indicating minimum value neighborhood cell focal minority return new cell value indicating value occurring least frequently neighborhood focal neighbor return new cell value indicating value nearest nonnullvalue neighborhood cell focal percentage return new cell value indicating percentage neighborhood cell value equal original cell focal percentile return new cell value indicating percentage neighborhood cell value original cell focal proximity return new cell value indicating distance nearest nonnull cell new value treated measure distance already accumulated location new distance calculated focal ranking calculate new cell value indicating many zone neighborhood lower value original cell focal sum calculate new cell value summing neighborhood cell focal variety return new cell value indicating number zone neighborhood operation immediate neighborhood focal area calculate new cell value indicating area whatever portion areal condition represented cell first raster projected onto another raster focal aspect calculate new cell value indicating compass direction steepest descent plane inferred surface layer value location adjacent neighbor share first layer value focal drainage return new cell value indicating cell lie upstream surface inferred surface layer location first layer zone focal frontage calculate new cell value indicating length boundary formed whatever portion areal condition represented location first raster projected onto another raster focal gradient calculate new cell value indicating slope plane inferred original value cell adjacent neighbor value focal length return new cell value indicating length whatever portion lineal condition represented location original value projected onto another raster value focal linkage calculate new cell value indicating type form cell neighborhood focal partition return new cell value indicating areal boundary upper upper right right neighbor focal volume return new cell value indicating surficial volume beneath whatever portion areal condition corresponds first raster value projected onto second raster zonal operation generates new map layer every location set value computed specified function value one existing map layer associated location common zone another existing map layer geotrellis package geotrellisiomapalgebrazonal operation zonal classification explicitly assign new cell value combination value occurring first second raster zonal combination calculate new cell value indicates combination value one raster also present second raster zonal majority calculate new cell value indicating value one raster occur often second raster zonal maximum calculate new cell value indicating value one raster occur frequently second raster zonal maximum calculate new cell value indicating highest value first raster within second raster zone zonal mean calculate new cell value indicating average first raster value present second raster zone zonal minimum calculate new cell value indicating minimum first raster value second raster zone zonal minority calculate new cell value indicating value first raster occurs least frequently second raster zonal percentage calculate new cell value indicating cell count second raster zone whose value equal value first raster zonal percentile calculate new cell value indicating cell count second raster zone whose value lower value first raster zonal ranking calculate new cell value indicating number zone second raster lower value first raster zonal sum new cell value sum first raster value present second raster zone zonal variety new cell value indicates count zone first raster also occur second raster reading catalog checking geotrellis doc going attempt include endpoint three operation implementing api issue local variety focal standard deviation zonal histogram geotrellis ops dont map precisely onto catalogued theyre documented geotrellis capability along endpoint ops going try writing two additional endpoint endpoint generate png tile color ramp documented endpoint write data geotiff seems available via geotiffwriter module five api endpoint going implement path service localvariety return local variety result focalstandarddeviation return focal standard deviation result zonalhistogram return zonal histogram result pngtile return png tile fit shape geotiff return geotiff drawn shape along raster data accept geojson posted client consequence one upcoming issue research project choose raster project ill keep mind whether data set may interesting local variety focal standard deviation zonal histogram ops
adr messenger july given unique case six classifier single interface likely time classifier communicate one another app global scale apparent considering notification one classifier send message subject answer another classifier simply isnt enough one parent view model communicate child viceversa pubsub technology remove complexity architecture although wpf framework come shipped messenger build simple messenger better understand happening behind scene messenger building messenger scratch also remove reliance thirdparty framework consequence messenger fulfill app interclassifier communication easy become dependent messenger said messenger sparingly way view model component communicate one another retrospect messenger incredibly useful multitouch table initially relied much messenger later refactoring removed dependence lieu parentchild communication view model also found messenger helpful view model needed initiate animation view due event firing
open source permutation library jscombinatorics order check possible hand person make available card well generate hand common problem established open source implementation reimplement npm package jscombinatorics popular almost weekly downloads external dependency api exactly ill combinatoricspermutationary nelem creates generator generates permutation ary nelem element nelem ommited arylength also since instruction ask production level code worth noting jscombinatorics licensed mit license jscombinatorics instead writing something bespoke generate permutation consequence test write debug permutation code
adr env user want reference workflow variable defined workflow yaml file action input displayname condition add env runner runner create populate env every job execution following logic job start create env environment variable job message env defined customer yaml file jobworkflow level env section update env customer setenv set env runner level update env step env block step run env available runner customer cant env server evaluation part like runner example yaml yaml env env env env job build env env env runson ubuntulatest step run echo envenv echo env echo env echo env envenv true name envenv envenv env env dont populate env environment variable runner machine job container container action env may right value customer want cause confusion yaml build runson ubuntulatest userrunner hosted machine container ubuntu userroot container step run echo envuser customer expect output runnerroot dockerubuntu args echo envuser customer expect output runnerroot
direct emission exploration data source like plain table csv tsv txt json xml slowratelimited apis share fact want keep interaction count low plain table parsed missing index fast navigation wich reduces speed reading often computation time memory ratelimited apis consumed twice information allow retrieving list data similar single entry preferred allow smart ratelimit usage allow emission take place moment exploration consequence two place emit data therefore conversion logic data source payload heptaconnect dataset entity extracted pro portal developer support multiple data flow named data source processed efficient portal developer cache data structure exploration anymore efficient emission con portal developer decide data flow model want support additional complexity return type explorer explore method change data flow direct emission flow
payment nonpayment operation approved case payment related case considering managing token recurring payment bound payment rather bound particular customer considered customer endpoint interact adyen nonpayment operation payment endpoint interact adyen nonpayment operation outcome chose payment adyenintegration already payment code base ready flow would similar payment method already place extendable backoffice action future case related customer anymore pro con customer endpoint good payment token bound customer payment bad adyenintegration currently customer endpoint bad clear error case handled would user see request response adyen bad operation would always customer anonymous operation would possible bad cannot distinguish adyenintegration called customerrelated change nonpayment operation payment endpoint good adyenintegration already payment code base ready good flow would similar payment method already place good extendable backoffice action future case related customer anymore good customer resource useful case customer anonymous customer managed commercetools bad payment amount really payment rather payment management operation bad direct connection payment customer case recurring payment user define reference customer recurring payment
title component weight problem statement application structured main component goal able multiple rest serverswebapps multiple document processor component working togehter outcome following main module may helper module library support implementing feature store code related database access also provides job queue designed library joex joex stand job executor application executes job queue therefore depends store module provides code task submitted job job queue joex sleep must waked via external request provides document processing code provides http rest server get insight joex state also notified new job backend provides logic except document processing set operation operation directly mapped rest endpoint designed library rest api module contains specification rest server openapiyml file packaged scala library also provides type conversion tofrom json idea rest server module depend well rest client rest server main application directly depends backend module rest endpoint map backend operation also responsible converting json data inside http request tofrom type recognized backend module webapp module provides user interface web application
composite handler design proposed decisers daniel grant tom crane donald gray stephen fraser problem statement design implementation delivery component dlcs process composite artifact artifact typically take form single object containing multiple embedded resource rasterized treated individual resource within dlcs considered additional standalone component consumes dlcs ingest payload retrieves object rasterizes accordingly invokes existing dlcs ingestion workflow deployment image server cantaloupe provides functionality sit behind orchestrator process request component part composite artifact onthefly outcome delivery standalone component consumes dlcs ingest payload tailored composite artifact trigger ingestion workflow rasterizes constituent part invokes existing dlcs ingestion workflow pro con standalone component positive consequence selfcontained enhancement potentially requires modification existing component worst minimal configuration api component extended support arbitrary composite type assuming tooling available language negative consequence requires development effort front ongoing image server positive consequence preexisting outofthebox solution minimal development effort requirement artifact processing rasterization code already highly optimised negative consequence requires modification multiple existing component orchestrator thumbnail generation etc potentially heavyweight solution cantaloupe image server resource intensive result two image server deployed within dlcs iipimage cantaloupe significant effort remove iipimage entirely vendor lockin requiring significant effort migrate away specific image server implementation link rfc pdfs input
title adr automated certificate rotation adr automated certificate rotation certificate rotation largely manual process involving operator triggering series concourse pipeline job particular sequence routine rotation would typically part upgrade mean knowing cert rotation necessary checkcertificates job createcloudfoundry concourse pipeline would fail certificate day expired augustseptember moved platform secret aws credhub covered thirdparty service credential platform password certificate since credhub support certificate rotation chose implement automatic certificate rotation adr contains detail credhub notion transitional certificate written documentation transitional certificate new version signing yet added server trusted certificate list certificate rotation process built around setting migration transitional flag number deployment active certificate retired new certificate deployed without downtime order make certificate rotation automatic require operator interaction implemented job tail end createcloudfoundry pipeline acceptance test release tagging new rotatecerts job three task removetransitionalflagforca movetransitionalflagforca settransitionalflagforca three task reverse order process rotating certificate task ordered normally first task would set state second second would set state third bosh would unable deploy certificate without downtime however task explained proper order make easier understand certificate rotated understand happens pipeline assume bosh deploy happens step settransitionalflagforca first step process iterates certificate credhub looking expiring day regenerated transitional certificate result credhub holding two certificate credential name expiring certificate new certificate transitional flag movetransitionalflagforca second step process two job find certificate credhub value oldest certificate transitional flag newer one swap transitional flag older certificate finally look leaf certificate signed certificate regenerates new certificate look leaf certificate expiring day regenerates one step process deployed next bosh deploy removetransitionalflagforca third final step process iterates certificate credhub looking value older certificate marked transitional newer certificate remove transitional flag older certificate effect dropping certificate existing checkcertificates job also modified check certificate expiring day certificate fails check suggest something gone wrong certificate rotation process consequence certificate rotation happen frequently well update documentation surrounding certificate rotation documentation reference
adr backwards compatibility automate route pending previously rule governing automate route lifecycle past likely broke backwards compatibility renaming moving route additionally top nav highlighting automate driven root route everything setting tab must live setting route highlighted properly page live mean want move page new tab require new route every route originally linked page still webapp must still work backwards compatibility must maintained webpage original route linked removed app route removed deep linking source blog post etc well link customer internally continue work longer make sense original resource longer exists maintain backwards compatibility original route must redirect new route achievable approutingmodulets test must added verify redirection deprecatedrouteseespects see commit example route renamed proper backwards compatibility test look like page move topnav tab consequence deprecated automate route redirect new location relevant content removed webapp testing verifying redirection work also mean route add app exist corresponding part app deleted choose route namespaces carefully
deployment heroku department education cloud infrastructure program based azure would like digital service access azure heavily restricted production slightly restricted lower environment able work quickly particularly early stage project able deploy prototype experimental feature version service user research heroku deploy application herokus pipeline feature run deploy application consequence team full access control infrastructure service deployed ability grant access new team member required work dfe get access azure make plan deploy service later beta
route repository angular app considered wildcards toscatypes explicitly define route toscatype outcome chosen explicitly define route toscatype choosing whole project get type save lightweight tradeoff maintaining list available mainroutes toscatypes enum harder add new main route add extra module routingmodules type however easier define invalid route lead found error page pro con wildcards toscatypes easy add new mainroutes subroutes multiple toscatypes available subroutes come free component invalid route reached difficult understand explicitly define route toscatype easier understand therefore eas start new developer clear responsibility implicit better type safety valid route available toscatype file extendedcreated order add new route license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
itemtmsrendering title item rendering make franklin useful tool people working machine learning project able serve json metadata imagery label also imagery label asset adr focus two question particular domain serving imagery render render user discover something renderable render stac api many item may may cog challenge deciding make endpoint available different level user interaction could render item case user dont get choose collection since collection could render item collection item catalog case transaction endpoint implemented would user create container put item inside could render arbitrary search result case user would describe sort item want see would provide way visualize itemcollection response wouldnt anything persistent collection item though would something least semipersistent visualization collection item rendering collection hard technical problem however rendering collection also expose risk people returning item different sort imagery shortterm viewing image label risk doesnt come much benefit attached reason render single item render single item goal support rendering solves problem data accessed doesnt solve problem render imagery rendering label since working rendering paint raster label least three possibility state raster label three band one band surprising number band raster label three band dont help user make decent effort coloring assume band rgb produce png ship back walk away raster label one band situation ambiguous case probable label categorical take first stab coloring image labelitems labelclasses property determine distinct class choose random color render image color map strategy expose new problem dont anywhere currently persist color map either color map choose query parameter somehow well associate item database detail problem section persisting style case strategy available coloring singleband label well raster label number band obvious instinct refuse render dont think guess stage someone would produce label want come listen see incorporate rendering imagery several attempt made standardize interface describing render imagery raster foundry described bunch imagery adjustment custom type color ramp color palette last summer someone proposed extension stac specification include visualization parameter based google earth engine experience ogc description style styled layer descriptor slds past particular district builder project getting speed slds wasnt easy getting essential color polygon challenge wanted however think slds right move reason first district builder slds hand edited gigantic config xml file made easy construct incomplete invalid object since franklin written scala capitalize scalaxb automatically generate type necessary write slds hand pull request geotrellisserver add relevant xml schema verify type exist publishing opengis submodule locally importing opengissld ammonite repl second slds allow describe rendering strategy vector raster data adr address rendering raster data render vector data future come another rendering strategy helpful third dialog stac ogc direction geospatial web service take make likely wed justify sld chose something else probably better writing forcing champion usage standard persisting style since user probably dont want specify visualization parameter every time look layer well want persist slds item somewhere right franklin backed postgresql database backends possible well one store style information separate table storing style separate table would open possibility conforming ogc style api specification ogc style api prescribes set endpoint creating managing style either sld mapbox style adding endpoint style management would make api interaction slightly easier user would able color style raster later vector layer qgis export sld post api request would add asset stac item would require patching additional asset instead full sld document two store sld document property item separate column downside inserting sld directly item property since sld xml well mixing json xml json people generally expect conform specification property stac item freeform preference avoiding nesting throwing potentially nested raw xml string property sound like great idea however could provide json codec type generated sld schema downside throwing separate column extent break model foreign key json document entire record postgres expanding column represent entity conjunction entity json document make postgres like backends might pursue question whether attempt develop line ogc api style specification win get attempting conform style specification dont limb design style management justify choice make people think weird since previous section already say sld describing render attempting conform ogc style api specification natural choice user discover there tile layer available item one question whether tile url link asset since link link object resource related url asset asset object downloaded tile layer url link asset isnt currently iana relation type tile however map tile api specification include link rel tile map tile specification still work progress least sign direction ogc going thinking advertise tile collection planning serve tile item rather collection still reasonable source inspiration pursuit shortterm goal get rendering machinery place render item styling slds since provide many styling compatible open source geospatial tool standard style persisted separate table style management occur endpoint described ogc api style specification user know view layer item link relation type tile consequence result adr well familiarize sld open issue appropriate repository rendering entity tmsreification hasrasterextents latter histogram add geotrellisserver dependency franklin typeclass evidence tmsreification hasrasterextents stacitems add extension directory franklin including stac extension rendering strategy conforms add migration add style table franklin database add dao route managing style conformance ogc api style specifiation add route serving imagery item command line argument franklin server activate
iso specify time timezone implement pubsub implement event sourcing json specify datetime string formatted iso standard widely within json community specify datetime object rfc describes usage iso standard iso latest version standard described rfc formatting datetime object whenever datetime object serialized applies limited json message logging datastorefirestore timestamps object must timezone included consequence format transformed iso format whenever needed may cause little overhead reference rfc iso
create observation repository sort researcher may require method sorting list whale observation extract key information regarding whale migration population etc observation available comparison method proposed sorting possible create sortbydate sortbyid method observationrepository sortbydate comparator comparebydate comparatorobservation interface collectionssort sort list observation field sightingtime sortbyid default compareto method comparableobservation interface collectionssort sort list observation field observationid long collectionsort implement abstract strategy comparator interface concrete strategy comparebydate return integer referring order object consequence whale observation list sortable future iteration program easily add new comparators sorting since implemented strategy design pattern comparatorobservation interface
adr graphql data layer discussion participant roanna james david mailtorfbdavidchaucom complete installation ariadne apollo complete graphql schema completed philipp april boxwise middle planned migration old phpbased dropapp new app based new stack pythonreact old app backend data model closely intertwined sql string written directly within php made challenging evolve data model app turn imposed many product functionality constraint slowed development time especially since dropapp data model prototype rather designed scalability productmarket fit team migrates new app explores possibility entering new market time reexamine team might benefit separation concern data layer driver scalability well support expected future change restructuring database migration etc timescale technology expected defunct developer experience given rotating environment loosely affiliated developer different background support rapid onboarding developer data structure onboarded chosen technology pleasant useful career progression standpoint maintainability expect rapid change structure expand functionality easy solution maintain evolve documentation support productionreadiness library mature enough production environment active community support channel run problem considered api style full rest interface backend would involve creation multiple endpoint resource devs request wellunderstood professional devs new devs coming data analysis background example would learn correct rest standard overunderfetching problem cause network traffic heavy difficult evolve api dont know query requesting field specific resource often lead creating one endpoint per client data layer separation concern would require devs fluent current table structure change data model paired cascading sql query change equivalent orm blended environment graphql endpoint inventory rest endpoint login logic might easier create rest endpoint login user proof concept already started rest overfetching underfetching issue user katie said preferred build everything one style point implementing login graphql single endpoint everything benefit avoids underfetchingoverfetching problem readable frontend query language super easy compared learning sql scratch enables parameterized query inherently support incremental evolution field explicitly specified query supported facebook adopted major tech company paypal github ebay etc con new kid block devs much familiar graphql concept requires devs understand concept query mutation resolvers problem easy cache rest server graphene take code first approach development reportedly lagging behind maintainer looking people take oldest python solution around likely quite stable many frustrated user reddit ariadne take schemafirst approach excellent documentation functionality designed mimic industry leader apollo server nodejs compatible python backend fewer star compared graphene however compensates somewhat spectrum support channel wellloved reddit release supported small dev shop mirumee software client apollo client wellsupported industry leader extensive documentation sophisticated caching solution large footprint previously considered hard set configure due sophistication apollo boost package make thing super simple speedy urql lightweight tiny client solution intended make graphql simple however lack one major benefit apollo client cacheing supported mediumsize dev shop younger apollo client well server graphql single endpoint everything selected paired ariadne serverside apollo client side reasoning graphql may steeper learning curve professional developer familiar standard long run scalable iteration easier maintain multiple rest endpoint future end ingesting external data apis unhcr data easier pull graphql endpoint well also favorable developer experience standpoint onboarding maintaining codebase due graphqls introspective capability humanreadable json query structure degree clientside specificity requesting fieldlevel data apollo selected clientside due maturity product robust feature including sophisticated caching excellent documentation huge community ariadne selected graphene server side due designed deliberately intended mimic apollo server ariadne active development mirumee software excellent documentation developer crossreference apollo server documentation believe outweighs con come mature library graphene finally believe performance concern could result query abstracted sql resolvers compensated load network due overfetching long query created consequence easier requesting data backend initial set complete integrating external data source readability query making change database without breaking every single existing query data structure understanding keeping track data structure relationship one another versioning difficult initial set mean cannot take advantage flask utility create rest endpoint thing like login routing initial set data schema optimizing query performance error handling graphql inherently http response code like rest potentially optimizing scalability performance within large scale distributed system reading httpsgoodapicoblogrestvsgraphql
info graphqlimport import export definition graphql sdl also refered graphql module consequence consequence
jpeg ingest support ingestion jpeg image added accommodate scanned map record cannot find original tiff vip library generate pyramidal tiff thumbnail cant read jps directly temporary intermediate tiff generated openjpeg opjdecompress command command large amount memory eventually crash host server several jps decompressed simultaneously derivative generation functionality jpeg image removed consequence figgy longer generate derivaties ingested jpeg image functionality needed future better performing intermediate step required
paymentforbotdeployer deployment bot guaranteed succeed due network failure misbehaving node grid user pay bot reserve capacity case failing initialize solution lose money capacity wont usable payment bot deployer start funded wallet user want create instance create pool instance funded wallet min enough initialization step manage deploy initialize bot ask user extend lifetime bot chatflow case pool extension failure refunded explorer consequence user guarantee payment wont lost small amount token might lost wallet guarantee safety user payment successful deployment solution
http patch method requested functionality synchronize specified route either add replace main route table custom route table triggered log event would limited information available construct request available http method isnt perfect fit case put patch generally recommended similar scenario http patch method consequence implementation follow rfc specification http patch method patch document idempotent
time field agree way handle time form firestore currently following time field encounter form saved timestamp starttime endtime added near future habitat form starttime endtime saved string ideally would like save time related field timestamps however order generate timestamp access time value moment pas encounter habitat form however application flow going change user navigated habitat form first instead encounter form way pas starttime endtime field encounter form containing field filled habitat form submitted dont want add field habitat form want single source truth always habitat form within encounter form access database one composite key querying creates relationship habitat encounter form match unable generate timestamp based start time end time field habitat form however encounter form access time field considering following save time field string web app firestore able query data range save field encounter timestamp time midnight pro consistency saving type data one format ability query con inability query start time end time time timestamp starttime field value pro consistency saving type data one format ability query either start time con inability query end time save information twice start time saved starttime field therefore make sure save time field habitat form string encounter form merge time field timestamps save two field database starttimestamp endtimestamp pro ability query start time end time ability easily calculate elapsed time con start time end time saved different format habitat encounter form work required translate time field separate field database one timestamp decided following reason requires least amount dev work indication querying either start end time needed still able convert time field timestamps requirement change future link github issue extend encounter form include field
paypal ipn queue deciders kai nissen gabriel birke corinna hillebrandt abban dunne conny kawohl technical story httpsphabricatorwikimediaorgt declined problem statement paypal ipns fundraising frontend started fail deployment noticed day project manager needed export data upon investigation discovered error logging inactive application fixed cant debug response system returned paypal dont access ipn log led situation couldnt get information required debug error suggested queue incoming request paypal system processing system driver transparency system fails would stored queue debugging automation ipns wouldnt fired error becomes fixed system would resume processing queue pro con good debugging would easier could existing data run code without involvement paypal good system would resume processing automatically good logic wrong mean paypal server error paypal receives many server error stop sending ipns bad another system support bad send back ipn paypal verify genuine unclear paypal would behave time delay duplicate verification reprocessing old item bad lag donation confirmation email bad something silently wrong processing queue paypal wont log failed ipns look notification successful bad current method handling ipns robust chance introduce brittleness bad complexity outcome since first occurrence problem fundraising application system running well decided introducing ipn queue feature
create observation repository search researcher may require method search particular whale observation set whale observation study program accomplish task two search method may require implementation create getbydate getbyid method observationrepository getbydate observation iterator compare observation object sightingtime passed method creates array list matching object function iterator rather collectionsbinarysearch reduce runtime given may exist multiple object similar getbyid collectionsbinarysearch search possibly return object observationid matching long passed method collectionsortused ingetbyidimplements abstract strategy thecomparatorinterface concrete strategycomparebydate return integer referring order object consequence searching whale observation object sightingtime particular observationid possible
jetstream encryption rest metadatavalue author derekcollison implemented tag jetstream problem statement present way natsserver provide encryption rest stored jetstream data seen encrypted filesystem block storage would provided cloud provider end user documentation feature found official documentation design design allow master key generate key asset encryption within jetstream asset account information metadata data stream consumer even within stream data broken multiple message block disk block different asset key encrypt key external key provided natsserver configuration via encryption service subsequent release kek encryption key derived always generated never stored generated via prf kek prfek hmacsha argonid aek asset encryption key encrypted via kek placed alongside asset disk encryption encryption utilize authenticated encryption aead chachapoly future support followon release may choose configure natsservers access direct access today recommended method environment variable demonstrated documentation key rolling initial release different key message block stream meaning kek aek reused subsequent message block however may want introduce ability roll key could tbd first release backup restore equivalent changing encryption key encrypt stream asset would want think rotating well point would access old one retrieving older asset client side could also consider allowing client provide header even server client could control course requires normally promote good provided solution like encrypted etc
aws host solution problem statement host web application client access solution must easy manage update driver easy update high availability easy configure http observability considered aws azure blob storage google cloud storage outcome chosen aws one experience solution analyzed pretty similar regard driver considered given made based previous experience pro con amazon host static website good enable server access logging good easy update deployment aws sync good extensive documentation guide good possible configure http amazon cloudfront good enable server side encryption bad cheapest also expensive azure blob storage tutorial host static website blob storage good enable storage analytics logging good easy update deployment storage blob sync good possible configure http azure cdn good data automatically encripted rest good cheapest bad documentation little cumbersome google cloud storage hosting static website good enable access log good easy update deployment gsutil rsync good enable server side encryption good extensive documentation guide bad expensive
adr textfromsubject task march support ocr verification digileap project subject consist image ocr output text file create text task initially includes ocr output text input volunteer edit appropriate create text task textfromsubject task disabled text subject load content initializes text task annotation value text subject content text task annotation value initialized text subject content volunteer edit annotation value similar existing text task consequence create text task textfromsubject task initializes annotation value text subject content
push transforms manifest applying issue motivating influence constrains note adr build idea introduced last push refactor havent read adr please reading one acceleration team working cli version push found implementation made certain feature difficult impossible implement refactored first part push described solve problem dream serverside manifest december capi cli acceleration team began discussing idea serverside manifest capi would build endpoint received manifest made necessary change api side previously push manifest file concept invented implemented fully cli result work app manifest space manifest endpoint one part dream serverside manifest cli would longer knowledge manifest content push command would pas manifest content directly api without ever parsing yaml api would apply manifest given cli would upload source code staging goal allow capi add additional manifest feature property without requiring implementation change cli side see topic including original goal serverside manifest serverside multiapp manifest server side manifest exploration adding support diffing point time push print diff output like feature push got lot positive feedback last piece push implement parity diff output meant show difference current state pushed apps desired state represented manifest flag override like diff push pushing manifest org org space space admin manifest file homepivotalworkspacecfacceptancetestsassetsdoramanifestyml getting app info updating app attribute name dora path homepivotalgosrcgithubcomcloudfoundrycfacceptancetestsassetsdora command bundle exec rackup configru port disk quota health check type port instance instance memory stack cflinuxfs route dorasheersharkliteclifun set explore adding diff output found straightforward way already parsing whole manifest actualizing property individually intentionally didnt parse whole manifest knowledge full desired state without knowledge could comparison necessary output diff unfixable bug due override handled late whole class bug could fixed push refactor case manifest property value invalid corresponding flag override acceptable example might memoryinmb manifest quota push fine prior change manifest property flag override handled separate api call manifest property applied first exactly manifest file applymanifest request successful flag override would handled sending request scale memory number specified flag manifest invalid memory setting would put app quota applymanifest step would fail even getting override step believe confusing unexpected behavior user user pass would expect number mattered memory value theyre overriding manifest example bug cli user get failed push flag override quota limit manifest value change proposing agreed implement refactored first half push step come uploading source code creating new droplet read detail push work change change push preserved manifest property exactly asis sent applymanifest endpoint flag override would handled applying manifest complete push work change push par manifest inmemory representation manifest transforms representation manifest based given flag override generates new yaml send applymanifest endpoint effect eliminate extra step fixing app applymanifest step run example longer send additional request scale apps process flag given instead manifest send api modified say instance see detailed explanation work addition api fully responsible handling logic validating resolving conflict manifest property case study lifecycle flag override see implemented follow path flag override take user code api imagine user run push manifest look like yaml application name dora instance pushcommand par manifest aswritten given flag override pass handleflagoverrides return transformed manifest func cmd pushcommand executeargs string error transformedmanifest err cmdactorhandleflagoverridesbasemanifest flagoverrides err nil return err handleflagoverrides method another example hexagonal pattern established refactor pass manifest sequence function transformmanifestsequence func actor actor handleflagoverridesbasemanifest pushmanifestparsermanifest flagoverrides flagoverrides pushmanifestparsermanifest error newmanifest basemanifest transformplan range actortransformmanifestsequence sequence transform function var err error newmanifest err transformplannewmanifest flagoverrides err nil return pushmanifestparsermanifest err return newmanifest nil list function transform sequence actortransformmanifestsequence handleflagoverridefunc app name override must come first trim manifest multiple apps one handleappnameoverride handleinstancesoverride instance transform function handlestartcommandoverride handlehealthchecktypeoverride handlehealthcheckendpointoverride handlehealthchecktimeoutoverride handlememoryoverride handlediskoverride handlenorouteoverride handlerandomrouteoverride must come routing related transforms handledefaultrouteoverride handledockerimageoverride handledockerusernameoverride handlestackoverride handlebuildpacksoverride handlestrategyoverride handleapppathoverride handledropletpathoverride handleinstancesoverride method responsible transforming manifest based iinstances flag given func handleinstancesoverridemanifest pushmanifestparsermanifest override flagoverrides pushmanifestparsermanifest error overridesinstancesisset manifestcontainsmultipleapps return manifest translatableerrorcommandlineargswithmultipleappserror webprocess manifestgetfirstappwebprocess webprocess nil webprocessinstances overridesinstancesvalue else app manifestgetfirstapp appinstances overridesinstancesvalue return manifest nil manifest transformed generate following new yaml sent applymanifest endpoint yaml application name dora instance updated apis point view flag override override behavior resolved fully cli side manifest ever applied consequence becomes easier difficult risk introduced change mitigated cleaner separation concern cli api one key outcome achieved clearer separation concern cli api come manifest idea flag override always clionly concept case responsibility getting blurred example consider noroute available flag noroute manifest property noroute true refactor order apply manifest exactly written still allow overriding behavior cli required introduced noroute query parameter applymanifest endpoint noroute given resulting request would look like post vspacesguidapplymanifestnoroutetrue although worked example specific oneoff solution broader problem want add query parameter every overridable manifest property instance making api overlytailored cli case change noroute override handled fully cli side applying manifest since flag override cli business able remove noroute query parameter api endpoint clean related code api side serverside manifest closer dream goal serverside manifest push much possible work related validatingapplyingresolving configuration change api side refactor get much closer goal cli lean fully api apply manifest rather applying manifest correcting configuration additional api call however goal serverside manifest cli know little possible content manifest refactor deliberate departure goal order apply flag override cli must parse almost entire manifest risk serverside manifest wanted allow capi introduce new manifest property could leveraged user manifest without requiring code change cli biggest risk refactor capi could make change manifest specification would break user push experience cli release new version mitigation accept risk described reason designed cli new manifest parser preserve unrecognized yaml property inmemory representation yaml sent along api end mean capi free make additive change manifest specification user leverage without needing cli change capi make breaking change manifest specification impact cli however discussed capi team unlikely anytime soon since also force user refactor manifest require change client dependent manifest spec want make breaking change likely introduce idea versioned manifest continue support multiple manifest specification time fewer leftover push fails refactor failed push could result state change change would get rolled back push exited error setup suppose cli user started existing app space memory quota supplied manifest yaml application name dora instance memoryinmb pushed command push refactor push would apply manifest create instance allotted per instance case allotted memory would within quota manifest would applied successfully apply manifest succeeded separate api call would apply flag override allot per instance instead however case push would fail error indicating desired memory quota however instance created would stick around despite failed push refactor push transforms inmemory representation manifest following yaml application name dora instance memoryinmb push would apply manifest would fail validation error indicating desired memory quota therefore never even get step scaling app instance fewer api request per app nice sideeffect refactor number api call required push app decrease considerably previously apply manifest property make one call apply manifest call app pushing roughly number flag override make one call apply manifest pushed apps mean push faster resilient flaky network connection likely fail middle due poor connection requires code implement maintainability refactor build hexagonal architecture established push refactor make push consistent easier reason diff possibility simpler path towards implementing diff output feature representation full desired manifest flag override applied make request api current manifest compare two manifest better capture user intent flag override superceding manifest property believe user run push manifest look like yaml application name dora instance intention really push instance refactor would create one instance first scale refactor feel better capturing user intent outset without intermediate step incorrect manifest applied
remove adr util sync module proposed supersedes mention adr util module grew attempt centralize list utility function require adr file directory resulting module central logic entire program resulted module much differing concern many responsibilitiesreasons change eventually resulted tangled code sometimes unintentional circular dependency trying isolate handling link time usage shared adr file directory hasnt proved useful case case defined cached divide utility defined module focused module core directory filesjs handle file reading writing adrobjjs handle adr logicallevel operation essentially linking file linksjs handle logic around linking adrs case caching adr file needed adrobjjs done module consequence case api change instead api defined logical adr level adr defined file level client module namely command bridge gap case see repeat add wrapping adrobj module bridge gap done contentof function
remove enum struct fill macro generation problem statement cxrefactory generate macro filling structs turning enums string requires prepass cxrefactory source generate macro compilation said source creates catch situation requires bootstrap step also make build script much complicated difficult maintain replace macro actually remove generation feature cxrefactory actually real consequence risk hopefully source easier maintain build script easier modify slight risk functionality might broken fairly simple trivial replacement considered remove functionality keep functionality
resource endpoint integration namestatusintegrateswithrepo deputy reportingin developmentdigideps siriushttpsgithubcomministryofjusticeopgdatadeputyreporting resource endpoint root actionmethodendpoint healthget healthcheck report actionmethodendpointintegrations healthget reportshealthcheckdeputyreporting createpost clientscaserefreportsdeputyreporting supporting document actionmethodendpointintegrations createpost clientscaserefreportsidsupportingdocumentsdeputyreporting
extend application bar search feature consistent way add menu within fragment every fragment handle menu independently achieved calling sethasoptionsmenutrue overriding specific method needed creating menu handling selection event consequence implementation could differ fragment address code review
rigconfig global configuration supercedes config prefer prefix nesting dont hide default code previous way handling application configuration allow clean way override value environment variable override necessary configexs evaluated compiletime instance changing rig http port require corresponding docker image recompiled confex make flexible consider following example configexs elixir config rig riginboundgatewayapiproxybase recvtimeout system integer proxyrecvtimeout note default value given configexs never implementation keyword list supplied macro specifies required key presence checked note also validate configuration value customvalidation example elixir defmodule rigkafkamessagehandler rigconfig customvalidation defp validateconfignil validateconfig defp validateconfigconfig targetmod targetfun keywordfetchconfig userchannelnamemf messageuserfield keywordfetchconfig messageuserfield userchannelname user applytargetmod targetfun user end end end consequence user configuring rig becomes easier developer application configuration within module straightforward little boilerplate code involved
routing routing system allow user describe condition survey respondent complete answer question page condition boolean expression complex routing structure handle implement new version routing api handle nested expression heavily inspied httpsgithubcomonsdigitaleqauthorappwikiroutingmk terminology routing rule etc page fallback destination rule match rule series expression evaluated true destination specified expression either binary expression expression group expression group group binaryexpressions combined either binary expression base item left hand side condtion right hand side left hand side item compared question condition way comparing left right includes notincludes right hand side value compared left example page user enters page select red white page otherwise page page title page answer answer type number label answer routing rule expressiongroup operator expression left answer answer type currency condition equal right number destination page page expressiongroup operator expression left answer answer type radio condition oneof right value red value white destination page page else page page consequence allow build arbitrarily complex routing rule without change routing graphql structure
gradle build system modern software easy build reason software build system specify software build dependency work popular build system java world ant maven gradle ant pretty flexible lack dependency management also rarely day maven rigid ant support dependency management still widely gradle newest build system programmed groovykotlin flexible build system gradle also way build android platform gradle enjoys widespread usage author proficient gradle build system consequence gradles flexibility make easy add custom task accommodate change gradles flexibility make troubleshooting harder time gradle steep learning curve time spent learn
api description api responsible administering vehicle timetable map service real time vehicle tracking recive information localization source team decide make api wich allows organize timetable receive vehicle localization send information frontend api consequence api lightweight fast provides reusability
adr adding navigation override originally added feb lrud navigation tree already work well every component render included inside tree render entire page element inside tree eventually pointing root container current ssr requestresponse system build multiple lrud tree however partial page update system ppus inside mountain relys region system region defines markup lrud navigation tree ability hot swap region page along navigation node new region loaded primary tree rebuilt navigation node loadedin region primary tree made purely concatonated node region tree none region information relate example region currently horizontally aligned next alongside also situation arising desired journey around page dont align exactly layout example given page may want land node node user press even navigation tree node horizontally aligned next productux requirement etc want implement override system lrud instance override live alongside navigation object array object representing override direction node another node example given override may represent node user press node override live separate data item instance checked run time updatedaddedremoved needed based app state approved consequence lrud handle information navigation tree extra complexity extra data item lrud implementation currently move data around also move around override naive override cause unexpected behaviour lrud example setting override target actually cause final focus end first focusable child make sense somewhat unintuitive first
import implemented proposed adam gibson discussed generally every neural network file format defines sequence operation execute mathematical operation comprises neural network element sequence node contains information desired operation set attribute represent parameter mathematical function execute order write importexport different framework adapt attribute based format various popular deep learning framework ndj different list based format operation execution argument previous adr added make easier interop framework adr work extended add file format describing list operation mappingrules allow transformation one framework another transformation manipulate protobuf input output ndjs new opdescriptor format output related work see import implement mapping process framework defines transforms input file format mappingprocess defines list mappingrules represent sequence transformation attribute definition assist mapping mapping needed information like rule argument transformation current node whole graph input input protobuf file specific framework output descriptor described mappingrule convert attribute arg definition potential definition found appendix attribute named value supporting wide variety type floatsdoubles list primitive type see appendix theoretical definition arg definition argument opdescriptor described import adr see appendix potential definition arg definition together describes implement framework agnostic interface convert target deep learning framework ndj format implementation detail order implement proper mapping functionality common interface implemented needed common type mapping irnodedef node definition graph irtensor tensor type mapping iroplist list operation irattrdef attribute definition irattrvalue attribute value iropdef definition irdatatype data type irgraph graph abstraction one type wrapper around specific framework input type equivalent concept wrapper know convert specific concept ndj equivalent interpretation mapper applies mapping rule particular framework allow share logic mapper making implementation mapping possible calling associated getter method concept like data type node serialization order persist rule protobuf rule know serialize simple serialize load method implemented cover conversion interface method user implement describes persist protobuf representation applies relevant functionality rule process custom type type map directly applicable ndj order combat unknown type discovered mapping adapter function specific type must specified supported type include longint doublefloat string boolean byte ndarrays example dim tensorflow mapped long ndj shape information list longs multiple list depending consequence advantage allows language neutral way describing set transforms necessary mapping set operation found graph one framework ndj format allows straightforward way writing interpreter well mapper different framework ndj standardized way replaces old import make maintenance importsmappers straightforward disadvantage complexity code base instead straightforward java implementation risk introducing new error due rewrite appendix contrasting mappingrules another implementation map name type equivalent concept framework onnx tensorflow attribute converter done handler one found appendix challenge mapping ndj ops format vastly different onnx tensorflow purely attribute based ndj index based challenge addressed adding name property order actually map property define rule example mapping rule needed different convention concept one example stand conv padding padding represented string boolean say string equal ndj represent boolean issamemode conversion inline order invoke ndj correctly another issue implicit concept commonly convolution requires configure layout nwhc batch size height width channel nchw batch size channelsheight width tensorflow allows specify ndj also allows specify onnx depth conversation specific issue relating framework found order address challenge introduce mappingrule allowing define series step map input format ndj format language neutral way via protobuf declaration appendix theoretical attribute definition kotlin enum class attributevaluetype float listfloat byte listbyte int listint bool listbool string liststring interface irattribute fun name string fun floatvalue double fun listfloatvalue listfloat fun bytevalue byte fun listbytevalue listbyte fun intvalue long fun listintvalue listlong fun boolvalue boolean fun listboolvalue listboolean fun attributevaluetype attributevaluetype fun internalattributedef attributetype fun internalattributevalue attributevaluetype appendix theoretical kotlin definition argument descriptor descriptor found kotlin interface irargdef fun name string fun description string fun datatype irdatatypedatatype fun internalvalue fun indexof integer interface iropdef fun opname string fun internalvalue fun inputargs listirargdefargdeftypedatatype fun outputargs listirargdefargdeftypedatatype fun attribute listirattributeattributetypeattributevaluetype appendix theoretical kotlin definition mapping rule mappingprocess argdef found kotlin interface mappingprocess fun opname string fun frameworkversion string fun inputframework string fun rule listmappingruleattributetypeattributevaluetype fun applyprocessinputnode irnodettensortypeattributetypeattributevaluetypedatatype opdeclarationdescriptor fun applyprocessreverseinput opdeclarationdescriptor irnodettensortypeattributetypeattributevaluetypedatatype fun createdescriptorargdescriptors listopnamespaceargdescriptor opdeclarationdescriptor interface mappingrule fun name string convert attribute list link argdescriptor fun convertinputs listirattributeattributetypeattributevaluetype listopnamespaceargdescriptor fun convertreverseinput listopnamespaceargdescriptor listirattributeattributetypeattributevaluetype
authentication progress couple client project simple authentication system one project already flask postgres another design phase short term want minimal functional authentication system implemented soon possible long term hope implementation would reused many time easily customized dropin library flask project create minimal reference authentication implementation flask postgres include unit test hopefully strive high code coverage database migration organize database logic simplified cqrsinspired style code structure appmodelspy contain sql model appservicespy contain command modify database state appqueriespy contain query database delay feature arent current project requirement kind feature may addressed future version initially implement reference flask extension possibly add pypi public repository create react reference implementation password reset email account verification permission multi factor authentication oauth expiring token revokingblacklisting token prevent reuse old password consequence project template run risk creating lot little ball mud antipattern
rail backend onset link platform project needed decide framework backend discussion two choice presented serverless architecture aws lamda api gateway etc ruby rail made ruby rail backend consequence comparing two choice listed decided ruby rail ror allow take advantage intrinsic value framework development speed zendesk developer familiarity language also concern around adoption serverless architecture resolve since going ror added complexity lack subject knowledge well versioning open source contribution issue
adr directory identified marker file proposed adr utility meant run inside project initialize adr management project file system would like rely project file system make versionable traditional version control tool git end script utility must rely solely file system find correct location adr file relevant configuration order rely environment setting decided opt special marker file named specifically adr mark location adrs include environment variable rely naming convention specify configuration root marker file seems safest time simplest least number assumption convention made user downside course moving file potentially lead malfunctioning script time moving marker file adrs new place easy move file remaining assumption adr utility working directory parent adr usually problem user working specific project init command create marker adr file identify adr directory addition file simple property file maintain program configuration allows user modify different feature configuration editor consequence see adr utility must invoked ancestor directory adr directory loss file prevent adr directory working properly configuration adr part versioned source might prevent different user different configuration easily worked around changing locally committing file
int timer implemented timer way uniquely identified order processed several recorded something easy user work integer string enumeration enum class custom object consequence becomes easier difficult risk introduced change mitigated advantage easy understand beginner advanced user lightweight reduce overhead library requires fewer object type disadvantage lack type safety requires extra work associate label name reporting
adr focus english content first iteration content item written different language publishingapi return contentid along locale assigned content item focus content written english main reason would different algorithm library make application consistent among language locale real support future iteration data warehouse benefit make codebase simpler
global variable want able autocompletion cmdlet make user friendly easyvista rest api relies guid parameter well able query friendly name within cmdlet parameter tried environment variable dont seem work hashtable check extensively global variable named globalezvvariablename set dedicated cmdlet setezvcontext cmdlet define execution cmdlet project consequence pro cmdlet easier con global variable might allready exist
flask architecture flask allows whatever want appfolderstemplatesetc quickly become messy plus deal configuration within extension harder declare flask app load configuration architecture based httpsgithubcomstephaneflaskskeleton consequence breaking change mostly configuration
allow dynamic loading yetibot plugins via config yetibot currently resides across two primary repos githubcomyetibotyetibot githubcomyetibotyetibotcore code base continue grow size consist diverse range feature many many user wont care switching plugin system allows split code base much fine grained logical unit example may split github command plugin first plugin yetibotkroki continue extract plugins code base consequence primary yetibot jar docker image artifact decrease size feature extracted separate plugins configured dynamic plugins resolved upon startup mean potentially longer startup time especially user configured many plugins
service api metadata value author aricart implemented tag client spec release history revision description initial release configurable queue group add version regex info explicit naming problem statement simplify development nats microservices design goal api reduce development complexity similar writing nats subscription simple configuration allow specified metadata allow standardization discovery observability design service configuration relies following name really kind service shared service name name dash underscore version semver string impl validate semver one official semver regex description humanreadable description service optional metadata optional object string holding free form metadata deployed instance implemented consistently metadata stream consumer adr statshandler optional function return unknown data serialized json handler provided endpoint building endpointstats queuegroup override default queue group service created function called addservice passed function return objectstruct represents service minimum service expected offer functionsmethods allow stoperror function allows user code stop service optionally function allow optional error stop always drain service subscription reset reset tracked metric info return serviceinfo stats return stats service callback handler promise framework notify service stopped note independent nats connection possible run multiple service single connection addendpointname handler configure new endpoint service see adding group endpoint addgroupname set endpoint group addgroup see adding group endpoint startup service assigned unique distinguish different instance service allow specific instance service addressed discovery specified name automatically generated service automatically create subscription handle discovery monitoring request subject discovery request prefixed srv note prefix overridable much way order enable targetting tool work across account prefix honor whatever case specified initial verb supported service include ping stats info verb becomes possible build service subject hierarchy like srvpingstatsinfo ping retrieves service srvpingstatsinfoname ping retrieves service specified name srvpingstatsinfonameid ping retrieves particular service instance note name match whatever specified match whatever generated service service respond service request service request match name service request match name standard field discovery response contain following field typescript identifier message type example ionatsmicrovstats type string kind service reporting name string unique service reporting string version service validated official semver regexp httpssemverorgisthereasuggestedregularexpressionregextocheckasemverstring version string supplied service metadata metadata recordstringstring info return json following structure typescript type string name string string version string metadata recordstringstring description service description string array info service endpoint endpoint endpointinfo typescript endpointinfo name endpoint name string subject endpoint listening subject string queue group endpoint assigned queuegroup string metadata specific endpoint metadata recordstringstring field map metadata provided service created type ionatsmicrovinforesponse ping return following json standard response field typescript type string name string string version string metadata recordstringstring intention ping client calculate rtt service discover service type ionatsmicrovpingresponse stats typescript type string name string string version string metadata record individual endpoint stats endpoint endpointstats iso string service started utc timezone started string endpointstats name endpoint name string subject endpoint listening subject string queue group endpoint assigned queuegroup string number request received endpoint numrequests number number error endpoint raised numerrors number set last error triggered endpoint lasterror error field customized data returned stats handler see link serviceconfig data unknown total processingtime service processingtime nanos average processingtime total processingtime divided numrequests averageprocessingtime nanos type ionatsmicrovstatsresponse adding group endpoint service extended adding additional group endpoint group group serf common prefix endpoint registered group created addgroupname method service group name valid nats subject empty string cannot contain wildcard group name serf subject prefix group default queuegroup endpoint override service queuegroup group expose following method addendpointname handler register new endpoint service default endpoint registered subject created concatenating group name endpoint subject thisgroupnamename alternatively user may pas subject case service registered thisgroupnamesubject addgroupname creates return new group prefix group created follows thisgroupnamename endpoint service endpoint consists following field name alphanumeric humanreadable string describe endpoint multiple endpoint name handler request handler see request handling metadata optional recordstringstring providing additional information endpoint subject optional nats subject endpoint registered subject created concatenating subject provided user group prefix applicable subject provided name instead queuegroup optional override service group queuegroup enpoints created either service directly serviceaddendpoint group groupaddendpoint error handling service may communicate request error back client see fit help standardization also must include header natsserviceerror natsserviceerrorcode natsserviceerrorcode value always safe parse number natsserviceerror string describing error could shown user mean client making request service must check response error looking header allows client code fairly standard term handling regardless additional error handling convention service api library must provide error formatting function user produce properly formatted response header service msg client may optionally implement service msg add additional respond functionality responderrorcode number description string data uintarray opts publishoptions boolean enables service easily onboard service error without requiring user create shim add two required argument error code description rest match client implementation respond request handling service request handler operate default queue group mean order scale user add stop service possible send request multiple service example minimize response time quickest responder achieve requires running service instance different queuegroup configured endpoint queue subscription created note handler subject contain srv prefix prefix reserved internal handler handler specified client process request operate standard subscription handler mean assumption made whether returning callback signal request completed framework dispatch request fast handler return naming consistency documentation understanding user client implement service api tooling interacts service term service service
image stored addition store image explained moveimagestowebrootmd also store image icon meldingenkaart django done without feature flag reason storing django application manager municipality capable changing icon desired without developer image meldingenkaart stored django without feauture flag
interpreter rejected proposed adam gibson discussed interpreter import mapping rule execute map operation one framework ndjs file format back also allows execution different framework via conversion ndj engine combination allows uniform interface interpreter mappingrules transform file format another mapping rule execution mapping rule named function contain function signature input output mapping rule interpreter know function execute interpreter built implementation defined function desired transforms import process import process defined overall framework map input graph samediff graph specified mapping process name framework import process needed create graph needed concept import process implement graph creation order execution happen graph built happens java via samediff builder conversion happens follows input node convert node descriptor via defined mapping rule add descriptor graph descriptor converted customop added graph via addargsfor handle declarative graph creation setting dependency delegation graph structure creation existing samediff library enables scope interpreter focused mapping operation custom sub graph one common case mapping sub graph custom layer custom layer thought sequence operation order map named process created generally know ops sub graph made declare set rule based rule map individual ops existing framework consequence advantage common interface across different framework making maintenance simple allows easy maintain abstraction interop different file format allows easy entry point framework without knowing much framework disadvantage ensure compatibility across different framework requires extensive testing ensure proper compatibility may necessarily support ops people expecting addressed new adr
title convert text file weight problem statement plain text markdown document converted pdf file rendering image important since file must self contained uploaded docspell test file current documentation page docspell found micrositedocsdocmd layout doc position title documentation page title docspell assist organizing large amount pdf file work document two maintain kind address book list possible correspondent concerning peoplethings grows incrementally new unknown document docspell analyzes document try find match within address inspect set meta data docspell draw suggestion must maintained term order better understand page term explained first item item roughly pdf document item may span multiple file called attachment item meta data associated correspondent side communication organization person concerning person equipment person thing item maybe insurance contract car collective user application part collective collective group user share access item account name therefore comprised collective name user name user collective equal permission access plain text file tried without markup maecenas mauris lectus lobortis purus mattis duis vehicula vel pretium non mauris justo duis vehicula vel pretium viverra erat efficitur cras aliquam est eros varius iaculis duo auctor duis pretium neque ligula pulvinar placerat nulla nec nunc sit amet nunc posuere vestibulum neque eget tortor mattis tristique donec ante est blandit sit amet tristique vel lacinia pulvinar arcu pellentesque scelerisque fermentum erat posuere justo pulvinar cras eros sed enim aliquam lobortis sed lobortis nisl eros efficitur tincidunt cras justo porttitor quis mattis vel ultricies purus facilisis lacus cursus eleifend velit vitae libero sollicitudin euismod fusce vitae vestibulum velit pellentesque vulputate lectus quis pellentesque commodo end considered flexmark markdown html existing machinery described adr pandoc external command flexmark markdown library java process file flexmark create pdf resulting html following snippet scala def rendermarkdown exitcode val opts new mutabledataset optssetparserextensionsasinstanceofdatakeyutilcollection utilarraysaslisttablesextensioncreate strikethroughextensioncreate val parser parserbuilderoptsbuild val renderer htmlrendererbuilderoptsbuild val reader filesnewbufferedreaderpathsgetintxtmd val doc parserparsereaderreader val html rendererrenderdoc val body htmlheadheadbody stylepadding html bodyhtml fileswrite pathsgettesthtml bodygetbytesstandardcharsetsutf exitcodesuccess run result wkhtmltopdf markdown file figurefileexamplemdjavajpg txt file figurefileexampletxtjavajpg pandoc command pandoc markdown html testpdf micrositedocsdocmd markdownlatex figurefileexamplemdpandoclatexjpg markdownhtml figurefileexamplemdpandochtmljpg textlatex figurefileexampletxtpandoclatexjpg texthtml figurefileexampletxtpandochtmljpg outcome java library flexmark think result great depends type document one expects see guess people expect something like pandochtml produce kind file docspell newspaper article pandoclatex would best fit choosing pandoc mean yet another external command depend result flexmark really good one fiddle make look better introduce another external command flexmark already existing htmlpdf conversion
frequency local storage save deciders pietro problem statement issue often save local storage user type previous implementation saved every character caused issue driver simple straight forward way save local storage saving good frequency without introducing performance issue especially performant device possible without introducing third party dependency considered loadash debounce timer note debounce debounce function debounce function limit rate function fire youll pas debounce function function execute fire rate limit millisecond httpsjohndugancomjavascriptdebounce detail httpsdavidwalshnamejavascriptdebouncefunction example httpscsstrickscomdebouncingthrottlingexplainedexamples httpslodashcomdocsdebounce outcome chosen timer timer consolidated one final one rather lot save delayed one final save user stopped typing second timer cleared called final one left leaving one final save end performance optimization thissavetimer undefined cleartimeoutthissavetimer thissavetimer settimeout thislocalsavethispropsmediaurl
switch luxon manipulation hard whilst app require much manipulation across timezones make sure anybody world time see right time pride event london day happens noticed issue current library datefns reformats string situation represent location current device issue javascript paved library switch manipulation library luxon luxon cousin momentjs slightly different api immutable data luxon come full timezone support allows parse iso string without manipulating defined timezone string consequence new bug might introduced result understanding nuance library able switch luxon minimal change unit test least suggests avoided regression
heroku static buildpack decide deploy vue app heroku achieve either nodejs web server deploying app static site heroku static buildpack static buildpack deploy app essentially static frontend backed timdex consistent vues deployment guideline deployment consequence static buildpack began community project owned heroku still consider experimental project though buildpack appears widely rely introduces risk event buildpack becomes unsupported would reevaluate present express seems popular choice deploying vue heroku change cost would relatively low
layout default title adr navorder permalink record text derivative file generation sdr ocrtranscription proposed deciders peter mangiafico summer justin coyne justin littman alan lundgard niqui oneill mike giarlo andrew berger dinah handel proposed recommended problem statement automated ocr imagespdfs transcription videoaudio desired subset content deposited sdr order improve accessibility discoverability current process generating derivative file manual require operator intervention proposal automate generation derivative file via various mechanism either ondemand request made operator proposal address called nonimage derivative though may referred simply derivative throughout adr purpose adr nonimage derivative defined derivative file add value delivery content strictly required delivery example jps must created image viewer work derivative must generated accessioning prior shelving ocr transcription derivative file make content accessible searchable viewer still work without note viewer work may meet accessibly requirement derivative become available distinction useful derivative must generated accessioning others may generated accessioning additional planning see link section driver derivative able created automated process user able supply precreated derivative automated generation skipped precreated derivative present user able reaccession item providing changed file user able review generated derivative proceeding user able replace edit update generated derivative part review process user able regenerate existing derivative generation nonimage derivative delay accessioning derivative generation failure handled derivative versioned single system file retrieved considered three original considered summarized document derivative generated prior accessioning similar current manual process derivative generated accessioning similar derivative creation derivative generated accessioning also derivative generated accessioning via workflow instead tool access stack considering pro con approach selected described pro con various summarized document reason selected requirement generation derivative delay accessioning would possible proposed solution combination messaging workflow driven solution described detail document summarized outcome several discussion part architecture forum propose combination messaging new workflow produce nonimage derivative form described document listed basic flow architecture user initiate accessioning via current system preassembly goobi new user interface element added indicate ocr transcription needed material batch material set new field cocina andor add new workflow variable accessioning proceed normal last step accessionwf currently endaccession logic create new ocrcaptioning workflow object needed new workflow created immediately needed accessionwf allowed complete creation new workflow blocking new workflow consist several step include required versioning ocr transcription possible pause review review required indicated operator ahead time via element likely preassembly goobi passed workflow note since new workflow version object since new version cannot opened previous one closed may race condition new version opened previous one closed happens occasionally restart workflow fix problem happens often may implement automatic retries look alternate messaging based solution described ocr performed abbyy transcription performed whisper service likely run separately server monitoring endaccessioncompleted running new robot triggered api call robot part workflow object opened closed ocr transcription complete ensure file preserved closing object trigger accessionwf ensure file properly shelved preserved change made versioning separate workcycle ensure user process close object new workflow process preventing two process altering object time mechanism start ocrtranscription accessioning complete endaccessioncompleted message currently sent new ocrtranscription workflow triggered last step accessionwf listen message trigger new workflow message received new service would thus look message logic create new ocrcaptioning workflow object needed logic consider content type new field set existence derivative determine new ocrcaptioning workflow needed tbd issue known outstanding decided later exact variable passed accessioneer system variable stored cocina workflow model combination two review performed system edits performed system single new workflow handle ocr transcription two separate workflow code distributed existing codebases vms new codebases vms link integrating text extraction sdr accessioning architecture forum overview derivative generation proposal meeting running note high level overview andrew derivative generation proposal post processing
adr choice tool platform choice tool built accessibility monitoring team influenced suitability task cost ongoingcost opensource preference way defined adr meet number requirement maintaining organised list public sector website picking website test list triaging site prioritising site testing tracking progress testing website creating report completed test sending report site owner managing recording interaction site owner zendesk rationale license zendesk extensive welldocumented api lot experience general usage fair amount api sandbox zendesk environment driver testing work ticket created zendesk manually automatically representing website test prioritised zendesk assigned picked accessibility officer zendesk also handle communication followup site owner satisfies item postgres relational database best suited requirement public sector domain database testing record opensource well supported documented available plugandplay service govuk paas see satisfies item facilitates item govuk platformasaservice meet cloudfirst policy well supported extremely wellexperienced skilled team within support chosen technology deque axe deque axe rdparty opensource tool test web page give set predefined rule opensource run commandline probably automated produce result machinereadable format json satisfies item govuk design system frontend govuk design system set component style pattern created govuk team extensive userresearch serve readymade template engine know score extremely highly accessibility programming language nodejs axeintegration well suited asynchronous http call nodejs nunjucksfor frontend code thats govuk design system written python zendesk integration wellmaintained opensource python library review powermapper sortsite sortsite powermapper rdparty commercial product widely testing website thorough accessibility checking feature also crawl website catalogue page function axe perform would useful however opensource run window macos environment would easy integrate automated process web service whereby domain submitted return html report machinefriendly format would require screenscraping parsing quite major task one thats prone breaking ifwhen sortsite change output format sitemapping functionality sortsite could achieved existing opensource python node library consequence various rdparty product library system maintained order identify mitigate breaking change
feature caching zonder service worker moeten zowel tile feature kunnen cachen ngkaart voor offline gebruik offline data voorzien ngkaart werd initieel beslist met service worker werken voor zowel feature kaart tile bounding box gebruikt feature vragen echter afhankelijk van extent van view kaart omdat service worker enkel url kan cachen die altijd dezelfde url parameter hebben werd volgend systeem bedacht komt een extent binnen van kaart feature vragen nosqlfsloader component van ngkaart gaat deze call opsplitsen aantal nieuwe call gebaseerd een vaste grid bvb gebieden service worker kijkt voor aantal call die vaste grid boundary een tile bestaat indien stuur terug indien nee vraag online deze oplossing gaat echter gevolgen van beperkingen van service worker doortrekken tot logica van feature loader van ngkaart bovendien het aantal effectieve call per request dan veel hoger met performantie gevolgen daarom werd beslist voor het ophalen van feature geen gebruik maken van een service worker maar die wel niet een indexeddb bewaren mee integreren binnen nosqlfs van ngkaart stappen komt een extent binnen van kaart feature vragen nosqlfsloader gaat feature voor die extent opvragen aan featureserver bij ontvangen van feature worden deze bewaard een indexeddb per laag gemanaged door ngkaart indien nosqlfsloader binnen seconden geen antwoord heeft gekregen worden feature uit indexeddb gehaald consequence iets meer fetch strategy ontwikkelingen binnen ngkaart maar efficienter ophalen beheren van feature mogelijkheden ook extra metadata bij feature slaan bvb time saved indexeddb implementatienotas indexeddb essentieel een keyvalue store bij basale keyvalue store vergen complexe query inhoud van value table scan bij indexeddb kunnen echter wel index aangemaakt worden opzoekingen versnellen voor gekozen oplossing hebben vaak query deletes een view extent nodig een extent dimensionaal maar een index dimensionaal bovendien heeft een feature het algemeen zelf een bounding box wat maakt dat een feature gedeeltelijk een view extent kan vallen performant opvragen van feature die geheel gedeeltelijk met een extent overlappen dus niet triviaal een eenvoudig verstaanbaar algoritme volgt maken index aan voor minx maxx miny maxy waarden van bounding box van feature halen key van alle feature waarvoor minx binnen minx maxx van extent ligt halen key van alle feature waarvoor maxx binnen minx maxx van extent ligt halen key van alle feature waarvoor miny binnen miny maxy van extent ligt halen key van alle feature waarvoor maxy binnen miny maxy van extent ligt maken doorsnede van alle key daarmee halen alle waarden hoewel deze aanpak correct kunnen toch beter doen eens een index gebruiken kunnen waarden die bij index horen inspecteren die feature weerhouden die met extent overlappen die manier hoeven maar een keer door feature lopen het meeste voordeel kunnen behalen die index nemen die het minste feature zal opleveren weten helaas niet voorhand welke dat zal zijn maar die dimensie nemen waarvoor extent het smalste dan hebben grootste kans best index kiezen evenwel ook een nadeel aan deze aanpak vergelijking met die met doorsnedes plaats enkel key itereren moeten waarden ook binnen trekken dat heeft deserialisatie overhead metingen voorbeelddata tonen echter aan dat zowel voor kleine feature van naar grote extent van naar significante snelheidswinst behaald wordt een ander belangrijk voordeel van een enkele index dat feature onmiddellijk tijdens het itereren gemit kunnen worden gebruikers kunnen dus direct feedback van hun selectie krijgen
image loading glide android linshare application implement list file space user proposed user interface design includes thumbnail file preview user want show necessary library process first part image thumbnail preview best practice image processing library common android developer community glide picasso compare commonly usage glide much strengthen rather picasso process image source method generate thumbnail natively consume memory picasso library smaller packer much apis help process image witch could useful later implement functionality application decided glide instead picasso consequence base implementation application working well developer also save time develop feature base glide lib reference comparison source code
libcurl library deciders nathan fiedler authentication integration helix core server implemented extension library function available extension limited http call libcurl much else instance parsing xml available without writing parser heavylifting integration handled external authentication service connect service extension would http real libcurl connect service extension possibility explored architect time included web socket public key cryptography however web socket complicated build lua unnecessary http call client certificate ssl certificate also remove benefit public key cryptography available lua without building openssl server consequence extension libcurl since beginning worked well part one minor issue libcurl tends report error rather poorly error difficult debug
clojure developer good understanding clujure language ecosystem persist create apis secure etc pet project goal learning clojure ecosystem aplication consequence
median rather mean value discretizing gamma value order simulate smooth gamma curve discretize value gamma curve set category based decided median value rather mean calculating discrete value consequence slightly accurate
determine display facility map open apparel registry currently includes facility performance reason paginated facility data api endpoint data return maximum result single request turn mean frontend client ever display maximum facility time rendered clustered leaflet marker via reactleaflet facility api request currently filtered django querysets whose input querystring parameter included api request enable user view oar facility map simultaneously well update api return facility display client render map present mean updating application display facility simultaneously following upcoming msi integration work anticipate number oar facility increase around application able map addition also want user able filter vector tile query parameter like contributor facility name country along map bounding box accomplish decided vector tile generated ultimately postgiss stasmvt function rendering frontend leaflet vector grid possibly via reactleafletvectorgrid weve decided vector tile cluster facility zoom level would limit number actual point frontend display given time adr document subsequent setting dedicated stasmvtbased vector tile server like martin adding new vector tile endpoint existing django web application would make stasmvt query four rejected landing stasmvtbased solution consider ultimately rejected outright reusing existing facility api endpoint theory could remove maxpagesize limit facility api endpoint practice would cause performance problem size geojson response number leaflet marker increased web app would serialize ten thousand marker request geojson payload request could several megabyte size client would put ten thousand leaflet marker browser memory windshaft could potentially combination windshaft leafletutfgrid render facility wasnt much enthusiasm setting maintaining windshaft tiler specific reason windshaft requires adding another service windshaft pretty costly configure maintain windshafts documentation isnt great creating static vector tile ruled idea creating static set vector tile oar facility data change frequently lambda function tiler azavea undertaken research work determine viability tiler based lambda function connect postgis call stasmvt however research discovered limit approach dealing function warmup time handling concurrent database connection two stasmvtbased approach stasmvtbased approach generate vector tile dynamically seemed promising vector tile working group report note uncertainty around performant would generate tile postgis oar traffic may encounter performance problem could emerge higher traffic site considered two way generate tile stasmvt dedicated vector tile server like martin trex tegola adding vector tile endpoint existing django web app martin trex tegola vector tile server martin trex tegola opensource vector tile server connect directly postgis render vector tile judging documentation appear fairly straightforward configure operate slightly different api considered martin seriously part good documentation around write plpgsql function requesting tile data filtered set query parameter here martin function source example plpgsql create replace function publicfunctionsourcez integer integer integer queryparams json return bytea declare bound geometrypolygon tilebboxz mvt bytea begin select mvt stasmvttile publicfunctionsource geom select stasmvtgeomgeom bound true geom publictablesource geom bound tile geom null return mvt end language plpgsql immutable strict parallel safe pro configuration martin appears fairly straightforward configure documentation encompassed wed want performance martin tout suitable large database indicates might obviate performance concern around stasmvt con plpgsql function source since martin plpgsql function filtering would rewrite facility filtering logic currently exists django querysets web app work plpgsql moreover time added new filter search web application wed write version query plpgsql tiler security martin queryparams appear passed database string open security hole could create postgis role user limited readonly set permission solely martin instance requires taking additional risk complexity likewise adding postgisbased security tiler may also compel figure duplicate feature like api key authentication facilitiesdata request logging weve already written django unfamiliarity dont experience running martin production weve also got limited experience rust language martin written together mean martinbased tile server may difficult operate debug adding vector tile endpoint existing django web app adding vector tile endpoint existing web app seemed like promising approach since would enable trying stasmvt reusing apps database connection djangos querysets filtering approach would add tilelayerzxy endpoint django application update client make tile request rather rendering facility geojson response leaflet marker pro provides access existing django queryset apparatus martin similar solution would compel writing new version facility query plpgsql placing vector tile endpoint django let reuse existing query code also provides access django model querysets likewise would write new code new filter search two different language already secure database connection django web application already secure database connection would create solution securing martin another postgisbacked tile server enables switching stasmvt another python vector tile remains question viability stasmvt turn performant solution tile endpoint django make possible drop stasmvt altogether switch alternate python library generating vector tile doesnt require creating deploying different service adding martin another vector tile server would increase number different kind service running part oar add application complexity keeping tile endpoint django require adding new service allows scaling increasing number app instance adding tile endpoint django app also enables continuing scale application usual way increasing number app instance available serve request con mingles tile request traffic app traffic biggest downside adding vector tile endpoint django app would mean mingling tile request traffic app traffic plan limit size tile request response clusting facility different zoom level tile request traffic likely frequent sustained request current facility endpoint decided add vector tile endpoint existing django app martin particular seemed like compelling solution enough open question discourage taking complexity main apprehension adding tile endpoint existing web app itll mingle tile request request way could cause performance problem however given size oar traffic possibility addressing traffic increase scaling number app instance seemed like acceptable tradeoff consequence consequence add new tile endpoint api determine aggregation strategy clustering facility different zoom level adjust leaflet map tile endpoint determine symbology make necessary adjustment frontend sending selected filter search tile endpoint determine whether adjust gunicorn configuration change number worker per instance worker type decide whether add caching http header tile replicate change cloudfront
lightweight architecture proposed summary keywords lightweight iterative improvement inlined implementation testing production small scala aws lambda package size prefer direct inlined business logic abstracted indirection offtheshelf aws infrastructural facility instead bespoke implementation testing production via preconditionsprogrampostconditions instead mocked test prevent silent failure minimal custom abstraction zuora usage lightweight http json library vanilla scala design based observation lesson learned year various approach taken solve problem awszuora domain core idea minimalism tool abstraction indirection small scala aws lambda package size custom lambda library following vanilla scala snippet necessary define scala lambda scala object lambda def handlerequestinput inputstream output outputstream unit deserialise stream run program serialise stream importing web frameworkslibraries within lambda aws provides necessary facility outofthebox logging concurrency error handling etc many custom library necessary scala expressive language express concept vanilla facility something done couple line code import whole library prefer direct inlined business logic abstracted indirection generally speaking much algorithmically complicated logic business domain essentially http client json deserialiser request orchestration code able inline directly whole orchestration single file instead spreading many file library abstraction advanced feature place needed instead across whole system offtheshelf infrastructural facility instead reinventing wheel aws good documentation many example across open source github gdpr compliant setting infrastructure difficult largely onetime affair rarely change able look documentation example stack api gateway lambda import web framework implement custom router etc testing production via preconditionsprogrampostconditions instead mocked test favour runtime precondition postcondition testing production instead unit test mocked httpjson input tap precondition pipe program tap postconditions reserve unit test complicated business logic algorithm plumbing issue malformed json wrong http request orchestration likely surface quickly deployment long alarming setup thus roi unit testing aspect likely worth runtime preconditionspostconditions code alongside main business logic harder ignore lower maintenance cost relative unit test prevent silent failure multiple case silent failure introduced handling error technique swallow error without error logging wiring non response failing fast unrecoverable error hook aws outofthebox error logging alarming minimal cost automatic error recovery possible system cannot proceed fail slow automatic error recovery selfhealing etc difficult achieve ideal usually possible zuora due nature zuora outage hour long error handling cannot meaningfully addressed technique unit level instead addressed much higher infrastructural level sqs step function etc error recovery possible actually modelled error simply path system try minimal custom abstraction zuora work whitelisting opposed blacklisting principle system detects scenario cannot handle immediately notify developer make adjustment instead trying predict zuora model upfront handle imaginable scenario modelling zuora successful last five year due way guardian countless exception model instead zuora directly way document mean essentially rest api level favor precondition postconditions check done right thing invoice look correct production mutation opposed predicted model capturing way invoice generated corresponding mocked unit test zuora hard enough understand without developer putting another layer top usage lightweight http json library vanilla scala scala expressive language many concept directly implemented without depending external library json http boring sophisticated library even worse reinventing yet another custom implementation special logging config library aws provides outofthebox scenario require advanced techniqueslibraries technique necessary isolated segment codebase consequence argument silent failure subsecond aws lambda warmup lower maintenance cost easier lookup documentation easier onboard developer testing real data instead mocked data quicker build force developer stop ignoring alarm argument crucially depends developer responsibly reacting upon receiving alarm pending
launcher auto update process author seph directionless march superseded version one feature launcher ability securely update osquery unix implementation straightforward exec implementation however window exec adr document current implementation solution window new software version distributed update framework tuf client library built inhouse launcher periodically check new update new version detected downloaded staging directory running binary replaced code found autoupdatego unix launcher call syscallexec replace current executable without new process new binary code found updatergo window variation two needed change window first window support replacing running binary disk attempting result permission denied error workaround rename old version place new one correct location drawback losing atomicity second window support exec instead exit launcher assume service manager restart empirically start new binary configured path exiting launcher hard navigate thing inside tuf buried deep routine simple returning error isnt enough could call osexit seems abrupt instead plumb signal channel signal osinterrupt note signal posix sense constant sent channel example code example service exploring mechanism see code comment discussion consequence one consequence approach installed file updated place new binary verified launcher may look like corruption packaging system update process window based service manager restarting service dont believe there downside increase restart count due implementation limitation wix shortest recovery period day due nature update process update depend command line flag change require reinstallation launcher handled outside update process act moving new binary running old one unix result running binary longer disk trigger notice monitoring software example osquery
synthetic root tenant corvus tenancy provides underpinnings marain tenancy service always concept root tenant dating earlier preopensource incarnation adr capture aspect root tenant nonobvious learned nonobvious code written unaware special root tenant special tenant known root tenant wellknown fabbbcbf special three respect tenant hierarchical root tenant form root hierarchy tenanted storage mechanism fall back root tenant find default connection setting tenant defined tenantspecific setting within marain service root tenant always represented special inmemory instance roottenant type whereas tenant managed tenancy service third item support second service put roottenant service collection singleton becomes possible service attach whatever servicespecific fallback setting requires describe root tenant synthetic service creates object represent root tenant whereas object representing tenant obtained via maraintenancy service typically clienttenantprovider contemplated separating first two concern might enable third characteristic source confusion past however time planning keep way approach would require introduce extra mechanism support kind default consequence advantage synthetic roottenant service configure requires becomes possible service relying tenanted storage storage setting overridden pertenant level able pick servicedefined default case tenant wish bring storage come free result tenancy mechanism store setting without synthetic root would introduce additional mechanism enable servicespecific fallback downside currently possible define global default storage setting automatically apply service choose define servicespecific one thats cannot usefully define global property root tenant synthetic root tenant expectation client never fetch root tenancy service case fact allow fetched root tenant specialcased return dummy object expose tenancy service servicelocal root tenant setting block attempt modify root tenant
adr smart fridge kiosk handle payment customer able pay food currently supporting way acquiring food smart fridge kiosk home delivery smart fridge solution byte technology support payment creditdebig card kiosk home delivery payment handled toast also support payment creditdebit card customer also sometimes eligible discount free meal coupon provided farmacy food account problem system responsible communication payment provider know discount could achieved handling payment system assuming smart fridge kiosk communicate purchase system handling payment smart fridge kiosk system assuming system allow setting discount specified creditdebit card unique customer identifier let smart fridge kiosk system handle payment dismissed solution handling payment system concern around latency reliability backends operation important payment paramount stay fast reliable adding additional backend communication would lower change true additional advantage architecture doesnt focus characteristic important reliable payment processing consequence require smart fridge kiosk solution support setting discount specific customer creditdebit card uid
production ready service allinone setup deciders frederic lepied problem statement serve api production ready server driver production ready server good integration reverse proxy server like nginx apache support flask simple performant way considered uwsgi meinheld outcome chosen well known industry performant good performance serve wsgi app like flask thanks uwsgi protocol nginxapache negative consequence complexify architecture
logging request specific information got request logging specific information like tenant imposes problem distribute information around information contains stuff jwt tenant user potential custom information set request builder user passing around one one potential way would include information along method pas around practice pain would possible optional parameter stack get enormous executebuilduseorfetchdestinationgetdestinationgetdestinationfromdestinationservicedestinationfromserviceretriever would change add pro work node version performance affected con lot code changeswork code get cluttered continuation local storage since node single thread server concept thread local storage node world continuation local storage concept concept continuation local storage mainly implemented npm package since update since year claimed thing simply work would good feeling introduce however asynchooks node package available since version called asynclocalstorage idea always storage attached chain function write read point chain pro cluttering code change builder logger con work node higher performance great asyncawait see api really stable yet conclusion try answer question answered see blocker definitely switch turn due performance implication question rest community two finding artem open telemetry configures tracer system receive trace app one still storepass setting log level dynamically seem possiblerelated issue clsrtracer add nice automation approach know framework express since know sdk get really much dynatrace default support scp tracer also consider tracer support via sdk future supported node version checked via buildpacks nodejs buildpack version available available node version tag specified via enginesnpm attribute packagejson older node version support checked found backport asynclocalstorage version node really easy way ensure compatibility node would const asynclocalstorage requireasynchooks export const instance asynclocalstorageasynclocalstorage new asynclocalstorageasynclocalstorageundefined instancerun executes function call asynchronously return anything get result one could wrap like new promise lookup work central instance storage ifinstance const data instancegetstore datadata consolelogi found work frontend import return anything frontend code ignored performance test order measure performance following test done fixed number testentityrequestbuildergetall request executed parallel mocked response time measured promise finished case node version number request time variance change wrapped lookup one lookup three lookup see around increase lookup number call seems matter node node memory exception created even without wrapping number reduced case node version number request time variance three lookup three lookup three lookup change change change summary node implementation become efficient general handle request compared time increase node approx node effect stronger increase per default would switch wrapping decrease performance two way switch via env variable temporarily via enabletenantlogging method logger util permanently logger also log package
archunit checking architecture issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
jetstream publish retries responder metadata value author wallyqs partially implemented tag jetstream client motivation nats server running jetstream cluster mode occasional blip leadership result number responder available error election order try mitigate failure retries added jetstream enabled client attempt publish message jetstream ready implementation responder available error header signal client one available serve published request synchronous publish request jetstream internally request produce message jetstream service ready moment publishing server send requestor message right away improve robustness producing message jetstream client back bit try send message later default client wait retry time sending message total would attempted send message time found example implementation request api client stream persists message sent foo jsaddstreamnatsstreamconfigname foo var retrywait timemillisecond maxattempts loop publish message every range timenewticker timemillisecondc subject foo msg fmtsprintfid err ncrequestsubject bytemsg timesecond err nil err natserrnoresponders attempt attempt maxattempts attempt backoff retrying timesleepretrywait next attempt err ncrequestsubject bytemsg timesecond err nil err natserrnoresponders retry continue error exhausting number attempt result either timeout error case deadline expired nats response stream error error last attempt still responder error example customizing retries retrywait retryattempts two added customize retry logic default err jspublishfoo bytebar natsretrywaittimemillisecond natsretryattempts err nil logprintlnpub error err make publish retry needed deadline possible set maximum deadline retries client retry needed example client attempt publish second wait ack response server backing needed service available package ctx cancel contextwithtimeoutcontextbackground timesecond defer cancel err jspublishfoo bytebar natscontextctx natsretrywaittimemillisecond natsretryattempts err nil logprintlnpub error err custom ackwait err jspublishfoo bytebar natsackwaittimesecond natsretrywaittimemillisecond natsretryattempts err nil logprintlnpub error err
place utility utils module control utilitary function tool might utils module responsibility whose domain seem part object essence every time feel helper function good candidate utils rely typeof also good sign needing utils want maximize reuse function single static place understand might temporary solution consequence centralized place logic placed somewhere utils module potentially become hotspot code file grows high pace subfolder particular utils might needed point future utils also good place interaction external dependency although want keep zero dependency
library cli control toscana software commandlineinterface cli integrated program code therefore could library considered library created ourself common cli argsj jcommander jopt simple jewelcli picocli conclusion chosen picocli support everything create cli like cloudfoundrygit pro con common cli open source customer suggested good documentation subcommands supported jcommander open source customer suggested good documentation subcommands supported customized usage message picocli open source customer suggested support ansi color style good documentation support subcommands nested subcommands positional parameter customized usage message posix clustered short autocomplete feature pretty new license copyright university stuttgart right reserved made available term eclipse public license apache license accompany distribution
revisiting enrollment detail continues work started initial host detail author seph directionless last several year roughly since late weve seen occasional problem starting internally weve called monterey bug information link github issue httpsgithubcomkolidelauncherissues never managed diagnose reproduced small part nothing hold leading theory somehow related runtime complexity osquery startup time thrift socket contention may multiple related unrelated issue play additional complexity stem original implementation getenrollmentdetails osquery socket cannot run osquery started simultaneously launcher trying register extension osquery trying enroll simplify startup ordering reduce socket contention gather enrollment detail via execing osquery semantically fairly simple change query osquery consequence incur exec call startup return gain several benefit decouple enrollment detail main osquery startup reduce contention socket early startup enrollment longer circular dependency enables future work completely pull enrollment launcher
bot start testnet funded wallet reduce overhead user interaction grid hassle money flow every bot start testnet wallet funded faucet tft consequence requires upgrade entrypoint minor update frontend reflect simplifies money flow testnet reduces overhead
nodejs service select language web service restricted java nodejs decided nodejs web service felt existing team experience combined flexibility provided dynamic language made right choice java would provided static typing object orientation opted felt little heavy weight would provided lighter weight modern statically typed given neither team tessella existing experience viewed great risk project consequence integration kubernetes may harder nodejs would supported client prove difficult still build dedicated service kubernetes integration
dynamic indexing discussion proposed adam gibson april dynamic indexing wide variety application building deep learning graph expressing dynamic index get resolved runtime entail specifying negative index desired index indexing operation runtime indexing engine count backwards element user specified example start end start second last samediff ndj numpy style indexing support samediff way either ndjs indexing engine building previous work similar interface ndjs indexing engine build strided slice operation call previously indexing would allow initialization negative index without passing ndarray problem ndarrays known samediff till execution time proposal support ability dynamically resolve index execution happens follows index concept initialized return boolean indicating whether operation initialized initialized mean negative value present index specific boolean flag set representing index fully initialized negative index specified index set index considered initialized runtime upon deep copy index happens initialization occur upon relative ndarray currently happens java level indexing exist fully level consequence advantage allows flexible indexing possible time resolution error thrown indexing disadvantage bit overhead indexing process harder debug
adr hashfiles expression function first party action actionscache input explicit key restoring saving cache package caching common key might hash result content packagelockjson nodemodules folder serval different way get hash key input actionscache action customer calculate key different action customer wont like since extra step cache feature yaml step run hashsomelinuxhashmethodfile file file echo setoutput namehashhash createhash actionscachev key stepscreatehashoutputshash make key input actionscache follow certain convention calculate hash limited key input certain format customer may want yaml step actionscachev key runneros githubworkspace packagelockjson add hashfiles function expression engine calculate file hash hashfiles allow runner side since read file disk hashfiles server side evaluated expression cause runtime error hashfiles support hashing file githubworkspace since expression evaluated runner customer job container container action runner wont access file system inside container hashfiles take parameter hashfilespackagelockjson search file githubworkspace calculate hash question support one match pattern hashfilespackagelockjson toolkitcorepackagelockjson toolkitiopackagelockjson answer support single match pattern always add later help customer better experience actionscache action input yaml step actionscachev key hashfilespackagelockjsongithubrefrunneros search pattern basic globbing globstar additional pattern detail root relative path githubworkspace main repo make match file start case insensitive window accept path separator window hashing logic get file githubworkspace search pattern filter file get file match search pattern search pattern apply file path folder path sort matched file full file path alphabet order sha algorithm hash matched file store hash result sha hash stored file hash result get final char hash result question include folder structure info hash answer
adr highlighter task mar support ocr verification digileap project subject consist image ocr output text file create highlighter task highlighter task allow volunteer highlight text ocr output label label defined researcher fem highlighter task iteration pfe highlighter task feature highlighter task volunteer highlight related text text subject viewer selects label task area repeat highlighting label selection completes task highlighted text unhighlighted highlighter task label description defined researcher highlighter task label color selected researcher limited provided zooniverse related task editor highlighter task utilize selection api highlight text text subject viewer selection api supported modern browser following example highlighter task annotation label scientific name collector name habitat location json value labelinformation color fff label scientific name start end text allium vineale lfieldgarlic labelinformation color fde label collector name start end text derick poindexter labelinformation color ffa label habitat start end text growing base ofnthe mountain wet meadow adjacent trail margin infrequent exotic perennialnforbherb labelinformation color dcce label location start end text located sheep rock along airnbellows gap prior pruitt left task tasktype highlighter create highlighter task fem consequence create experimental task highlighter task fem proposed
centralize definition filename proposed evolution tool several place code somehow relate formattemplate adr file name immediately mean change template take account different place example feature suffers customizing adr file name template issue currently identified place refer file name new command newjs adrutiljs file several function adrutilsyncjs file centralize definition adr file name template easily changed configured given want shared code adrutilsync probably centralize definition consequence given file name template centralized code place refer file name template reuse place functionality shouldnt harmed otherwise
xml editor enforce validation userstory winery offer editing stored xml tosca definition validation considered winery never creates nonschemaconforming xml instance user create topology template first allowed save service template winery generate random data gain schemaconforming xml winery generates nonschemaconforming xml assumes user make eventually valid casea user xml tab user know winery force user generate schemaconforming xml editor winery generates nonschemaconforming xml warns user user xml editor winery force user generate schemaconforming xml xml editor outcome chosen line editor allow save warn file compile error validation error license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
flask aws lambda function project would like package api endpoint logic small flask app single lambda function found whilst working document integration managing multiple lambda function quickly became quite hard work especially project lot shared code place hindsight refactored shared code separate lambda function never got due time constraint also would give lambda function maintain flask wsgi app lambda good idea reuse infra setup last project get started fast easy run develop locally run like normal flask app easy test normal flask app written lot flask apps lot people documentation plentiful well established antipattern aws library called chalice similar thing propose flask deployment stuff dont aws official package antipattern maintaining single lambda function much easier maintaining many project small well defined boundary none data artifact accessed anything api meaning completely independent service excluding aws security good candidate experimenting nothing reused outside app flask wsgi app lambda bad idea whole app faa seems like antipattern cant find evidence supportcontradict potentially longer coldstart initialise whole app single function flasklambda small package contributor though pretty simple script map request variable depending source request single lambda function containing small flask app provides endpoint flasklambda help easily switch local dev aws consequence api may slow respond due flask app startup time implementing metric time see concern wrong want move container code little rework infra rework large wrong want move separate lambda function code rework infra pretty much flasklambda package may require maintenance futher reading flask serverless api aws lambda easy way serverless deployment python apis deploy flask api serverless cloud platform simple pattern aws chalice
generating odata client template proposed odata client generator currently based tsmorph library provides functionality programmatically navigate manipulate typescript code proposal base generation typescript code javascript native string template consequence focus tsmorph navigating existing code generating new code point benefit switch templatebased approach performance first test showed make pure generation typescript code time fast including parsing time faster seems similar including transpilation although final result yet readability convenience without tsmorph dont handle additional layer abstraction brings along useful analyzing code really necessary generating code native string template free structure suit purpose name accordingly vdmentity abstraction enough deduct resulting file new team mate wont get tsmorph api without additional abstraction template become frame closer final code allows developer easier understand actually looking also little power formatting template approach directly modify generated string currently additional lint step could left improving performance bit testability currently generated code quite difficult test test either match tsmorph structure involve save generated code read string test small chunk generation easily comparing string becomes even easier snapshot testing
see httpsgithubcomazavearasterfoundryissues feature requirement provide way user request shipment export imagery system geotiff format able deliver finalized export user able deliver export large area high resolution provide user indication progress requested export high level matter architecture choose workflow probably going look something like user make export request via api generate export configuration based user request render output report delivery report imagery handling source imagery come several source project collection scene user may select subset available band user may request rgb image output tool ndvi ndwi evi either limited areaofinterest polygon delivery imagery able delivered via ratelimited metered http link direct deposit user bucket direct deposit user dropbox user able select projection imagery receive data model choosing appropriate internal data representation export parameter important ideally would like single export process handle exporting imagery tool node project want process easy reason well resilient change tool project user dont lot information actual usage pattern functionality look like beta user band rgbnir imagery however know many beta user expressed pressing able view imagery map exporting result analysis urgent many focus immediate development effort providing solution user want export rgb imagery project already contain rgb band little analysis alteration aside color correction mosaicking approach constrain scope development allow iterate quickly addressing concrete problem faced real user put another way explicitly deferring implementation export functionality following case falsecolor composite hyperspectral nonrgb data source project whose scene dont available band resolution tool output arbitrary tool node however expect cover deferred case sooner rather later design data model way believe allow easily expand export functionality going forward detail design given additionally order avoid making functionality limited information aspect functionality outlined addressed adr noted end section data model internally wrap export configuration inside tool definition even though initial focus providing export rgb data project mean user request export particular project without colorcorrection internally generate oneoff tool look something like following export output tool project user wanted colorcorrect would colorcorrection operator middle instead identity operator approach increase initial complexity developing export process work specifying tool generating imagery arbitrary tool definition still progress finalized process work least extent necessary support case ultimately believe adopting architecture upfront net win term development effort following reason force functionality tool dogfooding provide opportunity discover problem tricky area functionality user make tool robust overall let get head start exporting tool making eventual implementation functionality straightforward get ideally able simply userdefined tool definition export rather internallygenerated tool everything work unlikely thing work perfectly practice almost certainly save time simplify architecture export job able assume always receive tool definition input implement separate export logic depending whether user chooses export project tool workflow user request create api endpoint allows user request export project stage development endpoint accept minimum parameter allowing user specify project export delivery http link deposit dropbox deposit areaofinterest geometry mask export output output projection srid endpoint prevent export project scene user making request authorized access may also basic verification delivery user dropbox configured enough space dropbox etc generate export configuration endpoint convert user request internal representation export configuration toolcentric structure described export configuration stored database record trigger creation airflow dag run perform actual export airflow dag run triggered similarly way ingests currently triggered user make api request row written exportconfiguration table table name important signaling pending requires processing airflow task run periodically every minute two kick dag run export configuration marked pending change configuration dont get processed twice outline export configuration might look like given end section exact schema expected change add functionality note airflow early version rest api may allow trigger dag run directly userfacing api endpoint would eliminate periodic task scan pending export thereby reduce latency however feature early stage wait mature utilize render output spark job take export configuration relevant portion render necessary output store result detail job function run defined delivery result export task stored consistent format delivery mechanism structured process copy data make available target three target know internal accessible via http external dropbox internally store information database record user multiple aws dropbox credential tied account authentication detail external account treated sensitive information password internal delivery process make export result available via http could done number way moving specific bucket making database record link export result publiclyaccessible url delivery also include ratelimiting metering exact detail functionality left undefined external delivery process require bucket prefix file stored aws credential external aws account sufficient permission write location parameter provided user delivery process authenticate provided credential copy result export process provided bucket prefix location dropbox delivery process require credential dropbox account well location within dropbox functionality similar external delivery mechanism delivery process authenticate provided credential attempt copy export result provided dropbox account dropbox account limited storage delivery mechanism preverify enough space available store export result handle error may arise user dropbox running space update provide user update progress export consistent existing update mechanism express enumeration export record database enumeration expected look something like following subject change pending export airflow dag kicked submitted export dag processed rendering export rendered delivering export rendered delivered success export delivered successfully complete error export encountered error failed complete structure update separate airflow task wherever possible update mechanism tightly coupled task report often brought fails causing incorrect reporting keeping task separate task real work ensure reporting based airflow view task expect often correct example dag structure given sample export configuration schema schema omits common field user creation datetime intended starting point change expected exportconfiguration source tool could also stored json field represents tool definition outputprojection srid mask multipolygon area interest clip result deliveryconfig deliveryconfig user create object providing credential dropbox etc enum pending submitted rendering delivering success error result json link deliveryconfigtype http error message failure deferred structure following feature left undefined gather information usage desired functionality rate limiting metering downloads dont know much detail necessary could carry high engineering cost depending solution chosen user interface allowing user select different band export falsecolor composite anticipated priority early user dont enough information case develop clear path forward implementing backend handling project contain scene different set band andor different resolution previous consequence wrapping export inside tool likely require greater upfront development effort exporting project directly would however described believe approach pay significant dividend term development effort robustness later storing update enumeration make difficult store extra metadata export prevents storing finegrained percent completion simpler implement however flexible solution also complex believe simplicity enumerationbased solution make straightforward extend update functionality concrete case arises complex feature developed largely without direct user feedback far deferred architecting number aspect functionality gather realworld usage information reduces risk expend development resource feature user dont deferring implementation expose possibility may develop feature time pressure point future balanced fact situation occur much clearer understanding necessary functionality point
autofac dependency injection supercedes hardcode dependency amends unity dependency injection issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
macro creating new timer implemented creating holding timer object introduce error noise code thats also hard remove release code optimize performance example include timediagnostics static const timerid timer tdgettimertimerid user code provide macro start new timer disabled recompile example uncomment remove timer release code define disabletimediagnostics include timediagnostics static const timerid starttimertd timerid user code consequence advantage user explicitly create name timer object user input creation anyway simple definition disabletimediagnostics turn starttimer macro empty statement removing overhead stand code clarifies intent disadvantage macro
create castable spell want give variation combat system beyond physical attack allow reason create separate build player character enemy fight give game element combat opposite system based luck alone create spell integrate character combat system progress damage spell aoe single target added healing spell aoe self ally target added
toolscli library working command line argument toolscli consequence
store new tide projection firebase want able store projection tide especially task aim display pertask detailed pipelinelike much real time possible firebase helped lot log appear successful make sense extend usage projection order ensure permission control tide stored following hierarchy flowsflowuuidtidestideuuid consequence coupling party dependency even higher sort permission control database accessed directly client sort archiving detailed tide
editor online part moj onlines toolkit editor software allows user form owner build test form editor actually made several piece software mainly editor console application console application electron application function installs editor run editor preview form runner creates github repository editor interact service instead produce collection file finally stored github link github publisher obtain file create form online currently editor application managed electron console application time either edit form create form console start web server unused port open editor host browser therefore could one form editing time application available mac signed notarised stapled apple run decided redesign editor self service end method storing form metadata changed see adr evaluating different including direction product decided rebuild editor ruby rail custom javascript front end consequence editor runner develop feature desktop editor publisher runner already acceptable editor design changed enough make rewriting editor combining publisher new runner new metadata schema amount effort form metadata compatible editorsrunners form live production task backlog look migrating form new self service editorpublisher
choose orm orm especially flasksecurity available moment flasksqlalchemy bloated flaskmongoengine relies mongo harder migration flaskpeewee initial choice maintained anymore ponyorm look great code hard contribute flaskmongoengine migration manually might want findcode tool future consequence inform hosting company mongodb update existing pullrequests
useisoformatfordates title iso format iso format system composed number api related datastores currently number differing format iso format yyyymmdd time consequence time displayed standard cultureneutral format standardisation simplify development effort permitting focus business value
cliscripting language easi application require set command line utility setup test serve application script executed local developer environment cicd pipeline similar application script require language framework organization pattern create maintain value adr well decide language package writing script main driver ease setup maintainability developer adoption considered standard library cobra bash make rubypythonother dynamic language outcome chosen cobra since language server application allow lower learning curve higher adoption among developer many service looking work docker aws postgres package help write develop set resource maintainable long term make bash electing add cobra library offer substantial value command line flag configuration package maintainability cobra style code outweighs complexity setting third party package mitigate downside building command execution helper package opposed executing shell pro con standard library language server application standardization around code style support packagingeasier organization lower learning curve bash verbose scripting requires package run command line tool flag config support isnt great cobra language server application support packagingeasier organization robust flagconfig support standard lib subcommand flag syntax lend towards sustainable code verbose scripting requires package run command line tool requires additional setup possible package lock make bash shell command execution native ubiquitous scripting difficult read syntax subjective common larger codebases hard maintain rubypythonother dynamic language lot built helper scripting string manipulation formapreduce shorthand etc support packagingeasy organization learn another language setup another language
stale data fridge proposed smart fridge system external system provides vital information customer ordering system control frequency update data structure management available position nonetheless provide service based provided data try keep inventory side precise possible avoid collision situation user might dissatisfied service risk point time cant get actual data offline maintenance throttling caching etc ordering system handle situation occasional user pay cash major factor issue prepaid meal still picked offline scenario dont really contribute stale data issue payment server must already done job cache maintain data integrity available stock fridge side get new data smart fridge system point data adjusted consequence storing data available stock add computational pressure system cognitive complexity concurrency model system data integrity accept consequence able operate estimated stock provide service endusers impact purchasing process requires business edge case something purchased delivered monitoring alerting system smart fridge system team informed timely data gap defined gap ping pattern involved smart fridge system health check handler risk loses compensation coupon customer action define business tech team raise alarm case data gap might minute hour instance
decouple game web server problem statement want create multiplayer web game structure project driver software architecture important clear separation concern testable code considered standalone otp application game business logic single otp application web server game outcome chosen standalone otp application game business logic good business domain isolation ignoring web concern beginning help thinking game api possible different client command line web make complex interaction test easier different release bundled together server one game application many server
secret environment variable record issue access database info username port host etc decided create environment variable hosting platform access info without leaking code decided pro code simple con everytime host change environment variable reset believe something cannot avoid secret make sure confidential information wont accessible reading code
metadata stream consumer metadatavalue author jarema approved tag jetstream client server problem statement way easily add additional information stream consumer solution description field ergonomic workaround server httpsgithubcomnatsionatsserverpull design solution add new metadata field consumer stream config metadata field would map string key string value json representation map would represented json object nested keyvalue pair default way marshal mapshashmaps language size limit avoid abuse metadata size limited size equal len key value summed reserved prefix nats reserved prefix potential internals server client server lock metadata immutable deny change example json durablename consumer consumerstream field metadata owner nack domain product natscreatedversion
adr clojure function etl akvo lumen system allows user connect different data source import data user must able transform clean aggregate etc looking different open source etl framework like pentaho data integration clover etl onyx platform bubble kiba etl provide gui build transformation others require coding one based hadoop ecosystem really much current luigi oozie azkaban based skill team clojure expertise fact clojure excels data transformation decided small adhoc function handling import transformation enough current depending requirement well scheduling library like quarzite scheduling import consequence current approach create adhoc function handle import extract different data source setup easy transition onyx platform see conversation onyx author
mvvm android development start develop android application chose right architecture dont choose right architecture android project hard time maintaining codebase grows team expands come mostly behavioral design patent mvc mvp mvvm linshare application target code quality mvvm suitable code base could testable reduce middle code biding layer advantage mvvm architecture code even easily testable plain mvvm code decoupled biggest advantage package structure even easier navigate project even easier maintain team add new feature even quickly layer mvvm clean architecture code divided three separate layer presentation layer domain layer data layer agreed implement mvvm application design android application consequence atenatives mvc drawback presenter android api easily tested mvvm easy unit test base design comparison reference also concern design patent mvvm take time newcomer explain layer work together add maybe extra class ideal lowcomplexity project reference mvvm pro comparison
adr graphql error response structure trello card deadline author pylipp proposed updated problem statement boxtribute web app graphql define interface frontend backend reason graphql specific framework found elsewhere according request frontend data error transferred via graphql interface data error response field especially case error important provide clear information error occurred time development well runtime app currently backend follows strategy similar one apollo server custom exception extension attribute containing least alphabetical error code description however arbitrarily extending possible raised case error processing response frontend act depending error code defining result type description text condition necessary approach convenient default graphql error response structure mentioned ariadne community brittle error code string might changed missspelled backends exception definition description text past showed complex bulk operation like mutation receive box shipment handle various error dont define dedicated structure indicate instead error might ignored leading confusing state frontend bug driver clarity app reliability impact development considered keep current state string code defined backend distinguish error union type defined graphql schema indicate error result custom result type encapsulating data error set mutually exclusive detail approach taken recommend read blog post also highlight idea operation possible result considered directly woven graphql schema let look issue approach putting error error response field like boxtribute backend error treated matter kind hard know error came esp complex operation hard client know error care proposed approach think possible result operation model union type fetching user username might turn exist blocked unavailable example schema query graphql type user name string type doesnotexist type isblocked message string blockedbyuser user type unavailableincountry countrycode int message string union userresult user isblocked unavailableincountry doesnotexist query userusername string userresult example query graphql userusername ash typename user name doesnotexist isblocked message blockedbyuser name unavailableincountry countrycode message success response graphql data userresult typename user bbee name ash ketchum error response graphql data userresult typename isblocked message user blocked ash blockedbyuser username brock advantage result customizable entity user different result type example tweet know error came error come query attached entity actually encoded schema client decides error care error ignore client query query different result decides whats important detail approach taken ariadne documentation adaption discussion discouraged main error field convey error since message present key technical nature shouldnt displayed end user instead one define custom result type including field data case success error case failure set mutually exclusive graphql type query userid userresult type mutation createuserinput createuserinput userresult type userresult user user nonexisting user invalid input user name user organisation missing permission arguably could custom error type like error string depending success failure mutation resolver may return either error message displayed user newly created user api resulthandling logic may interpret response based content two key falling back main error key make sure wasnt error query syntax connection application likewise query resolvers may return none instead requested object client developer may interpret signal api display requested item doesnt exist message user place requested resource allows return multiple error back client instead single error actual resolver implementation able collect error success result like python def resolvecreateuser input error authorize errorsappendnot authorized validationerrors validateinput validationerrors errorsextendvalidationerrors error return user none error error user dbcreateuserinput return user user error none apply new addition graphql schema existing operation updated refactor would changed anyways clarity possible error operation immediately obvious graphql schema app reliability since dont integration test currently incautious change error code description backend spelling error frontend error response handling might undetected automated testing end production impact development frontend devs dont look backend business logic code find type error possibly returned operation dont define additional result type either however query body verbose due handling union type see example resolver verbosity resolvers return lengthy result one two field set none anyways there real advantage returning multiple error anyways since occur frequently would potentially overwhelm end user consequence improved errorprone graphql interface mixed error response style schema frontendbackend code base reference graphql framework adr httpswwwapollographqlcomdocsapolloserverdataerrorserrorcodes httpsgithubcomboxwiseboxtributeblobfcdeadacbdcbdbackboxtributeserverexceptionspyll httpsgithubcomboxwiseboxtributeblobfcdeadacbdcbdfrontsrchooksuseqrresolvertsll httpsgithubcomboxwiseboxtributeblobfcdeadacbdcbdfrontsrcviewstransferscreatetransferagreementcreatetransferagreementviewtsxll httpsgithubcommirumeeariadneissuesissuecomment httpsgithubcomboxwiseboxtributeblobfcdeadacbdcbdbackboxtributeserverbusinesslogicboxtransfershipmentcrudpyl httpstrellocomcrblcigkxbugwhenamultibaseusergoestoashipmentfromanotherbaseheshecannotreconcileitbutheshegetsasuccessmessage httpssacheemediumcomokerrorhandlingingraphqlecaecbc httpsariadnegraphqlorgdocserrormessaging httpsgithubcommirumeeariadnediscussions
calculation pvalues want provide user pvalue individual family lambda provided either calculated provided user procedure follows every possible root family size starting randomly generate family based lambda compute likelihood family generated sort result smallest largest result conditional distribution compute likelihood user family every root family size every root family size largest specie size family compute pvalue user family based conditional distribution family size take maximum pvalue calculated consequence correctly calculate likelihood generated family calculation root take account root size known reflected matrix multiplication single row root rather possible row note although family generation routine accept error model model calculating pvalues clear lambda estimated error model produce correct conditional distribution tip error model attempt account error lambda due poor annotation genome etc accounted rate estimation rate calculate probability generate expected conditional distribution reflects true corrected distribution however family generated simulator take error model account adjusting family size tip adding subtracting single copy based model discretion user
rail already decided ruby new application see adr team already familiar rail widely within moj rail web framework new application consequence wont make many library common functionality would chose minimal framework rail default everywhere microservices try include part reduce risk unneeded behaviour introducing vulnerability bug
migrate testnet devnet std stellar wallet stellar testnet network overloaded recently cause lot delay error stellar mainnet network std tft price vary according explorer type example devnet would cost mainnet testnet would cost mainnet price consequence deprecate testnet wallet apps staging app payment stellar std stable network
api key requested functionality synchronize specified route either add replace main route table custom route table triggered log event access api endpoint restricted since modify custom route table simplistic either accepts reject call first request given nature trigger optimally lambda proxy function called user present proper information minimize cost api gateway api key limit access given constraint consequence end user must api key value successfully call endpoint
execute build task make dont want development tool continuous integration pipeline strongly bound gradle make utility agnostic language build management tool make execute build task abstracting gradle potential tool build execution consequence gradle task wont executed directly rather encapsulated make target make help abstract different tool build execution provide cohesive way run build task make may help integrating multiple tool build even gradle plugin manage tool directly also simplify command development lifecycle well known clean build run target help target list available
adr concrete state monad superseded adr adr decided mtlstyle effect implied would monadstate state like haskell somefunction monadstate hassomestate somefunction something somestate unfortunately monadstate significant drawback cannot zoom lens library see info current structure game lot situation want zoom consider current structure spawnpoint two timer haskell data spawnpoint spawnpoint position position position spawn direction direction direction spawned entity face spawntimer timer interval spawn looptimer timer interval loop deriving show want able call timerstep timer without zoom something like haskell stepspawnpoint time monadstate hasspawnpoint stepspawnpoint spawntimer spawntimer newspawntimer timerstep spawntimer spawntimer newspawntimer looptimer looptimer newlooptimer timerstep looptimer looptimer newlooptimer zoom greatly simplify code haskell stepspawnpoint time monadstate hasspawnpoint stepspawnpoint zoom spawntimer timerstep zoom looptimer timerstep desirable doesnt work monadstate apparently way work around combination functor zoomed zoom typeclass constraint outlined dont understand work well enough confident approach could also define specific zoomspawnpointtotimer zoomgamestatetocar zoomatob function zoom want outlined given amount zooming going fan approach mind think make sense statet directly feeling may eventually lead completely different approach moment seems reasonable way solve problem concrete statet instead monadstate consequence invalidates adr toplevel main crossytoad module complicated manually unwind stack zoom
adr inserting dynamic proposed deciders redeboer spflueger problem statement physic model usually include assumption simplify structure model example splitting model product independent part every part contains certain responsibility case partial wave amplitude model make separation spin part dynamical part spin part control probability wrt angular kinematic variable dynamic control probability variable like invariant mass state generally dynamic part simply function defined complex space consists mathematical expression sympyexpr set parameter expression tweaked optimized set kinematic variable expression applies technical story see refadrissues existing setup way supply custom dynamic least modtensorwaves understand custom dynamic adr parameter variable expressed sympysymbols dynamic specified mapping sympyfunction sympyexpr way supply sympyexprs expected sympysymbols parameter variable issue existing setup clear way apply dynamic function specific decaying particle specific edge statetransitiongraphs stg currently work mapping particle dynamic expression feasible identical particle edge set variable dynamic expression applies determined position within stg applied instance relativistic breitwigner applied resonance isobar decay described stg final state edge intermediate edge would work invariant mass edge msq like variable parameter identifiable position within stg take relativistic breitwigner form factor would require breakup momentum parameter also require suggested starting value expected pole position starting value usually taken edge node property within stg driver following point nice influence essential part user responsibility parameter dynamic function requires registered automatically linked together kinematic variable dynamic function also linked appropriately easy define custom dynamic boilerplate code solution requirement easy apply dynamic specific component stgs note important dynamic applied resonance selected graph generally graph resonance appears possible suggested initial parameter value provided well possible inspect dynamic expression independently expertsystem follow openclosed principle probably important driver solution flexible enough handle possible scenario without change interface defined requirement considered solution group expression builder satisfy requirement propose following syntax python model modelinfo graph statetransitiongraph modelsetdynamicsgraph edgeid expressionbuilder toggle another style would modelinfo contain reference list statetransitiongraphs user way express edge apply dynamic function python modelsetdynamics filterlambda pnamestartswithf edgeid expressionbuilder expressionbuilder function method create dynamic expression also class contains implementation expression static method build statetransitiongraph dynamic expression formulated way satisfies rest requirement following illustrate three different way formulating dynamic expression taking relativistic breitwigner relativistic breitwigner form factor example toctree maxdepth composition function expr group expressiononly second branch solution would propose following interface python model modelinfo graph statetransitiongraph modelsetdynamicsgraph edgeid expression key difference usage general sympy expression sympyexpr argument instead constructing builder object solution evaluation expression builder solution drawback arising choice interface expressionbuilder enforces logic correctly coupling variable parameter builder extremely hard get right since code able handle arbitrarily complex model always knowing user would like impossible therefore much better already built expression assumed correctly built see solution group solution group also following additional drawback however related correct building dynamic expression implicit assumption signature expression first argument assumed kinematic variable remaining argument parameter addition argument cannot keywords positional number variable parameter verified runtime static typing check element sympysymbol composition cleanest design tune design modsympy docfunction docexpr follow modsympy implementation result obscure inheritance hierarchy implicit convention result nasty bug instance one call method either sympyfunction sympyexpr implementation pro con specific implementation listed doccomposition positive implementation expression transparent negative refadrcompositionalternative signature way see relativisticbreitwignerfromgraph builder relativisticbreitwigner name make implementing custom dynamic inconvenient errorprone signature builder checked classtypingprotocol see refadrcompositiontype checking docfunction positive dynamicsfunction behaves classsympycorefunctionfunction implementation builder kept together implementation expression negative possible identify variable parameter docexpr positive docrecursing amplitude model sympytutorialmanipulation still possible identify instance dynamicsexpr doit called additional property method added carried around class negative boilerplate code required implementing custom dynamic refadrexprissue lambdify expressiononly positive choice interface follows principle solid solution group handing complete expression dynamic setter sole responsibility insert expression correct place full model expression negative direct negative aspect solution split responsibility construction expression correct linking parameter initial value etc performed code code subject issue mentioned individual solution group outcome composition based solution group important definition interface following solution group ensures openclosed keep responsibility separated expertsystem favor composition inheritance intend inheritance define interface insert behavior design expertsystem fundamentally different sympy thats another reason favor composition interface determined dependency instead remain doccontained within dynamic class composition decide keep responsibility separated possible mean responsibility setdynamics method attribute expression sympyexpr correct symbol within complete amplitude model position specified statetransitiongraph edge syntax may improved later see python def setdynamics self graph statetransitiongraph edgeid int expression spexpr none dynamicssymbol graph edgeid selfdynamicsdynamicssymbol expression pas assumed expression correct user responsibility formulating expression correct symbol aid user construction expression building code handle common task variablepool facilitate finding correct symbol name avoid typo python mass variablepoolgetinvariantmassgraph edgeid dynamic module provides description common lineshapes well helper function example would python invmass mass gamma buildrelativisticbreitwignergraph edgeid particle relbw sympyexpr relativisticbreitwignerinvmass mass gamma modelsetdynamicsgraph edge relbw sympymodel responsibility defining full model term expression keeping track variable parameter instance python attrskwonlytrue class sympymodel top spexpr attrib intensity dictspsymbol spexpr attribdefault amplitude dictspsymbol spexpr attribdefault dynamic dictspsymbol spexpr attribdefault parameter setspsymbol variable setspsymbol variablepool def fullexpressionself spexpr
title switching frontend technology slug switchingfrontendtechnology author marvin amend choosingafrontendframeworkmd pullrequest provide reason adr provide taken team consequence provide consequence side effect
architecture record persistent configuration many arachne application transient config rebuilt initialization script every time instance started user might wish instead store config persistently full datomic instance number possible benefit approach deployment configuration highly reproducible organization maintain immutable persistent log configuration change time external tooling persistently build define configuration including full drag drop architecture application design introduces number additional challenge initialization script persistent configuration introduces question role initialization script play setup merely persistent config make easier modify hand quite opposite init script could create configuration clear would updated point absent full config editor rerunning modified configuration script existing configuration pose challenge well would require script idempotent create spurious object subsequent run also script would support concept retraction scope naming extremely convenient dbuniqueidentity attribute identify particular entity configuration configuration init script convenient required init script idempotent since mechanism datomic determine new entity older entity system however multiple different configuration database risk unique value might unintentionally collide causing inadvertent linkage ought logically distinct configuration mitigated simple case ensuring every config unique namespace still something keep mind configuration copying versioning although datomic support full history history linear datomic currently support forking maintaining multiple concurrent version logical data set introduce complexity thinking modifying configuration still keeping old one kind fork would require deep clone entity config well renaming dbuniqueidentity attrs renaming identity attribute compound complexity since implies either idents cannot hardcoded initialization script init script cannot generate update two different configuration environmentspecific configuration application slightly different configuration different instance application instance software told address make sense put data configuration mean would longer single configuration distinct yet identical configuration one solution would store data configuration instead picking runtime environment variable secondary config file multiplying source configuration run counter arachnes overriding philosophy putting everything configuration start relationship module load process would stored configuration represent initial configuration updated active module would represent complete configuration module completed update present issue usersupplied initial config stored usefulness stored config diminished since provide comprehensive complete view configuration hand complete postmodule config persisted raise question happens user edits configuration way would cause module something different config possible run module update process multiple time config would old stale modulegenerated value removed goal technical approach good answer challenge described enables clean user workflow useful enumerate specific activity would useful persistent config implementation support define new configuration init script run init script existing configuration updating edit existing configuration repl edit existing configuration clone configuration deploy based specific configuration time careful overly complicate thing common case application still pattern generating configuration init script immediately running application attempt implement concrete strategy config persistence time run risk becoming quagmire halt forward momentum instead make minimal set choice observation enable forward progress preserving ability revisit issue persistent configuration point future configuration schema compatible several configuration present persistent database specifically logical configuration namespace namespace dbuniqueidentity value ensuring global uniqueness configuration entity reifies config possible root component constructed etc entity configuration must form connected graph every entity configuration must reachable base config entity required ability identify config whole within purpose current initial tooling building configuration including init script focus building configuration scratch tooling capable editing existing configuration sufficiently different different set requirement constraint design process future tooling storing viewing editing configuration explicitly determine whether want work configuration processing module since distinct set tradeoff proposed consequence continue making forward progress local configuration case storing persistent configuration remains possible immediately possible save configuration repeatability debugging purpose editing persistent configs difficult want edit persistent configuration analyze specific case determine best way develop tool specific task
simulator description api receive vehicle location information simulator generate vehicle movement testing purpose team decide make separate simulator service consequence separate service improve api functionality separation introduces singleresponsibility principle
method representing event onprefix onboarding new engineer software project fast also future self back track project fast consistent logical naming benefit eventmethods within viewmodel class prefix event method called view onclickfavorite onsearchchanged consequence existing viewmodel class edited
title convert pdf file weight problem statement pdfs contain image coming scanner therefore one able click pdf select text copypaste also searchable pdf viewer really shortcoming fixed especially already ocr build image work already tesseract create pdf file tesseract creates file additional text layer containing ocred text considered ocrmypdf ocrmypdf add ocr text layer scanned pdf file allowing searched ocrmypdf nice python tool tesseract ocr page add extracted text pdf text layer page additionally creates pdfa type pdfs great archiving fix exactly thing stated integration docspell already built image converting image pdf done early processing process creates text pdf file docspell set text step text extraction step skip work already text available would possible sidecar ocrmypdf create text file extracted text one run exactly like work tesseract text pdfs ocrmypdf writes infomessage text file ocr skipped page ocr skipped page docspell cannot reliably tell wether extracted text would reqiured load pdf check content bit bad luck everything would work already requires small change textextraction step default text extraction happens source file pdfs text extraction run converted file avoid running ocr twice converted pdf file either textpdf first place ocrmypdf would convert pdfa file may converted file containing ocred text pdf layer ocrmypdf disabled converted file source file pdfs outcome add ocrmypdf optional conversion pdf pdf ocrmypdf distributed gpl license
expose command line interface want maximise usability adrviewer whilst maintaining flexibility future output format live webserver entry point project commandline utility called adrviewer python click library provide commandline documentation consequence click added dependency improvement consider user experience commandline interface
adr web framework way government digital service make technology choice described service manual selecting web framework data api performance platform writing api python support accepting unstructured data returning structured data read api restful initially want optimise easy writing hard work return structured data read time understand model resource think allow data set created written transformation query time data set mean think allow simple postput data set complex read query produce structured data time expect see common data set type look structured approach defining resource relationship point might also want consider restful feature switching framework support approach considered include django flask since familar write data api flask dont orm django flask seems simpler term starting small api consequence devs operation comfortable flask apps
handle index detail route separately currently index route detail route rendered dynamic route optional catchall segment srcappidpagetsx route share similar behaviour route display detail latest entry posted route display detail entry specified url either alias approach issue parameter either undefined array singular noun array type confusing singular noun make sense route contain zero one segment dynamic route optional catchall handle four potential case case matter one specific type route case present index route case present match entry detail route case alias entry detail route case present match existing entry detail route time writing opengraphimage file cannot specified detail route prevents colocating code generate preview image page preview image source github issue next opengraphimage cant accept params catchall route error catchall must last part url dynamic route reimplemented two separate route pagetsx handle index route idpagetsx handle detail route consequence detail route specify preview image opengraphimage file note time writing open graph image cannot statically generated dynamic route source github issue opengraph image statically generated dynamic route may lag navigating route route codesplit
build mvp based webidl manual workflow deciders rfkelly linacambridge eoger jhugman tarikeshaq thereabouts problem statement deciding build tool main risk identified wed spend much time ultimately unworkable unmaintainable idea early design make mitigate risk thing existential risk success project must included first version thing safely defer future work word build mvp tool minimal viable driver strictly timebox effort prove approach establish whether effectively maintain kind tool team support initial development new rust component externallyimposed nearterm deadline considered adr encompasses several several related design question feed together overall approach building mvp tool developer specify api component external interface definition file based webidl external interface definition file based custom language infer api directly rust code annotation macro developer integrate tool workflow buildscripts macro deeply integrate rust crate build system provide tool developer run hand prioritize work capability offered tool broad implementing many data type api capability even theyre slow incomplete deep implementing core data type api capability make sure theyre done well outcome chosen external interface definition file based webidl provide tool developer run hand broad implementing many data type api capability even theyre slow incomplete set chosen make explicit tradeoff preferring get something running quickly accepting certain amount jank developer experience dont build perfect tool right away build something thats better work hand like result polish mvp tool read api definition external webidl file bit weird inconvenient consumer webidl precise fit avoids bikeshedding perfect apidefinition experience first phase mvp developer experience involve cargo installing tool onto system manually running integrating build process risk mildly inconvenient consumer give lot flexibility learn better workflow might look like mvp tool may support feature turn strictly necessary interest ensuring multiple team member involved development early stage tradeoff mvp generated code allowed contain inefficiency limitation handwritten code might premise first consumer performancesensitive lot scope improving implementation detail time likely revisit every single one choice mvp tool prof successful attempt build theyre easy revisit pro con external interface definition file based webidl require developer specify component api external definition file syntax webidl provide something thats familiar existing spec good webidl exists feature first consumer good weedle crate provides readymade parser webidl good webidl base level familiarity around mozilla bad developer duplicate api rust code idl bad webidl designed different usecase likely awkward fit bad weedle doesnt generate particularly helpful error message seems designed parsing knowngood webidl definition rather helping develop new one ultimately seems like lowestcost way get started deferring importantbutnotexistentiallyrisky work making idl experience fit really well rust code external interface definition file based custom language require developer specify component api external definition file custom variant idl syntax good syntax custom designed fit well developer mental model generated code good already several different idl variant mozilla webidl xpidl chance building something feel familiar high bad developer duplicate api rust code idl bad make document whole syntax bad rust parsing crate nom seem generate particularly helpful error message default adding friction developer ultimately custom syntax would probably feel better consumer perspective webidl cost involved worth tradeoff mvp beyond mvp expect direct annotation rust code provide better developer experience leaving unnecessary middleground infer api directly rust code annotation macro allow developer sprinkle macro annotation directly rust code order declare component api similar approach taken wasmbindgen good rust code single source truth api definition good developer familiar approach tool bad team doesnt much experience working macro scale bad poke around wasmbindgen code seem pretty scary thing order make macro work various edgecases ultimately feel like good approach longerterm risk much timesink mvp buildscripts macro deeply integrate rust crate build system encourage consumer structure rust component crate take buildtime dependency tool magic thing existence part cargo build good slick developer experience make work bad assumes many detail consuming component built deployed dont know exactly work yet bad could hard integrate gradlebased build system android package bad build script arent supposed create file outside rust target directory doesnt really make sense generate foreign language binding directory ultimately approach provide enough flexibility initial consumer risking declaring bad fit based nonessential detail tool provide tool developer run hand provide consumer uniffibindgen commandline tool manually run component code order generate foreign language binding good give consumer lot flexibility generate different bit code bad consumer install external tool ultimately approach win based flexibility may also provide light wrapper around tool integrates cargo build convenience broad implementing many data type api capability even theyre slow incomplete focus initial effort fleshing broad suite data type api capability spending time focused performance edgecases generated code good consumer iterate api chance limited tool good make opportunity team member get involved implementing feature tool helping understand like maintain time bad suboptimal performance may offputting consumer bad might accidentally entrench design limit ability improve generated code future ultimately win based known first target consumer favour iteration performance team want ensure multiple developer familiar tool codebase get ground deep implementing core data type api capability make sure theyre done well focus initial effort identifying data type api capability required first target consumer implementing really well spending time feature unlikely required consumer good show resulting generated code best possible light bad might identify correct set feature bad harder parallelize kind work among multiple team member ultimately first target consumer make performance argument fairly weak selected link webidl specification reference
integrating new client app dep pennsylvania department environmental protection dep desktop mapshed mmw workflow time workflow involves running mapshed model mmw huc also area interest within huc copying output table specific part mmw bmp spreadsheet tool cumbersome error prone would much better done automated fashion user download spreadsheet prepopulated right value right place since requires two effective area interest workflow fit neatly mmw always expects single area interest rather change mmw accomodate unusual rare case would much simpler create new client app focused workflow mmw api calculation given well new client app opportunity introduce modern tech stack frontend recently done similar project new frontend stack added within django app sandbox rest project document aim discus pro con different arrangement new client app pick one satisfies project constraint one major directive client user perspective site deeply integrated mmw say color branding feel like project development perspective aim latest frontend stack clean communication backend api fast deployment pipeline consideration find right balance coupling two apps must consider code stored written different repository apps deployed paired independently apps accessed user via subdomain subdirectory consideration entirely independent paired deployment easier repository must also consider nontechnical factor explicit directive consistent user experience apps requirement rule subdomain access would break immersion app repository different advantage repository familiarity done beekeeper project issue one repo simplifying project management task affect frontend backend tracked one commit simpler deployment frontend backend always sync style easily reused two apps easier simulate production environment development start single development environment advantage different repository cleaner logical separation codebase fewer cohabiting developer entry point packagejson multiple nodemodules require changing node npm version mmw require adding docker environment mmw building frontend case change node version mmw isolate new build toolchain docker environment faster deployment client app deployed independently main app deployment paired independent advantage paired deployment frontend backend always sync require extra configuration aws extra step deployment easier write endtoend test advantage independent deployment frontend iterated much faster without heavy deployment cycle mmw architecture repository paired deployment similar beekeeper create django app house file new client app evaluate node version app upgraded add docker container building frontend django configured handle routing render different home page new route deployment affected proceed usual basic style color shared two apps independent stylesheets common resource color may shared two different repository independent deployment new app get repository better isolates new frontend code legacy code development mmw would running addition client app app deployed static host like netlify nginx configured proxy static host subdirectory route deployment cosmetic change new client app made independently functional change api consumed coordinated mmw project management split across two repos frontend task listed new repo backend task listed mmw keeping one repository codebase paired deployment advantage familiar approach keeping back frontends sync needing change deployment pipeline consequence since modern stack new app require modern version node investigate one app safely upgraded without affecting current bundle pipeline require isolation within docker done beekeeper new app deeply integrated mmw change matter small require full mmw deployment
manage contentful schema state via migration superseded chosen contentful powerful configured via quite easily however wanted bring control migration change explicit reviewable repeatable stored would key part moving cmsascode approach contentful contenttype change data migration outside regular content entry managed via code wanted close possible experience provided excellent django migration framework would able script migration rather resort clickops able apply individually masse able store state migration havehave applied central datastore ideally contentful experimented handcutting framework looking viable came across httpsgithubcomjungvonmattcontentfulmigrations weve evaluated seems fit purpose even gap weve adopted current way manage apply migration contentful setup consequence weve gained tool enables codebased change contentful help two way enables eas initial work migrate legacy compose new compose way structuring page contentful lay track moving cmsascode
marketplace automate payment marketplace demo website work testnet automate payment defined wallet demoswallet payment wallet lot tfts solution live max hour consequence reduces amount click user get demo deployed money flow package wont usable marketplace probably rethought anyhow
adr task classifier plugins wed like new classifier easily extensible however adding new task classifier involved updating code several place add new code three place task view task model annotation model import new module name several place register registered view import task model workflow step import annotation classification model register annotation classification store easy forget one step lot could automated code keep code together store task view model next filesystem import named module registry object similar load code register delegate responsibility classification individual task implementation task code moved libclassifiersrcpluginstasks task directory subdirectory component react component render task model mobx state tree model task one task model one annotation model taskregistry object added described task readme responsibility creating new annotation removed classification store removing classification store know different type task create annotation new method added task model delegate responsibility make task flexible taskcreateannotation creates new annotation correct type specific task taskdefaultannotation readonly return default annotation specific task consequence similar architecture could register subject viewer classifier task could removed completely classifier workflow load task could instantiated outside classifier task needed workflow could passed prop classifier could make better mobx state tree classification could store task generate classification task holding reference annotation open possibility flexible code tracking workflow history handling recursive workflow could also take advantage tree via getparent getparentoftype easily reference task generated specific annotation classification task currently work registry model equivalent import singlechoiceannotation multiplechoiceannotation textannotation pluginstasksmodelsannotations would helpful necessary able setting classifier store task registry available task model set initialised limiting usefulness accessing model order set model drawing tool
title convert html file weight problem statement html document converted pdf file look much possible like original would nice javaonly solution external tool better outcome external tool fine since docspell free software tool must also free considered pandoc external command wkhtmltopdf external command unoconv external command native firefox view figurefileexamplehtmlnativejpg downloaded html file disk together resource save browser pandoc figurefileexamplehtmlpandoclatexjpg figurefileexamplehtmlpandochtmljpg showing version pdfengine since looked similiar latex variant wkhtmltopdf figurefileexamplehtmlwkhtmltopdfjpg unoconv figurefileexamplehtmlunoconvjpg outcome wkhtmltopdf show best result
marain service list instance manifest desire define formally unambiguously component part marain instance instance one deployed set service operating isolation instance maintain dev instance separate production customer marain service endjins hosted production instance instance maraininstance repo repo includes master service list solutionsmarainservicesjsonc json comment file contains entry service part marain instance give name service maraintenancy identifies github project service defined also defines api prefix scenario service made available behind single api management layerthe api prefix indicates first part url api gateway accessing relevant service whereas marainservicesjsonc common instance instance also defines manifest determines whether particular service deployed particular instance version consequence putting information json jsonc file narrowly defined purpose easy see exactly service marain instance particular version deployed particular instance also drive automaticed deployment process implemented deploymaraininstanceinfrastructureps
custom view model problem statement common model custom view cause tight coupling block moving library custom view creation facing concern tight coupling decided create model custom view domain neglected common model achieve loose coupling app component
standalone jaeger issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
title introducing tax provider area checkout tag tax taxprovider checkout country like usa different tax rate different state county shipping leading thousand different tax rate usa alone purpose tax provider exist like taxjar vertex avatax output tax rate depending customer cart detail want implement possibility interface hook called cart calculated able overwrite tax customer logged therefore information shipping billing available call interface receive necessary information tax rate implementation detail new entity taxprovider want create new entity called taxprovider register available tax provider defines rule following field therefore required idfield translatedfield name intfield priority default fkfield availabilityruleid stringfield provideridentifier unique translatedfield customfields location prioritization tax provider taxproviderprocessor called cartruleloader whole cart calculated promotion delivery calculated therefore rule may change due changed tax gross price validated anymore tax provider called customer logged availability rule match highest priority defines tax provider called first parameter filled taxprovidernotavailableexception thrown next tax provider priority called calling tax provider taxproviderprocessor call class tagged shopwaretaxprovider named provideridentifier implement taxproviderinterface class exist processor throw taxproviderhook identifier return struct additional parameter filled via app scripting identifier match app allow app scripting call provider add possibility request app via guzzle php interface taxproviderinterface throw taxprovideroutofscopeexceptionthrowable public function providetaxcart cart saleschannelcontext taxproviderstruct tax provider throw exception taxprovideroutofscopeexception due connection issue proceed next tax provider provider provide tax throw first exception since dont want invalid tax return processing value taxproviderstruct filled class hook call taxproviders afterwards line item shipping cost total tax respectively overwritten cart persisted php class taxproviderstruct extends struct param nullarray key line item protected array lineitemtaxes null param nullarraystring calculatedtaxcollection key delivery protected array deliverytaxes null protected calculatedtaxcollection cartpricetaxes null
single callerid oppija virkailija frontend request every service required pas callerid header request previously ehoks frontend separate oppija virkailija codebase largely shared oppija virkailija service separate hence separate created header simple add request made component either oppija virkailija dynamically figuring shared component given time proved harder separate replaced single frontend callerid since request made oppija virkailija frontends ehoks backend service dont call external service directly sufficient request oppija virkailija distinquished via mean different backend apis altogether consequence request made frontends easily include callerid header arises filter frontend responsible particular request cannot done checking callerid header
adr mermaid simple smart answer visualisation proposed following user research identified content designer struggling understand flow smart answer communicate colleague confidently edit typically third party tool visualise smart answer complex flow according user research would prefer within mainstream publisher list potential feature derived user research diagram show full flow question answer outcome illustrate path answer next node questionoutcome flow line node box sensible order create additional cognitive load question answer outcome box look different different shapecolours interactive user select questionoutcome flow tofrom highlighted carried spike identify viable diagramming tool meet requirement potential diagram interactive limited scope javascript based diagramming tool allow modify diagram dynamically evaluated following reason mermaid yes open source visualisation library support flowchart easily configurable implementable build visualisation tool problem novel enough require bespoke solution doesnt specifically cover flow diagram fit purpose flowchartjs standalone visualisation generator possible integrate application jointjs open source per licence graphviz graph visualisation quite purpose gojs open source developer licence kroki unified api wrapper around suite visualisation library functionality require performed high level review variety visualisation library decided mermaidjs right balance simplicity functionality require also possible customise presentation visualisation tested implementation mermaidjs standalone project api able render diagram within html page also ran webpack demo demonstrates mermaidjs dependency foresee limitation autopositioning node questionoutcome box something control mermaid rearranges position depending flowchart evolves connecting line always render visually appropriate way sometimes sit behind box overlap line consequence able integrate mermaidjs publisher build data translation service take flow described data model convert mermaidjs syntax largest remaining uncertainty however concern specific mermaidjs would tackled visualisation library
adr planned flipbook viewer oct migration project pfe fem requires building flipbook viewer classification nontranscription subject multiple image flipbook viewer separate viewer multiframe viewer multiframe viewer designed built transription project pan zoom rotate annotation consistent flipping multiple frame per subject flipbook viewer feature pfe design catered landscape oriented subject image invision design feature feature fem flipbook viewer include thumbnail subject image currently selected image clicking button change currently selected image nextback button navigate available thumbnail playpause flipanimate image switching flipbook display separate image display full imagetoolbar component pan zoom rotate invert etc control playback speed similar videocontroller
expand subscription platform metadata google cloud firestore deciders ben bangert barry chen bianca danforth danny coates dave justice orchard vijay budhram problem statement subscription platform stripe metadata numerous purpose including product checkout content legal document download url product support form metadata updated product manager stripe dashboard enabling product manager manage certain aspect subscription product without involving subscription platform engineer however stripe metadata limit number value reach near future order continue metadata fashion subscription platform overcome limit placed stripe driver higher storage limit stripe metadata manager product subscription platform edit metadata access management updated data accessible respective environment without deployment considered google cloud firestore kinto mysql redis configuration file outcome chosen google cloud firestore data management user access control provided google cloud platform gcp console require deployment data update novel tech fxa already elsewhere pro con google cloud firestore google cloud firestore hosted nosql document based database access management data management gcp console event broker pro already fxa monorepo novel tech new dependency includes access management data editing form gcp console require deployment data edits builtin support access control validation security rule con product manager learn gcp console allowing update live data management deployment security rule kinto kinto json storage service elsewhere mozilla pro already deployed mozilla remote setting firefox data updated without fxa deployment multiple collection per kinto instance dev stage prod product set record creation data validation via json schema maybe friendlier raw json implement review process pending change approve reject flow maintains changelog update involved acls group read write review access con backed postgresql fxa mysql turnkey set something like firestore yet another service new dependency fxa mysql mysql relational database system fxa pro existing tech thats immediately available engineer familiarity require deployment data update con data management product manager redis redis inmemory data store part current fxa stack pro already tech stack familiarity updated without deploy con management might ops manually update entire would populatedseeded entry startup configuration file require product manager add edit configuration file submit github pull request get update production pro dependency external service product manager free file editing tool edits reviewed access control approval con update require entire deployment process product manager learn github minimum product manager learn file format configuration file
url parameter structure updated mapviewer application configured several url parameter current format layer configuration look follows example topic snow text layerschswisstopopixelkartefarbewinterchswisstopohangneigungueberchswisstopokartohangneigungchbafuwrzjagdbanngebieteselectchbafuwrzwildruhezonenportalchbazlgebirgslandeplaetzechswisstoposchneeschuhwandernchswisstopokartoschneeschuhroutenchswisstopokartoskitourenchswisstoposkitourenkartemetadatachbavhaltestellenoev layersopacity layersvisibilitytruefalsetruetruetruefalsetruetruetruefalsefalse including layer different timestamps probably also text layerstimestamp current format limitation confusing configuration case multiple layer order determines attribution lot unnecessary character represent default value generic pattern layer configuration new format look follows generic form text layerslayeridvisibilitytfopacityflayeridvisibilitytfopacityf example one layer without changing default opacity defined catalog visibility topic opacity visibilitytrue layerslayerid two layer without changing default layerslayeridlayerid one layer changed visibility layerslayeridf one layer changed opacity visibility layerslayeridf one layer default visibility changed opacity layerslayerid two layer changed visibility opacity layerslayeridtlayeridf case wrong format given error printed console example boil following given opacity value default defined topic text layerschswisstopopixelkartefarbewinter chswisstopohangneigungueberf chswisstopokartohangneigung chbafuwrzjagdbanngebieteselect chbafuwrzwildruhezonenportal chbazlgebirgslandeplaetzef chswisstoposchneeschuhwandern chswisstopokartoschneeschuhrouten chswisstopokartoskitouren chswisstoposkitourenkartemetadataf chbavhaltestellenoevf layerid layerid one following catalog chswisstoposchneeschuhwandern catalog parametrized time possibly parameter future chswisstopozeitreihentimeheightm note allows parametrization future like height timestamp format must iso compliant yyyymmdd yyyymmddthhmm yyyymmddthhmmss yyyymmddthhmmsssss yyyymmddthhmmsshhmm external layer layer external layer following format note one wms order changed consistently typeurlother external wms wmsgetcapbaseurllayerid wms version taken get capability external group wms layer wmsgetcapbaseurllayerid dont differentiate group layer regular wms layer url differentiation neither done legacy viewer external wmts wmtsgetcapbaseurllayerid wmts version taken get capability external kml kmlurl title read metadata geoadmin kml kmlurl title read metadata geoadmin kml adminid kmlurladminidadminid title read metadata external gpx gpxurl title read metadata external kmz kmzurl pas proxy unzipped consequence described format implemented new viewer new viewer implement furthermore retrocompatibility module able interpret old format convert new one
ordered consumer metadatavalue author scottf implemented tag jetstreamclient problem statement provide ordered push subscription user automatically check recovers gap occurs consumer sequence subscription deliver message synchronously asynchronously normally supported client behavior subscription leverage gap management auto management ensure message received proper order subscription must track last good stream consumer sequence gap observed subscription close current subscription release consumer creates new one starting proper stream sequence hearbeats missed consumer might gone deleted lost reconnect node restart etc recreated last known stream sequence optionally make state available user subscription limitation subscription cannot pull consumer durable consumer cannot bind direct subscription allowed queuesdeliver group consumer configuration check user provide consumer configuration must validated error creating validation fails check durablename must provided deliversubject must provided ack policy must provided set none set none provided maxdeliver must provided set set provided flowcontrol must provided set true set true provided memstorage must provided set true set true provided numreplicas must provided set check set setting without error idleheartbeat provided set second ackwait set something large like hour match implementation
remove state object view model reverted adr think exposing whole state viewmodel fragment move logic fragment error prone opinion instead exposing whole state object expose single property individually handled fragment consequence fragment viewmodels refactored longer possible log whole state update within fragment class
prober package responsible markind address ready ready endpoint ressource two controlling structure endpoint reconciler prober probemanager according worker seperate concern resource therefore endpoint reconciler responsible modifying objectmeta general structure subset make sure exactly externalservice ressource exist also endpoint add missing always notreadyaddresses list prober prober package soley responsible moving address address notreadyaddresses vice versa consequence consequence endpointreconciler conciders endpoint equal matter ready notready state mean merge list compare list would set component except prober package allowed move ready ready
adr extend upgrade plan changelog nov initial draft may proposal abandoned prerun postrun necessary anymore adding artifact brings minor benefit abandoned abstract adr expands existing xupgrade plan proto message include new field defining prerun postrun process within upgrade tooling also defines structure providing downloadable artifact involved upgrade upgrade module conjunction cosmovisor designed facilitate automate blockchains transition one version another user submit software upgrade governance proposal containing upgrade plan plan currently contains following field name short string identifying new version height chain height upgrade performed info string containing information upgrade info string anything however cosmovisor try info field automatically download new version blockchain executable autodownload work cosmovisor expects either stringified json object specific structure defined documentation url return json json object identifies url download new blockchain executable different platform architecture linuxamd url either return executable file directly return archive containing executable possibly asset url return archive decompressed daemonhomecosmovisorupgrade name daemonhomecosmovisorupgrade namebindaemonname exist daemonhomecosmovisorupgrade namedaemonname latter copied former url return something archive downloaded daemonhomecosmovisorupgrade namebindaemonname upgrade height reached new version executable version isnt available cosmovisor stop running daemonhome daemonname environment variable configure cosmovisor currently mechanism make cosmovisor run command upgraded chain restarted current upgrade process timeline upgrade governance proposal submitted approved upgrade height reached xupgrade module writes upgradeinfojson file chain halt cosmovisor back data directory set cosmovisor downloads new executable already place cosmovisor executes daemonname preupgrade cosmovisor restarts app new version args originally provided protobuf update update xupgradeplan message providing upgrade instruction upgrade instruction contain list artifact available platform allows definition prerun postrun command command consensus guaranteed executed cosmosvisor upgrade handling protobuf message plan existing field upgradeinstructions instruction new upgradeinstructions instruction field must optional protobuf message upgradeinstructions string prerun string postrun repeated artifact artifact string description field upgradeinstructions optional prerun command run prior upgraded chain restarting defined executed halting downloading new artifact restarting upgraded chain working directory command run must daemonhomecosmovisorupgrade name command must behave current preupgrade command take commandline argument expected terminate following exit code exit code handled cosmosvisor assumes preupgrade command executed successfully continues upgrade default exit code preupgrade command implemented preupgrade command executed failed fails entire upgrade preupgrade command executed failed command retried exit code returned defined app supervisor cosmovisor must run app prerun postrun command run upgraded chain started defined command must executed upgrading node output exit code logged affect running upgraded chain working directory command run must daemonhomecosmovisorupgrade name artifact define item downloaded one entry per platform description contains humanreadable information upgrade might contain reference external resource structured processing information protobuf message artifact string platform string url string checksum string checksumalgo platform required string format oscpu linuxamd string also allowed artifact platform fallback specific oscpu entry found artifact exists platform match system cpu otherwise artifact exists platform otherwise artifact downloaded url required url string must conform rfc uniform resource locator request url must return either executable file archive containing either bindaemonname daemonname url contain checksum specified checksum attribute checksum checksum expected result request url required recommended provided must hex encoded checksum string tool utilizing upgradeinstructions must fail checksum provided different checksum result returned url checksumalgo string identify algorithm generate checksum recommended algorithm sha sha algorithm also supported recommended sha checksum provided checksumalgo must also provided url required contain checksum query parameter url contain checksum query parameter checksum checksumalgo field must also populated value must match value query parameter example url httpsexamplecomchecksummdddcdfbeecfe checksum field must ddcdfbeecfe checksumalgo field must upgrade module update upgrade plan new upgradeinstructions field existing functionality maintained parsing info field either url binary json deprecated validation info field warning issued error update creation upgradeinfojson file include upgradeinstructions update optional validation available via cli account new plan structure add following validation upgradeinstructions provided must least one entry artifact artifact must unique platform artifact url contains checksum query parameter checksum query parameter value must format checksumalgochecksum checksum query parameter must equal checksum provided artifact checksumalgo query parameter must equal checksumalgo provided artifact following validation currently done info field apply similar validation upgradeinstructions artifact platform must format oscpu url field must empty url field must proper url checksum must provided either checksum field query parameter url checksum field value url also checksum query parameter two value must equal url must return either file archive containing either bindaemonname daemonname checksum provided field query param checksum result url must equal provided checksum downloading artifact happen way url info currently downloaded cosmovisor update upgradeinfojson file contain upgradeinstructions existing functionality maintained update cosmovisor look handle new upgradeinstructions upgradeinfojson upgradeinstructions provided following info field ignored artifact field identify artifact download based platform cosmovisor running checksum provided either field query param url downloaded artifact different checksum upgrade process interrupted cosmovisor exit error prerun command defined executed point process app preupgrade command would executed executed environment command run cosmovisor postrun command defined executed executing command restarts chain executed background process environment command output generated command logged complete exit code logged deprecate info field anything human readable information warning logged info field define asset either url json new upgrade timeline similar current one change bold upgrade governance proposal submitted approved upgrade height reached xupgrade module writes upgradeinfojson file possibly upgradeinstructions chain halt cosmovisor back data directory set cosmovisor downloads new executable already place cosmovisor executes prerun command provided else daemonname preupgrade command cosmovisor restarts app new version args originally provided cosmovisor immediately run postrun command detached process consequence backwards compatibility since change existing definition addition instruction field plan message field optional backwards incompatibility respect proto message additionally current behavior maintained upgradeinstructions provided backwards incompatibility respect either upgrade module cosmovisor forward compatibility order utilize upgradeinstructions part software upgrade following must true chain must already sufficiently advanced version cosmos sdk chain node must sufficiently advanced version cosmovisor positive structure defining artifact clearer since defined proto instead documentation availability prerun command becomes obvious postrun command becomes possible negative plan message becomes larger negligible xupgrades module store one upgrade plan upgrade rare enough increased gas cost isnt concern providing url return upgradeinstructions way provide multiple asset executables file platform archive platform artifact neutral existing functionality info field maintained upgradeinstructions arent provided discussion draft comment consider different name upgradeinstructions instruction either message type field name draft comment consider putting string platform field inside upgradeinstructions make upgradeinstructions repeated field plan consider oneof field plan could either upgradeinstructions else url return upgradeinstructions consider allowing info either json serialized version upgradeinstructions else url return draft comment consider including upgradeinstructionsdescription field info field purpose instead draft comment consider allowing multiple artifact downloaded given platform adding name field artifact message comment allow new upgradeinstructions provided via url comment allow definition signer asset checksum reference current upgradeproto upgrade module readme cosmovisor readme preupgrade readme draftpoc rfc uniform resource locator
single command subcommands tool provides number related command create manipulate architecture record user find command available tool defines single command called adr first argument adr subcommand specifies action perform argument interpreted subcommand running adr without argument list available subcommands subcommands implemented java class defined interface package adrcommmand reflection mechanism new command added without changing rest code subcommand new implemented classcommandnew subcommand help class commandhelp command class annotated name command class name important also help instruction completely selfcontained consequence user easily explore capability tool user already style commandline tool example git work way subcommand implemented different developer
create player interface completed create way player interact character potential ally choice involved combat player side instead randomly decided action create child class character give branching functionality playerspecific character
authentication several application openfido require apis application level authentication authorization include pipeline api worker openfido service web client blob service service want import application role table function defined project api endpoint might pipeline endpoint doc openfido dbservice model create separate application role package set model within project imported separately pipeline api ensure logic enforce permission decorator enforcing requirement specific set systempermissions included package model included way included existing alembic database schema one central configured importing app create setuppy file reference flask project import project basis example project consequence anticipate importing application role trivial setup ended moving entire source slacgismoopenfidoutils share multiple repository repository private needed rework docker image built could access private repository
aleph circrequests denied entry resubmission july original caia implementation denied item resubmitted part every submission caiasoft long item included list aleph denied item typically denied multiple time causing redundant entry appear caiasoft interface decided resubmit denied item consideration concern never resubmitting denied item could result patron request getting lost decided denied item resubmitted sufficient interval day long denied item still list provided aleph modify application item denied caiasoft resubmitted still reported aleph configurable wait interval consequence add complexity application especially diff functionality must take account denied item wait interval also may affect upgrade migration new server application additional state file containing denied item timestamps may migratedreplicated new server hopefully however functionality prevent patron hold lost simply initial denial caiasoft
translation form builder must able present different language must way serve custom human translated content would prudent also include pretranslated content common field like name phone number address etc lastly fallback apibased machine translated service internal consideration spoke nicole anthony sfgov translation service various online translation service discussed team came conclusion want require code access addupdate translation leaf two primary approach file uploads repository database entry talked henry different data structure store translation including scenario additional table column considered easiest solution would leverage lumenlaravel localization feature box httpslaravelcomdocslocalization however form author way input translation app additional work must done accomodate template file laravel lumenlaravel default file system file uploader might easiest solution instantly becomes complicated editing file also must formatted php syntax php return welcome welcome application package exists load override file translation database httpsgithubcomspatielaraveltranslationloader preliminary outcome translation loader store language line database file system store localized string hardcoded version template order fetch human translated database pretranslated file template machine translated cached database machine translated api mvp require human translated pretranslated layer file structure resource lang templatenamephp templatenamephp templatename would determined formtypeversion sfullname database generate new table named languagelines php schemacreatelanguagelines function blueprint table tableincrementsid tablestringgroup tableindexgroup tablestringkey tabletexttext tabletimestamps group column formid key fieldid attribute phonelabel php languagelinecreate group key namelabel text name nombre retrieve name form transnamelabel additional consideration anytime new field added removed form changed languagelines synced also create full form string export add localization toggle preview lumen translator package generate translate data httpsgithubcomjcarrizaleztranslator google translate look feasible initially translation api service may fit better
jetstream simplification metadata value author aricart derekcollison tbeets scottf jarema piotrpio approved tag jetstream client spec problem statement consuming message jetstream require large number design client api user current jetstream client create update consumer definition fly subscribe functionality consuming message invoked lead unexpected behavior different client possibly written different version different library attempt consume consumer client implementing jetstream code also confronted choice whether implementing pull push subscriber goal adr provide simpler api jetstream user reduces number confronted provides expected performance design jetstream api consists three main component jetstreamcontext stream consumer jetstream jetstream mainly responsible managing stream serf entry point creating configuring controlling stream jetstreamcontext also expose method manage consumer directly bypassing getcreate stream example set method jetstreamcontext stream operation addstreamstreamconfig updatestreamstreamconfig getstreamstreamname deletestreamstreamname liststreams consumer operation getconsumerstreamname consumername createconsumerstreamname consumerconfig updateconsumerstreamname consumerconfig createorupdateconsumerstreamname consumerconfig deleteconsumerstreamname consumername accountinfo stream stream created jetstreamcontext provide set operation managing stream content stream perform operation purging entire stream fetchingdeleting individual message stream also allow managing consumer example set method stream operation consumer getconsumerconsumername createconsumerconsumerconfig updateconsumerconsumerconfig createorupdateconsumerconsumerconfig deleteconsumerconsumername operation stream purgepurgeopts info gettingdeleting individual message getmsggetmsgopts deletemsgdeletemsgopts consumer consumer jetstream api entity message read consumer expose method getting consumer info well method consuming message consume fetch next example set method consumer operation consumer instance info operation consume message consume fetch next design naming individual client library client library implementing jetstream api adhere languagespecific library best practice following outlined design method name may vary add versus create certain method may placed differently based idiomatic convention consumerdelete instead streamdeleteconsumerconsumername library may support chaining functionality aligns jetstream implementation semantics getstreamnamegetconsumername operation consumer following operation fetch next consume info optional operation return consumer info consumer delete optional operation delete referenced consumer lifecycle consume may controlled example stop delivering message callback drain message already accumulated stopping consumer additional method consumer implementation appropriate object return value callback driven consumer note pull request issued client clientside timeouts addition serverside timeout expiry clientside timeout value always larger expiry fetch get one message operation end rpc expires number messagesdata batch requested provided user control retrieve message server depending language message delivered via callback signal indicate fetch finished could message null via iterator functionality getting next message block message yielded operation operation finish terminates iterator client also expose fetch certain amount data maxbytes instead message depending language either fetch different consumer method fetchbytes fetch configuration maxmessages number max number message return expires number amount time wait request expire nanosecond maxbytes number max number byte return idleheartbeat number amount idle time server wait sending heartbeat request expires heartbeat enabled default note maxmessages maxbytes described optional least one required next get single message server pull request fetch message sent next invoked depending language implementation may fetchmaxmessages return iterator next configuration expires number amount time wait request expire nanosecond idleheartbeat number amount idle time server wait sending heartbeat request expires heartbeat enabled default consume retrieve message server maintaining buffer refill point message processing client may want way drain buffer iterator without pulling message client cleanly stop without leaving many message unacked consume configuration maxmessages number max number message stored buffer expires number amount time wait single pull request expire maxbytes number max number byte stored buffer idleheartbeat number amount idle time server wait sending heartbeat thresholdmessages number number message left buffer trigger low watermark client influence request message thresholdbytes number hint number byte left buffer trigger low watermark client influence request data note maxmessages maxbytes exclusive client allow depending constraint provided client default value maxmessages set maxbytes constraint corresponding threshold set note maxbytes set client set batchsize request large number instead leaving empty bypass server sending one message batchsize default constraint default configuration value consume may vary client implementation depending value efficient specific programming language maxmessages depends client probably message expires default minimum maxbytes set maxmessages provided idleheartbeat default expires capping minimum maximum thresholdmessages maxmessages thresholdbytes maxbytes client make sure consume work properly maxmessages set getting stuck default thresholdmessages consume specification algorithm continuously fetching message implemented client taking account language construct nats subscription consume create single subscription handle response pull request subject subscription created reply consumermsgnext request max message max byte user able set either maxmessages maxbytes value provided default value maxmessages maxbytes set maxmessages set user value set maxmessages maxbytes set maxbytes set user value set maxbytes maxmessages set large value internally user cannot set constraint single consume execution constraint custom threshold set containing number messagesbytes processed trigger next pull request value threshold cannot higher corresponding constraint value pull request batch maxbytes value calculated pull request fill buffer buffering message consume prebuffer message limit set maxmessages maxbytes whichever provided client track total amount message pending buffer whenever threshold reached new request consumermsgnext published track specific pull request long aggregate message byte count maintained consume able fill buffer appropriately pending message byte count updated new pull request published add value requestbatchsize pending message count value requestmaxbytes pending byte count new user message processed subtract pending message count subtract message size pending byte count pull request termination received containing natspendingmessages natspendingbytes header subtract value natspendingmessages header pending message count subtract value natspendingbytes pending byte count client could check header future proof request timeout message size exceeds maxbytes batchcompleted message size calculation message size byte calculated server size consists data payload header subject reply subject consumergo calculate payload size calculated client side include transport subject since generally known client lenpmsgsubj lenackreply lenpmsghdr lenpmsgmsg handling addition providing termination natspendingmessages natspendingbytes header message indicate termination pull error telegraphed user language specific way telegraphing warning optional error bad request consumer deleted consumer push based warning exceeded maxrequestbatch exceeded maxrequestexpires exceeded maxrequestmaxbytes exceeded maxwaiting telegraphed message request timeout message size exceeds maxbytes call next fetch concluded pull terminated hand consume recover maintaing state pending count issuing new pull request unless consumer deleted consumer push based case consume call conclude implementation specific way idiomatic language idle heartbeat consume always utilize idle heartbeat heartbeat value calculated follows warning triggered timer reach request idleheartbeat value timer reset received message either user message message heartbeat message heartbeat timer reset paused event client disconnect resumed reconnect heartbeat error terminal rather telegraphed user language idiomatic way server reconnects client detect server disconnect reconnect disconnect event received client reset heartbeat timer pause heartbeat timer reconnect event received client resume heartbeat timer check consumer exists fetch consumer info consumer available terminate consume execution error operation may retried several time jetstream may immediately available publish new pull request message processing algorithm algorithm receiving processing message take account server reconnects heartbeat check process handling described previous section verify whether new pull request sent pending message count reach threshold pending byte count reach threshold yes publish new pull request add request batch maxbytes pending message byte counter check new message available yes reset heartbeat timer verify type message message heartbeat message message user message handle return execute callback subtract message pending message count message size pending byte count message error verify error type message contains natspendingmessages natspendingbytes header verify error terminal based handling issue warningerror required conclude call necessary read value natspendingmessages natspendingbytes header subtract value pending message count pending byte count respectively info optional operation return consumer info note depending consumer exported across account api retrieve info consumer may available client may optionally expose way retrieved cached info consumer instance bypassing consumerinfo request server delete optional operation allows deleting consumer note depending consumer exported across account api delete consumer may available consequence new jetstream simplified consumer api separate legacy functionality legacy functionality deprecated
api translation power version related description problem solve provide unified way manage translation translatable entity api possible solution translation collection could embedded object within productoptionproductoptionvalue resource provided iris reasoning translation always embedded collection object theyre irrelevant outside main object provide value alone
systemd init system extended systemd unit dapps several choice init system traditional sysvinit plain shell script startup service openrc modern reimplementation advanced feature dependency tracking systemd standalone native application service unit description instead shell script take role many standard unix service logging network configuration ubuntuderived upstart similar systemd idea sort discontinued least embedded application systemd init system consequence fragility startup process native support lazy service loading lazy mount one package replace init syslog cron etc good dependency tracking service devs emotionally hate systemd write glue code package devs layout config
opting study affect rollouts decided author travis long deciders nimbus team trust legal desktop firefox product team mobile firefox product team data science problem statement rollouts feature nimbus distinct experiment measurement instrument instead represent offtrain configuration update rollouts serve many purpose launching winning branch experiment faster train launching configuration nonexperiment user experiment short period verification configuring different setting feature different audience remotely kill switch want launch feature turn something wrong currently rollouts ignored user opted study nimbus treat rollouts study obeying user preference setting experiment one requirement messaging system work message set rollouts shown user regardless experiment setting product management mobile team would like able rollout feature capability user regardless preference experiment audience set outcome difference rollouts experiment nimbus team would like treat independently would involve disconnecting rollouts study application preference rollouts could still delivered user otherwise opted participating experiment rollout intentional internal configuration change update initiated mozilla thus may important release new feature user user allowed opt rollouts could degrade user experience due effect applying change treating rollouts automatic configuration update mean subject release update approval process respect update opt experiment subject launching experiment approval process respect study opt
http api single access point august pending originally software tool became flowkit designed extensible library connected one shared database user would extend copy library add query type even modify existing one introduced considerable difficulty guarantee analysis written one person could run another person future user required highly privileged access database way manage usage shared resource way ensure upstream change difficult effectively exploit ability reuse already computed result analyst significant complexity blurred functional boundary main library difficult tool outside python ecosystem substantial challenge logging access activity motivates revised design single copy library responsible constructing running query accessed language neutral http api facilitates significant improvement easy produce client multiple language ecosystem make substantial change enclosed code database structure etc little disruption support granular access control enables secure storage raw data removing direct access data allows much efficient sharing resource support comprehensive logging much clearer seam functional part simpler codebase simpler code scheduling query run controlled single point considerable opportunity efficient scheduling run caching query flowmachine wrapped http api consequence analyst significantly reduced freedom work database scheme number docker container required constitute running flowkit system considerably increased
title fault tolerance smartfridges polling mechanism getting smartfridges inventory would last known inventory even polling mechanism regularly obtain smartfridges stateinventory consequence without might smartfridges info fridge offline
decided nodejs platform backend system deployed heroku two main reason platform familiar key stakeholder project brendan uniformity frontend netlify part project potentially sharing model code future see message slack message around
adr choosing framework july novice wpf thought might helpful adopt popular framework make development process easier remove unnecessary gotchas writing new language framework might also quicken pace development remove write many helper class galaxy zoo touch table app framework adopting framework seems like shortcut learning basic want focus language work rather simply getting something working also framework might cause lot overhead aspect framework learning new framework along learning net might overwhelming declined consequence framework well documented mvvm light others quickly becoming deprecated silverlight worry framework could soon lose favor net community declining framework potential adding dev time spent creating messenger view model base component often found wpf framework retrospect becoming familiar wpf wish chosen framework perhaps mvvm light achieve app example although created messenger based stack overflow post often ran issue messenger unable find advice stack overflow answer reference mvvm light messenger dont think mvvm light wouldve huge load code likely framework couldve cleaned section code see merit declining framework novice wpf dont think much gained going without
notification error handling error occurs validating additional notification data sending request ctp platform adyen notification wrap thrown error customized error object commercetoolserror validationerror class validationerror extends error constructor stack message super thisstack stack thismessage message thisretry false class commercetoolserror extends error constructor stack message statuscode super thisstack stack thismessage message thisretry thisshouldretrystatuscode shouldretrystatuscode return statuscode statuscode statuscode displayed customized error object wrap partial information original error since whole error object logged important information may missing debug purpose error occurs making request ctp platform adapt verror package help wrap entire original error propagate function caller try attempt perform request ctp platform catch err throw new verrorerr customized error message wrapped error retrieved verror wrapper either following code snippet const cause verrorcauseerr const cause errcause detais please refer verror documentation case error thrown external call happens fail data validation dont adapt verror simply instantiate error object parsing error message like example transactionstateflowhasownpropertycurrentstate transactionstateflowhasownpropertynewstate const errormessage wrong transaction state passed currentstate currentstate newstate newstate throw new errorerrormessage consequence fewer boilerplate code customized error object obsoleted information original error listed log example show log customized error wrapper name ctpadyenintegrationnotifications hostname pid level notification eventcode authorisation eventdate pspreference testauthorisation success true err message got concurrent modification error updating payment undefined version tried undefined currentversion wont retry reached limit max retries failed action actionaddinterfaceinteractiontypekeyctpadyenintegrationinteractionnotificationtypeidtypefieldscreatedattzstatusauthorisationtypenotificationnotificationeventcodeauthorisationeventdatetpspreferencetestauthorisationsuccesstrueactionaddtransactiontransactiontypeauthorizationamountcurrencycodeeurcentamountstatesuccessinteractionidtestauthorisation object fcefdceec different version expected expected actual name verror stack verror got concurrent modification error updating payment undefined version tried undefined currentversion wont retry reached limit max retries failed action actionaddinterfaceinteractiontypekeyctpadyenintegrationinteractionnotificationtypeidtypefieldscreatedattzstatusauthorisationtypenotificationnotificationeventcodeauthorisationeventdatetpspreferencetestauthorisationsuccesstrueactionaddtransactiontransactiontypeauthorizationamountcurrencycodeeurcentamountstatesuccessinteractionidtestauthorisation object fcefdceec different version expected expected actual updatepaymentwithrepeater usersleungkinghinprojectscommercetoolsadyenintegrationnotificationsrchandlernotificationnotificationhandlerjsn async processnotification usersleungkinghinprojectscommercetoolsadyenintegrationnotificationsrchandlernotificationnotificationhandlerjsn async objecthandlenotification usersleungkinghinprojectscommercetoolsadyenintegrationnotificationsrcapinotificationnotificationcontrollerjsn async contextanonymous usersleungkinghinprojectscommercetoolsadyenintegrationnotificationtestunitnotificationcontrollerspecjsncaused concurrentmodification object fcefdceec different version expected expected actual buildmockerrorfromconcurrentmodificaitonexception usersleungkinghinprojectscommercetoolsadyenintegrationnotificationtesttestutilsjsn objectanonymous usersleungkinghinprojectscommercetoolsadyenintegrationnotificationtestunitnotificationcontrollerspecjsn objectinvoke usersleungkinghinprojectscommercetoolsadyenintegrationnotificationnodemodulessinonlibsinonbehaviorjsn objectfunctionstub usersleungkinghinprojectscommercetoolsadyenintegrationnotificationnodemodulessinonlibsinonstubjsn functioninvoke usersleungkinghinprojectscommercetoolsadyenintegrationnotificationnodemodulessinonlibsinonproxyinvokejsn objectupdate usersleungkinghinprojectscommercetoolsadyenintegrationnotificationnodemodulessinonlibsinonproxyjsn updatepaymentwithrepeater usersleungkinghinprojectscommercetoolsadyenintegrationnotificationsrchandlernotificationnotificationhandlerjsn async processnotification usersleungkinghinprojectscommercetoolsadyenintegrationnotificationsrchandlernotificationnotificationhandlerjsn async objecthandlenotification usersleungkinghinprojectscommercetoolsadyenintegrationnotificationsrcapinotificationnotificationcontrollerjsn async contextanonymous usersleungkinghinprojectscommercetoolsadyenintegrationnotificationtestunitnotificationcontrollerspecjs msg unexpected exception occurred time following example log verror package applied name ctpadyenintegrationnotifications hostname pid level notification eventcode authorisation eventdate pspreference testauthorisation success true cause body statuscode message object fcefdceec different version expected expected actual error code concurrentmodification message object fcefdceec different version expected expected actual currentversion name concurrentmodification code statuscode originalrequest uri myprojectpaymentsfcefdceec method post body version action action addinterfaceinteraction type key ctpadyenintegrationinteractionnotification typeid type field authorised type notification response header accept applicationjson contenttype applicationjson authorization bearer retrycount header server nginx thu mar gmt contenttype applicationjson charsetutf contentlength servertiming projectsdur xcorrelationid projectsddacbacfbcdf xservedby apixxxcommercetoolsde xservedconfig sphereprojectsws accesscontrolalloworigin accesscontrolallowheaders accept authorization contenttype origin useragent accesscontrolallowmethods get post delete accesscontrolmaxage via google altsvc clear connection close msg unexpected exception occurred time
splitting agent fronthouse backhouse holo user agent key source chain client machine rest holochain agent dht shard etc held holoports february arthur eric nico discussed cocreative session london made assumption holochain agent split two piece called fronthouse backhouse prior left right hemisphere fronthouse meant entail source chain private key management well ribosome run app provide interface nonholo case bridging everything useragent facing backhouse dht shard routing table metric etc basically everything network facing separation reasoning february rewrite fronthouse able run piece web browser needed holo eric nico continued map specific two module would interface process became apparent dividing agent two piece run different remote machine huge problem every network communication including world model happens ongoing basis backhouse signed agent key agent key definition part fronthouse backhouse cant live main accountability without communicating fronthouse requesting signature every packet communication might even triggered networkdht user offline key accessible conversation including arthur may make clear thinking term two different kind agency seems appropriate discussed separating authoring creative agency part run validation hold dht shard world model information allows later proxy former separate key decide emulate single agency represented one key across two remote device word decide try implement distributed agent instead solve initial holo frontend problem establishing two subagencies distinct key holo client authoring agency explicitly grant proxy right holoports dht agency word holo user local key sign statement grant another agent holoport act behalf case needed holoport carry dht weight agent technically another agent key consequence holo user stay full control key source chain dont implement backhouse dht handling holo browser part dont think two piece interface interact implement proxy authorization statement handling holochain affect routing metric dht lookup process user entry retrieved holoports address lookup mechanism know somehow similar mechanism may work case well especially solving multidevice problem user laptop phone tablet different agent treated identity
user standalone kiali issue motivating influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
activemq activemq java aliyun ons ons ons mqtt consequence image image minday day shour ref httpshelpaliyuncomdocumentdetailhtmlspmdocxiqapd mnsons httpshelpaliyuncomdocumentdetailhtmlspmdocpixs sdk httpshelpaliyuncomdocumentdetailhtml python httpshelpaliyuncomdocumentdetailhtmlspmdocmnhdf java httpshelpaliyuncomdocumentdetailhtmlspmdocvwclgj
title convert office document weight problem statement office document like docx odt converted pdf file look much possible like original would nice javaonly solution external tool better outcome external tool fine since docspell free software tool must also free considered apache poi together library pandoc external command abiword external command unoconv external command choose document converted pdf compared format docx odt considered format look well xlsx pptx doesnt look great native view compare odt figurefileexampleodtnativejpg xwpfconverter couldnt get example work exception javalangillegalargumentexception value parameter bound orgapachepoiutilidentifiermanagerreserveidentifiermanagerjava orgapachepoixwpfusermodelxwpfruninitxwpfrunjava orgapachepoixwpfusermodelxwpfruninitxwpfrunjava orgapachepoixwpfusermodelxwpfparagraphbuildrunsinorderfromxmlxwpfparagraphjava orgapachepoixwpfusermodelxwpfparagraphinitxwpfparagraphjava orgapachepoixwpfusermodelxwpfdocumentondocumentreadxwpfdocumentjava orgapachepoipoixmldocumentloadpoixmldocumentjava orgapachepoixwpfusermodelxwpfdocumentinitxwpfdocumentjava docspellconverttestingwithpoitestingscala docspellconverttestinganonfunruntestingscala catseffectinternalsiorunloopcatseffectinternalsiorunlooploopiorunloopscala catseffectinternalsiorunlooprestartcallbacksignaliorunloopscala catseffectinternalsiorunlooprestartcallbackapplyiorunloopscala catseffectinternalsiorunlooprestartcallbackapplyiorunloopscala catseffectinternalsioshifttickrunioshiftscala catseffectinternalspoolutilsanonanonrunpoolutilsscala javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava javalangthreadrunthreadjava project apache poi seems unmaintained could find website artifact maven central pandoc know pandoc great tool converting markup document try office document support docx odt listinputformats pandoc manual default pandoc latex create pdf requires latex engine installed see pdfengine alternatively pandoc roff html intermediate format specify output file pdf extension add pdfengine html command line tool generate pdf intermediate format may specified pdfengine trying latex engine pandoc odt testpdf exampleodt result odt figurefileexampleodtpandoclatexjpg pandoc odt testpdf exampledocx result docx figurefileexampledocxpandoclatexjpg trying engine pandoc odt testpdf exampleodt result odt figurefileexampleodtpandoccontextjpg result docx figurefileexampledocxpandoccontextjpg trying engine pandoc odt testpdf exampleodt result odt figurefileexampleodtpandocmsjpg result docx figurefileexampledocxpandocmsjpg trying html engine requires wkhtmltopdf present pandoc extractmedia odt html testpdf exampleodt result odt figurefileexampleodtpandochtmljpg result docx figurefileexampledocxpandochtmljpg abiword trying abiword topdf exampleodt result figurefileexampleodtabiwordjpg trying docx file failed worked doc file unoconv unoconv relies libreofficeopenoffice installing result installing part libreoffice large dependency trying unoconv pdf exampleodt result odt figurefileexampleodtunoconvjpg result docx figurefileexampledocxunoconvjpg outcome unoconv result unoconv really good abiword also bad didnt convert chart font markup would great depend something big libreoffice result much better also pandoc deal well docx file engine thing rendered embedded chart like abiword image font styling present configurable external command anyways user exchange time different one
web backend language framework backend web framework needed order handle web request coordinate component backend interacting database starting batch processing workflow variety potential candidate choose including django written python play written scala akka http successor spray written scala team working component project experience django usually goto choice however compelling reason investigate framework written scala project important component consider making tile server would likely benefit written scala since could easily make geotrellis tile server doesnt necessarily implemented within framework web server advantage many way architect system separate server component requires form communication two order perform action user permission management reading andor writing stored object metadata may accomplished either one server access api server connecting database directly potentially duplicating logic single framework component minimize pain point open pull request aim allow ingesting geotrellis avro record python merged deemed stable could offer compelling reason django however since pull request yet merged given phase project scala tile server seems building upon initial solution may least risky fastest way forward regarding language python dynamically typed programming language scala statically typed programming language many pro con python generally easier quickly get something running however typesafety also easier introduce runtime error particularly codebase grows larger size many test must written compensate feedback loop writing code compiling running test larger scala number runtime error reduced much easier perform refactors codebase two major scala backend web framework consideration akka http play akka http lightweight framework word http framework rather actorbased toolkit interacting web service client focus allow elegant expression web service provide tool testing play quite lightweight aim djangotype backend web framework come ability serve static asset perform html templating well defining apis however unlike django included orm wed still involve library slick interact database application primary backend web framework create api wont needing html templating functionality well third party authentication service fewer reason choose play akka http given bulk play functionality unused well manually orm anyway given previous experience working spray translatable akka http also geotrellis team primary choice backend web framework seems like safe choice web backend language project scala akka http framework despite fact team dont much scala experience pro outweigh con scenario knowing advance interact scala tile server codebase likely quite large advantageous minimize intraserver communication pain point discussed compiletime error checking easier time refactors unified language backend also make contextswitching burden intraserver communication still required interaction spark cluster job reducing total number component must communicate potentially reduce error expedite development process consequence team member must willing put effort extend experience scala includes participating necessary training instituting bestpractices interacting geotrellis team pairprogramming code review one potential consequence aware akka http still relatively young listed production ready may potential bug encountered geotrellis team experimented seems similar interface spray worstcase scenario potentially switch spray minimal headache needed another consequence akka http django django batteriesincluded solution solution many common usecases built whereas akka http much limited scope one item django handle well box connecting database performing migration another set library accomplish within akka http likely candidate connecting database via orm slick weve good result past currently geotrellis slick builtin way load database schema perform migration investigate choose library good candidate include scala forklift slickmigrationapi flyway
django web framework proposed updated proposed django popular mature web framework comprehensive documentation large ecosystem app plugins provide extra functionality django provides objectrelational mapping orm schema migration system simplifies persistent storage application data simple convenient admin panel allows developer see interact application data web browser tbd consequence
main programming language backend deciders achotard jpthiery problem statement want code backend handle inbound information message broker expose dashboard frontend programming language driver interesting fun new people either already adopted xebians hard adopt based existing knowledge library support usecases considered elixir scala kotlin java language outcome chosen good library support thing http protobuf separately talking grpc help establish strong bidirectionnal persistant streaming dashboard http also open way protobuf serialized message message bus maybe comme addition rabbitmq people project want play seems appropriate small microservices like one going build however excluding language depending usecases wish people working want people contribute wont force anyone given language people free language want well try default main language much possible
title encryption weight problem statement since docspell may store important document possible encrypt server almost transparent user example user must able login download file clear form server must also decrypt user collective access file requires share key among user collective even file encrypted associated meta data especially access database would allow see tag associated person correspondent document short encryption mean file content blob extracted text encrypted metadata secret key stored server protected passphrase file downloaded clear form driver major driver provide possible privacy user even expense feature currently think associated meta data enough finding document full text search needed considered clear blob file content encrypted associated metadata extracted text must encrypted obviously public key encryption pke pke server automatically encrypt file publicly available key data wouldnt require user provide passphrase encryption decryption would allows first processing file extracting text text analyisis encrypting text afterwards public secret key stored database secret key must protected done encrypting passphrase secret key user login password user log must provide correct password password private key unlocked requires store private key passphrase encrypted every user password database whole security depends user password quality plenty difficulty approach password change new secret key adding user etc kind encryption would protect data offline attack also accidental leakage example bug software would access file another user encryption blob encrypted type attack would provide protection user must still trust server first order provide wanted feature document processing server must see file content receive serve file clear form access anyways mind feature protect stolen database attack database somehow leaked attacker would see metadata real document also protects leakage maybe caused pogramming error downside increase complexity lot since personal tool personal worth effort outcome encryption complexity tool meant self deployment personal change enough time reconsidered
replacing storage center form builder platform form metadata collection json file file created editor application stored github git version transfer editor interact service instead produce collection file finally stored github link github publisher obtain file create form online github chosen due giving transparency versioning form collaboration data ownership could integrated local service easily built another reason user base form builder would developer would understanding version control git therefore beneficial change shift product proposal moving supported model full self service model shown git github blocker least friction point new user also facilitate move true self service platform method user intervention editor publisher remove git github store form metadata solution move saving form metadata github database api manage new service hosted cloud platform utilise postgres database ruby rail api connection service current method platform api data available authorised application metadata stored version number giving ability specific version editingpublishing make sure form builder principle upheld database scheduled backup disaster recovery plan published moj online runbook consequence form data stored public default mitigated future release
title introduction unique identifier checkout method area checkout tag payment shipping current implementation exists challenge extension developer uniquely identifying payment shipping method identifier issue particularly significant app server necessitates call shopware admin api identification payment shipping method based respective introduce new property called technicalname paymentmethod shippingmethod entity technicalname property serve unique identifier payment shipping method significantly simplifying identification process technicalname field optional within database api ensure backward compatibility made mandatory administration ensures merchant update payment shipping method accordingly upcoming requirement unique index ensure uniqueness starting version technicalname field also become required within database api part database migration process technicalname field automatically generated default payment shipping method provided shopware illustrated type name technical name payment debit paymentdebitpayment payment invoice paymentinvoicepayment payment cash delivery paymentcashpayment payment pre payment paymentprepayment shipping standard shippingstandard shipping express shippingexpress furthermore payment shipping method provided apps also benefit automatic generation technicalname generation based apps name identifier defined payment method manifest app name identifier technical name myapp mypaymentmethod paymentmyappmypaymentmethod myapp myshippingmethod shippingmyappmyshippingmethod consequence plugin developer required supply technicalname payment shipping method least beginning version merchant must review custom created payment shipping method new technicalname property update method administration accordingly essential exercise caution modifying technicalname administration change could potentially disrupt existing integration
title arch gpu gts parent index haschildren false layout post sidenav doc permalink adrsarchgpuongts proposedexploratory issue motivatina gpus support growth arcgis pro gts usage proposed exploratory optional deciders scott sharp michelle douville jeff card david ell optional optional technical story description ticketissue url optional arcgis pro main case gpus iitd maintain server arcgis pro currently part proof concept currently two gpus test server nvidia provides esri recommends httpsdesktoparcgiscomenarcmaplatestextensionsarcglobefaqsforselectinggraphicscardsglobehtm esri dev summit nvidia concurrent licensing model cheap convoluted subscription level scott sharp email cost published provide cost calgary chip see one memory accessible already obsolete single newer cheaper concurrent kamloops test license manager unlimited key load testing occurs gpu could well thing graphical mining process requires heaving processing env mike flood modelling firewall opened run desktop well gpu faster processing iteration license manager local run desktop cpu based gpu arcgis pro case data gpu cpu heavy cpu gts load test raw lidar harold steiner people without gpu spinning around people gts still responsive mark mcgirr building geoprocessing tool statusing tool built ago built qgis comparison current server arcgis pro may require gpu metric uptake pro high anticipated currently concurrent max user arcgis pro pool user still arcgis desktop scott upgrading arcgis eol may last veresion server production desktop year max still desktop patch update concurrent user desktop qgis server server distinct user concurrent unique gts bcts rest stand alone license gpu around concurrent license info perhaps david ell citrix licensing add another trickiness level zenapp zendesktop zenapp come served server gpu fully available one server see core affect user server zendesktop allows divy resource interferes hpas agreement essentially creates handle requires good power user great others ideal statue gpu pro card per user zenappzendesktop esri doesnt recommend support unknown cost gpu licensing ocio offered sag little desktop another ministry citrix another ware bcts server arcgis flipping switching going pro pool may want gpu carol gjetturd admin pool harry scott lrm oracle desktop bcts specific tool done carole year amortization brand new gpu would waste server single concurrent price comparison advanced desktop gts pool deal patching licensing version latency file share licensing manager standalonebctswfptsghaida gwaii cop discussed pro desktop training access geobc lot stand alone pro arcgis arcgis online geobc license databc disabled gpu place isolated prod test concurrent license manager manager frank burkheart david ell problem statement describe problem statement free form two three sentence may want articulate problem form question driver optional driver force facing concern driver force facing concern number driver vary considered number vary outcome chosen justification meet criterion driver resolve force force come best see positive consequence optional improvement quality attribute satisfaction followup required negative consequence optional compromising quality attribute followup required pro con optional example description pointer information optional good argument good argument bad argument number pro con vary example description pointer information optional good argument good argument bad argument number pro con vary example description pointer information optional good argument good argument bad argument link optional link type link adr example refined adr number link vary influence constrains change proposing agreed implement consequence becomes easier difficult risk introduced change mitigated
title heroku deployment environment desirable keep project online testing purpose easy environment cost decided heroku easy environment cli tool make easy deploy command free plan also great integration lot platform recognizes spring boot box consequence fast deployment process smooth integration spring boot cost minute idleness instance turned start little lazy firts access
layout page title jettyfailsafe allow jetty management component run configuration deciders aaron mcgrath lewin chan problem statement way enable jetty management component bootstrapproperties first bootstrap jetty configured xml configuration file second bootstrap jetty server minimal default also doesnt default deploy webapp provider mean started unless optional webserverwebappurl specified always considered fromproperties variant production ready message logged effect startup managementcomponentsjmxjetty webserverconfigurlconfigjettyxml want override jetty port instance syspropjettyhttpport managementcomponentsjmxjetty webserverport webserverwebappurlwebapps normally well jettyxml contains reference default descriptor file xml set namedefaultsdescriptor property namejettydeploydefaultsdescriptorpathname default property namejettyhome default configwebdefaultxml default property set generally people dont edit jettyxml default mean gradle style project carry around srcmaininterlokconfigjettyxml webdefaultxml inside git configuration even dont formally within interlok configuration problem able start jetty management component actual sensible default jetty component enabled port config file specified considered nothing make fromproperties production ready embed jettyxml interlokcommonjar jetty enabled setting defined outcome embed jettyxml interlokcommonjar jetty enabled setting defined pro con nothing course easy change user since template file emit part project saving might make difference medium term since project automatically get jettyxml webdefaultxml present save project generate bootstrap file good change code bad additional artefact cluttering interlok project additional object git neutral build new deployment scratch problem doesnt manifest onwards make fromproperties production ready tightly couple default configuration jetty version effectively would replicate variant existing jettyxml code directly jetty setter getters add benefit add additional maintenance burden want expose various thing configuration user would define property inclusion bootstrapproperties define another fine load put back class problem always jettyxml file bad tight coupling internal jetty object bad wanted configurability would expose webserverxxx property similar bad maintenance overhead embed jettyxml since already jettywebdefaultfailsafexml present interlokcommonjar jettyfailsafexml well introduce new serverbuilder implementation build jetty configuration xml file found classpath add new fromclasspath serverbuilder implementation extracting commonality fromxmlconfig take effect webserverconfigurl webserverport defined fromclasspath jettyfailsafexml jettywebdefaultfailsafe build jetty instance since javaneturl reference file inside jar already work jettyxml inside custom jar zzlcjettyjar find resource create url calling resourcenewresourceurl syspropjettydeploydefaultsdescriptorpathjarfilecadaptrisworkruntimegradlenightlyinterlokjettyclasspathbuilddistributionlibzzlcjettyjarmetainfwebdefaultxml webserverconfigurljarfilecadaptrisworkruntimegradlenightlyinterlokjettyclasspathbuilddistributionlibzzlcjettyjarmetainfjettyxml basically jettyxml remains overload jettydeploydefaultsdescriptorpath location jettywebdefaultfailsafexml interlokcommonjar good jetty start sensible set default neutral still maintenance overhead single file since already check default jettyxml work anyway neutral build new deployment scratch problem doesnt manifest onwards
timed text editor choice draft deciders pietro james problem statement build timed text editor editing audio video transcription useful open source text editor add functionality driver simple straight forward way keep word time sync playback text editing considered draftjs quilljs prose mirror time article building text editor digitalfirst newsroom atjson outcome chosen draftjs previous work space explored stressed test editor altho quilljs straight forward api despite quircky data model internal representation quickly make text based prototype see demo even multi user collaboration support togetherjs hard tell whether quilljs going around long term draftjs core part facebook starting see community around growing number plugins also advanced feature like adding speaker label timed text non timed text transcription workarounds draftjs immediatly obvious would implemented quilljs
keep config simple possible existing verify configuration thing like metadata quite intimidatingly complex wed like application simple possible configure well try make config sane default wherever possible user doesnt specify thing shouldnt care user shouldnt specify thing dont truststorepath consequence may modify library class make flexible msa default could example
sidebarposition snapshot aggregable item blockchain terminology term description aggregablesaggregable item term refers project subprojects orand workflowitems snapshot snapshot data model containing latest state aggregable item currently aggregable item project subprojects workflow item fetched via api stored cache basically inmemory storage nodejs application since cache invalidation impact memory becomes concern number aggregable item increase time want able still form caching reduce memory impact data sent network blockchain also sake minimalist design want avoid introducing middleware application perform caching operation current implementation inmemory caching diagram explains inmemory caching work trubudget aside working similar simple cache step update cache impact performance application aggregable item requested blockchain cache fetch available aggregable item update whole cache storage example requested project found cache storage whole cache updated including project subprojects workflow item result unnecessary amount data processing data transfer size network order reduce application memory load inmemory cache removed solution without help middleware application utilizing blockchain onchain storage new type event aggregable item created snapshotpublished suffix data stored event called snapshot event data model common event data snapshot event consists following common field field type source time publisher item specific event data addition common field following field given event present projectsnapshotpublished field project subprojectsnapshotpublished field projectid subproject workflowitemsnapshotpublished field projectid subprojectid workflowitem marked field aggregable object contain latest event item data relevant item type find info object created workflow planned implementation snapshot logic create update request api receives request modifies creates aggregable item check snapshot aggregable item exists snapshot available creation scenario create snapshot uptodate aggregable data creating project snapshot would contain created project data snapshot api check following condition least event happened last snapshot event roughly translates item state change least time since last snapshot yes make new snapshot event applying event data happened since last snapshot event top last snapshot including current event apply eventrequested change normally snapshot made event number default condition environment variable changed per deployment get request workflow get request bit different api check usual snapshot aggregable item exists check received snapshot actually latest event applied aggregable item mean snapshot contains latest uptodate state aggregable latest event snapshot event aggregable event latest snapshot event applied order latest snapshot data served back api uptodate aggregable data performance metric loading time metric average request duration network aggregable item test project subprojects workflowitems inmemory caching blockchain snapshot project subprojects workflow item test project subprojects workflowitems inmemory caching blockchain snapshot project subprojects workflow item consequence despite significantly reduced load application memory reduced loading time increased amount network request due fetching snapshot mean slightly higher chance networkcaused error occurring displaying project subprojects workflowitems
apps page model summary issue define strategy page model definition ensure code fit project requirement remove contentplatform app migrate main page model one app longer concept product detail history past defined apps based assumption different area website managed different team different requirement called product behind headline condition guide medicine etc since project started change make different content area look behave similar mean apps different share lot similar code beginning project concept core app called contentplatform contaied shared component project project phased longer requirement contentplatform app separate information architecture team created defining structure enforcing consistency page model current state currently contentplatform app suite apps product module suite apps core module target state suite apps core module providing sitewide functionality make sense standalone apps standalone app smallest unit people might realistically want different project one app containing nhsuk wagtail model related code one app containing campaign wagtail model related code
hardcoded namespaces threat modeling problem statement threat modeling approach relies pair threat mitigation threat referenced one particular mitigation considered hardcoding namespaces default node type property dynamic namespaces similar pattern namespaces threat mitigation outcome chosen hardcoded namespaces due ease implementation static nature problem positive consequence threat modeling multiple different type threatsmitigations necesaary minimal base type carry required property reference extended license copyright contributor eclipse foundation see notice file distributed work additional information regarding copyright ownership program accompanying material made available term eclipse public license available httpwwweclipseorglegalepl apache software license available httpswwwapacheorglicenseslicense spdxlicenseidentifier epl apache
title add native lazy loading image storefront area storefront tag image lazyloading storefront currently imagesthumbnails inside storefront making lazy loading mechanism without thirdparty extension includes something like lazysizes possible get lazy loading image native lazy loading image available current browser see httpscaniusecomsearchloading want make native lazy loading image storefront without adding additional javascript logic consequence pas new attribute loadinglazy several usage thumbnail component resourcesviewsstorefrontutilitiesthumbnailhtmltwig enables native lazy loading default thumbnail component loadingeager default behaviour effect setting attribute default lazy order avoid unexpected behaviour extension might added thumbnail component javascript solution lazy loading add native lazy loading appropriate area reduce initial network load main menu flyout category preview image load flyout opened product box product image load appear viewport inside listing also affect product slider horizontal scrolling crossselling image element layout load image appear viewport scrolling page line item image product image line item cart page load appear viewport dont add loadinglazy everywhere even though would technically work pitfall considered example recommended add lazy loading image likely inside initial viewport loading page aka abovethefold reading httpswebdevbrowserlevellazyloadingforcmssavoidlazyloadingabovethefoldelements system like shopware content almost entirely dynamic easy determine generic image component rendered could position page even guess like add lazy loading product listing invalid soon monitor portrait mode viewport change mobile therefore live small drawback product box lazy loading appear abovethefold however still benefit loading image later scrolling page scrolling product slider implementing javascript solution would contradict usage native lazy loading area without loadinglazy image gallery product detail page likely abovethefold gallery already javascript lazy loading image zoom well image slider sliding next image lazy loading lead bad user experience image appear late activate lazy loading thumbnail component pas loading attribute value lazy diff swthumbnails mythumbnail medium categorymedia attribute class mycssclass loading lazy
folder structure modified tyson fixed structure project may advantage limiting spread file across multiple folder contraining location known place advantage letting folder strucute emerge oganically also large risk thing break lowlevel file location change necesitating log bug fixing refactoring rigid initial structure canb lead later restriction imposed complexity following folder strucure adopted app controller model public img route view doc adr misc projectartifacts template nodemodules test localonly update removed folder originally specified found required project development log utility consequence disciplined file location naming convention produce naming convention document accompany folder structure adr localonly repo nodemodules must repo utility backend maintenance task folder related site siteserving doc must maintained directly main branch updated seperate branch
approach brain weighted neural network different amount node developed adjacency matrix first step grammar rule yielded first step second step network representation rationalization able develop brain many node scalably unevenly grammar approach building graph picked best known one however approach grammar pattern exist beforehand take first step algorithm running adjacency matrix figure finesse brain pattern
pull subscribe internals metadata value author wallyqs partially implemented tag jetstream client motivation one form message delivery jetstream pull based consumer adr described current state implementing consumption message type consumer pull based consumer type consumer delivery subject server know send message instead client request message delivered needed server example given stream bar consumer durable name dur pull subscriber durable pull request would look like term protocol shell pub jsapiconsumermsgnextbardur inboxxtkdpdlcoeknrfbrhvubzed request body possible field presented json body request body presented example default assumed batch number message server send minimum limit batch size level library account server may limit nowait boolean value indicating make pull request wait type see detail default false expires number nanosecond pull expire supplied mean expiration applied wait take precedence expires supplied pulln request request empty payload identical pull batch size result server sending next available message example shell sub inboxexample pub jsapiconsumermsgnextbardur inboxexample msg bar jsackbardur helo note even though inbox request inboxexample message got delivered subject rewritten bar subject message persisted jetstream pull request next message linger interest subject client disconnected batch size filled pull request increase numawaiting counter consumer inflight pull request consumer inflight pull request though changed creating consumer maxwaiting shell pub jsapiconsumerinfobardur inboxumfjlecclhcsclfwfrsjdszxco msg inboxumfjlecclhcsclfwfrsjdszxco type ionatsjetstreamapivconsumerinforesponse streamname bar name dur created config durablename dur deliverpolicy ackpolicy explicit ackwait maxdeliver filtersubject bar replaypolicy instant maxwaiting maximum inflight pullfetch request maxackpending delivered consumerseq streamseq ackfloor consumerseq streamseq numackpending numredelivered numwaiting inflight pullfetch request numpending cluster leader ncuouhyicresecktxesmgaznktelxpuiejcrtlifuwebz making pull request also possible request one message shell pub jsapiconsumermsgnextbardur inboxxtkdpdlcoeknrfbrhvogym batchexpires whenever pull request time count numwaiting increase consumer eventually reset reach max waiting inflight configured pull consumer wait pull request order get response server rigth away client make pull request nowait enabled example shell pub jsapiconsumermsgnextbardur inboxxtkdpdlcoeknrfbrhvogym batchnowaittrue result wait pull request guaranteed instant response server either next message error error could server error case service available commonly result wait pull request message error shell hmsg inboxxtkdpdlcoeknrfbrhvogym nats message design implementation pull subscribe combination wait lingering pull request described previously client simple example api look follows sub err jspullsubscribestreamname durable err nil logfatalerr msg err subfetch err nil logprintlnerror err continue msg range msg msgack implementing pullsubscribe two main case consider pulln pull pulln pulln batch request implemented somewhat similarly old style request making pull request first wait request done try get message may already available needed message message error jetstream server long pull request made shell sub inboxnquaixdgoozkotfectig pub jsapiconsumermsgnextbardur inboxwvajlnixcjzfsrxlhmts batchnowaittrue result wait request message hmsg inboxwvajlnixcjzfsrxlhmts nats message next pull request long pull request client side timeout pub jsapiconsumermsgnextbardur inboxnquaixdgoozkotfectig expiresbatch part request payload batch field set number expected message expires set cancel request client side timeout example timeout payload expires result represented nanosecond making first request wait request also recommended send auto unsubscribe protocol discounting message already received result wait request case batch request message client would auto unsubscribe receiving since first message error unsub batch account initial error message shell unsub successful result batch request least one message delivered client case message delivered client time away pull request recommended unsubscribe remove interest awaited message server otherwise risk server sending message inbox connected client longer expecting message shell sub inboxwvajlnixcjzfsrxlhmts pub jsapiconsumermsgnextbardur inboxwvajlnixcjzfsrxlhmts batchnowaittrue hmsg inboxwvajlnixcjzfsrxlhmts nats message unsub pub jsapiconsumermsgnextbardur inboxwvajlnixcjzfsrxlhmts expiresbatch msg hello jsackbardur helo message receives client away unsubscribes unsub error message handling receiving message point client may instead receive error server message msg hello jsackbardur hello system reached many inflight pull request condition hmsg inboxwvajlnixcjzfsrxlhmri nats request timeout whenever message recommended error returned user processable message instead handle error condition msg err subfetch err nil error client timeout request timeout bad request responder system unavailable current quorum logprintlnerror err continue msg never error message case error loop break msg range msg msgack pull optimization case pulling single message possible optimize thing making first pull request wait request instead preparing new style like requestresponse handler wildcard subscription result chatty protocol also work better topology jetstream running leafnode edge shell sub inboxmiojjnkoghobmcgcwkjz pub jsapiconsumermsgnextbardur inboxmiojjnkoghobmcgcwkjzasdf batchnowaittrue similar pulln first wait request fails first pull longer old style request made unique inbox note pull subscriber must pull requestresponse handler default implementation new style request cannot purpose due subject get rewritten would cause response dropped
replace old model zoo discussion proposed adam gibson jan todo centralized sum directory list directory stored local dljresources config file configuration file format listing directory type additional check old directory default value covered newer support pre cataloging based default dataset directory found prior release number current downloaders exist various resource deeplearningj function include following strumpf resource resolver manages test resource relies azure original code strumpf found deeplearningj model zoo legacy model zoo omnihub new model zoo replacing deeplearningj datasets dataset download various datasetiterators accumulated year made maintenance download related logic complex relevant adrs include omnihub zoo download omnihub zoo download implementation omnihub replace old model zoo proposal resource hosted github resource abstraction binding various resource type abstraction downloader resource handle aware following concept base url downloading file cache directory managing resource common download retry logic ensuring download succeeds resource manages remote resource like file similar current resource type deeplearningjcommon resource mostly stored git part introduction unified resource abstraction cache aware exposing cache user delete wish existing datasets old source common abstraction knowing dataset want download another problem file verification legacy model zoo simpler adler checksum verification download cache verification implementation mdsum mdsum standardize resource note order avoid maintenance burden checksum verification optional default resource return null empty string verification performed distinction important resource type test resource end user asset like pretrained model weight also important compatibility due legacy checksum verification zoo module checksum verification come later lead resource type omnihub omnihub pretrained model datasets legacy datasets custom iterators like mnist lfw dlj zoo legacy zoo model strumpf legacy test resource manager custom custom resource user specify url file destination consequence advantage reduced cost migrating github one module handling resource replaces legacy abstraction preserving backwards compatibility allows easier management local resource disadvantage potential bug migration take time
provide user error code fatal error deciders rossmurry roleyfoley implementation log httpsgithubcomhamletioarchitecturaldecisionlogissues problem statement hamlet deploy compiled binary file written single programming scripting language combination java freemarker wrapper freemarker dsl original hamlet deploy executor presently primarily bash script click cli executor written python handled exception occurs consistency error information provided handled error freemarker likely provide large json object review whilst error bash executor provide brief summary problem summary always uniquepererror many provide generic error message considered create manuallymaintained library error code assign one handled error introduce logging class group together message simmilar kind outcome chosen introduce logging class group together message simmilar kind later reevaluate determine specific approach error handling individual error code outlined would remain useful necessary build upon framework manuallymaintained library error code good provide method providing tailored error message possible fix user good could extended provide avenue review mostencountered error message good improved reporting communication around error experienced good consistency across spectrum potential error source bad increase maintenance overhead bad may challenge enforce consistently bad difficult make extensible community content logging class good provide method tailoring message whilst allowing reusability good accessible community content good consistency across spectrum potential error source good framework could extended upgraded later time good minor maintenance overhead established bad specificity possible compared unique error message
adr record classifier store snapshot session storage march volunteer ordered subject selection ran problem shown already seen subject prevents classifying unlike workflow random selection refreshing page workflow ordered selection always give back subject panoptes solution problem would remember active subject state across page visit going talk returning mobx state tree built concept snapshot immutable object representing state store given moment snapshot generated automatically whenever store change state retrieved getsnapshot const snapshot getsnapshotstore store created snapshot const store storecreatesnapshot snapshot applied existing store applysnapshot applysnapshotstore snapshot either case store state match snapshot snapshot preserve volunteer session saving session storage creating store stored snapshot enter page const classifierstore rootstorecreatesnapshot big change classifier behaviour ive split across several making change incrementally verifying step proceeding internally saving loading state snapshot implemented hook toplevel classifiercontainer component consequence classifier store written assumption start empty state load reaction run reset tree load new data api classifier store created snapshot snapshot mostly deleted datafetching reaction starting store existing state snapshot datafetching intelligent tree empty request new data panoptes tree already populated request fresh data stored resource stale volunteer expect refreshing page load new subject project loading store snapshot careful reset subject queue unless workflow explicitly ordered subject loading existing classification continuing snapshot isnt supported moment march leaving classifier returning destroy work progress classifier state saved session storage multiple classifier open different tab without page interfering session storage behind flag cachepanoptesdata passed classifier order enable storage project cachepanoptesdata automatically set project workflowprioritized ongoing
architecture record try clojure reasoning behind move clojure threefold nontrivial get rail talk neoj even basic data modeling case ruby library spent week bringing speed may drop neoj support future may require even update since handful people seem interested rubyrailsneoj combination library many thousand line code total worry without energetic rubyneoj community might paint corner depending ruby seem surface area thought addition volunteer come forward seem either willing learn whatever language happen chosen vastly prefer powerful jvm language like clojure kotlin seems like sensible language jvm middleground hard say much weight clojure clojure decade old volunteer whove come forward actively contributed kosa actually strong preference clojure rather insist another boring safe language like java kotlin two failed attempt python ruby quite happy thing going far language development team actually enjoys weve experimenting moving kosa ruby jvm language going well experiment simply reimplement ruby clojure stop reconsider move run issue along way experiment kosacrux repository github varunpai design work vast majority deployment infrastructure ansible script move ruby codebase wholesale without rework wont call experiment success weve implemented major component exist ruby codebase feel quite close nothing slowed development far reach point well start implementing feature ruby code lack feed parsing daily doha dwob card etc pending consequence clojure friendly language developer wider community willing volunteer clojure better language work neoj choose database crux currently evaluating parallel clojure library required pariyatti library much burdensome equivalent ruby library
create repository interface exercise system various data type user may want aggregated together easily accessible sortable type whale observation system consistent interface user may access various type record decided implement repository interface realised whale observation object user access large listrepository whale observation repository interface consequence design ensures common method sorting accessing large record whether type whale observation make working data structure straightforward another type class going recorded large collection collection implemented realising repository interface
adr validation taxonomy proposed author damir murat damirmuratgit gmailcom reviewer none today technology framework validation input data look like solved problem add annotation dtos data transfer object hook validation service app move however much cover digging detail various question pop exactly best place input data validation multiple level phase validation system state validation happens numerous inbound channel play trying answer turn validation involved commonly shown basic example solution complex require establishing principle rule architectural system klokwrkproject execute syntactic validation application facade layer necessary requirement may also executed adapter layer core validation application facade layer ensures input data inbound channel validated way example seen bookingoffercommandapplicationservice class cargotrackingbookingappcommandside module validation inbound channel adapter layer clientspecific validation typical example email verification scenario repetition want assure user submitted correct email organize validation syntactic semantic phase divided subphases necessary execute semantic validation inside domain layer depending nature happen either aggregate application facade syntactic validation consider validation syntactic require system state validates input data field isolation possibly interdependency crossfield validation syntactic stateless validation executed first fail semantic validation wont triggered semantic validation hand semantic validation requires access system state may deal checking current aggregate state request valid may also check nonaggregate condition existence necessary data registry reporting semantic validation failure domain exception regarding order advisable group execute nonaggregaterelated validation first checking registry data example validation require transactional aggregate locking may transaction must aggregate transaction pas proceed validation require opening transaction aggregate example input data valid current aggregate state syntactic validation subphases divide syntactic validation several internal phase phase ordered simplest complex existence size lexical content syntax format existence validation ensures provided data exist empty processing make sense data empty subphase check null object empty string zerolength whitespace empty collection etc size validation verifies data reasonably big phase checking lengthsize input data matter data type size check prevent additional processing big data might cause performance issue also reporting size failure might helpful user perspective widespread mistake lexical content validation check data contain correct character encoding phase might helpful receiving data complex format like json xml html simpler data input like sizelimited string phase commonly executed part following stage syntax format validation verifies format correct string often achieved regular expression regex complicated might get better result specialized validator implementation reporting syntactic validation failure mean employed validation framework jsr jakarta bean validation implementation syntactic validation failure reported jakartavalidationconstraintviolationexception jsr implementing syntactic validation ordering groupsequence annotation demonstrated bookcargocommandrequest class cargotrackingbookingappcommandside module consequence positive consistency predictability validation handling processing negative none considered none reference manning secure design httpswwwmanningcombookssecurebydesign chapter validation domaindriven hexagon httpsgithubcomsairyssdomaindrivenhexagontypesofvalidation
pipeline couple client project infrastructure process gridlabd job goal would project could either include project service infrastructure incorporate directly flaskbased project kind job long running produce artifact project may store different way primarily create flask rest service coupled celery job processing organize database logic simplified cqrsinspired style code structure appmodelspy contain sql model appservicespy contain command modify database state appqueriespy contain query database structure presenceaccountservice project reference consequence initially manual validation parameter passed route implemented route realized needed improved validation verify url really url nested array structure correctly structured added marshmallow library enforce consistent validation work consequence oldersimpler route implemented early arent validated marshmallow arent consistent refactored time marshmallow error message verbose since auth project initial template copied deliberately empty api deliberately targeted application development api informative model route ultimately formed two big domain pipeline workflow route model single file unwieldy general structure refactored submodule pipeline workflow apppipelinesmodelspy apppipelinesroutespy apppipelinesservicespy apppipelinesqueriespy
json schema spec graphql recommends testing behaviour graphql api client perspective test data returned graphql query conforms type definition system explored individual expectation example validating key response ruby expectresponseto includeid expectresponseto includecommonname expectresponseto includestops factorybot potentially could achieved factorybot however validating dynamic graphql query may possible example wanted test graphql query return one key type test query return multiple key testing graphql response primarily interesting shape structure data really content jsonschema jsonschema provides declarative domain specific language define validate schema json object furthermore allows define json schema test conformity tflgraphql json schema validation test response graphql query implement custom rspec matcher based article thoughtbot match given object schema defined specschemas consequence pro dynammically test schema conform graphql type definition rspec expectation schema validation short one liner matchesresponseschemaschemapath matcher valid json schema could reused purpose con extra work needed define json schema expect graphql query longer term could explore automatically generating schema perhaps consuming openapi spec
adr subject viewer config created june workflow determines subject viewer workflowconfigurationsubjectviewer property subject viewer include singleimage lightcurve multiframe subjectgroup creation adr subject viewer utilize require additional configuration information multiframe workflow multiframe subject viewer might preference regarding mark per frame might prefer mark filtered per frame like transcription workflow frame represents unique page transcribe mark relevant page workflow might prefer mark persist frame like space warp power people however reviewing project enabled mark persist frame multiimageclonemarkers pfe appears pfe setting unclear related workflow include drawing task subject multiple frame positioning might prefer pan zoom rotation reset per frame like transcription workflow frame represents unique page transcribe workflow might prefer pan zoom rotation maintained frame like wildcam gorongosa backyard world flipbook mode separate frame subjectgroup workflow subjectgroup subject viewer might want define subject cell width height style subject viewer grid column grid row subject viewer configuration object stored workflowconfigurationsubjectviewerconfig structured follows subject viewer noted multiframe javascript filtermarksperframe boolean replaces multiimageclonemarkers pfe positioning enumerable includes pan zoom rotation enumerable maintain reset subjectgroup javascript cellwidth number pixel cellheight number pixel cellstyle property property value gridcolumns number gridrows number subject viewer define configuration object related subject viewer readme applicable scatterplotviewer barchartviewer accept configuration object directly json structure subject data support variability display setting including plot label since possible might vary per subject subjectviewerconfig object configuration apply subject linked workflow proposed consequence workflow selects subject viewer related subjectviewerconfig defined applicable subject viewer utilize subjectviewerconfig define default fallback
deal authentication user able register login retrieve lost password testing flasklogin limited went flasksecurity relies complete glue across flask extension consequence strong dependency respect convention limitation especially orm side plus configure email sending server
expect automating tui interaction dec draft summary publishing automatically npm want interact lerna dont want require human interaction decided expect automatically interact textbased user interface lerna terminal tool requires interaction via tui textbased user interface publishing package part effort automate task way interact tui automatically without human intervention different tuis different complexity require entering text others interactive menu controlled arrow key case lerna decided expect tool designed purpose mind lightweight dependency pro con shell script shell scripting powerful dangerous solution good doesnt dependency bad hard write robust script bad complicated interact output tui automate expect expect tool automating interactive application telnet ftp passwd fsck rlogin tip etc good built purpose mind good syntax readable straightforward bad learn new language tclexpect node script htmlintegrations repository already contains node script similar automation task wouldnt place javascript well good already familiar language good powerful bad wellsuited interacting terminal consequence expect requires simple aptget install come many command utility dealing terminal tuis general implementation script interacts lerna already designed pretty readable maintainable link expect
avoid offensive vocabulary initiative questioning technical vocabulary avoiding word widely may offend people project adheres initiative therefore remove existing technical vocabulary might offensive prevent term added future instance masterslave replaced mainreplica similar whitelistblacklist safelistblocklist similar consequence supporting cause like black life matter let people know voice heard friendly place contributor around world
cache meal catalogue proposed user satisfaction speed application priority case slowunstable connection wed like smallest delay possible catalog browsing user expect quick response time safely assume menu catalog wont drastic change day cache catalog estimated number meal fridge user area probably whole menu formed week provided ordering system based assumption could upload meal catalog per day amount available stock keeping unit sku fridge estimation update package size show catalog meal could weigh around kbkb without image even might significant amount data single entry multiplying number user give large amount data transfer isnt free user catalog update meal amount might organized additional event message lightweight compare entire catalog save money cost ownership upload information upfront purchase process payment confirmation always take time user get attempt actualize certain position menu cache menu catalog actual check purchase confirmation moment connection required going upload keep entire meal catalog user device consequence user experience longer delay purchase confirmation step perspective app would logic related storing data scheduled data update process simple nature require excessive design meal catalog might require additional finegrained api support checking available stock particular meal user area geolocation service involved anyway wont affect overall flow size application grow user device kitchen provide catalog also increase code base add logic clientside side easier operate local catalog upload client device meal might access code generation dont want compromise system risk catalog might stale term available meal going check possibility purchase backend anyway
adr wsgi server running flask wsgi application builtin flask server meant production problem mainly due potential debug shell server single thread default configuration mitigated setup decided test proper wsgi server point especially log entry text serving flask app connaisseurflaskserver lazy loading environment production warning development server production deployment production wsgi server instead cause anguish among user see issue considered choice wsgi server there plenty wsgi server around question pose one pick flask list server there comparison around example choice wsgi server test somewhat arbitrary among better performing one post contender bjoern cheroot flask gunicorn uwsgi bjoern immediately dropped since worked python later testing bjoern support python stuck dropping gunicorn tested bit since delivered worse result others requires writable workertmpdir directory also dropped contention remaining three tested rather long time development first bit validation parallelization release test run local minikubekind cluster rather constrained resource expectation still provide reasonable insight server behavior regular production cluster test result since result span longer timeframe least first performed find way distinguish server instead clear plan test feature different configuration specified different cheroot run default configuration minimum number thread maximum limit flask default configuration uwsgi process thread low already bigger footprint idle begin connaisseur configured default pod integration test parallelization paralellization ever implemented test running integration test cluster seeing often test failed error rate across execution cheroot flask uwsgi error rate could high nonparallelized fetching notary trust data regularly took around second maximum timeout second simple parallelization parallelization fetching base trust data added test rerun time check server run together randomized order server test run error rate cheroot uwsgi flask tested stress test complex request test setup complex individual request containing multiple different initcontainers container many instantiation particular image test performed kubectl apply loadtestyaml file loadtestyaml apiversion appsv kind deployment metadata name rediswithmanyinstances label app redis loadtest loadtest spec selector matchlabels app redis replica template metadata label app redis spec container name redis image redis apiversion kind pod metadata name podwithmanycontainers label loadtest loadtest spec container name container image busybox command sleep name container image redis name container image node name container image nginx name container image rabbitmq name container image elasticsearch name container image sonarqube apiversion kind pod metadata name podwithmanycontainersandinitcontainers label loadtest loadtest spec container name container image busybox command sleep name container image redis name container image node name container image nginx name container image rabbitmq name container image elasticsearch name container image sonarqube initcontainers name init image maven name init image vault name init image postgres apiversion kind pod metadata name podwithsomecontainersandinitcontainers label loadtest loadtest spec container name container image busybox command sleep name container image redis name container image node name container image nginx initcontainers name container image rabbitmq name container image elasticsearch name container image sonarqube apiversion kind pod metadata name podwithcoincidingcontainersandinitcontainers label loadtest loadtest spec container name container image busybox command sleep name container image redis name container image node initcontainers name init image busybox command sleep name init image redis name init image node none server regularly managed pas particular loadtest however pod powered flask server regularly died restarted whereas cheroot uwsgi nearly restarts never instance uwsgi seldomly even managed pas test complex request load since complex request bottleneck tried instance test complexity individual request request instead however led real distinguishing behaviour across server load test check server behaviour hit lot easy request time also implemented actual load test ran parallel job testnsh seq parallel job testnsh seq file file content testnsh tmpfmktemp filecnrnr envsubst tmpf kubectl apply tmpf loadtestyaml apiversion appsv kind deployment metadata name redisnr label app redis loadtest loadtest spec selector matchlabels app redis replica template metadata label app redis spec container name redis image redis afterwards checked many pod actually created server created pod parallel job created pod parallel job cheroot cheroot numthreads flask uwsgi uwsgi process thread uwsgi process thread uwsgi process thread interestingly flask narrowly performs best test strong load massive load cheroot uwsgi adding parallelization doesnt necessarily help stability even intuitively job parallel low creation rate due pod dying point barrage resource consumption measured via kubectl top pod connaisseur loadtest shown representative sample across multiple invocation job since job often pod died metric api slow give accurate information restart cheroot name cpucores memorybytes connaisseurdeploymentdtfjp connaisseurdeploymentdkfzdq connaisseurdeploymentdtlp flask name cpucores memorybytes connaisseurdeploymentdtc connaisseurdeploymentdthgzd connaisseurdeploymentdwcprp uwsgi process thread name cpucores memorybytes connaisseurdeploymentdfbfcdcm connaisseurdeploymentdfbfcdhvsp connaisseurdeploymentdfbfcdwdz flask staying flask server obviously doesnt resolve problem good service there known problem usage practice however author discourage running publicly rather development builtin development server flask run development server provided werkzeug convenience designed particularly efficient stable secure source performs worst far complex request cheroot cheroot performs better flask complex request better uwsgi strong load however massive load even increasing minimum number thread doesnt really add lot stability addition seems known among server flask project list hand memory footprint better uwsgis almost par flask whereas cpu footprint par uwsgi slightly better one flask uwsgi uwsgi narrowly best showing complex request performs worst strong load however trying deal massive load scaling resource allows uwsgi significantly outperform massive load memory footprint higher cheroot flask cpu footprint par cheroot slightly better flask chose forward cheroot wsgi server based server performing best relevant part stress load test
