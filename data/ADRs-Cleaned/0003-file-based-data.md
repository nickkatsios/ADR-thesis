file metric data rejected adr backfilled historical purpose problem statement glam data consists mainly histogram percentile count set dimension stored file whose path name represent dimension whose content contain actual data driver data efficient look read frontend data efficient write etl data cost efficient write maintain considered move aggregation data output etl postgresql database move aggregation data another file format usable glam frontend outcome moving data postgresql chosen outlined proscons summarize update file new aggregation data produced set dimension cause file based approach complex something database created solve sql approach insert conflict update accomplishes well pro con file based aggregate storage idea would write json file based path file live cloud storage interim database required example implementation sqlite intermediate table make grouping dimension simpler python generate sqlite table glam csv something like cat glamfilexxxcsvgz gunzip sqlite csv separator glamdb import devstdin glam script run much faster create index table create index metricsindex glammetric channel process import json import import sqlite sqliteconnection sqliteconnectglamdb cursor sqliteconnectioncursor cursor sqliteconnectioncursor metric channel process operatingsystem cursorexecuteselect distinct metric channel process glam outdir ospathjoindata metric channel process operatingsystem osmakedirsoutdir existoktrue aggregate cursorexecute select appbuildid aggregate glam metric channel process metric channel process operatingsystem fetchall openospathjoinoutdir datajson wwritejsondumpsaggregates proscons pro could simpler local dev set pro could improve slow import time due materialized view pro could make adding new product glam bit simpler create new django model con since data outside range etl kept cant simple write operation fresh data added updated keeping older data resulting data written complicates file based architecture database aggregate storage approach would write data unindexed postgresql table maintain speed import refresh materialized view data index make querying data api fast pro already written pro handle data updating case easily since database con import slow due size data materialized view