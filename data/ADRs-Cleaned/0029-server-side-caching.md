server side caching user story easi certain type call easi make considered expensive usually take form something like party api call cedar core example database call caching often good way effectively reduce number time expensive call made cost data considered alternative application memory caching caching database caching redis outcome chosen alternative application memory caching redis caching later right likely dont engineering staff implement infrastructure redis instance would require since implementing inmemory cache relatively simple task especially compared massive benefit get seems worthwhile implement come back replace redis later time additionally main con inapplication memory caching shared across multiple task huge deal time since typically running task time due workload relatively low open question way avoid minimize amount time user feel load time expensive call potential periodically seed cache rather populating request made data upside always user hit cache directly downside wed write scheduled code periodically seed cache lambda cache never expire always return data cache instead refreshing cache returning data frontend refresh cache return data upside also always returning cache fast major downside potentially data cache old pro con alternative application memory caching easy implement see poc branch example implement requires change infrastructure likely lowest response time available easily temporarily introduced later replaced another solution cache shared across multiple server exists per task caching database requires change infrastructure persistent across multiple server caching logic would manually written column track timestamp cleaning old data etc going slowest term response time doesnt solve caching query caching redis fast response time submillisecond solves caching lot different api query query etc redis purposebuilt solve caching support lot different box requires introducing new infrastructure