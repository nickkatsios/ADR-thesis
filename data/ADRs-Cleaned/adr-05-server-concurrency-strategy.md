server concurrency strategy cpu intensive work main event thread hurting performance causing healthchecks fail node singlethreaded default cpu intensive work main thread block responding request exploratory branch cbac initial work moving topojson merge operation main thread likely well also want move import export well still unacceptably slow large region due deserialize topojson data merge operation nodejs memory model prevents directly sharing topojson object asis thread process part node actor model message passing copy data directly sharing memory node two exception arraybuffer transferred thread instead copied sharedarraybuffer multiple thread store typed numeric array generic object considered improve deserialization ondemand performance threading strategy pursued cbac involved keeping binary serialized data sharedarraybuffer deserializing worker request benchmarking largest region current vdeserialize method showed deserializing lrc region two largest took second average attempted swap protobuf geobuf version last version support topojson saw significant difference performance however note significant size reduction seriously consider switching protobuffer part also tried mmapobject caused performance decline relative serialization fork topojson library merge algorithm store data sharedarraybuffer basic work towards think would radically rework topojson merge operation work format stored worthwhile experiment involved swapping arc array topology ndarray backed sharedarraybuffer worse performancewise deserialize route including attempt arc array feature guess transferring hundred thousand sharedarraybuffer object still pretty slow way really push would radical restructuring entire way access geometrycollection store data structofarrays would limit number sharedarraybuffer fixed amount determined number field rewrite cpu intensive task think viable nodejs good binding subject constraint nodejs memorymodel could easily share readonly topology data thread downside significant though wed rewrite topojson mergearcs method also business logic topojson data district merge operation project import export significant amount code rewrite working test harness dont many test wed write much significant test suite tested current codebase feel confident rewrite implemented correctly also dont real expertise team would either offteam resource build maintain part codebase expect significant amount training learning required beforehand cache data load worker thread approach keep buffer data available main thread deserialize needed like first approach also add lru cache worker thread allows skip deserialization performance penalty first request setting maxsize parameter lru cache ensures dont exceed memory limit system made test branch dfa showed acceptable speed believe room potential improvement data caching route request worker thread already data loaded another worker busy allowing degree concurrency main downside bit duplicative data serialized deserialized format data potentially duplicated thread data keep around could increase memory requirement also largest datasets mostly static instead constantly serializing deserializing change data cached worker thread potential change runtime behavior application unexpected way becomes much attractive reduce time spent loading loading buffer see second could also load buffer worker thread caching deserialized data case memory requirement keeping deserialized file around memory main thread load data worker thread variation keeping data cached worker thread instead loading binary data main thread would instead load data directly worker thread thread loading subset state conceptually simpler caching approach ensuring memory footprint large datasets stay static predictable avoids potential cachehit causing request slower limit concurrency potential one thread capable handling given region concurrent request user would block well caching approach outlined four relatively quick implement allow degree concurrent data processing state evaluate improving file loading performance consider whether skip initialization step load cache binary data regardless well still lru cache worker thread switching pbf format part would prudent keep precaching seemed reduce binary size would require maintaining protobuffer binding topojson could fork geobuf version last version supported topojson consequence well carefully monitor application performance making change likely affect steadystate memory usage consequently probably wait reduce instance size make change instead defer later release longterm approach might better bestpossible performance sticking entirely nodejs backend seems worthwhile term longterm maintenance support