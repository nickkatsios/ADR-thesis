cli dependency launching proposed alex black discussed sham multiple way user might want konduit serving serve model sake adr ill refer two case immediate deployment case deploy server pipeline right machine via cli deployment artifact case create artifact jar docker image etc deployment somewhere else adr packagingsystemdesignmd dealt create deployment artifact case however build system current form well serve immediate deployment case particularly well mainly due uberjar design cause usability problem deploying pipeline different module dlj samediff cpu gpu requires building uberjar uberjar build take long time second plus download time either always rebuild slow launch uberjar cache potentially lot unnecessary disk space old api cli dependencylaunching approach case also hadhas following problem requiring user build jar ahead time manually include module able launch example cpu gpu server simultaneously without rebuilding whole konduit serving uberjar launching different server clibased deploy right case alternative proposed immediate deployment via cli scenario create uberjar instead konduit serving build tool work dependency download return list dependency list jar file path konduit serving server launched similar ides like intellij work consider example command intellij launching unit test etc part omitted cprogram filesadoptopenjdkjdkhotspotbinjavaexe dfileencodingutf classpath cprogram filesjetbrainsintellij idea community edition libideartjarcdljgitkonduitservingkonduitservingmodelskonduitservingdeeplearningjtargettestclassescusersalexmrepositoryorgndjndjapisnapshotndjapisnapshotjarcusersalexmrepositorycomjakewhartonbyteunitsbyteunitsbyteunitsjarcusersalexmrepositorycomgoogleflatbuffersflatbuffersjavaflatbuffersjavajarcusersalexmrepositoryorgndjprotobufsnapshotprotobufsnapshotjarcusersalexmrepositorycommonsnetcommonsnetcommonsnetjar comintellijrtjunitjunitstarter ideversion junit aikonduitservingdeeplearningjtestdljstep note classpath list jar path component practice wont pas list jar file path directly due constraint maximum command line length window instead small jar containing manifest file list absolute path dependency httpswwwbaeldungcomjavajarmanifest single manifest jar passed via classpath path arg launch note exact manifest jar approach also intellij command line shortening work around maximum command line length problem key aspect design static cli jar cli jar static jar without modulesdependencies needed run pipeline step never get modified rebuilt etc matter type pipeline launched konduit serving build tool downloads resolve dependency user launch server based konduit serving pipeline configuration following occurs cli call build tool build tool resolve dependency included run pipeline direct transitive dependency downloaded normal via gradle stored usual location build tool creates required manifest jar introduce concept device profile cli practice allow user switch different target launching cpu cuda instead xavx needed reason specifically first run konduit serving cli automatically create set appropriate device profile based hardware software available system also set default device profile cuda profile present practice usually cpu profile highest level supported avx avx etc cuda profile cuda device present system cuda profile well also detect cuda installed well javacpp presets cuda redist binary provide runtime avoiding manual install running well default profile unless user pass profilename launch konduit serve configjson cpu practice user wont worry device profile unless run cpu gpuenabled device rarely ever downgrade target example instead xavx avx compatible system workaround issue avx higher binary example workflow launch locally suppose user want deploy server inference system without konduit serving installation here could look like text pip install konduitserving easy installation method apt yum etc etc konduit serve configjson konduit serving konduit serving first run initialization detecting hardware done cpu arm aarch core cuda gpu cuda installation found cuda usrlocalcuda creating device profile profile cuda arm cuda installed profile cpu arm cpu execution creating device profile complete setting default profile cuda set default profile pas launching override first run initialization complete launching server default device profile cuda acquiring dependency done note user line brand new system install hosting model server optimal hardwareconfiguration device cuda highest supported avx level system etc furthermore slow build uberjar step delay launching server second top dependency downloading launching deployment artifact case manifest jar approach likely situation docker could either uberjar switching assemblyjar style embed originalunmodified dependency jar instead uberjar rpm deb per docker standalone exe continue uberjar approach decide assemblyjar style approach useful deployment artifact implement later also principle add extra dependency top uberjar may especially elegant design combining uberjars extra classpath dependency may possible ever really however wont something support detecting hardware creating profile detecting cpu detail straightforward least xbased system library oshi httpsgithubcomoshioshi well oshi support armbased platform something explore though raspberry armhf support seem available httpsgithubcomoshioshiissues falling back system utility cat proccpuinfo similar also possibility detecting presence absence compatible cuda gpu may harder cuda installed available path becomes easier cuda install assume cuda device present parse output nvidiasmi cuda installed cuda gpu available case oshi may show may command line based approach find like cpuinfo principle solveable problem additional work required find robust solution detecting hardware including cuda gpus maybe gpus future work across device operating system expect deploy practice consequence advantage command konduit serving server launched faster build uberjar build disk space uberjars redundant copy dependency easily allows mixing cpu gpu deployment one system distribute prebuilt binary variant idea adaptable osgi ifwhen disadvantage relying jar gradlemaven cache rarely might cause problem user try install similar command server running relies build tool hence gradle maybe problem offlineno network space restricted deployment scenario network deployment probably bundle gradle gradlew gradle offline however still uberjar style deployment instead clistyle deployment scenario