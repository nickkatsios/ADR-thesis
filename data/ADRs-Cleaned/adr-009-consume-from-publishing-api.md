adr consume content item publishing api created etl pipeline originally publishing api message flag item updated would fetch item content store overnight grow item dimension every time update instead limiting one record per day rely two source truth data publishing api content store make request content store content store intended support frontend architecture etlanalytics addressing want change data warehouse store individual part guide travel advice difficult implement due complexity message processing publishing api message extract content rather issuing additional request content store data flow refactoring publishing api message hander first transforms message contentitem class store information input present content item calculate hash content neccessary calculate quality metric content decided processing synchronously time pipeline predictable easy debug growing item dimension subscribe kind update publishing api major minor link republish unpublish new item record created weve never seen content item content hash change link change link appear different order still considered otherwise dont insert new record creating new item promote setting latestfalse existing latest item content setting latesttrue new item impact multipart item multipart item transform single message multiple item unique base path shared content base path partitem basepath attribute publishing api content item plus slug part detail hash grow dimension mark part contentid latestfalse create new item record part item new message benefit implement multipart document easily data warehouse doesnt depend frontend infrastructure