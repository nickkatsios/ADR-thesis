applicative read repair poc mailbox mailboxcounters adopted lazy consensus implemented completes cassandra mailbox object consistency cassandra mailbox counter inconsistency cassandra eventual consistency replication denormalization consistency handled applicative layer due lack transaction nosql database past set solve inconsistency task assimilated cassandra repair task scheduled ensure according entity denormalization correctly denormalized however inconsistency persist run experienced inconsistency production platform mailbox entity mailbox counter entity whose table structure exposed adrs monitoring required detect run time consuming platform administrator given large dataset could even impossible run task timely fashion another classic eventual consistency mechanism enables autohealing readrepair randomly piggy back upon read synchronous asynchronous consistency check missed repair performed order achieve denormalization autohealing thus implement applicative read repair provide proof concept applicative read repair mailbox mailboxcounters entity enables read path simplification performance enhancement mailbox object imap list read mailbox counter information uneeded avoid paying price read repair operation provide comprehensive documentation page regarding distributed james consistency model consequence expected autohealing inconsistency existing deployment limited configuration cost ease operation distributed james server configuration james distributed server added control read repair per entity cassandra provides secondary index avoids denormalization first place however efficient distributed environment node queried limit ability scale materialized view enables cassandra maintain projection behalf application coming expensive write cost requiring synchronisation fit complex denormalization like message one primary key originating table appear materialized view primary key update performed asynchronously mechanism considered experimental cassandra batch suffers following downside batch containing conditional update operate within single partition unadvised update many partition single batch keep cardinality low performance reason batch could good keep table synchronized apply mailbox conditional update counter already propose several task solve denormalization inconsistency applicative read repair seen complement another classical mechanism eventual consistent system called hintedhandoff consists retries given period replicating data replica also already similar mechanism james retry several time failure writing data denormalization table hard shutdown however defeat strategy otherwise efficient limit inconsistency across denormalization table reference read repair cassandra cassandra mailbox object consistency cassandra mailbox counter inconsistency hinted handoff link document materialized view limitation materialized view considered experimental cql batch especially materialized view limitation update view happen asynchronously unless corresponding view replica node must ensure availability compromised easy imagine worst case scenario materialized view update base table requires writing separate node normal operation view see data quickly new metric track viewwritemetrics read repair view base table meaning read repair view correct view data base table data reading base table though read repair send update base view mutation base table partition must happen sequentially per replica mutation touch column view improve ticket cassandra jira discussing adr