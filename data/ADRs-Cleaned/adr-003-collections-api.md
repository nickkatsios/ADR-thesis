switching collection api motivation currently geoprocessing service run apache spark container spark jobserver http interface layer reading done rdd help parallelize heavy operation counting number cell large raster however since geoprocessing service run single machine take advantage parallelism resulting significant overhead little payout benefit geotrellis add collection api layer reading return scala sequence rather rdd mmw case better fit since geoprocessing operation counting cell averaging value faster single machine collection api remove spark overhead case lead performance improvement table performance improvement nlcd soil request huc huc huc taken develop current service staging current service prototype service collection api nlcdsoilshuc develop staging collectionsapi nlcdsoilshuc develop staging collectionsapi nlcdsoilshuc develop staging collectionsapi average develop staging collectionsapi nlcdsoilshuc nlcdsoilshuc nlcdsoilshuc here chart table difference develop staging two factor staging worker powerful much faster access tile advantage carry collection api variant well thus making even faster deployed addition make code simpler understand maintain well make provisioning deployment simpler removing spark spark jobserver since geoprocessing service packaged single jar also remove docker run directly openjdk improved speed may also allow increase area interest threshold frontend allowing user select even bigger area get faster result back challenge geotrellis compiled java whereas current mmw environment setup java make number update mmw environment support java since spark jobserver longer switch akka http exposing geoprocessing service also require update relevant geoprocessing task celery provisioning script also updated change geoprocessing service may result difference cell counted may lead different result input already seen extent mmwgeoprocessing difficult say correct current new implementation explain justify change collection api far never deployed production come risk unknown unknown may solve unforeseen technical challenge drawback removing spark jobserver lead interaction celery geoprocessing becoming synchronous rather asynchronous tolerable difference since new synchronous request time faster old asynchronous one celery task waiting second manageable celery task timeout sensible period collection api support far fewer mapalgebra operation rdd api okay counting cell averaging value however require mapalgebra operation future may add back rdd api approach make set case cover functionality current geoprocessing service make new project within geoprocessing repo add akka http service add endpoint take json input current service perform operation collection api instead fine tune result match previous one explain justify different update geoprocessing service deployment push jar github instead docker image quay update mmw provisioning remove spark jobserver docker dependency add openjdk pull geoprocessing jar github update geoprocessing celery task new service test ensure value still similar sensible update area interest threshold allow larger size better new capacity experimental branch part covered make card rest branch cleaned including api design build pipeline also implement counting ability handle vector stream average value added client currently evaluating alternative performance enhancement may involve preprocessing lot information storing database making runtime geoprocessing matter pulling information database assembling could much faster little precise case route spending time optimizing geoprocessing wouldnt help much service wouldnt much however current model continues approach outlined applied improve geoprocessing performance order magnitude