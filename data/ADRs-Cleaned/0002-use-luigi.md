luigi build workflow extracttransformload task currently project contains single step single pipeline extract application error rate idea single metric report automate process end end proof concept scaled metric well way joining individual task note already lot existing job move data around implemented different way example script bundled application httpsgithubcomalphagovcontentperformancemanager script packaged single thing httpsgithubcomalphagovsearchanalytics data pipeline autotagging content taxonomy httpsgithubcomalphagovgovuktaxonomysupervisedlearning monitored combination jenkins icinga time new data task created write puppet code set luigi declare dependency data processing task govuk starting task repository luigi lightweight framework sequencing arbitrary task task anything defined dependency output luigi task doesnt run pure python script set run sparkhadoop job docker container etc luigi already verifys data pipeline think reasonable starting point normal way run luigi scheduler web let visualise monitor task dependency dont set straight away think would useful project grows local scheduler mode work fine luigi come contrib module interacting many data store govuk bigquery postgres mongodb elasticsearch could help minimise amount code write shift data building new task adhere guideline custom extracttransformload code decoupled luigi task testable independently task validates input asserts thing output task persists output somewhere cant modified variable assumption documented glossary output follow consistent naming convention consequence easy add additional pipeline pipeline step later without making code hard navigate youre familiar pattern able quickly debug pipeline make change easy remove luigi dependency doesnt meet pipeline step reusable task make assumption whats already run output intermediate output reused task pipeline work batch processing stream processing see also luigi design limitation