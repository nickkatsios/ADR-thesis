adr ensuring cluster stability replacing node sres sometimes change various thing cluster worker node therefore replace node ami eks update instance type anything else launch template way instance role addition terraform get latest ami eks version aws mean soon aws release new ami current eks version next time cluster deployer step run terraform also replace node cloudformation updatepolicy worker node autoscalinggroups tell replace node time asg would fine didnt asgs small number node right practice terminates many instance result cluster becoming unstable turn cause outage application running cluster without policy wed able update launch template asg wouldnt remove existing node set new future node correctly reason small asgs cluster autoscaler scale node independently know pod attempting failing schedule tied persistent volume claim particular availability zone scale asg zone possible action action may want consider expected well choose subsetvariation action make cloudformation updatepolicy wait new node healthy scaling specify waitonresourcesignals minsuccessfulinstancespercent pausetime cloudformation updatepolicy mutually exclusive action likely also requires action safe aws doc say waitonresourcesignals parameter specifies whether auto scaling group wait signal new instance update property ensure instance completed installing configuring application auto scaling group update proceeds aws cloudformation suspends update auto scaling group new instance launched group aws cloudformation must receive signal new instance within specified pausetime continuing update signal auto scaling group cfnsignal helper script signalresource api sometimes new worker node dont appear ready kubernetes previous worker node theyre replacing terminated allow resolve ensure every instance terminated launch template change replacement already inplace could one approach worker node start could schedule job selecting run call signalresource could daemonset call signalresource sleep infinitely note signalresource caller instance well cloudformation stack created asg come pro aws mostly take care process wed code call signalresource cluster encounter health issue new instance ready accept new pod existing instance get terminated con concourse job would probably time process happens probably adjustlive action custom process rolling node instead cloudformation updatepolicy remove cloudformation updatepolicy find update policy ensures cluster eventually fully roll expected launch template mutually exclusive action action manually roll node manual cordoning draining termination node pro total control step process con would make rather irritating toil engineer would manually run process might possible make mistake cordondrain many node without termination therefore replacement requires admin privilege wed like avoid routine maintenance task action script rolling node triggered manually script run cordon drain terminates node triggered manually pro would able choose exactly replace node optimise low load critical operation ongoing staff availability event problem etc con wed notice new launch template trigger manually action regularly terminate node script run regularly terminates node would ensure cluster eventually updated immediately pro added benefit regularly killing node regardless launch template change meaning node dont stick around long con cronjob inside cluster might terminate running leave inconsistent cluster lambda maybe written kill one node wait next run kill another might also okay would immediately replace node rollout would slow new launch template broken cluster would slowly break terminating remaining healthy node action node operator write operator manages taking control desired instance count asg asgs worker node work replaces cluster autoscaler mutually exclusive action pro would able manage node replacement new launch template scale load time con code write maintain potentially reinventing wheel replace cluster autoscaler action auto scaling lifecycle hook lifecycle hook asg tell cordon drain node etc terminates doc auto scaling lifecycle hook enable perform custom action pausing instance auto scaling group launch terminates instance paused remains wait state either complete lifecycle action completelifecycleaction cli command completelifecycleaction api action timeout period end one hour default essentially node started register hook asg launch node wait node healthy cluster terminates node wait weve cordoned drained pro might benefit want spot instance future wed confident quickly cordon drain node event notification saying current worker node terminated shortly work kind autoscaling event cloudformation updatepolicy work lifecycle hook place con none action avoid interference cluster autoscaler scale autoscaler running replace node mutually exclusive action would likely done every time terraform apply run thats run dont know node replaced check permit cluster creation avoid breaking cluster autoscaler deployment exist pseudocode would look like ekscluster exists clusterautoscaler deployment exists scale autoscaler deployment replica terraform apply clusterautoscaler deployment exists scale autoscaler deployment replica pro awss recommended approach con introduces risk burst pod wanting schedule replacing node action lifecycle hook therefore action node rolling process mean asg know wait node ready cluster launching wait node drained terminating also mean choose method node rolling relative freedom keep existing cloudformation updatepolicy actual mechanism rolling node action turn autoscaler rolling node probably script run run terraform scale autoscaler afterwards scale autoscaler back consequence node replacement much safer node replacement likely slower old instance drain properly rather suddenly disappearing cluster scale response unschedulable pod node replacement operation progress could cause problem deployment lot new pod occurs time