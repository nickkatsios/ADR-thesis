record dropping kafka first started model register two separate apps mint presentation explored kafka mean storing appendonly datastore streaming mint presentation database kafka initially chosen appendonly journal model seemed good fit way model register appendonly list entry kafka also offer ability replay journal start allows create new way presenting data retrofit existing datasets however kafka found certain pain point kafka offered service computing platform targeting amazon heroku kafka zookeeper dependency increase operational complexity kafka zookeeper consume lot memory requiring deploy larger machine costing one kafka main selling point sheer throughput performance isnt really kafka new technology team understand well older technology particular good understanding failure mode last point key kafka new technology confidence rely primary data source ended running postgres primary source truth wellunderstood technology confidence back replicate mitigate risk data loss kafka mean communicating mint presentation running postgres kafka store data seemed wasteful ended needing administer postgres kafka operational complexity considered choosing one technology play role mint primary data store communicating stream entry mint presentation therefore thought would mean choose either postgres alone kafka alone kafka primary data store downside already mentioned lack confidence primary data store also understand failure mode well particular message sent kafka connection time successful safely retry get duplicate furthermore key part domain model incrementing serial number identify entry register kafka messagelevel serial number instead index stream byte want assign serial number entry entered register sort coordination mechanism ensure add serial number strictly serial order postgres kafka together postgres provided coordination mechanism removed postgres wed add something else meet presentation side equation also discovered separate process consuming register stream inserting presentation database original design presentation app consume kafka stream directly however didnt fit well presentation stateless appserver could horizontally scaled app instance would independently try consume kafka stream one would actually successful also looked amazon kinesis similar kafka however discard message hour fit postgres alone mint primary data store also mean communicating mint presentation app remove kafka zookeeper architecture postgres tool assigns serial number serial column type order replicate data mint presentation database indexer app created consequence remove kafka zookeeper system administrative effort associated indexer first directly consuming mint primary data store security performance concern indexer always configured consume postgres read replica instead architecture depend heavily heterogeneous apps integrating common database firstly indexer consuming mint primary postgres data store secondly indexer injecting data presentation indexed data store quite bit written problem integration database keep problem mind said reasonably confident schema wont change mint simple serial number json entry schema change presentation create new indexer presentation instance indexer replay entire stream start migrate user new presentation turn original service