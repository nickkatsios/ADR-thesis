adr wsgi server running flask wsgi application builtin flask server meant production problem mainly due potential debug shell server single thread default configuration mitigated setup decided test proper wsgi server point especially log entry text serving flask app connaisseurflaskserver lazy loading environment production warning development server production deployment production wsgi server instead cause anguish among user see issue considered choice wsgi server there plenty wsgi server around question pose one pick flask list server there comparison around example choice wsgi server test somewhat arbitrary among better performing one post contender bjoern cheroot flask gunicorn uwsgi bjoern immediately dropped since worked python later testing bjoern support python stuck dropping gunicorn tested bit since delivered worse result others requires writable workertmpdir directory also dropped contention remaining three tested rather long time development first bit validation parallelization release test run local minikubekind cluster rather constrained resource expectation still provide reasonable insight server behavior regular production cluster test result since result span longer timeframe least first performed find way distinguish server instead clear plan test feature different configuration specified different cheroot run default configuration minimum number thread maximum limit flask default configuration uwsgi process thread low already bigger footprint idle begin connaisseur configured default pod integration test parallelization paralellization ever implemented test running integration test cluster seeing often test failed error rate across execution cheroot flask uwsgi error rate could high nonparallelized fetching notary trust data regularly took around second maximum timeout second simple parallelization parallelization fetching base trust data added test rerun time check server run together randomized order server test run error rate cheroot uwsgi flask tested stress test complex request test setup complex individual request containing multiple different initcontainers container many instantiation particular image test performed kubectl apply loadtestyaml file loadtestyaml apiversion appsv kind deployment metadata name rediswithmanyinstances label app redis loadtest loadtest spec selector matchlabels app redis replica template metadata label app redis spec container name redis image redis apiversion kind pod metadata name podwithmanycontainers label loadtest loadtest spec container name container image busybox command sleep name container image redis name container image node name container image nginx name container image rabbitmq name container image elasticsearch name container image sonarqube apiversion kind pod metadata name podwithmanycontainersandinitcontainers label loadtest loadtest spec container name container image busybox command sleep name container image redis name container image node name container image nginx name container image rabbitmq name container image elasticsearch name container image sonarqube initcontainers name init image maven name init image vault name init image postgres apiversion kind pod metadata name podwithsomecontainersandinitcontainers label loadtest loadtest spec container name container image busybox command sleep name container image redis name container image node name container image nginx initcontainers name container image rabbitmq name container image elasticsearch name container image sonarqube apiversion kind pod metadata name podwithcoincidingcontainersandinitcontainers label loadtest loadtest spec container name container image busybox command sleep name container image redis name container image node initcontainers name init image busybox command sleep name init image redis name init image node none server regularly managed pas particular loadtest however pod powered flask server regularly died restarted whereas cheroot uwsgi nearly restarts never instance uwsgi seldomly even managed pas test complex request load since complex request bottleneck tried instance test complexity individual request request instead however led real distinguishing behaviour across server load test check server behaviour hit lot easy request time also implemented actual load test ran parallel job testnsh seq parallel job testnsh seq file file content testnsh tmpfmktemp filecnrnr envsubst tmpf kubectl apply tmpf loadtestyaml apiversion appsv kind deployment metadata name redisnr label app redis loadtest loadtest spec selector matchlabels app redis replica template metadata label app redis spec container name redis image redis afterwards checked many pod actually created server created pod parallel job created pod parallel job cheroot cheroot numthreads flask uwsgi uwsgi process thread uwsgi process thread uwsgi process thread interestingly flask narrowly performs best test strong load massive load cheroot uwsgi adding parallelization doesnt necessarily help stability even intuitively job parallel low creation rate due pod dying point barrage resource consumption measured via kubectl top pod connaisseur loadtest shown representative sample across multiple invocation job since job often pod died metric api slow give accurate information restart cheroot name cpucores memorybytes connaisseurdeploymentdtfjp connaisseurdeploymentdkfzdq connaisseurdeploymentdtlp flask name cpucores memorybytes connaisseurdeploymentdtc connaisseurdeploymentdthgzd connaisseurdeploymentdwcprp uwsgi process thread name cpucores memorybytes connaisseurdeploymentdfbfcdcm connaisseurdeploymentdfbfcdhvsp connaisseurdeploymentdfbfcdwdz flask staying flask server obviously doesnt resolve problem good service there known problem usage practice however author discourage running publicly rather development builtin development server flask run development server provided werkzeug convenience designed particularly efficient stable secure source performs worst far complex request cheroot cheroot performs better flask complex request better uwsgi strong load however massive load even increasing minimum number thread doesnt really add lot stability addition seems known among server flask project list hand memory footprint better uwsgis almost par flask whereas cpu footprint par uwsgi slightly better one flask uwsgi uwsgi narrowly best showing complex request performs worst strong load however trying deal massive load scaling resource allows uwsgi significantly outperform massive load memory footprint higher cheroot flask cpu footprint par cheroot slightly better flask chose forward cheroot wsgi server based server performing best relevant part stress load test