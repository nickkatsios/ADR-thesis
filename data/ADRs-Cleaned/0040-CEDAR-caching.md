cedar caching user story easi easi heavily relies cedar core data systemcentric system profile view however cedar api response range hundred millisecond multiple second causing considerable wait time easi application cedar relies lownocode solution limited caching create caching solution end expedite call cedar data number solution listed considered main factor revolve around maintainability solution tenable foreseeable future scale solution handle increased traffic easi andor increased amount cached data development velocity solution allow team iterate quickly considered alternative inmemory caching already present within easi server app ask cedar cache endpoint proxy server cache request nginx optimized external keyvalue store store data lieu making request rediselasticache outcome decided move forward implementing nginx proxy server application cedar since caching nginx happens automatically choice requires last amount integration code achieving desired result addition since almost entirely external easi app either shift another approach integrate solution easily future pro con alternative inmemory caching already present within easi server app there additional architecture required one endpoint already cached way system summary would scale poorly cache inmemory essentially memory leak would make debugging production server difficult would analyze stack determine cache code causing problem ask cedar cache endpoint cedar easily cache endpoint end adjust cache time work required easi team except coordinating cedar cedar ability invalidate cache certain endpoint programmatically mean certain endpoint would likely remain uncached low cache time proxy server cache request nginx poc found easinginxcaching branch link proxy set get request cached automatically nginx performant requires least amount code written still providing cache invalidation capability solution purposebuilt caching cedar providing clear philosophy caching application separate easi making debugging management easier request invalidate number way sending purge method url path adding query parameter adding path parameter etc poc sends purge method accomplish cache invalidation opensource version nginx support caching natively community module must requires special dockerfile extend main nginx image note also explore varnish alternative nginx support cache purging natively unfortunately support meaning would separate layer handle http traffic light opted nginx optimized external keyvalue store store data lieu making request rediselasticache poc found easirediscaching branch link allows control store store store value cache query etc easily integrated aws current workflow official redis docker image redis performant requires writing code retrievestore every cached api call following additional consideration manage key delete multiple value key prefix allows storing value outside cedar response introduces possibility bandaid slow query caching data redis example expensive solution term operating cost