managed prometheus proposed proposal amazon managed service prometheus amp monitoring cloud platform instead selfmanaged instance prometheus monitoring metric good operational practice good observability includes monitoring achieved regular checking metric health number container running timeseries data collected shown graph indicator dashboard evaluated rule trigger alert operator typical operator include become familiar typical quantity resource consumed software alerted deteriorating health fix becomes incident alerted incident able react quickly user flag incident getting ataglance overview problem exist incident understand went wrong help review action taken response reviewing longterm pattern health choice prometheus prometheus cloud platform monitoring metric since established prometheus number year happy functionality prometheus remains popular choice industry open source large community recommended cncf commercial proprietary team investigated commercial monitoring solution datadog splunk honeycomb tend several related thing including metric monitoring dashboard alerting logging application performance monitoring dont offer functionality particular nice monitoring logging nicely integrated managed service would reduce operation architect future scaling concern offshoring log data circumstance personal data leak log cost varied suggestion even managed service wed still retain prometheus concern user config code whether easy deploy open source would cost migration user config would migrating existing prometheusalertmanagergrafana syntax overall happy stick prometheus prometheus prometheus setup monitor whole cloud platform including tenant container tenant aws resource kubernetes cluster kubeprometheus prometheus configured store worth data enough support case data also sent thanos efficiently store year metric data make available query promql syntax alertmanager prometheus data evaluating alert rule concern hosting prometheus currently prometheus container run smoothly recent month performance resolved serious performance issue alert rule taking long evaluate prometheus data however successfully alleviated increasing disk iop remaining concern custom node group single prometheus instance monitoring entire platform consumes lot resource weve put dedicated node full resource memory node mean custom node group bit extra management overhead scalability scaling vertical way ideal scaling smooth eventually well hit limit cpumemoryiops shard see also address management overhead managed cloud service generally preferred selfmanaged cost tends amortized large customer base far cheaper inhouse staff people ops skill premium management overhead prometheus kubeprometheus high availability single instance prometheus simply weve got round choosing implementing arrangement yet risk period outage dont collect metric data although impact case likely disruptive value fixing addressing concern thanos take load prometheus suggested could reduce load prometheus retaining say log shift much possible work thanos however since latest data want running query alert rule clear close realtime thanos kept thanos rule unreliable would likely reduce load prometheus may temporary might simply shift scalability concern onto thanos sharding could splitshard prometheus instance perhaps dividing two tenant platform multicluster could one prometheus instance per cluster appears relatively straightforward would concern however split scale future well hit future scaling threshold necessary change divide shard bit planning would needed high availability recommended approach would run multiple instance prometheus configured scraping endpoint independently source replica however would also load balancer promql query prometheus api failover primary unresponsive clear work duplicate alert sent alertmanager doesnt feel like paved path prometheus operator saying currently implementing groundwork make possible figuring best approach definitely roadmap jan updated since managed prometheus managed service prometheus amp would address concern evaluated detail next section evaluation managed prometheus managed prometheus amp would outsource operational concern including performance scalability well management custom node group well examine financial cost potentially monitoring outside vpc change architecture adr aim understand issue specifically interested amazon managed service prometheus amp scaling amp scale automatically without configuration high availability amp highly available distributed across multiple automatically contrast question mark selfhosted see resilience amp relatively isolated cluster issue data kept durable storage away cluster lockin configuration syntax interface similar existing selfhosted prometheus maintain low lockin migration cost existing install monitoring namespace configured component terraform calling cloudplatformterraformmonitoring module installs kubeprometheusstack helm chart kubeprometheus among thing kubeprometheus contains number thing prometheus operator add kubernetesnative wrapper managing prometheus crds install prometheus alertmanager grafana thanosruler crds configuring servicemonitor podmonitor probe prometheusrule alertmanagerconfig allows specifying monitoring target kubernetes label kubernetes manifest grafana dashboard prometheus rule example configs nodeexporter scrape target alerting rule cluster issue high availability implemented yet resilience absence resilience offered presence backup node node prometheus instance running fails backup node ready run prometheus instance downtime capped minute backup node spec configuration running access prometheus data httpsgithubcomministryofjusticecloudplatformissuesissue prometheus config held resource servicemonitor prometheusrule alerting would work amp weve spiked terraform module implement httpsgithubcomministryofjusticecloudplatformterraformamp forwarding prometheus instance installed cluster scrape data keep copy remote write forward data amp transfer look pretty robust write ahead log queue forwarding prometheus could simply standard community helm chart httpsprometheuscommunitygithubiohelmcharts simple make upgrade easy dont kubeprometheus doesnt store much enough forward amp todo work link amp break period arrangement prometheus helm chart configures prometheus scrape resource prometheusio annotation however well let user define servicemonitor configs storage throw much data instead day limit day plenty long enough case thanos useful alertmanager amp alertmanagercompatible wed rule sending alert would configure create topic forward user slack channel grafana amazon managed grafana terraform support yet setup aws console meantime stick selfmanaged grafana work fine prometheus web interface previously amp headless come web interface prometheus rule alert existing cluster get prometheus rule httpsgithubcomkubernetesmonitoringkubernetesmixin kubeprometheus compiles json applies cluster new cluster thing new cluster let avoid kubeprometheus copy upgrade prometheus version well manually run jsonnet config generation paste resulting rule terraform module httpsgithubcomministryofjusticecloudplatformterraformampblobmainexamplerulestf still figure tenant rule alert tenant create prometheusrule resource kubectl apply environment repo going get config inserted amp could cronjob copy resource config amp something similar grafana check invalid rule dont get applied cause problem tenant cost look scale cost ingestion sample price ireland euampmetricsamplecount per metric sample next metric sample euampmetricstoragebytehrs per gbmo storage region amp released london region yet time writing however could run another region data ingestion regio free would pay grafana query component check usage related component still new cluster cloudwatch exporter node exporter ecr exporter pushgateway showing alert show user alert config firing currently alertmanagers web interface well equivalent maybe could run alertmanager purely purpose rely amp alertmanager actually sending would show inactive might expose difference functionality maybe give user readonly access console team workspace service could offer user prometheus workspace full monitoring stack fully control terraform module run maybe better everyone centralized one specialized user comparison