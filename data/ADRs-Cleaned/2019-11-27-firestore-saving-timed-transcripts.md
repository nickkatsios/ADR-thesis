saving word level transcript firebase progress deciders eimi pietro technical story description ticketissue url problem statement development application work transcription audio video interview could range minute hour length depending production requirement save word level timed text transcription firebase firestore domain generally component bbcreacttranscripteditor way manipulate timed text seen min worth timed text transcription json see referred dpe json format roughly roughly word minute conservative could also pushed minute think limit least aim around mark generally data structure transcription quite efficient comparing hour worth transcription gcp stt dpe json gcp stt easily equivalent dpe data format example see soleio interiview example dpe demo click export btn arrow top right choose last digital paper edit json transcription paragraph speaker interpolated client data structure referred dpe json json word start end text hello paragraph start end speaker tbc problem problem balancing technical limitation cost want take advantage firestore limit uploads per document challenge balancing number operation monetary cost engineering effort instance following limit freetier firestore gib stored gib chat message byte per chat message document writes writes number time data written document read read number time data read document deletes deletes number time data deleted firebase storage stored highres photo per photo transferred highres photo per photo operation uploads downloads ops uploads downloads cloud function invocation invocation number time function invoked gbseconds gbseconds time memory provisioned cpuseconds cpuseconds time ghz cpu provisioned networking egress outbound data transfer driver easy reason around keeping cost firestore document size limit firestore read document charged individually ideally solution scale storing hour worth transcription without breaking sweat needed paragraph word attribute could saved separate collectionsdocuments considered break data firestore paginated every min break data firestore paginated every paragraph break data firestore every word document saving json file firebase cloud storage storing location path firestore compression bson binary json compression jsonc gzip compression ubjson universal binary json convert collection tsv document compression gzip zlib outcome tbc pro con break data firestore paginated every min data could paginated firestore could collection word every number word roughly every word object corresponding min worth word object could split new document word fragment mean one hour instance would split collection document two hour would split collection document saving could splitted document retrieving could combined back one data structure show cost extra read per transcription would outrageous firebase http callable function could save retrieve firestore fragmenting aggregating cloud function way perform crud operation would also incur extra cost cloud function also double check would introduce considerable delay user experience function might boot performing operation good cost read would increase smaller increment based length content good easy cost estimation bad introduces cost calling firebase cloud function perform operation break data firestore paginated every paragraph alternative could also group word paragraph however correcting paragraph client might change get rearranged might lot value saving back firestore might easier override everything diff change good easy reason around bad could get expensive would increase number read bad could get expensive would increase number writes bad paragraph breakdown subject change break data firestore every word document alternative could also save word document collection word thing could done paragraph however could get expensive read whole document wed fetch word etc wed get charge every read even minute transcript word could incur substantial cost good easy reason around bad could get expensive would increase number read saving json firebase cloud storage another firestore trigger andor http callable function save dpe json format cloud storage would size limit would able take advantage firebase functionality data current client saving timed transcript whole payload returned currently save intermediate result whats latest change might change get optimised future also want solution work look ahead refactor optimization good file size limit cloud storage enough bad introduces cost calling firebase cloud function perform operation bad might introduce delay compression bson another compress json jsbson consider hour dpe format reference gcp stt json format bson compressed data structure example dpe json paragraph word could separated word compressed paragraph dpe json jsonb compression average save size occasion increased size would testing documentation official faq bson may happen frequently comparison information see hard know compression would reliable consistent good around hour worth transcript could get bad lot testing compression jsonc github jsonc npm jsonc careful method really impressive json big amount data could awful compress json object small amount data could increase final size article coderwall compress json data const requirefs const jsonc requirejsonc const gcpsttresponsejson requirecreatejson const gcptodpe requiregcptodpe const gcptranscript gcpsttresponsejsonresponse const dpetranscript gcptodpegcptranscript fswritefilesyncdpejson jsonstringifydpetranscript null const compressedjson jsoncparsedpetranscript fswritefilesyncjsonccompressedjson compressedjson got error return result insidecomment stripjsonstringsliceoffset jsonstringsliceoffset typeerror jsonstringslice function bad wasnt able try libary compression binary ubjson ubjson firestore support binary data json could compressed binary trying const requirefs const ubjson requireshelacekubjson const gcptodpe requiregcptodpe const gcpsttresponsejson requirecreatejson const gcptranscript gcpsttresponsejsonresponse const dpetranscript gcptodpegcptranscript const buffer ubjsonencode dpetranscript ubjson fswritefilesyncubjson buffer got error rangeerror maximum call stack size exceeded bad wasnt able try libary convert collection tsv document stated firebase doc within could hold whole book soruce needed generally whole book plain text moby dick project gutenberg roughly word word minute word minute roughly hour math failing word like json word start end text start end text start end text hear start end text could converted one string document collection text starttime endtimettext starttime endtimet tyou thear tit alternatevely proper tsv texttstarttimetendtime texttstarttimetendtime cantnyouttn generally break say new record tab differentiate value instead space see tsv lib parse back list word object could collection document type text string first one text cantyoutheartitt document start timecodes ttt last least document end timecodes ttt quick example code separate text start end time const dpejson requiredpejson const text dpejsonwords mapword return wordtext joint consolelogtext const starttime dpejsonwords mapword return wordstart joint consolelogstarttime const endtime dpejsonwords mapword return wordend joint consolelogendtime end time start time text combined const dpejson requiredpejson consolelogdpejson const text dpejsonwords mapword return wordtexttwordstarttwordend joint consolelogtext example output space tab scrape ematic lee think like journalism organization json tsv quick example reassambly tsv json const requirefs const texttsv fsreadfilesyncdpetexttsvtostring const starttimetsv fsreadfilesyncdpestarttimetsvtostring const endtimetimetsv fsreadfilesyncdpestarttimetsvtostring const starttimelist starttimetsvsplitt const endtimelist endtimetimetsvsplitt const word texttsvsplittmapwordtext index return text wordtext start starttimelistindex end endtimelistindex const result word consolelogresult paragraph would get saved similar way speaker attribute instead text attribute separate collection conversion could done either client cloud function good save lot space bad serializing deserialising could introuce error data compression gzip gzip zlib module zip unzip entire json see implementation gzip give compression rate entire json without extraction word simpler might good enough assuming longest video might hour long transcript size size compression itll result limit tldr gzip give good balance simplicity compression good save lot space good dont extra library nodejs good pretty fast bad serializing deserializing data would additional step debug there error