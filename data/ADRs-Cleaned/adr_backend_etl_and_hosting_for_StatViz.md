adr etl backend dseex project statviz deadline author pylipp haguesto first made still iterating part adr dsee project titled statviz goal construct data visualization derived boxtributes data allow user showcase contribution impact public various medium website newsletter currently data meant visualization planned served public graphql endpoint implemented stack mysql peewee flask ariadne problem statement committed implementing visualization several question related data extraction transformation loading etl hosting caching addressed hosting host public backend statviz project interfere performance boxtribute app data structure transformation existing data structure compatibility assessment efficiently extract necessary data proposed visualization present structure modify extend data schema suggested additional data structure data written transformation needed data format ensure consistency seamless integration backend frontend must define standard format returning data format look like driver noninterference boxtributes performance solution adopt compromise responsiveness efficiency main boxtribute application security private data accessible public want introduce new security risk keep simple let try add complexity codebase especially low maintenance sake cost efficiency implementing etl process serving data done minimal additional financial impact server response latency time take server respond requested data minimized ensure seamless user experience manageable data size size returned data optimized frontend application perform operation like dynamic filtering sorting without performance degradation utilization existing data target already leveraging data already present boxtribute scalability amount data likely analyze scaling linearly implement solution refactor six month data freshness isnt requirement realtime data oneday lag data freshness acceptable might open opportunity batch processing scheduled update minimize server request aim reduce number request made server ensure efficient data retrieval reduce server strain considered data format olap cube star schema inspiration come architecture data warehouse especially olap cube provide insight data analysis intend standardize return data star schema facilitate creation reusable component sample structure returned graphql query dataqueryforvisualization fact dimid dimid fact dimension dim name dim determining visualization dimension hard part determine best set returned dimension visualization general differentiate dimension three category basic dimension least returned dimension foundation visualization instance demographic plot requires dimension like gender age user filter user apply filter creation including dimension let frontend dynamically adjust data excluding necessitates backendside data preparation passing graphql query variable url filter filter like organization base visualization target passed dimension graphql query variable nton dimension handling manytomany nton relationship olap cube tricky introduce ambiguity potential double counting fact instance examining beneficiary demographic potential nton relationship tag considered star scheme look like beneficiarydemographics fact gender string age int tagid int count int dimension tag int name string however grouping gender age cause double counting due lost relational information among tag tackle chose nonstandard star scheme since data isnt restricted relational table layout dimension represented array lead beneficiarydemographics fact gender string age int tagids int count int dimension tag name data structure transformation current method tracking change database record like stock people employ single centralized history table design follows create table history int unsigned null autoincrement tablename varchar default null recordid int default null change text userid int unsigned default null varchar default null changedate datetime default null fromint int default null toint int default null fromfloat float default null tofloat float default null instance box transition one warehouse external location history table capture tablename recordid change changedate fromint toint stock box locationid change free shop stock box boxstateid change instock donated data structure efficiently capture transactional data change extracting historical snapshot like warehouse stock particular time complex order figure whether current history table enough started directly transforming operational data boxtribute response incoming graphql request cache transformation create additional datastructure learned see structure history table already allows reproduce old state data data structure compatible respond probably query however come great cost computationheavy part executed pure python see even small sample size latency recreating old state data transactional data history table lead unacceptable latency add cache extend schema optimized sql query make analytical query run faster extending schema especially querying historical snapshot data readintensive transactional history table therefore reduce latency query consider adding data structure schema make querying snapshot easier adding bitemporal shadow table one considered approach add bitemporal table called shadow table certain entity box stock table beneficiariespeople table structure similar boxid location boxstate timelower timeupper box instock box free shop donated infinity pro first attempt actually transformed data history table structure format point transformation process con duplication data data stored shadow table hold data combination stock history table extension history table instead adding new table schema also extend existing history table could done adding column hold information state changed entity transaction currently good idea implement approach since save change different entity stock people different structure history table straightforward way would create table like proposed people stock add column history table reference corresponding state different entity corresponding shadow table update data new structure general following update strategy update change boxtribute app shadow table updated app change happens pro directly implemented app outofmind outofside problem con touch dropapp update change trigger history updated call trigger update shadow table pro easy implement since add trigger con adding business logic layer outofmind outofsight problem batch update request graphql request coming query analytical data update shadow table data since last request pro implementation happen statviz con adding complexity adding batch update process outofmind outofsight problem batch update scheduled time update shadow table recurring interval time nightly con adding complexity adding batch update process adding complexity adding recurring time trigger outofmind outofsight problem live data outofsight outofmind mentioned multiple time refers situation data shadow table derived secondary source aka history table lead problem update shadow table disconnected actual transaction app thus transaction app changed transformation shadow table easily broken live data data visualization close live generate support request user cannot resolve nightly transformation usually implemented multiple primary data source involved case caching another approach reduce latency analytical query cache query result instead extending schema question cache populated similar caching storage database filesystem redis similar cache update strategy full refresh purge cache regularly transform data new incremental update sequentially extend cache data change occurred day pro implementation needed statviz con probably query cache pure sql query sql alone powerful extract transform data especially appropriate indexing table largest table far history table row stock table row considered fairly small production database pro query integrated pure sql previously tested via sql ide similar con advanced sql knowledge required query performance might deteriorate time increasing data size done data format incorporation user filter integrate user filter dimension returned data assume including dimension bloat data size front end cannot handle reloads dynamic filtering user attractive factor done data format handling url filter url filter implemented variable graphql query rather dimension returned data visualization typically embedded via url design mean user wont dynamic control filter value within embedded visualization consequently embedding url filter query variable suffices without burdening system additional dimension offer direct user benefit done data structure way speed certain analysis query see section done rather extend schema cache result query cache storage advanced sql query avoid additional complexity would introduced adjusting software architecture andor database structure extending schema solution creates duplication data complex implement maintain filesystem redis caching would additionally increase complexity probably cost currently work concrete proposal data schema likely additional shadow table stock people interlinking history table done hosting implement readonly replica host public endpoint separate service visualization accessible via public endpoint anticipation embedding public channel there potential rapid increase backend request might peak especially promotional campaign user prevent disruption boxtribute app important driver make visualization accessible boxtribute user public exposure postponed also data privacy concern host public graphql api endpoint distinct google service separate boxtribute backend query analytical data readonly replica postponed security measurement separate public private personal data creation adr also touched ensure personal data data identifies person passed public endpoint separate user statviz user access table people cmsusers data table needed create view table contain personal information irrelevant data transformation update change boxtribute app see even though touch dropapp cleanest solution add complexity probably easiest maintain long run since outofsight outofmind problem since keep historical data parallel two separate place exists potential risk shadow table history becoming unsynchronized discrepancy might arise deleted history entry direct edits action save change history table counteract intend introduce test crosscheck shadow table history table next step data format define rough threshold data size returned monitor data format monitor performance dynamic filtering hosting graphql endpoint hosted service hosting figure readonly replica security implement new user statviz data structure figure transaction tracked incorrectly history table data structure create diagram data structure proposal data transformation estimate work dropapp