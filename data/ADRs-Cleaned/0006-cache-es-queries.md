cache query deciders frederic lepied problem statement handle load multiple connected user api service always elasticsearch request index minmize number request driver simple solution start integrating well existing choice capacity evolve distributed solution needed future considered caching front api service reverse proxy caching inside api service outcome chosen optional authentication scheme would beed difficult manage picked flask caching simple caching memory memoize method cache query time capacity distrubted setup later needed positive consequence siege able simulate user without problem single laptop