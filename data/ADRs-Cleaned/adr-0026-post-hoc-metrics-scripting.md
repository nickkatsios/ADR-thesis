adr posthoc metric scripting adr answered question track metric event raster foundry server doesnt answer track event request elsewhere example total logins user nonevent like storage uploads since wed also like metric third party service ongoing usage data database querying eventual visualization determine strategy either pushing regularly importing event well event webhooks basically there thing posthoc metric since hook send event api whenever something occurs interested strategy seemed like might possible auth logins focused experimentation execute almost arbitrary javascript credential exchange via client credential exchange hook mean could fire request increment login count user part login hook see makebogusrequest hook staging tenant example look like papertrail log evidence work strategy would require api endpoint post metric superuser auth hook auth fired post request endpoint client credential exchange investigation similar integration opportunity third party service ever want track metric would nice strategy would prevent anything sathenalambdastep function vendor lockin would nice perspective someday supporting fully featured local deployment however cant figure get user info auth credential exchange workflow doesnt seem another hook latch onto two problem knowing whether viable future metric wed track certain strategy possible make worth additional investment additionally doesnt help problem thing arent metric shrink space metric well special handling would possible doesnt help special handling scheduled metric event aggregation lambda step function thing good bad first adr however since adr two thing changed make strategy easier accomplish lambda scala layer allows ship smaller jar include raster foundry dependency like datamodel datamodel includes metricevents constrain shape sent database api metric choosing strategy require api endpoint post metric superuser auth unless ship dao lambda function lambda function kick athena query metric want calculate lambda function check whether athena query complete step function organize function execution lambda function parse athena query result metric event ship api nonevent thing arent event choice extending database schema support querying value care add file size attribute uploads calculating usage object check combined size bunch key based database query extending database extension know would necessary adding ingestsizebytes back scene table adding filesize uploads adding column would migration however wed oneoff asynchronous process backfill file size information existing scene uploads additionally since uploads scene come anywhere wed add special handling check fill upload file size scene ingest size file scene stored raster foundry bucket finally consistency also delete object scene upload deletion bucket location since otherwise reported usage number underestimate actual usage finally update database record cleanup unused object since dont well overestimate actual usage complexity example general depends trying maintain consistent state database life going hard probably going miss sometimes thats especially costly measuring usage billing purpose get information general theme know big thing let tell weve consistent enough ingests uploads wont difficult tell look thing owns workflow case either reactive lambda function responding event based bucket filter updating database record accordingly periodic result scheduled rollup operation either case event somewhere since case extending database include information object keep separate table usage information table could look something like sql create type meteredobjecttype enum scene upload create table usagedata meteredobjecttype meteredobjecttype null objectid uuid null objectlocation uri null usageamount bigint null createdat timestamp time zone null want track type usage object storage later easily add usagetype enum member like storage computeseconds etc external event since first isnt possible dont access event theyve occurred elsewhere second since first maybe impossible currently might work metric except logins abandon make robust posthoc aggregator manage nonevent get information cost wrong consistency undercharging someone future really bad outcome regardless direction cost keeping eventual metric mind every interaction external service future high make ease adding two column worth consequence external event well create issue item lambda step function strategy require well also make sure way verify inserting metric information twice consider enforce scaffolding place nonevent well create migration add usagedata table asynchronous job backfill usage data uploads ingested scene stored raster foundry bucket lambda function respond event lambda function increment decrement usage data table depending eventname event