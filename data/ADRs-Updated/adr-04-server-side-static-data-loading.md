# Server-side Static Data Loading

## Context

In order to support performant block-level redistricting for states, we need to be able to quickly perform manipulation operations on state-specific [TopoJSON](https://github.com/topojson/topojson) objects. [ADR-02](https://github.com/PublicMapping/districtbuilder/blob/develop/doc/arch/adr-02-district-data-storage.md) provides the rationale for using TopoJSON and [ADR-03](https://github.com/PublicMapping/districtbuilder/blob/develop/doc/arch/adr-03-static-data-storage.md) describes the client-side approach to storing this data, and this ADR provides the rationale for our approach to storing this data on the server-side.

Our current approach is to keep the TopoJSON files stored in S3, where they are retrieved and loaded into memory when the application starts. While this increases startup time, it allows for rapid access once the files are loaded into memory. However, the size of the TopoJSON object increases with the complexity of the districting geometries. California has a particularly complex geometry and requires approximately 215 MiB of memory. Most states are not this complex but we can use this as an upper bound for memory required per state.

If we calculate our memory requirements based on assuming that each of the 50 states requires at most as much memory as California, we get an upper bound of approximately 215 MiB * 50 = 10.5 GiB. In reality the amount of memory required will be lower but this gives us a worst-case scenario to use as a boundary.

An additional constraint is our timeline. At the time that this ADR was written, we are planning to launch with support for block-level redistricting for all 50 states within 6 weeks. An appropriate solution should be attainable within this timeline.

Considering this upper bound of 10.5 GiB to keep all 50 states loaded into memory, we would need to allocate additional memory in order for the application to continue serving requests. Allocating approximately 12 GiB of memory should be sufficient. Fargate also requires that additional vCPUs be provisioned for higher memory allocations which will add additional cost. Running a task with 2 vCPUs and 12 GiB of RAM would cost us approximately $98.04 per month per task. We are likely to run more than one instance in user-facing environments to enable rolling deployments.

An alternative approach would be to implement an external caching layer using a service like [AWS ElastiCache](https://aws.amazon.com/elasticache/). This approach of using an external shared in-memory data store is a good fit from an architectural perspective, but would require a substantial integration effort from an application perspective. In terms of cost, an `r5.large` instance with 13.07 GiB of RAM would cost an additional $0.216 per hour or approximately $155.52 per month. This would reduce the amount of memory we need to allocate per each application task, though we would still need to maintain our baseline ability to serve the application and compute district manipulation. This may be a desirable long-term solution in situations where we need to be able to scale our ability to serve the application beyond two tasks but it is likely not feasible for our current timeline or worth the additional engineering cost at low scale.

We could also define separate services for individual states as a way to distribute the memory load. This is appealing from an on-going infrastructure cost perspective and would allow us to separate user-facing application services from data processing services, but it introduces a significant amount of architectural complexity, especially with respect to routing requests for a particular state to the appropriate service. It also doesn't solve the memory allocation problem in Fargate, it merely distributes it. This would allow independent scaling for busy tenants or for large amounts of generic application traffic that doesn't tax individual tenants. However, this optimization may be premature without recent production metrics and usage patterns to rely on.

## Decision

Given time constraints and a desire to minimize application development work, we have decided to provision more memory for Fargate to allow keeping TopoJSON objects for all 50 states in memory for each application service instance. We will allocate 12GB of memory per task. We will start by running the minimum number of tasks necessary: two tasks in production to allow for rolling releases and one task in staging to allow for testing prior to a production release.

## Consequences

This approach will couple the application server to the TopoJSON in-memory store. This means that if we need to add more application service instances to handle more web traffic or computations, then we would need to scale the in-memory store as well rather than scaling them independently. Given that we are allocating 12 GiB to each service instance, each additional instance will cost an additional $155.52 per month. This could become expensive during periods of high traffic or usage and may make an external caching service more appealing from a cost perspective.

We may need to account for the data loading process in application health checks. Tasks should not be declared healthy and added to the load balancer rotation until their in-memory cache has warmed for all 50 states. This will likely increase application startup and deployment times. However, given that we intend to run multiple instances of the application task, this primarily impacts time to recovery and deployment time rather than application availability during a deploy.

We should also keep in mind that Fargate currently has an upper limit of 30 GiB of allocated RAM for each task. We aren't likely to run into that in the short-term, but it could become a problem if we introduce a significant amount of additional geographical units that can be processed in DistrictBuilder or offer support for custom units. Services that support geographic units beyond states and districts may merit an alternate approach and should have their memory requirements reevaluated.

An additional factor to be aware of is that at some point we may want to be able to support multiple versions of data for each state. For example, we'll be launching all states using 2010 census data. When 2020 census data becomes available we'll need to load it as well, and then there would be two versions of the data for each state. This would effectively double the amount of memory needed.
