\chapter{ADR Dataset Analysis}
    \section{Analysis Methods}
        For the analysis of the ADRs, and to answer the research questions, several topic modelling techniques and algorithms were used as mentioned in chapter 4. This section presents the two approaches that led to the final results.
        \subsection{TF-IDF and LDA} 
        A fist approach employed Term Frequency-Inverse Document Frequency (TF-IDF) for vectorization of words and Latent Dirichlet Allocation (LDA) to perform the topic modelling. TF-IDF is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents. By applying TF-IDF, each document is converted into a numerical vector, where each element of the vector represents the TF-IDF score of a term, which in extension is essentially the product of TF, the frequency of a a term appearing in a document and IDF, a metric of importance of the term across all documents. After documents have been vectorized, we can apply LDA which is is a generative probabilistic model that assumes documents are mixtures of topics and topics are mixtures of words\cite{LDA_paper}. LDA assumes each document is generated from a fixed number of topics, and each topic is a distribution over a certain fixed vocabulary. The result of this method is a distribution of topics for each ADR, indicating the prevalence of each topic within itself. TF-IDF is used since LDA expects the input in the form of integers and TF-IDF accomplishes just that, along with encoding information about words in the documents. hyper parameter tuning using grid search was performed to obtain the best parameters, namely max features of TF-IDF, the optimal number of LDA components, and lda learning decay. This resulted in four broad topics discovered. The topics were projected in a 2 dimentional space and visualized in \ref{fig:LDA_results}. All algorithms were executed using Python and visualized using the pyLDAvis library. When interpreting topics, the top ten words by frequency in each cluster were used.

        \begin{enumerate}
            \item 34.98 percent of the documents were represented with the following most common words: data, api, user event, service, type, message, request, object, client. This topic is broad and could potentially revolve around decisions about how APIs manage, process, and integrate data. This is topic (a) in figure \ref{fig:LDA_results}.
            
            \item 32.62 percent of the documents were represented with the following most common words: test, component, code, project, library, file, framework, version, package, change. This topic seems to revolves around decisions on the processes, tools, and practices involved in software testing and development. This is topic (b) in figure \ref{fig:LDA_results}.
    
            \item 25.51 percent of the documents were represented with the following most common words: aws, service, environment, docker, cluster, container, image, kubernetes, cloud, deployment. Based on these results this topic is more clear and revolves around decisions about cloud infrastructure containers and container orchestration. This is topic (c) in figure \ref{fig:LDA_results}.
    
            \item 6.89 percent of the documents were represented with the following most common words: record database search architecture adrs architectural markdown elasticsearch index document adr article. This topic is more intertwined and seems to contain ADRs avout the use of ADRs and database decisions. This is topic (d) in figure \ref{fig:LDA_results}.
        \end{enumerate}

        \begin{figure}[hbt!]
            \begin{subfigure}{.475\linewidth}
              \includegraphics[width=\linewidth]{figures/LDA-results/topic1.png}
              \caption{LDA topic 1}
              \label{MLEDdet}
            \end{subfigure}\hfill % <-- "\hfill"
            \begin{subfigure}{.475\linewidth}
              \includegraphics[width=\linewidth]{figures/LDA-results/topic2.png}
              \caption{LDA topic 2}
              \label{energydetPSK}
            \end{subfigure}
            \medskip % create some *vertical* separation between the graphs
            \begin{subfigure}{.475\linewidth}
              \includegraphics[width=\linewidth]{figures/LDA-results/topic3.png}
              \caption{LDA topic 3}
              \label{velcomp}
            \end{subfigure}\hfill % <-- "\hfill"
            \begin{subfigure}{.475\linewidth}
              \includegraphics[width=\linewidth]{figures/LDA-results/topic4.png}
              \caption{LDA topic 4}
              \label{estcomp}
            \end{subfigure}
            \caption{LDA topic results with representative words for each topic}
            \label{fig:LDA_results}
        \end{figure}

        LDA served as the base for some further exploration and optimization of employed techniques. While the initial topics generated were not entirely clear, they highlighted the necessity for finer categorization into more specific topics that LDA alone could not effectively capture, even after tuning with many parameter combinations. This was evident as attempting to increase the number of topics resulted in significant noise and incoherence. To address this, other models were introduced and applied, presented in the following subsection.

    \subsection{BERTopic}
        The second approach utlilized the Python library BERTopic \cite{bertTopic} to analyze the contents of the ADRs. BERTopic uses transformer-based language models and a class-based TF-IDF variation to generate coherent topic representations. The whole procedure and the algorithms used for the final analysis can be broken down to the steps below:

        \begin{enumerate}
            \item Document embeddings are generated using pre-trained models to capture semantic similarities, ensuring that documents with similar topics are close in vector space. In order to produce rich embeddings, the "all-mpnet-base-v2" transformer model \footnote{https://huggingface.co/sentence-transformers/all-mpnet-base-v2} from Hugging-Face was used for its support of longer documents up to sequences of 512 tokens and due to the fact that it was trained on datasets related to software engineering such as CodeSearchNet\footnote{https://huggingface.co/datasets/code-search-net/code\_search\_net}, that contains over 2 million (comment, code) pairs and StackExchange questions.
            
            \item These embeddings are then reduced in dimensionality to make the clustering process more efficient. For this, the UMAP method was used as it "keeps some of a dataset's local and global structure"\footnote{https://maartengr.github.io/BERTopic/algorithm/algorithm.html\#2-dimensionality-reduction} which is important to keep as it contains the information necessary to create clusters of semantically similar documents. This technique introduces randomness into the procedure so a set seed was used to make results reproducible.

            \item Clustering is then performed with the reduced embeddings to separate the documents. For this, HDBSCAN was used. This technique was chosen as it can handle varying densities and can also identify outliers, that do not get assigned to a particular topic. Information of this kind is useful for RQ3. The minimum cluster size hyperparameter, which is the main determinant for the number of  topics the model identifies, was set to 40 or about one percent of total ADRs, as smaller numbers produced very distributed niche topics, that related to specific technologies or tools without providing much information about the context or architecture. A larger minimum cluster size on the other hand, produced incoherent clusters without clear separation.

            \item A bag-of-words representation is then created using all documents in the clusters by counting how often each word appears in each collection. This is important since popular words at the cluster level are needed for the analysis. 

            \item Finally, from the generated bag-of-words representation, TF-IDF is applied again, at a cluster level highlighting important words within a cluster and producing a label. Since we now have a set of representative words for each cluster along with the associated documents a fine-tuning technique was used using OpenAI's model GPT-3.5. Specifically, using a custom prompt, the main set of words for each cluster along with the four documents closest to the center of the cluster were passed as input to the LLM, prompting it to generate characteristic labels for this cluster using natural language. The prompt also contained context of the analysis, stating that the document collection consisted of ADRs, which are part of software engineering.
            
        \end{enumerate}
        
        
    \section{Results and answers to questions}
        The first form of the analysis' results are presented in figure \ref{fig:bertopic_datamap_original}.

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.5]{figures/BerTopic_Original/datamap_original.png}
            \caption{Datamap of documents from BerTopic analysis}
            \label{fig:bertopic_datamap_original}
        \end{figure}
        
        In the graph, documents' embeddings are projected in a two dimensional space with each data point representing one ADR. Clusters of documents are highlighted in different colors and their label is the result of the LLM representation model. 21 topics were identified based on the specified parameters. Around 15 of them are formed in tight clusters with clear semantic separation from the others. Those are mostly located around the edges of the graph. However, in the center of the graph, results are ambiguous and clusters are sparse. It is also important to note that 2575 ADRs, highlighted in grey in the center of the datamap, were not able to be assigned to a specific topic. Taking a closer look at the documents themselves by zooming in figure \ref{fig:docs_original}, the center also appears sparse with many documents that have not been classified. 
        
        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.5]{figures/BerTopic_Original/docs_original.jpeg}
            \caption{Document embedding representation from BerTopic analysis}
            \label{fig:docs_original}
        \end{figure}
        
        However, the model seems to have captured semantic similarities in ADRs that serve a clear purpose, especially in certain areas like infrastructure management as presented in in figure \ref{fig:infra_docs}.

        \begin{figure}[h]
            \centering
            \includegraphics[scale=0.5]{figures/BerTopic_Original/zoomed_docs_infra.jpeg}
            \caption{ADRs related to cloud and infrastructure are located  closer in the embedding space}
            \label{fig:infra_docs}
        \end{figure}
        
        Examining the topics from a different perspective, a similarity matrix can be created to determine how clearly the topics have been separated by the model. This can also provide insights into the quality of the labels derived from the LLM, as conceptually similar topics should have a high similarity score and vise versa. The results are presented in figure \ref{fig:similarity_matrix_orginal}. 

        % TODO: Topic names changed from llm
        % 1) Software arch decisions --> Python development decisions
        % 2) api kati kati --> Frontend Component and Design Decisions
        % 3) data kati -->  Data Storage Decisions
        
        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.5]{figures/BerTopic_Original/heatmap_original.png}
            \caption{ADR topic similarity matrix}
            \label{fig:similarity_matrix_orginal}
        \end{figure}
        
        Following the previous patterns, some topics appear to be clearly separated and others intertwined. For example, decisions about database transaction management and data schema evolution have a high similarity score of 0.7, whereas architectural decisions about containerization and code style formats present a lower score of 0.28. An observation can be made, from the color distribution and scale in the matrix, that many topic pairs, including irrelevant ones, have relatively high similarity, with the lowest being close to 0.2. The lowest score is related to code styling formats topic and the secure HTTP header implementation document cluster while the highest, approaching 0.77 is compares dockerized application architectural decisions with decisions related to kubernetes cluster management. The high correlation, may be attributed to the similarity of the general theme of ADRs, with it being software architecture.

        To enhance the clarity of the results and create larger, more information-rich clusters, outlier reduction was applied to the topics, ensuring that only semantically similar documents were assigned to each cluster following the initial analysis. By utilizing the pre-calculated probabilities of an unlabeled document's likelihood of belonging to a specific cluster, the number of outliers was reduced to 704. The similarity threshold was set at 10 percent, meaning outlier ADRs were included in the nearest topic cluster as long as they shared at least 10 percent similarity. This low similarity threshold was chosen to maximize the number of documents assigned to a topic while isolating true outliers for further examination . The updated topic and document graphs can be seen in figures \ref{fig:similarity_matrix_reduced} and \ref{fig:docs_reduced}. 
        
        \begin{figure}[ht]
            \centering
            \includegraphics[scale=0.4]{figures/BerTopic_Reduced/datamap_reduced_outliers.png}
            \caption{Datamap of documents after outlier reduction}
            \label{fig:datamap_reduced}
        \end{figure}
        
        Topics now cover larger areas in the embedding space and there is more topic coverage in the certer parts of the axes. Topic clusters have been extended to include ADRs with more distance, modifying their initial state. From a visual perspective, clusters do not appear overly altered although outliers have been reduced by 72 percent which indicates promising results. The remaining outliers are also more apparent, indicated in grey data points and will be used for later analysis to determine the reason for their low similarity.

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.4]{figures/BerTopic_Reduced/docs_reduced_outliers.jpeg}
            \caption{Document embedding representation after outlier reduction}
            \label{fig:docs_reduced}
        \end{figure}

        In regards to topic similarity, the newly introduced documents, increased cluster diversity, indicated by the lowered similarity scores across all pairs of topics in figure \ref{fig:similarity_matrix_reduced}. Semantically similar pairs also retained their higher score while irrelevant pair scores were reduced significantly, with the minimum being 0.02 between testing strategy decisions and library code component management,  indicating clearer topic separation. 

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.4]{figures/BerTopic_Reduced/similarity_matrix_reduced_outliers.png}
            \caption{ADR topic similarity matrix with reduced outliers}
            \label{fig:similarity_matrix_reduced}
        \end{figure}

        All research questions were answered using the results after the outlier reduction due to improved clarity. RQ3 also considered only the 704 final outliers as the filtering ensured their high degree of dissimilarity. A complete representation of the defined topics can be found in table \ref{table:topic_table}.
        
        \begin{longtable}{|p{1cm}|p{1.12cm}|p{3.3cm}|p{9cm}|}
            \caption{Merged Topics Analysis} \\
            \hline
            \textbf{Topic} & \textbf{ADR Count} & \textbf{LLM Representation Name} & \textbf{Topic Keywords} \\
            \hline
            \endfirsthead
            
            \hline
            \textbf{Topic} & \textbf{ADR Count} & \textbf{LLM Representation Name} & \textbf{Topic Keywords} \\
            \hline
            \endhead
            
            \hline
            \endfoot
            
            \hline
            \endlastfoot
            
            0 & 770 & Frontend Component and Design Decisions & 'react', 'component', 'typescript', 'npm', 'framework', 'frontend', 'dependency', 'design', 'development', 'angular' \\
            \hline
            1 & 276 & Architecture Decision Records (ADRs) & 'architectural record', 'architecture record', 'documentation', 'changelog', 'example description', 'document', 'architectural' \\
            \hline
            2 & 248 & User Authentication Architecture & 'access control', 'authorization', 'oauth', 'authentication', 'openid', 'organization', 'authenticate', 'access token', 'auth', 'security' \\
            \hline
            3 & 225 & Test Strategy Evolution & 'test suite', 'testing framework', 'unit testing', 'unit test', 'testing', 'acceptance test', 'development', 'test' \\
            \hline
            4 & 345 & Release Process Standardization & 'versioning', 'release note', 'repository', 'pull request', 'git', 'github', 'version', 'github action', 'workflow', 'deployment' \\
            \hline
            5 & 467 & Database Schema Management and Data Migration & 'database', 'schema', 'sql', 'metadata', 'implementation', 'data', 'information', 'structure', 'migration', 'json' \\
            \hline
            6 & 165 & Module Communication Decisions & 'sdk', 'implement', 'protocol', 'module', 'implementation', 'node', 'interface', 'proposal', 'cosmos' \\
            \hline
            7 & 209 & API Documentation Strategy & 'api management', 'apis', 'api', 'openapi', 'schema', 'endpoint', 'json', 'metadata', 'odata', 'specification' \\
            \hline
            8 & 136 & Monitoring and Metric Management & 'cloudwatch', 'monitoring', 'analytics', 'telemetry', 'api', 'logging', 'metric', 'endpoint', 'aws', 'dashboard' \\
            \hline
            9 & 136 & Containerized Application Development & 'docker container', 'dockerfiles', 'docker image', 'dockerhub', 'dockerfile', 'dockercompose', 'kubernetes', 'container registry' \\
            \hline
            10 & 144 & Messaging System Design Approach & 'message bus', 'event sourcing', 'system event', 'device service', 'messagebus', 'event', 'command service', 'api', 'rabbitmq', 'implementation' \\
            \hline
            11 & 118 & Search Indexing Architecture Decision & 'elasticsearch', 'indexing', 'search index', 'search engine', 'lucene', 'solr', 'opensearch', 'new index', 'index', 'documentdb' \\
            \hline
            12 & 74 & Python Development Decisions & 'python version', 'support python', 'python package', 'python path', 'pythonpaths', 'python python', 'pythontuf', 'python paths' \\
            \hline
            13 & 107 & Infrastructure Management Strategy & 'terraform', 'terraform module', 'aws resource', 'cloud platform', 'kubernetes', 'cloudformation', 'aws lambda', 'aws', 'infrastructure code', 'provisioning' \\
            \hline
            14 & 290 & Cloud Infrastructure Management & 'kubernetes', 'cloud platform', 'cluster', 'elasticsearch', 'docker', 'pod', 'aws', 'eks', 'apigroups', 'cloud' \\
            \hline
            15 & 231 & Modular Architecture Decisions & 'implement', 'interface', 'implementation', 'module', 'framework', 'interactor', 'structure', 'dependency', 'constructor', 'architecture' \\
            \hline
            16 & 157 & Cluster and Traffic Management Strategy & 'kubernetes', 'haproxy', 'load balancer', 'aws', 'cloud foundry', 'endpoint', 'nginx', 'balancer', 'paas', 'ingres controller' \\
            \hline
            17 & 214 & Build System Configuration Decisions & 'configuration file', 'maven', 'build tool', 'gradle', 'configuration', 'dependency', 'config', 'kotlin', 'environment variable', 'implementation' \\
            \hline
            18 & 50 & Code Formatting Decision Strategy & 'style eslint', 'typescript', 'eslint prettier', 'eslint', 'stylelint', 'code style', 'enforce code', 'coding style', 'linting code', 'tslint' \\
            \hline
            19 & 63 & Data Management System Optimization & 'atlasdb', 'concurrency', 'lock table', 'cassandra', 'timelock', 'column', 'table', 'metadata', 'operation', 'storage' \\
            \hline
            20 & 196 & Data Storage Decisions & 'postgres', 'azure blob', 'database', 'aws', 'azure', 'blob storage', 'dynamodb', 'storage dedicated', 'storage', 'storage encrypted' \\
            \hline
            21 & 43 & Email Delivery Architecture & 'alert system', 'email service', 'email notification', 'email alert', 'notification type', 'email provider', 'notification', 'alert api', 'mail', 'sending email' \\
            \hline
        \end{longtable}

        
        \subsection{RQ1: What are the most frequently discussed software architecture topics in ADRs?}

        To determine which topics are more prevalent in our dataset, the total number of ADRs per topic were counted and sorted. Then, for each topic, its document count was expressed as a percentage of total ADRs in the data. The results are presented in the bar chart in figure \ref{fig:docs_per_topic_percentage}. We will take a look at some notable ones. At a first glance, topics seem to be evenly distributed. The most frequent topic by a large margin, totaling 14.34 percent of all documents is represented by the title "Front-end Component Architecture", its most frequent keywords are 'react', 'component', 'typescript', 'npm', 'framework', 'frontend', 'dependency', 'design', 'development', 'angular'. This is the large orange cluster in figure \ref{fig:docs_reduced} that contains 770 ADRs. The second most frequent topic is labeled "Data transformation proposal" and its keywords are 'database', 'schema', 'sql', 'metadata', 'implementation', 'data', 'information', 'structure', 'migration', 'json' and seems to describe data related decisions such as storage and database structure. Other interesting topics include the topic labeled "User Authentication Architecture" that brings up security related topics at a 4,61 percent, described by keywords as 'access control', 'authorization','oauth', 'authentication','openid', 'access token','security' and the topic named 'Cloud Infrastructure Management' with 'kubernetes', at a 5.4 percent with 'cloud platform', 'cluster','elasticsearch', 'docker','pod','aws', as dominan words. An ADR topic about architectural decisions and ADR themselves seems to emerge as the 5th most frequent topic containing 5.14 percent of total documents. From its keywords, 'architectural record', 'documentation', 'changelog', 'record architecture', 'document', 'structure' it seems to also revolve around documentation and probably represents some of the first ADRs in each repository that state the need for ADRs and their usage moving forward. From the file cleaning process, at least 35 of those ADRs were identified. Lastly, the least frequent topics are related to email monitoring and notifications and code formatting conventions as indicated by their titles 'Code Formatting Decision Strategy' and 'Email Delivery Architecture' at percentages of 0.8 and 0.93 respectively. 

        \begin{figure}[H]
            \centering
            \includegraphics[scale=0.4]{figures/percentage_topics.png}
            \caption{Documents per topic as a percentage of total documents}
            \label{fig:docs_per_topic_percentage}
        \end{figure}

        % todo: include tree sort 

        \subsection{RQ2: How many topics from the general software architecture space are present in the ADRs? What prominent topics are missing?}

        Before determining which subset of topics from ADRs exist in the software architecture landscape, we must define a set of broad categories that architects have to consider when making design decisions. This is not a trivial task, as many trends, styles and general topics are implicit and documentation about actual architectural practices and decisions is limited.\cite{arch_patterns_in_practice_TOPICS}. In addition, design decisions can also be made to satisfy system attributes. Prominent attributes include availability, usability, performance, security, testability, modifiability and usability which are not topics but more so, systemic qualities that satisfy implied system or business needs \cite{patters+quality_requirements+tactics}. Architectural patterns, on the other hand, refer to a set of pre-defined styles and techniques for solving common reoccurring architectural problems, are more tangible but system-specific. \cite{Patterns+ArchDecisions}. Some popular patterns are Layers, Pipes-Filters, Model View Controller (MVC), Broker and Client–Server and are derived from the component-connector conceptual model \cite{survey_arch_patterns}. These aspects of decisions alone, do not constitute valid categorizations for our analysis as they refer to concepts that are either too implementation-specific or too broad. Combining the two, we get architectural tactics. Architectural tactics "serve as the
        meeting point between the quality attributes and the software architecture" \cite{patters+quality_requirements+tactics}. Tactics are essentially specific measures taken to improve the quality attributes of the system. For example, an architect may decide to incorporate authentication and authorization into a system which in turn enhances security. Or referring to the findings of the previous question, a project may decide to use a specific frontend development framework in order to promote reusability if the framework allows for reusable code components. A comprehensive collection of tactics to satisfy specific system quality attributes, can be found in the Software Architecture in Practice book \cite{software_arch_in_practice_book}. 
        To answer RQ2, each topic identified from the previous question's results was examined and interpreted based on its frequent keywords and LLM representation, aiming to match it with any specific architectural pattern, tactic, or technique that fulfills a particular quality attribute. If the associated quality attributes are not immediately clear, a deeper dive into the topic was necessary, reviewing its representative ADRs, and attempting to identify several potential quality attributes, as we can't conclusively determine the true intents of each ADR author. This is an empirical approximation since many ADRs mentioned the potential adoption of very specific technologies and tools rather than architectural patterns and architectures of system components, which is not ideal when trying to examine architectural styles used. Furthermore, many topics do not provide information about patterns and techniques. The results of the comparison are presented in table \ref{table:topic_tactic}.

        { \small
        \begin{longtable}{|p{3.8cm}|p{3cm}|p{2.2cm}|p{2.1cm}|p{2.8cm}|}
        \caption{Topic Tactic Analysis}
        \label{table:topic_tactic}
        \hline
        \textbf{Topic} & \textbf{Tactic} & \textbf{Pattern} & \textbf{Style} & \textbf{Quality Attribute} \\
        \hline
        \endfirsthead
    
        \hline
        \textbf{Topic} & \textbf{Tactic} & \textbf{Pattern} & \textbf{Style} & \textbf{Quality Attribute} \\
        \hline
        \endhead
        
        \hline
        \endfoot
        
        \hline
        \endlastfoot
        
        Frontend Component and Design Decisions & Modularization & Component-Based & N/A & Reusability, Modifiability \\
        \hline
        Architecture Decision Records (ADRs) & Documentation & N/A & N/A & Maintainability \\
        \hline
        User Authentication Architecture & Authentication and Authorization & N/A & N/A & Security \\
        \hline
        Test Strategy Evolution & Automated Testing & N/A & N/A & Testability, Modifiability \\
        \hline
        Release Process Standardization & Continuous Integration/Continuous Deployment (CI/CD) & N/A & N/A & Maintainability, Reliability \\
        \hline
        Database Schema Management and Data Management System Optimization & Database Normalization, Data Optimization & N/A & Data-Centric & Maintainability, Performance, Efficiency \\
        \hline
        Module Communication Decisions & Asynchronous Messaging & Publish-Subscribe & Event-Driven & Performance, Scalability \\
        \hline
        API Documentation and Design Strategy & API Documentation & RESTful API & REST & Interoperability, Usability \\
        \hline
        Monitoring and Metric Management & Monitoring and Logging & N/A & N/A & Reliability, Maintainability \\
        \hline
        Containerized and Cloud Infrastructure Management & Containerization, Container Orchestration & Microservices & Service-Oriented Architecture (SOA) & Scalability, Availability, Modifiability \\
        \hline
        Messaging System Design Approach & Event-Driven Messaging & Event-Driven & N/A & Performance, Scalability \\
        \hline
        Search Indexing Architecture Decision & Indexing & N/A & N/A & Performance, Efficiency \\
        \hline
        Python Development Decisions & Scripting & N/A & N/A & Maintainability, Flexibility \\
        \hline
        Infrastructure Management Strategy & Infrastructure as Code & N/A & N/A & Scalability, Efficiency \\
        \hline
        Modular Architecture Decisions & Modularization & Modular Architecture & N/A & Modifiability, Reusability \\
        \hline
        Cluster Traffic and Load Management & Load Balancing & N/A & N/A & Performance, Availability \\
        \hline
        Build System Configuration Decisions & Configuration Management & N/A & N/A & Maintainability, Reliability \\
        \hline
        Code Formatting Decision Strategy & Code Quality & N/A & N/A & Maintainability, Readability \\
        \hline
        Data Storage Decisions & Data Storage Management & N/A & N/A & Performance, Data Integrity \\
        \hline
        Email Delivery Architecture & Notification Management & N/A & N/A & Usability, Reliability \\
        \hline
        \end{longtable}
    }
        
        % Sxolia sto telos:
        % Due to small dataset number and cluster number, because if more clusters --> less comprehencisve adrs --> small sample cannot reach conclusion --> we were not able to fing a lot of tactics but a lot where concrete ..... + adrs related to specific technologies confirmed by survey [cite] kanei pio dyskoli ti diadikasia gia patterns

        
        \subsection{RQ3: Are there any outlier topics in the dataset? What are they about and how do they relate to the rest of software architecture topics?}
        
        


        
    \section{Potential Biases in Interpretation}
    Topic modelling is subjective in interpretation ..... 